{"config":{"indexing":"full","lang":["it"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Appunti universitari \u00b6 Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"#appunti-universitari","text":"Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"AlgebraLineare/","text":"","title":"Algebra Lineare"},{"location":"AnalisiI/calcoloDifferenziale/","text":"Massimo, maggiorante ed insieme limitato \u00b6 Massimo di un insieme \u00b6 Massimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice massimo di A se } m \\ge a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Dato un subset A di R non vuoto, un numero m reale si dice massimo dell'insieme A se m >= di a e m \u00e8 in A Quindi ad esempio se A \u00e8 l'intervallo \\(A = [0,1] \\Rightarrow max(A) =1\\) Tuttavia non tutti gli insiemi hanno un massimo: \\(B = [0,1)\\) allora B non ha massimo La dimostrazione \u00e8 abbastanza semplice quando fatta per assurdo: Dimostrazione Preso come esempio l'intervallo B appena citato, possiamo prendere un numero nell'insieme B e chiamarlo m (ad esempio 0.9). Troviamo quindi un \\(\\epsilon=1-m > 0\\) (in questo caso \\(\\epsilon = 0.1\\) ) A questo punto possiamo definire \\(m_1 = m + \\frac \\epsilon 2\\) . Avremo quindi che \\(m < m_1\\) , con \\(m_1 \\in B\\) e quindi \\(m_1\\) dovrebbe essere il massimo. Quindi B non ha massimo. Maggiorante \u00b6 Maggiorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice maggiorante di A se \\(k \\ge a \\forall a \\in A\\) . L'insieme di tutti i maggioranti si indica con \\(\\mathcal M_A\\) Un maggiorante deve essere quindi pi\u00f9 grande di tutti gli elementi di A e non \u00e8 detto che appartenga ad A. Quindi, riprendendo l'esempio precedente \\(A=[0,1]\\) , \\(3 \\in \\mathcal M_A\\) , mentre \\(\\frac 1 4\\) non \u00e8 un maggiorante Possiamo quindi fare un paio di osservazioni: Se esiste un maggiorante di A allora ne esistono infiniti: se k \u00e8 un maggiorante di A allora m \u00e8 un maggiorante di A \\(\\forall m \\ge k\\) Alcuni insiemi non hanno maggioranti: \\(A = \\mathbb R\\) non ha maggioranti, cos\u00ec come la semiretta \\([4, +\\infty)\\) Insieme superiormente limitato \u00b6 Insieme limitato superiormente Se l'insieme dei maggioranti \u00e8 non vuoto \\(\\mathcal M_A \\ne \\varnothing\\) , l'insieme A si dice limitato superiormente Minimo, minorante ed insieme limitato inferiormente \u00b6 Minimo, minorante ed insieme inferiormente limitato Le stesse definizioni ma opposte si applicano per minimo, minorante e insieme inferiormente limitato Minimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice minimo di A se } m \\le a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Minorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice minorante di A se \\(k \\le a \\forall a \\in A\\) . Insieme limitato inferiormente Se l'insieme dei minoranti \u00e8 non vuoto \\(m_A \\ne \\varnothing\\) , l'insieme A si dice limitato inferiormente Insieme limitato \u00b6 Insieme limitato Dato un insieme \\(A \\subset \\mathbb R, a \\ne \\varnothing\\) se A \u00e8 sia superiormente che inferiormente limitato, allora A si dice limitato Un insieme A \u00e8 quindi limitato se e solo se \\(\\exists h,k \\in \\mathbb R\\) tale che \\(k \\le a \\le h \\quad \\forall a \\in A\\) Quindi i due valori sono estermi all'insieme, limitandolo. L'estremo di una funzione \u00b6 Teorema dell'estremo superiore Dato un sotto insieme di R \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) , superiormente limitato, allora esiste il minimo dell'insieme dei maggioranti. Tale minimo si dice estremo superiore di A e si indica con \\(sup(A)\\) L'estremo superiore \u00e8 quindi il minimo dei maggioranti, ed ogni insieme limitato superioremente ha un estremo superiroe. Possiamo quindi vedere che l'insieme dei maggioranti ha sempre minimo Quindi, ad esempio: \\(A = [0,1) \\Rightarrow \\mathcal M_A = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di A \u00e8 1. \\(B = [0,1] \\Rightarrow \\mathcal M_B = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di B \u00e8 1. Il massimo di un insieme \u00e8 il suo limite superiore Se esiste il massimo di un insime A, allora il massimo di A coincide con l'estremo superiore. un insieme limitato superiormente ha sempre un estremo superiore. Se questo elemento appartiene anche all'insieme \u00e8 anche un massimo: \\(\\exists \\; max(A) \\rightarrow max(A) = sup(A)\\) (Se esiste \\(max(A)\\) allora \\(max(A)=sup(A)\\) ) Insieme non limitato superiormente Se l'insieme A non \u00e8 superiormente limitato, scriviamo \\(sup(A) = + \\infty\\) Verificare che un oggetto \u00e8 un estremo superiore \\(A \\ne \\varnothing\\) superioremente limitato. Allora \\(m = sup(A)\\) se e solo se valgono: \\(a \\le m \\; \\forall a \\in A\\) (che significa che m \u00e8 un maggiorante) \\(\\forall \\epsilon > 0 \\; \\exists \\; \\bar a \\in A\\) tale che \\(\\bar a > m - \\epsilon\\) (spostarsi a sinistra di m c'\u00e8 un elemento a destra di m \\epsilon, non ci sono maggioranti pi\u00f9 piccoli di m; m \u00e8 il pi\u00f9 piccolo dei maggioranti) Un insieme superiormente limitato \u00e8 minore di infinito La scrittura \\(sup(A) < + \\infty\\) singifica che l'estremo superore di A \u00e8 un numero reale, quindi A \u00e8 superiormente limitato. La retta reale estesa \u00b6 Retta reale estesa \\(\\bar{ \\; \\mathbb{R} \\; } = \\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{+\\infty\\}\\) in modo che valga \\(-\\infty \\le m \\le + \\infty \\quad \\forall x \\in \\bar{\\;\\mathbb R\\;}\\) Ergo, se \\(x \\in \\mathbb R\\) (quindi \\(x \\ne +\\infty, x \\ne -\\infty\\) ), allora \\(-\\infty < x < + \\infty\\) Operazionu sulla retta reale estesa \u00b6 Operazioni in \\(\\bar {\\mathbb R}\\) Se \\(x \\ne +\\infty\\) , allora \\(x + (- \\infty) = - \\infty\\) Se \\(x \\ne -\\infty\\) , allora \\(x + (+ \\infty) = + \\infty\\) Se \\(x \\gt 0\\) allora \\(x \\cdot (+ \\infty) = + \\infty\\) e \\(x \\cdot (- \\infty) = - \\infty\\) Se \\(x \\lt 0\\) allora \\(x \\cdot (+ \\infty) = - \\infty\\) e \\(x \\cdot (- \\infty) = + \\infty\\) Operazioni vietate (forme indeterminate) \\((+ \\infty) + (- \\infty)\\) \\(0 \\cdot (+ \\infty)\\) \\(0 \\cdot (- \\infty)\\) Operazioni valide \\(+ \\infty \\cdot + \\infty = + \\infty\\) \\(+ \\infty \\cdot - \\infty = - \\infty\\) \\(- \\infty \\cdot - \\infty = + \\infty\\) Minimi e massimi di insiemi limitati \u00b6 Insiemi limitati hanno minimi o massimi Dato \\(A \\subset \\mathbb Z\\) (interi) se A \u00e8 superiormente limitato, A ha massimo. Se A \u00e8 inferiormente limitato, allora A ha minimo Parte intera Dato \\(x \\in \\mathbb R\\) si dice parte intera di x e si indica con \\([x]\\) il numero \\([x] = max \\{ m \\in \\mathbb Z : m \\le x \\}\\) . Ovvero: se abbiamo x (reale) tra due interi, la parte intera di x \u00e8 il primo intero che si ottiene spostandosi a sinistra. Ad esempio: \\([\\frac {25}{10}] = 2\\) \\([-\\frac {25}{10}] = -3\\) Funzioni limitate \u00b6 Funzione limitata f si dice limitata: superiormente se f(a) (la sua immagine) \u00e8 limitato superiormente inferiormente se f(a) (la sua immagine) \u00e8 limitato inferiormente se \\(f(a)\\) (la sua immagine) \u00e8 limitato Massimo e minimo di una funzione \u00b6 Funzione con massimo \\(f\\) ha massimo se \\(f(A)\\) (la sua immagine) ha massimo. Si dice che \\(M\\) \u00e8 il massimo di \\(f\\) e si scrive \\(M = max(f)\\) se \\(M = max(A)\\) Funzione con minimo \\(f\\) ha minimo se \\(f(A)\\) (la sua immagine) ha minimo. Si dice che m \u00e8 il minimo di \\(f\\) e si scrive \\(m = min(f)\\) se \\(m = min(A)\\) Limiti di una funzione \u00b6 Limiti di una funzione \\(sup(f) = sup(f(A))\\) Se \\(f\\) non \u00e8 limitata superiormente si scrive \\(sup(f) = + \\infty\\) . Lo stesso vale per inf (limite inferiore). Punti di massimo di una funzione \u00b6 Punti di massimo Se \\(f\\) ha massimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = max(f)\\) si dicono punti di massimo. Se \\(f\\) ha minimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = min(f)\\) si dicono punti di minimo. Massimo e punti di massimo Il massimo di \\(f\\) \u00e8 unico; i punti di massimo potrebbero essere molti. Lo stesso vale per il minimo. Nella funzione seno, il massimo \u00e8 \\(max(f) = 1\\) e 0 i punti di massimo sono \\(x_0 = \\frac \\pi 2 + k\\cdot 2 \\pi, k \\in \\mathbb Z\\) Una funzione come \\(f:(0, +\\infty) \\rightarrow \\mathbb R \\quad f(x) = \\frac 1 x\\) non ha n\u00e9 massimo n\u00e9 minimo. La funzione ad infinito tende a 0: Se avesse massimo \\(\\Rightarrow \\exists M\\) tale che \\(f(x) \\le M \\forall x \\in (0, + \\infty)\\) : \\(f(x) > 0 \\forall x \\Rightarrow 0\\) \u00e8 un minorante \\(0=inf(f)\\) (inf = estremo inferiore) 0 \u00e8 quindi l'estremo inferiore di f, ma 0 NON \u00e8 un minimo. Se la funzione avesse minimo, allora dovrebbe essere \\(min(f)=inf(f)=0\\) , quindi dovrebbe esistere un \\(x_0\\) tale che \\(f(x_0)=0\\) cio\u00e8 \\(\\frac 1 {x_0}\\) , che \u00e8 impossibile. \\(f: A \\rightarrow \\mathbb R\\) allora \\(m = sup(f)\\) se e solo se: \\(f(x) \\le m \\forall x \\in A\\) \\(\\forall \\epsilon > 0 \\exists \\bar x \\in S\\) tale che \\(f(\\bar x) > m - \\epsilon\\) Se si abbassa la quota di m si \"taglia\" la funzione Valore assoluto \u00b6 Valore assoluto Dato \\(x \\in \\mathbb R\\) si dice valore assoluto di x e si indica con |x| il numero \\(|x| = max(x,-x)\\) Quindi: \\(x \\le |x|\\) \\(|x| = x\\) se \\(x \\ge 0\\) , \\(|x| = -x\\) se \\(x \\le 0\\) \\(|x| \\ge 0 \\forall x \\in \\mathbb R\\) \\(|x| = 0 \\Leftrightarrow x = 0\\) \\(|x| = |-x|\\) \\(-|x| \\le x \\le |x|\\) \\(|x| \\le M \\Leftrightarrow -M \\le x \\le M\\) ( \\(M \\gt 0\\) ) \\(|x| \\gt M \\Leftrightarrow x \\gt M\\) oppure \\(x \\lt -M\\) Come altre propriet\u00e0 possiamo poi aggiungere: \\(|x| \\le x_0 \\Leftrightarrow -x_0 \\le m \\le x_0\\) \\(|x| \\ge x_0 \\Leftrightarrow x \\le -x_0\\) oppure \\(x \\ge x_0\\) Disuguaglianza triangolare \u00b6 Disuguaglianza triangolare Dati \\(a, b \\in \\mathbb R\\) , risulta che: \\(|a + b| \\le |a| + |b|\\) \\(||a| - |b| | \\le |a-b|\\) Questo discorso vale anche per pi\u00f9 valori: \\(|a + b + c| \\le |a + b + c|\\) \\(|a + b + c| = |(a + b) + c| \\le |a + b| + |c| \\le |a| + |b| + |c|\\) La continuit\u00e0 \u00b6 Funzione continua in un punto \\(A \\subset \\mathbb R, f: A \\rightarrow \\mathbb R, x_0 \\in A\\) . La funzione si dice continua in x_0 se \\(\\forall \\epsilon > 0 \\; \\exists \\; \\delta > 0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)| < \\epsilon\\) Spiegandola un po': \\(|x - x_0| < \\delta \\Leftrightarrow x_0 - \\delta < x < x_0 + \\delta\\) ( \\(x\\) \u00e8 compreso tra \\(x_0 \\pm \\delta\\) ) \\(|f(x) - f(x_0)| < \\epsilon \\Leftrightarrow f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) (la funzione oscilla intorno ad \\(f(x_0)\\) ad un ampiezza massima di \\(\\epsilon\\) ) Se esiste un \\(\\delta\\) nell' \\(epsilon\\) dato, la funzione \u00e8 continua Una funzione \u00e8 sempre continua nei punti isolati La continuit\u00e0 include un concetto di prossimit\u00e0 del punto (al punto dove si considera la continuit\u00e0): se il punto \u00e8 isolato non \u00e8 possibile avvicinarsi al punto, ci si pu\u00f2 solo \"trovare\" nel punto. Esempio di funzione non continua in un punto Data la funzione \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione non \u00e8 continua nel punto \\(x_0 = 0\\) (in cui scegliamo \\(\\epsilon = \\frac 1 2\\) ): In questa funzione, \\(\\forall \\delta > 0, x \\in (0, \\delta) \\rightarrow f(x) =1\\) La disuguaglianza \\(f(x) < f(0)+\\epsilon\\) \u00e8 falsa: \\(0-\\frac 1 2 < f(x) < 0 + \\frac 1 2\\) : \\(1 < \\frac 1 2 \\Rightarrow f\\) non \u00e8 continua in \\(x_0 = 0\\) Funzione continua in un insieme Dati \\(A \\in \\mathbb R, f: A \\rightarrow \\mathbb R, B \\subset A\\) , Si dice che la funzione \\(f\\) \u00e8 continua in B se \u00e8 continua in ogni punto \\(x_0 \\in B\\) . Se si dice che f \u00e8 continua (senza specificare il sottoinsieme B), significa che f \u00e8 continua in tutti i punti del suo dominio A. Esempio di funzione non continua in un insieme Riprendendo la funzione di prima \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione \u00e8 continua in \\((-\\infty, 0) \\cup (0, + \\infty)\\) Teoremi sulla continuit\u00e0 \u00b6 Teorema sulla permanenza del segno \\(A \\subset \\mathbb R, f:A \\rightarrow \\mathbb R, x_0 \\in A\\) Se f \u00e8 continua in \\(x_0\\) e \\(f(x_0) > 0\\) allora \\(\\exists \\delta > 0\\) tale che se \\(x \\in A\\) e \\(|x -x_0| < \\delta Rightarrow f(x) > 0\\) . Stesso risultato se \\(f(x) < 0\\) Quindi, se una funzione continua assume valore di segno positivo in un punto, allora mantiene lo stesso segno nei punti molto vicini al punto. Dimostrazione Sappiamo che \\(f(x_0) > 0\\) . Scelgo \\(\\epsilon = \\frac {f(x_0)} 2\\) e lo uso nella definizione di continuit\u00e0. Esiste quindi un \\(\\delta >0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)|< \\epsilon\\) Ovvero: \\(f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) Prendendo la prima parte della disuguaglianza, si ottiene che \\(f(x) > f(x_0) - \\epsilon = f(x_0) - \\frac {f(x_0)} 2 \\Rightarrow \\frac {f(x_0)} 2 > 0\\) Essendo il valore lontano da zero, se ci si sposta un po' vicino al punto; Il valore della fuzonone si sposta poco e quindi il segno rimane concorde. Questo discorso vale anche per un valore \\(m \\in \\mathbb R\\) tale che \\(f(x_0) > m\\) In tal caso \\(\\exists \\delta > 0\\) t.c. \\(x \\in A, |x - x_0| < \\delta \\Rightarrow f(x) > m\\) (Questo discorso vale anche con \\(f(x) < m \\Rightarrow f(x) < m\\) ) Teorema sulla combinazione di funzioni continue (somma e prodotto) Se \\(f\\) e \\(g\\) sono continue in \\(x_0\\) allora lo sono anche le funzioni \\(f+g\\) , \\(f \\cdot g\\) e \\(|f|\\) . Se inoltre \\(f(x_0) \\neq 0\\) , allora anche \\(\\frac 1 f\\) \u00e8 continua. \\(\\frac f g\\) \u00e8 continua (se \\(g(x_0) \\ne 0\\) ). \\(\\frac f g = f \\cdot \\frac 1 g\\) \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow B \\subset \\mathbb R\\) . Se \\(f\\) \u00e8 continua in \\(I\\) ed \u00e8 invertibile, allora \\(f^{-1}\\) \u00e8 continua. L'ipotesi che il dominios sia un'intervallo non pu\u00f2 essere omessa. Esempio \\(f:(-\\infty, 1] \\cup (2, +\\infty) \\rightarrow \\mathbb R\\) \\(f(x)= \\begin{cases} x \\quad \\;\\;\\; \\text{ se } x \\le 1 \\\\ x-1 \\text{ se } x > 1 \\end{cases}\\) Alla domanda se la funzione \u00e8 continua, la risposta \u00e8 s\u00ec. Tuttavia la sua inversa \\(f^{-1}: \\mathbb R \\rightarrow (-\\infty, 1] \\cup (2, + \\infty)\\) non \u00e8 continua in \\(x_0\\) . Non \u00e8 continua perch\u00e9 c'\u00e8 una specie di salto in \\(x=1\\) : Se f non \u00e8 definita su un intervallo, potrebbe accadere che la sua funzione inversa non sia continua, anche se la funzione \u00e8 continua. Continuit\u00e0 delle funzioni elementari \u00b6 Le funzioni costanti sono continue \\(f(x) = x\\) \u00e8 continua. Da ci\u00f2 segue che tutti i polinomi sono continui: Un polinomio ( \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_1 \\cdot x + a_0\\) ) ha i coefficienti come numeri reali ( \\(a_0, a_1, ..., a_n \\in \\mathbb R\\) ). Quindi dal teorema su somma e del prodotto so che la funzione \u00e8 continua: Una costante \u00e8 una funzione continua. Una costante (che \u00e8 una funzione continua) per x \u00e8 una funzione continua (perch\u00e9 x \u00e8 una funzione continua) Un monomio \u00e8 una funzione continua, in quanto \\(x^2 = x \\cdot x\\) , ovvero una funzione continua moltiplicata per una funzione continua - Le funzioni razionali sono continue nel loro insieme di definizione. Una funzione razionale \u00e8 un quoziente di polinomi ( \\(f(x) = \\frac {p(x)}{q(x)}\\) dove p e q sono funzioni polinomiali) Definita se \\(q(x) \\ne 0\\) - \\(e^x\\) , \\(sin(x)\\) e \\(cos(x)\\) sono funzioni continue. Quindi anche \\(log(x)\\) , \\(arcsin(x)\\) , \\(arccos(x)\\) saranno continue in quanto inverse. Ma anch e \\(tg(x)\\) (perch\u00e9 \u00e8 quoziente di seno e coseno) e anche \\(arctg(x)\\) Continuit\u00e0 di composizione di funzioni Date le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow \\mathbb R\\) , con \\(x_0 \\in A, y_0=f(x_0) \\in B\\) Se \\(f\\) \u00e8 continua in \\(x_0\\) e \\(g\\) \u00e8 continua in \\(y_0\\) , allora \\(g \\circ f\\) \u00e8 continua in \\(x_0\\) Esempio \\(e^{cos(x)}\\) \u00e8 una funzione continua in quanto composizione di \\(f(x) = cos(x)\\) e \\(g(y) = e^y\\) Il massimo di un insieme \u00e8 il suo limite superiore Se si ha una funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua in \\([a,b]\\) , L'estremo superiore \u00e8 uguale se l'intevallo \u00e8 aperto o chiuso: \\({\\sup _{x \\in (a,b)}} f(x) = \\sup _{x \\in [a,b]} f(x)\\) Vale poi lo stesso per l'estremo inferiore: \\({\\inf _{x \\in (a,b)}} f(x) = \\inf _{x \\in [a,b]} f(x)\\) Teorema degli zeri \u00b6 Teorema degli zeri Data la funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua Se \\(f(a) \\cdot f(b) < 0\\) allora \\(\\exists \\; c \\in (a,b)\\) tale che \\(f(c) =0\\) Fondamentalmente se la moltiplicazione tra i valori che la funzione assume agli estremi dell'intervallo \u00e8 minore di zero (quindi moltiplichiamo un positivo con un negativo), esiste almeno un punto \\(c\\) nell'intervallo \\((a,b)\\) tale \\(f(c) = 0\\) . L'ipotesi di continuit\u00e0 \u00e8 necessaria Teorema dei valori intermedi \u00b6 Teorema dei valori intermedi \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow \\mathbb R\\) continua. Allora \\(f(I)\\) (l'immagine di f) \u00e8 un intervallo. In questo caso, se f assume i valori y_1 e y_2, allora assume anche tutti i valori compresi tra y_1 e y_2. Notare che I deve obbligatoriamente essere un intervallo. Teorema di Weierstrass \u00b6 Teorema di Weierstrass Definita \\(f: [a,b] \\rightarrow \\reals\\) continua, allora f ha massimo e minimo. Quindi dati \\(a,b \\in \\reals\\) (quindi \\(a,b \\ne \\pm \\infty\\) ). L'intervallo [a,b] \u00e8 un intervallo definito limitato (gli estremi non sono pi\u00f9 e meno infinito) e chiuso (ha entrambi gli estremi). Perch\u00e9 \\([a,b]\\) deve essere limitato e chiuso? In una funzione come \\(f: (0,1] \\rightarrow \\reals, f(x) = \\frac 1 x\\) , f \u00e8 continua ma non ha massimo (inoltre \\(\\sup (f) = + \\infty\\) ). Inoltre l'intervallo non \u00e8 chiuso. Prendendo \\(f: \\reals \\rightarrrow \\reals, f(x) = arctg(x)\\) La funzione \u00e8 continua ed \u00e8 sempre compresa tra \\(\\pm \\frac \\pi 2\\) , ma non ha n\u00e9 massimo n\u00e9 minimo. Quindi \\(sup(f) = \\frac \\pi 2\\) e \\(inf(f) = \\frac \\pi 2\\) , ma non sono n\u00e9 massimo n\u00e9 minimo Teorema di Weierstrass generalizzato \u00b6 Teorema di Weierstrass generalizzato Siano \\(a,b \\in \\bar \\reals\\) e \\(f: (a,b) \\to \\reals\\) continua, tale che \\(\\exists \\limit a f(x) = L_1 e \\limit b f(x) = L_2\\) In tal caso: f \u00e8 limitata inferiormente \\(\\Leftrightarrow L_1 \\ne \\min \\land L_2 \\ne \\min\\) f \u00e8 limitata superiormente \\(\\Leftrightarrow L_1 \\ne \\pin \\land L_2 \\ne \\pin\\) f \u00e8 limitata \\(\\Leftrightarrow L_1 \\in \\reals \\land L_2 \\in \\reals\\) f ha minimo \\(\\Leftrightarrow \\exists x_0 \\in (a,b) . f(x_0) \\le min\\{L_1, L_2 \\}\\) f ha massimo \\(\\Leftrightarrow \\exists x_1 \\in (a,b) . f(x_1) \\ge max\\{L_1, L_2 \\}\\) Il teorema vale anche per funzioni da semirette I risultati precedenti valgono anche nel caso \\(a \\in \\reals\\) e \\([a,b) \\to \\reals\\) oppure \\(b \\in \\reals\\) e \\(f:(a,b] \\to \\reals\\) (Ovviamente avendo la funzione f continua) Gli intorni \u00b6 Intorno Dato \\(x_0 \\in \\reals\\) , si dice intorno di \\(x_0\\) un insieme del tipo \\((x_0 - \\epsilon, x_0 + \\epsilon)\\) , dove \\(\\epsilon \\in \\reals, \\epsilon > 0\\) . \\(\\epsilon\\) si dice raggio dell'intorno. L'intorno sono quindi i punti che sono vicini ad x_0 (ovvero che distano da x_0 una quantit\u00e0 strettamente minore di \\(\\epsilon\\) ). Intorno destro e sinistro In insieme del tipo \\([x_0, x_0 + \\epsilon)\\) si dice intorno destro di \\(x_0\\) . In insieme del tipo \\((x_0 - \\epsilon, x_0]\\) si dice intorno sinistro di \\(x_0\\) . Intorni di infinito Se \\(x_0 = + \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((a, + \\infty)\\) dove \\(a \\in \\reals\\) (l'insieme \u00e8 quindi una semiretta). Se \\(x_0 = - \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((- \\infty, a)\\) dove \\(a \\in \\reals\\) . Questo significa che l'insieme vale da qualsiasi punto di \\(\\reals\\) a \\(\\pm \\infty\\) Punti di accumulazione \u00b6 Punto di accumulazione Dato \\(A \\subset \\bar \\reals\\) (ricordando che \\(\\bar \\reals = \\reals \\cup \\{ + \\infty, - \\infty \\}\\) ); \\(x_0\\) si dice punto di accumulazione per l'insieme A se \\(\\forall u\\) intorno di \\(x_0\\) , risulta \\(u \\cap A \\backslash \\{x_0\\} \\ne \\varnothing\\) Questo significa che vicino \\(x_0\\) ci sono altri punti di A oltre a \\(x_0\\) (x potrebbe non appartenere ad A). Sotto un certo punto di vista, i punti di accumulazione sono tutti quei punti che sono parte dell'insieme o gli sono \"appiccicati\" Esempio di punto di accumulazione \\(A = (2,3)\\) I punti di accumulazione di A \\(Acc(A)\\) sono tutti i punti nell'intervallo \\((2,3)\\) : \\((2,3) \\subset Acc(A)\\) , ma lo \u00e8 anche per i punti 2 e 3. Quindi \\(Acc(A) = [2, 3]\\) Ma anche \\(Acc([2,3]) = [2,3]\\) Tenendo a mente il fatto che dal set viene eliminato il punto preso come \"perno\", se andiamo a vedere i punti di accumulazione del set \\([2,3] \\cup \\{5\\}\\) , 5 NON \u00e8 un punto di accumulazione, in quanto, scegliendo un intorno \\(u\\) con \"centro\" 5, rimuovendo poi il punto centrale, abbiamo che \\(I \\cap \\{5\\} \\backslash 5\\) , che quindi \u00e8 uguale a \\(\\varnothing\\) . I punti di accumulazione rimangono quindi quelli nel set \\([2,3]\\) Notare che un punto di accumulazione pu\u00f2 esere anche \\(\\infty\\) : \\(D= (3, + \\infty)\\) \\((3, + \\infty) \\subset Acc(D)\\) Prendendo un intorno \\(u\\) , intorni di \\(+\\infty\\) , abbiamo \\(u = (a, + \\infty)\\) \\(+\\infty\\) rispetta la definizione di punto di accumulazione, ed \u00e8 quindi punto di accumulazione per l'insieme D. L'insieme dei punti di accumulazione per l'insieme D \u00e8 quindi \\([3, +\\infty]\\) (estremi inclusi quindi) Se dovessimo poi prendere un insieme come \\(\\naturals\\) , che \u00e8 composto di elementi discreti, tutti gli elementi risultano essere punti isolati, quindi non ci sono punti di accumulazione, tranne \\(+ \\infty\\) . Quindi \\(Acc(\\naturals ) = \\{+ \\infty \\}\\) Stesso discorso poi vale anche per \\(\\mathbb Z\\) , solo che si aggiunge anche \\(- \\infty\\) all'insieme: \\(Acc(\\mathbb Z) = \\{ + \\infty, - \\infty \\}\\) Punto isolato \u00b6 Punto isolato Un punto \\(x_0 \\in A\\) si dice punto isolato di A se esiste un \\(u\\) intorno di \\(x_0\\) tale che \\(u \\cap A = \\{x_0\\}\\) . Esempio di punto isolato Prendendo l'esempio di prima ( \\(A = [2,3] \\cup \\{5\\}\\) ), 5 \u00e8 punto isolato di A Punto intero \u00b6 Punto interno \\(A \\subset \\reals, x_0 \\in A\\) si dice punto interno ad A se esiste \\(u\\) intorno di \\(x_0\\) tale che \\(u \\subset A\\) L'intorno deve quindi essere totalmente contenuto nell'insieme A Esempio di punto interno In questo esempio, \\(x_0\\) risulta essere un punto interno. Prendendo invece il punto di bordo (quel punto tale che appena mi muovo appena di pi\u00f9 esco dall'insieme) \\(x_1\\) , il suo intorno \"esce\" dall'insieme A. Di conseguenza non \u00e8 un punto interno. Punti di massimo e minimo \u00b6 Punto di massimo e minimo locale \\(A \\subset \\reals, f: A \\rightarrow \\reals\\) Un punto \\(x_0 \\in A\\) si dice punto minimo locale (o relativo) se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(f(x) \\ge f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di minimo locale stretto se \\(f(x) > f(x_0) \\forall x \\in a \\cap A \\backslash \\{x_0\\}\\) . Si dice punto di massimo locale se \\(f(x) \\le f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di massimo locale stretto se \\(f(x) < f(x_0) \\forall x \\in u \\cap A \\backslash \\{x_0\\}\\) . Un punto si dice di massimo o minimo (senza \"locale\", e a volte detto anche \"stretto\") quando si estende l'intorno a tutto il domino. Punto di minimo \u00e8 anche locale Se \\(x_0\\) \u00e8 punto di minimo, allora \u00e8 anche un punto di minimo anche locale.","title":"Calcolo differenziale"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-maggiorante-ed-insieme-limitato","text":"","title":"Massimo, maggiorante ed insieme limitato"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-di-un-insieme","text":"Massimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice massimo di A se } m \\ge a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Dato un subset A di R non vuoto, un numero m reale si dice massimo dell'insieme A se m >= di a e m \u00e8 in A Quindi ad esempio se A \u00e8 l'intervallo \\(A = [0,1] \\Rightarrow max(A) =1\\) Tuttavia non tutti gli insiemi hanno un massimo: \\(B = [0,1)\\) allora B non ha massimo La dimostrazione \u00e8 abbastanza semplice quando fatta per assurdo: Dimostrazione Preso come esempio l'intervallo B appena citato, possiamo prendere un numero nell'insieme B e chiamarlo m (ad esempio 0.9). Troviamo quindi un \\(\\epsilon=1-m > 0\\) (in questo caso \\(\\epsilon = 0.1\\) ) A questo punto possiamo definire \\(m_1 = m + \\frac \\epsilon 2\\) . Avremo quindi che \\(m < m_1\\) , con \\(m_1 \\in B\\) e quindi \\(m_1\\) dovrebbe essere il massimo. Quindi B non ha massimo.","title":"Massimo di un insieme"},{"location":"AnalisiI/calcoloDifferenziale/#maggiorante","text":"Maggiorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice maggiorante di A se \\(k \\ge a \\forall a \\in A\\) . L'insieme di tutti i maggioranti si indica con \\(\\mathcal M_A\\) Un maggiorante deve essere quindi pi\u00f9 grande di tutti gli elementi di A e non \u00e8 detto che appartenga ad A. Quindi, riprendendo l'esempio precedente \\(A=[0,1]\\) , \\(3 \\in \\mathcal M_A\\) , mentre \\(\\frac 1 4\\) non \u00e8 un maggiorante Possiamo quindi fare un paio di osservazioni: Se esiste un maggiorante di A allora ne esistono infiniti: se k \u00e8 un maggiorante di A allora m \u00e8 un maggiorante di A \\(\\forall m \\ge k\\) Alcuni insiemi non hanno maggioranti: \\(A = \\mathbb R\\) non ha maggioranti, cos\u00ec come la semiretta \\([4, +\\infty)\\)","title":"Maggiorante"},{"location":"AnalisiI/calcoloDifferenziale/#insieme-superiormente-limitato","text":"Insieme limitato superiormente Se l'insieme dei maggioranti \u00e8 non vuoto \\(\\mathcal M_A \\ne \\varnothing\\) , l'insieme A si dice limitato superiormente","title":"Insieme superiormente limitato"},{"location":"AnalisiI/calcoloDifferenziale/#minimo-minorante-ed-insieme-limitato-inferiormente","text":"Minimo, minorante ed insieme inferiormente limitato Le stesse definizioni ma opposte si applicano per minimo, minorante e insieme inferiormente limitato Minimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice minimo di A se } m \\le a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Minorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice minorante di A se \\(k \\le a \\forall a \\in A\\) . Insieme limitato inferiormente Se l'insieme dei minoranti \u00e8 non vuoto \\(m_A \\ne \\varnothing\\) , l'insieme A si dice limitato inferiormente","title":"Minimo, minorante ed insieme limitato inferiormente"},{"location":"AnalisiI/calcoloDifferenziale/#insieme-limitato","text":"Insieme limitato Dato un insieme \\(A \\subset \\mathbb R, a \\ne \\varnothing\\) se A \u00e8 sia superiormente che inferiormente limitato, allora A si dice limitato Un insieme A \u00e8 quindi limitato se e solo se \\(\\exists h,k \\in \\mathbb R\\) tale che \\(k \\le a \\le h \\quad \\forall a \\in A\\) Quindi i due valori sono estermi all'insieme, limitandolo.","title":"Insieme limitato"},{"location":"AnalisiI/calcoloDifferenziale/#lestremo-di-una-funzione","text":"Teorema dell'estremo superiore Dato un sotto insieme di R \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) , superiormente limitato, allora esiste il minimo dell'insieme dei maggioranti. Tale minimo si dice estremo superiore di A e si indica con \\(sup(A)\\) L'estremo superiore \u00e8 quindi il minimo dei maggioranti, ed ogni insieme limitato superioremente ha un estremo superiroe. Possiamo quindi vedere che l'insieme dei maggioranti ha sempre minimo Quindi, ad esempio: \\(A = [0,1) \\Rightarrow \\mathcal M_A = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di A \u00e8 1. \\(B = [0,1] \\Rightarrow \\mathcal M_B = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di B \u00e8 1. Il massimo di un insieme \u00e8 il suo limite superiore Se esiste il massimo di un insime A, allora il massimo di A coincide con l'estremo superiore. un insieme limitato superiormente ha sempre un estremo superiore. Se questo elemento appartiene anche all'insieme \u00e8 anche un massimo: \\(\\exists \\; max(A) \\rightarrow max(A) = sup(A)\\) (Se esiste \\(max(A)\\) allora \\(max(A)=sup(A)\\) ) Insieme non limitato superiormente Se l'insieme A non \u00e8 superiormente limitato, scriviamo \\(sup(A) = + \\infty\\) Verificare che un oggetto \u00e8 un estremo superiore \\(A \\ne \\varnothing\\) superioremente limitato. Allora \\(m = sup(A)\\) se e solo se valgono: \\(a \\le m \\; \\forall a \\in A\\) (che significa che m \u00e8 un maggiorante) \\(\\forall \\epsilon > 0 \\; \\exists \\; \\bar a \\in A\\) tale che \\(\\bar a > m - \\epsilon\\) (spostarsi a sinistra di m c'\u00e8 un elemento a destra di m \\epsilon, non ci sono maggioranti pi\u00f9 piccoli di m; m \u00e8 il pi\u00f9 piccolo dei maggioranti) Un insieme superiormente limitato \u00e8 minore di infinito La scrittura \\(sup(A) < + \\infty\\) singifica che l'estremo superore di A \u00e8 un numero reale, quindi A \u00e8 superiormente limitato.","title":"L'estremo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#la-retta-reale-estesa","text":"Retta reale estesa \\(\\bar{ \\; \\mathbb{R} \\; } = \\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{+\\infty\\}\\) in modo che valga \\(-\\infty \\le m \\le + \\infty \\quad \\forall x \\in \\bar{\\;\\mathbb R\\;}\\) Ergo, se \\(x \\in \\mathbb R\\) (quindi \\(x \\ne +\\infty, x \\ne -\\infty\\) ), allora \\(-\\infty < x < + \\infty\\)","title":"La retta reale estesa"},{"location":"AnalisiI/calcoloDifferenziale/#operazionu-sulla-retta-reale-estesa","text":"Operazioni in \\(\\bar {\\mathbb R}\\) Se \\(x \\ne +\\infty\\) , allora \\(x + (- \\infty) = - \\infty\\) Se \\(x \\ne -\\infty\\) , allora \\(x + (+ \\infty) = + \\infty\\) Se \\(x \\gt 0\\) allora \\(x \\cdot (+ \\infty) = + \\infty\\) e \\(x \\cdot (- \\infty) = - \\infty\\) Se \\(x \\lt 0\\) allora \\(x \\cdot (+ \\infty) = - \\infty\\) e \\(x \\cdot (- \\infty) = + \\infty\\) Operazioni vietate (forme indeterminate) \\((+ \\infty) + (- \\infty)\\) \\(0 \\cdot (+ \\infty)\\) \\(0 \\cdot (- \\infty)\\) Operazioni valide \\(+ \\infty \\cdot + \\infty = + \\infty\\) \\(+ \\infty \\cdot - \\infty = - \\infty\\) \\(- \\infty \\cdot - \\infty = + \\infty\\)","title":"Operazionu sulla retta reale estesa"},{"location":"AnalisiI/calcoloDifferenziale/#minimi-e-massimi-di-insiemi-limitati","text":"Insiemi limitati hanno minimi o massimi Dato \\(A \\subset \\mathbb Z\\) (interi) se A \u00e8 superiormente limitato, A ha massimo. Se A \u00e8 inferiormente limitato, allora A ha minimo Parte intera Dato \\(x \\in \\mathbb R\\) si dice parte intera di x e si indica con \\([x]\\) il numero \\([x] = max \\{ m \\in \\mathbb Z : m \\le x \\}\\) . Ovvero: se abbiamo x (reale) tra due interi, la parte intera di x \u00e8 il primo intero che si ottiene spostandosi a sinistra. Ad esempio: \\([\\frac {25}{10}] = 2\\) \\([-\\frac {25}{10}] = -3\\)","title":"Minimi e massimi di insiemi limitati"},{"location":"AnalisiI/calcoloDifferenziale/#funzioni-limitate","text":"Funzione limitata f si dice limitata: superiormente se f(a) (la sua immagine) \u00e8 limitato superiormente inferiormente se f(a) (la sua immagine) \u00e8 limitato inferiormente se \\(f(a)\\) (la sua immagine) \u00e8 limitato","title":"Funzioni limitate"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-e-minimo-di-una-funzione","text":"Funzione con massimo \\(f\\) ha massimo se \\(f(A)\\) (la sua immagine) ha massimo. Si dice che \\(M\\) \u00e8 il massimo di \\(f\\) e si scrive \\(M = max(f)\\) se \\(M = max(A)\\) Funzione con minimo \\(f\\) ha minimo se \\(f(A)\\) (la sua immagine) ha minimo. Si dice che m \u00e8 il minimo di \\(f\\) e si scrive \\(m = min(f)\\) se \\(m = min(A)\\)","title":"Massimo e minimo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#limiti-di-una-funzione","text":"Limiti di una funzione \\(sup(f) = sup(f(A))\\) Se \\(f\\) non \u00e8 limitata superiormente si scrive \\(sup(f) = + \\infty\\) . Lo stesso vale per inf (limite inferiore).","title":"Limiti di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-massimo-di-una-funzione","text":"Punti di massimo Se \\(f\\) ha massimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = max(f)\\) si dicono punti di massimo. Se \\(f\\) ha minimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = min(f)\\) si dicono punti di minimo. Massimo e punti di massimo Il massimo di \\(f\\) \u00e8 unico; i punti di massimo potrebbero essere molti. Lo stesso vale per il minimo. Nella funzione seno, il massimo \u00e8 \\(max(f) = 1\\) e 0 i punti di massimo sono \\(x_0 = \\frac \\pi 2 + k\\cdot 2 \\pi, k \\in \\mathbb Z\\) Una funzione come \\(f:(0, +\\infty) \\rightarrow \\mathbb R \\quad f(x) = \\frac 1 x\\) non ha n\u00e9 massimo n\u00e9 minimo. La funzione ad infinito tende a 0: Se avesse massimo \\(\\Rightarrow \\exists M\\) tale che \\(f(x) \\le M \\forall x \\in (0, + \\infty)\\) : \\(f(x) > 0 \\forall x \\Rightarrow 0\\) \u00e8 un minorante \\(0=inf(f)\\) (inf = estremo inferiore) 0 \u00e8 quindi l'estremo inferiore di f, ma 0 NON \u00e8 un minimo. Se la funzione avesse minimo, allora dovrebbe essere \\(min(f)=inf(f)=0\\) , quindi dovrebbe esistere un \\(x_0\\) tale che \\(f(x_0)=0\\) cio\u00e8 \\(\\frac 1 {x_0}\\) , che \u00e8 impossibile. \\(f: A \\rightarrow \\mathbb R\\) allora \\(m = sup(f)\\) se e solo se: \\(f(x) \\le m \\forall x \\in A\\) \\(\\forall \\epsilon > 0 \\exists \\bar x \\in S\\) tale che \\(f(\\bar x) > m - \\epsilon\\) Se si abbassa la quota di m si \"taglia\" la funzione","title":"Punti di massimo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#valore-assoluto","text":"Valore assoluto Dato \\(x \\in \\mathbb R\\) si dice valore assoluto di x e si indica con |x| il numero \\(|x| = max(x,-x)\\) Quindi: \\(x \\le |x|\\) \\(|x| = x\\) se \\(x \\ge 0\\) , \\(|x| = -x\\) se \\(x \\le 0\\) \\(|x| \\ge 0 \\forall x \\in \\mathbb R\\) \\(|x| = 0 \\Leftrightarrow x = 0\\) \\(|x| = |-x|\\) \\(-|x| \\le x \\le |x|\\) \\(|x| \\le M \\Leftrightarrow -M \\le x \\le M\\) ( \\(M \\gt 0\\) ) \\(|x| \\gt M \\Leftrightarrow x \\gt M\\) oppure \\(x \\lt -M\\) Come altre propriet\u00e0 possiamo poi aggiungere: \\(|x| \\le x_0 \\Leftrightarrow -x_0 \\le m \\le x_0\\) \\(|x| \\ge x_0 \\Leftrightarrow x \\le -x_0\\) oppure \\(x \\ge x_0\\)","title":"Valore assoluto"},{"location":"AnalisiI/calcoloDifferenziale/#disuguaglianza-triangolare","text":"Disuguaglianza triangolare Dati \\(a, b \\in \\mathbb R\\) , risulta che: \\(|a + b| \\le |a| + |b|\\) \\(||a| - |b| | \\le |a-b|\\) Questo discorso vale anche per pi\u00f9 valori: \\(|a + b + c| \\le |a + b + c|\\) \\(|a + b + c| = |(a + b) + c| \\le |a + b| + |c| \\le |a| + |b| + |c|\\)","title":"Disuguaglianza triangolare"},{"location":"AnalisiI/calcoloDifferenziale/#la-continuita","text":"Funzione continua in un punto \\(A \\subset \\mathbb R, f: A \\rightarrow \\mathbb R, x_0 \\in A\\) . La funzione si dice continua in x_0 se \\(\\forall \\epsilon > 0 \\; \\exists \\; \\delta > 0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)| < \\epsilon\\) Spiegandola un po': \\(|x - x_0| < \\delta \\Leftrightarrow x_0 - \\delta < x < x_0 + \\delta\\) ( \\(x\\) \u00e8 compreso tra \\(x_0 \\pm \\delta\\) ) \\(|f(x) - f(x_0)| < \\epsilon \\Leftrightarrow f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) (la funzione oscilla intorno ad \\(f(x_0)\\) ad un ampiezza massima di \\(\\epsilon\\) ) Se esiste un \\(\\delta\\) nell' \\(epsilon\\) dato, la funzione \u00e8 continua Una funzione \u00e8 sempre continua nei punti isolati La continuit\u00e0 include un concetto di prossimit\u00e0 del punto (al punto dove si considera la continuit\u00e0): se il punto \u00e8 isolato non \u00e8 possibile avvicinarsi al punto, ci si pu\u00f2 solo \"trovare\" nel punto. Esempio di funzione non continua in un punto Data la funzione \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione non \u00e8 continua nel punto \\(x_0 = 0\\) (in cui scegliamo \\(\\epsilon = \\frac 1 2\\) ): In questa funzione, \\(\\forall \\delta > 0, x \\in (0, \\delta) \\rightarrow f(x) =1\\) La disuguaglianza \\(f(x) < f(0)+\\epsilon\\) \u00e8 falsa: \\(0-\\frac 1 2 < f(x) < 0 + \\frac 1 2\\) : \\(1 < \\frac 1 2 \\Rightarrow f\\) non \u00e8 continua in \\(x_0 = 0\\) Funzione continua in un insieme Dati \\(A \\in \\mathbb R, f: A \\rightarrow \\mathbb R, B \\subset A\\) , Si dice che la funzione \\(f\\) \u00e8 continua in B se \u00e8 continua in ogni punto \\(x_0 \\in B\\) . Se si dice che f \u00e8 continua (senza specificare il sottoinsieme B), significa che f \u00e8 continua in tutti i punti del suo dominio A. Esempio di funzione non continua in un insieme Riprendendo la funzione di prima \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione \u00e8 continua in \\((-\\infty, 0) \\cup (0, + \\infty)\\)","title":"La continuit\u00e0"},{"location":"AnalisiI/calcoloDifferenziale/#teoremi-sulla-continuita","text":"Teorema sulla permanenza del segno \\(A \\subset \\mathbb R, f:A \\rightarrow \\mathbb R, x_0 \\in A\\) Se f \u00e8 continua in \\(x_0\\) e \\(f(x_0) > 0\\) allora \\(\\exists \\delta > 0\\) tale che se \\(x \\in A\\) e \\(|x -x_0| < \\delta Rightarrow f(x) > 0\\) . Stesso risultato se \\(f(x) < 0\\) Quindi, se una funzione continua assume valore di segno positivo in un punto, allora mantiene lo stesso segno nei punti molto vicini al punto. Dimostrazione Sappiamo che \\(f(x_0) > 0\\) . Scelgo \\(\\epsilon = \\frac {f(x_0)} 2\\) e lo uso nella definizione di continuit\u00e0. Esiste quindi un \\(\\delta >0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)|< \\epsilon\\) Ovvero: \\(f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) Prendendo la prima parte della disuguaglianza, si ottiene che \\(f(x) > f(x_0) - \\epsilon = f(x_0) - \\frac {f(x_0)} 2 \\Rightarrow \\frac {f(x_0)} 2 > 0\\) Essendo il valore lontano da zero, se ci si sposta un po' vicino al punto; Il valore della fuzonone si sposta poco e quindi il segno rimane concorde. Questo discorso vale anche per un valore \\(m \\in \\mathbb R\\) tale che \\(f(x_0) > m\\) In tal caso \\(\\exists \\delta > 0\\) t.c. \\(x \\in A, |x - x_0| < \\delta \\Rightarrow f(x) > m\\) (Questo discorso vale anche con \\(f(x) < m \\Rightarrow f(x) < m\\) ) Teorema sulla combinazione di funzioni continue (somma e prodotto) Se \\(f\\) e \\(g\\) sono continue in \\(x_0\\) allora lo sono anche le funzioni \\(f+g\\) , \\(f \\cdot g\\) e \\(|f|\\) . Se inoltre \\(f(x_0) \\neq 0\\) , allora anche \\(\\frac 1 f\\) \u00e8 continua. \\(\\frac f g\\) \u00e8 continua (se \\(g(x_0) \\ne 0\\) ). \\(\\frac f g = f \\cdot \\frac 1 g\\) \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow B \\subset \\mathbb R\\) . Se \\(f\\) \u00e8 continua in \\(I\\) ed \u00e8 invertibile, allora \\(f^{-1}\\) \u00e8 continua. L'ipotesi che il dominios sia un'intervallo non pu\u00f2 essere omessa. Esempio \\(f:(-\\infty, 1] \\cup (2, +\\infty) \\rightarrow \\mathbb R\\) \\(f(x)= \\begin{cases} x \\quad \\;\\;\\; \\text{ se } x \\le 1 \\\\ x-1 \\text{ se } x > 1 \\end{cases}\\) Alla domanda se la funzione \u00e8 continua, la risposta \u00e8 s\u00ec. Tuttavia la sua inversa \\(f^{-1}: \\mathbb R \\rightarrow (-\\infty, 1] \\cup (2, + \\infty)\\) non \u00e8 continua in \\(x_0\\) . Non \u00e8 continua perch\u00e9 c'\u00e8 una specie di salto in \\(x=1\\) : Se f non \u00e8 definita su un intervallo, potrebbe accadere che la sua funzione inversa non sia continua, anche se la funzione \u00e8 continua.","title":"Teoremi sulla continuit\u00e0"},{"location":"AnalisiI/calcoloDifferenziale/#continuita-delle-funzioni-elementari","text":"Le funzioni costanti sono continue \\(f(x) = x\\) \u00e8 continua. Da ci\u00f2 segue che tutti i polinomi sono continui: Un polinomio ( \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_1 \\cdot x + a_0\\) ) ha i coefficienti come numeri reali ( \\(a_0, a_1, ..., a_n \\in \\mathbb R\\) ). Quindi dal teorema su somma e del prodotto so che la funzione \u00e8 continua: Una costante \u00e8 una funzione continua. Una costante (che \u00e8 una funzione continua) per x \u00e8 una funzione continua (perch\u00e9 x \u00e8 una funzione continua) Un monomio \u00e8 una funzione continua, in quanto \\(x^2 = x \\cdot x\\) , ovvero una funzione continua moltiplicata per una funzione continua - Le funzioni razionali sono continue nel loro insieme di definizione. Una funzione razionale \u00e8 un quoziente di polinomi ( \\(f(x) = \\frac {p(x)}{q(x)}\\) dove p e q sono funzioni polinomiali) Definita se \\(q(x) \\ne 0\\) - \\(e^x\\) , \\(sin(x)\\) e \\(cos(x)\\) sono funzioni continue. Quindi anche \\(log(x)\\) , \\(arcsin(x)\\) , \\(arccos(x)\\) saranno continue in quanto inverse. Ma anch e \\(tg(x)\\) (perch\u00e9 \u00e8 quoziente di seno e coseno) e anche \\(arctg(x)\\) Continuit\u00e0 di composizione di funzioni Date le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow \\mathbb R\\) , con \\(x_0 \\in A, y_0=f(x_0) \\in B\\) Se \\(f\\) \u00e8 continua in \\(x_0\\) e \\(g\\) \u00e8 continua in \\(y_0\\) , allora \\(g \\circ f\\) \u00e8 continua in \\(x_0\\) Esempio \\(e^{cos(x)}\\) \u00e8 una funzione continua in quanto composizione di \\(f(x) = cos(x)\\) e \\(g(y) = e^y\\) Il massimo di un insieme \u00e8 il suo limite superiore Se si ha una funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua in \\([a,b]\\) , L'estremo superiore \u00e8 uguale se l'intevallo \u00e8 aperto o chiuso: \\({\\sup _{x \\in (a,b)}} f(x) = \\sup _{x \\in [a,b]} f(x)\\) Vale poi lo stesso per l'estremo inferiore: \\({\\inf _{x \\in (a,b)}} f(x) = \\inf _{x \\in [a,b]} f(x)\\)","title":"Continuit\u00e0 delle funzioni elementari"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-degli-zeri","text":"Teorema degli zeri Data la funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua Se \\(f(a) \\cdot f(b) < 0\\) allora \\(\\exists \\; c \\in (a,b)\\) tale che \\(f(c) =0\\) Fondamentalmente se la moltiplicazione tra i valori che la funzione assume agli estremi dell'intervallo \u00e8 minore di zero (quindi moltiplichiamo un positivo con un negativo), esiste almeno un punto \\(c\\) nell'intervallo \\((a,b)\\) tale \\(f(c) = 0\\) . L'ipotesi di continuit\u00e0 \u00e8 necessaria","title":"Teorema degli zeri"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-dei-valori-intermedi","text":"Teorema dei valori intermedi \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow \\mathbb R\\) continua. Allora \\(f(I)\\) (l'immagine di f) \u00e8 un intervallo. In questo caso, se f assume i valori y_1 e y_2, allora assume anche tutti i valori compresi tra y_1 e y_2. Notare che I deve obbligatoriamente essere un intervallo.","title":"Teorema dei valori intermedi"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-di-weierstrass","text":"Teorema di Weierstrass Definita \\(f: [a,b] \\rightarrow \\reals\\) continua, allora f ha massimo e minimo. Quindi dati \\(a,b \\in \\reals\\) (quindi \\(a,b \\ne \\pm \\infty\\) ). L'intervallo [a,b] \u00e8 un intervallo definito limitato (gli estremi non sono pi\u00f9 e meno infinito) e chiuso (ha entrambi gli estremi). Perch\u00e9 \\([a,b]\\) deve essere limitato e chiuso? In una funzione come \\(f: (0,1] \\rightarrow \\reals, f(x) = \\frac 1 x\\) , f \u00e8 continua ma non ha massimo (inoltre \\(\\sup (f) = + \\infty\\) ). Inoltre l'intervallo non \u00e8 chiuso. Prendendo \\(f: \\reals \\rightarrrow \\reals, f(x) = arctg(x)\\) La funzione \u00e8 continua ed \u00e8 sempre compresa tra \\(\\pm \\frac \\pi 2\\) , ma non ha n\u00e9 massimo n\u00e9 minimo. Quindi \\(sup(f) = \\frac \\pi 2\\) e \\(inf(f) = \\frac \\pi 2\\) , ma non sono n\u00e9 massimo n\u00e9 minimo","title":"Teorema di Weierstrass"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-di-weierstrass-generalizzato","text":"Teorema di Weierstrass generalizzato Siano \\(a,b \\in \\bar \\reals\\) e \\(f: (a,b) \\to \\reals\\) continua, tale che \\(\\exists \\limit a f(x) = L_1 e \\limit b f(x) = L_2\\) In tal caso: f \u00e8 limitata inferiormente \\(\\Leftrightarrow L_1 \\ne \\min \\land L_2 \\ne \\min\\) f \u00e8 limitata superiormente \\(\\Leftrightarrow L_1 \\ne \\pin \\land L_2 \\ne \\pin\\) f \u00e8 limitata \\(\\Leftrightarrow L_1 \\in \\reals \\land L_2 \\in \\reals\\) f ha minimo \\(\\Leftrightarrow \\exists x_0 \\in (a,b) . f(x_0) \\le min\\{L_1, L_2 \\}\\) f ha massimo \\(\\Leftrightarrow \\exists x_1 \\in (a,b) . f(x_1) \\ge max\\{L_1, L_2 \\}\\) Il teorema vale anche per funzioni da semirette I risultati precedenti valgono anche nel caso \\(a \\in \\reals\\) e \\([a,b) \\to \\reals\\) oppure \\(b \\in \\reals\\) e \\(f:(a,b] \\to \\reals\\) (Ovviamente avendo la funzione f continua)","title":"Teorema di Weierstrass generalizzato"},{"location":"AnalisiI/calcoloDifferenziale/#gli-intorni","text":"Intorno Dato \\(x_0 \\in \\reals\\) , si dice intorno di \\(x_0\\) un insieme del tipo \\((x_0 - \\epsilon, x_0 + \\epsilon)\\) , dove \\(\\epsilon \\in \\reals, \\epsilon > 0\\) . \\(\\epsilon\\) si dice raggio dell'intorno. L'intorno sono quindi i punti che sono vicini ad x_0 (ovvero che distano da x_0 una quantit\u00e0 strettamente minore di \\(\\epsilon\\) ). Intorno destro e sinistro In insieme del tipo \\([x_0, x_0 + \\epsilon)\\) si dice intorno destro di \\(x_0\\) . In insieme del tipo \\((x_0 - \\epsilon, x_0]\\) si dice intorno sinistro di \\(x_0\\) . Intorni di infinito Se \\(x_0 = + \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((a, + \\infty)\\) dove \\(a \\in \\reals\\) (l'insieme \u00e8 quindi una semiretta). Se \\(x_0 = - \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((- \\infty, a)\\) dove \\(a \\in \\reals\\) . Questo significa che l'insieme vale da qualsiasi punto di \\(\\reals\\) a \\(\\pm \\infty\\)","title":"Gli intorni"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-accumulazione","text":"Punto di accumulazione Dato \\(A \\subset \\bar \\reals\\) (ricordando che \\(\\bar \\reals = \\reals \\cup \\{ + \\infty, - \\infty \\}\\) ); \\(x_0\\) si dice punto di accumulazione per l'insieme A se \\(\\forall u\\) intorno di \\(x_0\\) , risulta \\(u \\cap A \\backslash \\{x_0\\} \\ne \\varnothing\\) Questo significa che vicino \\(x_0\\) ci sono altri punti di A oltre a \\(x_0\\) (x potrebbe non appartenere ad A). Sotto un certo punto di vista, i punti di accumulazione sono tutti quei punti che sono parte dell'insieme o gli sono \"appiccicati\" Esempio di punto di accumulazione \\(A = (2,3)\\) I punti di accumulazione di A \\(Acc(A)\\) sono tutti i punti nell'intervallo \\((2,3)\\) : \\((2,3) \\subset Acc(A)\\) , ma lo \u00e8 anche per i punti 2 e 3. Quindi \\(Acc(A) = [2, 3]\\) Ma anche \\(Acc([2,3]) = [2,3]\\) Tenendo a mente il fatto che dal set viene eliminato il punto preso come \"perno\", se andiamo a vedere i punti di accumulazione del set \\([2,3] \\cup \\{5\\}\\) , 5 NON \u00e8 un punto di accumulazione, in quanto, scegliendo un intorno \\(u\\) con \"centro\" 5, rimuovendo poi il punto centrale, abbiamo che \\(I \\cap \\{5\\} \\backslash 5\\) , che quindi \u00e8 uguale a \\(\\varnothing\\) . I punti di accumulazione rimangono quindi quelli nel set \\([2,3]\\) Notare che un punto di accumulazione pu\u00f2 esere anche \\(\\infty\\) : \\(D= (3, + \\infty)\\) \\((3, + \\infty) \\subset Acc(D)\\) Prendendo un intorno \\(u\\) , intorni di \\(+\\infty\\) , abbiamo \\(u = (a, + \\infty)\\) \\(+\\infty\\) rispetta la definizione di punto di accumulazione, ed \u00e8 quindi punto di accumulazione per l'insieme D. L'insieme dei punti di accumulazione per l'insieme D \u00e8 quindi \\([3, +\\infty]\\) (estremi inclusi quindi) Se dovessimo poi prendere un insieme come \\(\\naturals\\) , che \u00e8 composto di elementi discreti, tutti gli elementi risultano essere punti isolati, quindi non ci sono punti di accumulazione, tranne \\(+ \\infty\\) . Quindi \\(Acc(\\naturals ) = \\{+ \\infty \\}\\) Stesso discorso poi vale anche per \\(\\mathbb Z\\) , solo che si aggiunge anche \\(- \\infty\\) all'insieme: \\(Acc(\\mathbb Z) = \\{ + \\infty, - \\infty \\}\\)","title":"Punti di accumulazione"},{"location":"AnalisiI/calcoloDifferenziale/#punto-isolato","text":"Punto isolato Un punto \\(x_0 \\in A\\) si dice punto isolato di A se esiste un \\(u\\) intorno di \\(x_0\\) tale che \\(u \\cap A = \\{x_0\\}\\) . Esempio di punto isolato Prendendo l'esempio di prima ( \\(A = [2,3] \\cup \\{5\\}\\) ), 5 \u00e8 punto isolato di A","title":"Punto isolato"},{"location":"AnalisiI/calcoloDifferenziale/#punto-intero","text":"Punto interno \\(A \\subset \\reals, x_0 \\in A\\) si dice punto interno ad A se esiste \\(u\\) intorno di \\(x_0\\) tale che \\(u \\subset A\\) L'intorno deve quindi essere totalmente contenuto nell'insieme A Esempio di punto interno In questo esempio, \\(x_0\\) risulta essere un punto interno. Prendendo invece il punto di bordo (quel punto tale che appena mi muovo appena di pi\u00f9 esco dall'insieme) \\(x_1\\) , il suo intorno \"esce\" dall'insieme A. Di conseguenza non \u00e8 un punto interno.","title":"Punto intero"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-massimo-e-minimo","text":"Punto di massimo e minimo locale \\(A \\subset \\reals, f: A \\rightarrow \\reals\\) Un punto \\(x_0 \\in A\\) si dice punto minimo locale (o relativo) se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(f(x) \\ge f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di minimo locale stretto se \\(f(x) > f(x_0) \\forall x \\in a \\cap A \\backslash \\{x_0\\}\\) . Si dice punto di massimo locale se \\(f(x) \\le f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di massimo locale stretto se \\(f(x) < f(x_0) \\forall x \\in u \\cap A \\backslash \\{x_0\\}\\) . Un punto si dice di massimo o minimo (senza \"locale\", e a volte detto anche \"stretto\") quando si estende l'intorno a tutto il domino. Punto di minimo \u00e8 anche locale Se \\(x_0\\) \u00e8 punto di minimo, allora \u00e8 anche un punto di minimo anche locale.","title":"Punti di massimo e minimo"},{"location":"AnalisiI/limiti/","text":"Limite Dato l'insieme \\(A \\subset \\reals\\) , la funzione \\(f: A \\rightarrow \\reals\\) ed \\(x_0\\) punto di accumulazione per A, \\(L \\in \\bar \\reals\\) \u00e8 il limite per x che tende a \\(x_0\\) di \\(f(x)\\) (scritto \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) ) se \\(\\forall V\\) intorno di \\(L\\) (ovvero sull'asse delle y) esiste \\(u\\) intorno di \\(x_0\\) (il punto sulle x) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\in V\\) Quindi un x nell'intorno di U (e nel dominio della funzione), ma diverso dal punto \\(x_0\\) , \"finisca\" nell'intorno V di L, sull'asse delle y) Questo significa che, dato un punto \\(x_0\\) ed \\(L=f(x_0)\\) , quando mi muovo intorno ad \\(x_0\\) vado a finire in un intorno di L. In tutto ci\u00f2 NON ci interessa quanto vale la funzione nel punto \\(x_0\\) ! Come per la continuit\u00e0, prendiamo un intorno V di L e mi domando se esiste un intorno di \\(x_0\\) tale che la funzione nell'intorno di \\(x_0\\) va a finire nell'intorno di L determinato prima. Detto in un altro modo: \\[ \\lim_{x \\rightarrow a} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists \\delta > 0 . (|x - a| < \\delta \\rightarrow |f(x) - L| < \\epsilon) \\] Il limite pu\u00f2 essere di un punto NON appartenente al dominio, basta sia di accumulazione Nella definizione di limite non serve che \\(x_0\\) sia nel dominio della funzione. Basta che sia un punto di accumulazione per il dominio (ovvero, un punto nel dominio o \" appiccicato \" al dominio). Questa definizione vale quando \\(x_0\\) e \\(L\\) sono nei reali, che quando sono \\(\\pm \\infty\\) Dimostrazione della definizione con \\(x_0\\) ed \\(L\\) \\(\\in \\reals \\cup {\\pm \\infty}\\) \\(x_0 \\in \\reals, \\; L \\in \\reals\\) \\(x_0 \\in \\reals, \\; L = + \\infty\\) \\(x_0 \\rightarrow + \\infty, \\; L \\in \\reals\\) \\(x_0 \\rightarrow + \\infty, \\; L \\in + \\infty\\) L'intorno \\(u\\) di \\(x_0\\) \u00e8 \\(V=(x_0 - \\delta, x_0 + \\delta)\\) come da definizione E, sempre da definzione, \\(V\\) intorno di \\(L\\) (sulle y) \u00e8 \\(V= (L - \\epsilon, L + \\epsilon)\\) Possiamo quindi dire \\(x \\in u\\) (con \\(|x-x_0| < \\delta\\) ) e \\(f(x) \\in V\\) (ovvero \\(f(x_0)-\\epsilon < f(x) < f(x_0) + \\epsilon\\) ) La definizione quindi \u00e8 questa: \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists \\delta > 0 \\; . \\; \\biggr(x \\in A, |x - x_0| < \\delta \\text{ e } x \\ne x_0 \\rightarrow |f(x) - f(x_0)| < \\epsilon \\biggr) \\] Stavolta, \\(V\\) intorno di \\(+ \\infty\\) (sulle y) \u00e8 una semiretta \\(V= (a, + \\infty)\\) Quindi \\(f(x) \\Leftrightarrow f(x) > a\\) (infinito \u00e8 pi\u00f9 grande di ogni numero reale a) \\[ \\lim_{x \\rightarrow x_0} f(x) = + \\infty \\Leftrightarrow \\forall a \\in \\reals \\; \\exists \\delta > 0 \\; . \\; \\biggr(x \\in A, |x - x_0| < \\delta \\text{ e } x \\ne x_0 \\rightarrow f(x) > a \\biggr) \\] Quando la funzione ad infinito ha un numero nei reali, stiamo semplicemente dicendo che c'\u00e8 un valore di x oltre il quale, anche se x assume un valore pi\u00f9 grande a numero reale, \\[ \\lim_{x \\rightarrow + \\infty} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists a \\in \\reals \\; . \\; \\biggr(x > a \\rightarrow |f(x) - L | < \\epsilon \\biggr) \\] \\[ \\lim_{x \\rightarrow + \\infty} f(x) = + \\infty \\Leftrightarrow \\forall a \\in \\reals \\; \\exists b \\in \\reals \\; . \\; \\biggr(x > b \\rightarrow f(x) > a \\biggr) \\] Ovviamente le stesse cose valgono anche con \\(- \\infty\\) Parallelismo con la continuit\u00e0 \u00b6 Il concetto di limite \u00e8 molto simile a quello di continuit\u00e0. La differenza principale \u00e8 che: Nel limite non guardiamo il punto \\(x_0\\) ma il suo intorno. Inoltre consideriamo solo i punti di accumulazione (quindi anche punti esterni al dominio (come 0 con la funzione \\(\\frac 1 x\\) ). Inoltre non consideriamo i punti isolati in quanto non sono di accumulazione) Nella continuit\u00e0 guardiamo il valore \\(x_0\\) ed un suo intorno, considerando ogni punto nel domino (quindi anche i punti isolati) Inoltre nella continuit\u00e0 \\(x_0\\) pu\u00f2 essere uguale ad x, quindi \\(x_0 = x \\Rightarrow f(x) - f(x_0) = 0\\) La definizione di limite e continuit\u00e0 infine possono essere viste compatibili se (oltre al requisito \\(x \\ne x_0\\) ) si scambiano tra di loro L ed \\(x_0\\) Teorema dell'unicit\u00e0 del limite \u00b6 Teorema dell'unicit\u00e0 del limite Se il limite esiste, allora \u00e8 unico. Questo perch\u00e9 dire che una funzione tende ad un valore \\(L_1\\) per x che tende a \\(x_0\\) significa che si avvicina a quel valore quando x si avvicina a \\(x_0\\) , quindi non pu\u00f2 tendere contemporaneamente ad \\(L_2\\) perch\u00e9 non pu\u00f2 avvicinarsi a due valori distinti contemporaneamente. Limiti destri e sinistri \u00b6 Definzione di limite destro e sinistro \\(A \\subset \\reals, x_0 \\in Acc(A), x_0 in \\reals\\) \\(f: A \\rightarrow \\reals\\) , l in \\(\\bar \\reals\\) \u00e8 il limite di f(x) per x che tende a \\(x_0\\) da destra e si scrive \\[ \\lim_{x \\rightarrow x_0^+} f(x) =f \\] Se \\(\\forall V\\) intorno di l esiste \\(\\delta >0\\) tale che \\(x_0 < x < x_0 + \\delta, x \\in A \\Rightarrow f(x) \\in V\\) . Qui si possono notare due cose: Il fatto che x sia diverso da \\(x_0\\) si pu\u00f2 osservare dall'uso del minore stretto (quindi non mi interessa neanche in questo caso quanto vale la funzione del punto) Il motivo per il quale \\(x_0\\) \u00e8 finito (in \\(\\reals\\) ) \u00e8 perch\u00e9 non ha senso avvicinare \\(+\\infty\\) da destra Da sinistra, se \\(x_0 - \\delta < x < x_0, x \\in A \\Rightarrow f(x) \\in V\\) Questo significa che nella definizione di limite, si considerano solo i \" mezzi intorni \" a desta o a sinistra Esempio di limite da destra e da sinistra Prendendo la funone \\(f: (-\\infty, 0) \\cup (0, + \\infty) \\rightarrow \\reals\\) Definita come \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questo caso, il limite per x che tende a 0 da destra di f(x) vale 1 ( \\(\\lim_{x \\rightarrow 0^+} f(x) = 1\\) ) e quello che tende a 0 da sinistra -1 ( \\(\\lim_{x \\rightarrow 0^-} f(x) = -1\\) ). In questo caso non esiste il limite per f(x) che tende a 0, perch\u00e9 il limite che tende a 0 da destra \u00e8 diverso dal limite per x che tende a 0 da sinistra. Il limite esiste solo se i limiti da destra e da sinistra sono uguali \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\lim_{x \\rightarrow x_0^+} f(x) = \\lim_{x \\rightarrow x_0^-} f(x) = L \\] Nella definzione di limite destro si usa solo il \" mezzo intorno \" destro e stessa cosa con quello sinistro. Se vengono messi insieme si ottiene la definizione di limite. Funzione definitivamente positiva e negativa \u00b6 Funzione definitivamente positiva e negativa \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Si dice che \\(\\lim_{x \\rightarrow x_0} f(x) = L^+\\) (con \\(L \\in \\reals\\) ), se: \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) Esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\{x_0\\} \\Rightarrow f(x) > L\\) Ci\u00f2 significa che la funzione \"tende\" al valore ma da 'sopra': La stessa definizione vale per \\(L^-\\) Esempio di limite positivo \\[ f(x) = \\frac 1 x \\qquad \\lim_{x \\rightarrow + \\infty} f(x) = 0^+ \\] Questo perch\u00e9 considerare la funzione vicino \\(+ \\infty\\) , la funzione tende a 0. Scegliendo una semiretta (e quindi un intervallo \\((a, + \\infty)\\) ) come intorno u \\(a > 0 \\Rightarrow f(x) > 0\\) (in questo caso 0=l), e quindi possiamo dire che la funzione \u00e8 definitivamente positiva In questo caso a noi interessa che la funzione sia positiva in un intorno del punto di cui calcoliamo il limite Teorema della permanenza del segno \u00b6 Teorema della permanenza del segno \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Se esisiste \\(\\lim_{x \\rightarrow x_0} f(x) = L \\in \\bar \\reals\\) e \\(L \\ne 0\\) allora esiste un intorno u di \\(x_0\\) tale che se \\(x \\in A \\cap u \\{x_0\\}\\) allora f ha lo stesso segno di L. [44:00] Continuit\u00e0 di una funzione a destra o sinistra \u00b6 Funzione continua a destra o sinistra Dato \\(A \\subset \\reals, x+0 in A, x_0 \\in Acc(A)\\) Se \\(\\lim_{x \\rightarrow x_{0^+}} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a destra in \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_{0^0-} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a sinistra in \\(x_0\\) . Funzione continua a destra o sinistra Riprendendo l'esempio della funzione vista prima e modificandola appena, di d\u00e0 la seguente funzione: \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questa funzione, il limite per x che tende a \\(0^+\\) vale quanto la funzione a 0. Quando la funzine presenta questo comportamento, viene detta funzione continua a destra. Ovviamente lo stesso discorso vale anche per il discorso \"a sinistra\" Teorema di confronto \u00b6 Teorema di confronto \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) Se esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x)\\) , allora \\(L_1 \\le L_2\\) . Ovvero, se si hanno due funzioni in cui nel grafico una delle due funzioni assume valori maggiori allo stesso punto, la disuguaglianza \" passa \" al limite. Nelle ipotesi corrette quindi: \\[ f(x) \\le g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x) \\] Il teorema non funziona con minore/maggiore stretto Se \\(f(x) > g(x)\\) potrei concludere che \\(\\lim_{x \\rightarrow x_0} f(x) < \\lim_{x \\rightarrow x_0} g(x)\\) ? No, perch\u00e9 prendendo ad esempio le funzioni \\(g(x) = \\frac 1 x\\) e \\(f(x) = - \\frac 1 x\\) su \\(x > 0\\) , entrame le funzioni tendono a 0; ed ecco che una disuguaglianza stretta diventa debole. Quindi \\(f(x) < g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x)\\) Le disuguaglianze passano quindi al limite ma diventano deboli. Teorema dei carabinieri \u00b6 Teorema di dei carabinieri \\(A \\subset \\reals, x_0 \\in Acc(A), f,g, h: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x)= L\\) e \\(\\lim_{x \\rightarrow x_0} h(x)= L\\) (L in questo caso ha lo stesso valore). Se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(x \\in A \\cap u \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x) \\le h(x)\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} g(x) = L\\) Ovvero, se abbiamo tre funzioni, dall'esistenza dei limiti di f ed h (uguali tra loro) deduco che esiste il limite di g. Rispetto al teorema di confronto, dove si sa che i limiti delle funzioni g ed h esistono, in questo caso non so se esiste il limite di G ma sapendo che la funzione \u00e8 compresa tra due funzioni ed il limite delle due funzioni \u00e8 L, deduco che il limite di g sia L. Uso di \"met\u00e0\" del teorema Se la funzione di sinistra va a \\(\\pin\\) , spinge a \\(\\pin\\) tutto quanto (quindi ogni funzione alla destra della disequazione non pu\u00f2 che essere qualcosa che va a pi\u00f9 infinito). Lo stesso concetto lo ho quando la parte della disequazione pi\u00f9 a sinistra va a \\(\\min\\) Ho bisogno di entrambe le met\u00e0 quando il limite \u00e8 un numero finito ed ho bisogno delle altre funzioni per \"schiaccia\" sia da sopra che da sotto la funzione in mezzo. Teorema di somma e prodotto di limiti \u00b6 Teorema di somma e prodotto di limiti \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Supponiamo esistano i limiti \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) con \\(L_1, L_2 \\in \\bar \\reals\\) Allora: Se ha senso \\(L_1 + L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = L_1+L_2\\) Se ha senso \\(L_1 \\cdot L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = L_1 \\cdot L_2\\) Casi di indeterminazione \u00b6 Il \"Se ha senso\" nella definizione precedente serve per escludere i casi di indeterminazione : \\(+ \\infty \\cdot - \\infty\\) e viceversa \\(\\pm \\infty \\cdot 0\\) Esempi di casi di indeterminazione \u00b6 Somma di \\(+ \\infty\\) con \\(- \\infty\\) Ponendo \\(f(x) = 2x\\) e \\(g(x) = -x\\) Le due funzioni hanno i limiti che a \\(+ \\infty\\) valgono rispettivamente \\(+ \\infty\\) e \\(- \\infty\\) . La loro somma \u00e8 quindi questa: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (2x - x) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = + \\infty\\) Se invece prendo \\(f(x) = \\frac x 2\\) e \\(g(x) = -x\\) , allora i rispettivi termini per x che tende a \\(+ \\infty\\) varranno \\(+ \\infty\\) e \\(- \\infty\\) Ma se proviamo a fare il discorso che abbiamo appena fatto: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac x 2 - x) = \\lim_{x \\rightarrow + \\infty} - \\frac x 2 = - \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = - \\infty\\) Dato che il risultato di una somma deve essere costante, scegliamo di trattare le operazioni tra infiniti come casi particolari e quindi di non risolverle algebricamente. Non ha senso parlare di somma. Per questo motivo \\((+ \\infty) + (- \\infty)\\) non ha senso e si dice che il limite \u00e8 indeterminato. Il prodotto \\(0 * + \\infty\\) si considera allo stesso modo rispetto alla somma: Considerando la funzione \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x) = \\lim_{x \\rightarrow + \\infty} 1 = 1 \\] Ed in questo caso avremmo \\((0) \\cdot (+ \\infty) = 1\\) Prendendo invece \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x^2\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (f \\cdot g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x^2) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] Quindi avremmo \\(0 \\cdot (+ \\infty) = + \\infty\\) . Quindi \\(0 \\cdot (+ \\infty)\\) non ha senso. Risoluzione dei casi di indeterminazione \u00b6 Una funzione che tende ad un numero finito \u00e8 limitata \\(A \\subset \\reals, x_0 \\in Acc(A), f: A \\rightarrow \\reals\\) Se esiste \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) ( \\(L\\) non \u00e8 \\(\\pm \\infty\\) ), allora f \u00e8 limitata in un intorno di \\(x_0\\) . Ovvero esiste un intorno \\(u\\) di \\(x_0\\) ed \\(\\exists M \\in R, M > 0\\) tale che \\(x \\in u \\cap A \\Rightarrow |f(x)| \\le M\\) Quindi una funzione che tende ad un numero finito, vicino al punto deve essere finita (limitata). Esempio di funzione limitata che tende a 0 \\(f(x) = \\frac 1 x\\) \u00e8 limitata in un intorno di \\(+ \\infty\\) perch\u00e9 ( \\(\\lim_{x \\rightarrow + \\infty} f(x) = 0\\) E da un certo punto in poi la funzione sta tra \\(\\pm M\\) , dato che la funzione tende ad un numero finito (e quindi da un certo punto in poi \u00e8 finita, essendo la funzione limitata) Funzione infinitesima \u00b6 Funzione infinitesima, divergente e convergente Se \\(\\lim_{x \\rightarrow x_0} f(x) = 0\\) , allora si dice che f \u00e8 infinitesima per x che tende a \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = + \\infty\\) , si dice che f diverge positivamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = - \\infty\\) , si dice che f diverge negativamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) , f converge a L per x che tende ad \\(x_0\\) . Se f \u00e8 limitata inferiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = + \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = + \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = - \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = - \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = 0\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = 0\\) . Una funzione infinitestima per una limitata \u00e8 una funzione infinitesima La somma f + g \u00e8 indeterminata quando una funzione va a + infinito ed una a - infinito; quindi mi basta che la funzione sia limitata inferiormente (perch\u00e9 \u00e8 un caso in cui la funzione non va a - infinito) per dire che la somma va a pi\u00f9 infinito (e viceversa). Nel caso di prodotto di una funzione limitata per una infinitesima: per rimuovere l'indeterminazione mi \"basta dire\" che la seconda funzione \u00e8 limitata. Tutte queste cose appena evidenziate derivano dal teorema dei carabinieri Esempio: Applicazione del teorema sul limite della somma con funzioni senza limite Prendendo la funzione \\(\\limit {+ \\infty} x + sin(x)\\) , possiamo scomporla in due: \\(\\limit {+ \\infty} x = + \\infty\\) \\(\\limit {+ \\infty} sin(x)\\) che non esiste In questo caso non si pu\u00f2 applicare il teorema sul limite della somma (che richede che entrambi i limiti esistano). Tuttavia sin(x) \u00e8 una funzione limitata inferiormente; Quindi: \\[ \\limit \\pin x + sin(x) = \\pin \\] Questo perch\u00e9 \\(x-1 \\le x+sin(x)\\) (perch\u00e9 \\(sin(x)\\) \u00e8 limitat inferiormente): per il teorema dei carabinieri \\(x-1\\) tende a \\(\\pin\\) , quindi anche \\(x + sin(x)\\) tende a \\(\\pin\\) . Limite del reciproco \u00b6 Limiti dei reciproci Se \\(\\limit {x_0} f(x)= 0^+\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\pin\\) Se \\(\\limit {x_0} f(x) = 0^-\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\min\\) Se \\(\\limit {x_0} f(x) = \\pin\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^+\\) Se \\(\\limit {x_0} f(x) = \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^-\\) Se \\(\\limit {x_0} f(x) = L\\) con \\(L \\ne 0, \\pin, \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\frac 1 L\\) Questa proposizione ci dice che il limite del reciproco di una funzione (ammesso che sia definita), \u00e8 il reciproco del limite: Se f tende a L, \\(\\frac 1 f\\) tende a \\(\\frac 1 L\\) \\[ \\displaylines{ f \\rightarrow L \\Rightarrow \\frac 1 f \\rightarrow \\frac 1 L \\\\ \\frac 1 {0^+} = \\pin, \\quad \\frac 1 {0^-} = \\min, \\quad \\frac 1 \\pin = 0^+, \\quad \\frac 1 \\min = 0^- } \\] Esistenza dei limiti per funzioni monotone \u00b6 Esistenza dei limiti per funzioni monotone \\(a, b \\in \\bar \\reals, f: (a,b) \\rightarrow \\reals\\) con f debolmente crescente . In tal caso esistono: \\(\\limit {a^+} f(x) = \\inf_{x \\in (a,b)} f(x)\\) \\(\\limit {b^-} f(x) = \\sup_{x \\in (a,b)} f(x)\\) L'opposto vale quando la funzione \u00e8 debolmente decrescente (invertendo estremo superiore ed inferiore) Avevamo visto che le funzioni monotone assumono massimo e minimo in un intervallo a destra se il dominio ha massimo ed il minimo a sinistra se il dominio ha minimo Questo teorema ci dice che in una funzione monotona i limiti esistono sempre. Esempio \\[ \\displaylines{ f:(0,\\pin) \\rightarrow \\reals \\quad f(x) = - \\frac 1 x \\\\ \\limit {0^+} - \\frac 1 x = \\min = \\inf(f) \\\\ \\limit \\pin - \\frac 1 x = 0 = \\sup(f) } \\] Cambio di variabile \u00b6 Per risolvere alcuni limiti che si presenteranno, pu\u00f2 essere necessario effettuare un cambio di variabile. Un cambio di variabile \u00e8 fatto quando si sostituisce una funzione (ad esempio \\(e^x\\) con una variabile come \\(y\\) ) Quando questo accade, \u00e8 necessario cambiare anche il limite, per far s\u00ec che non perda di significato: \\[ \\lim \\pin e^x = \\lim_{y \\to \\pin} y \\] Limiti fondamentali \u00b6 Esistono alcuni limiti fondamentali: Somma e prodotto di limiti \u00b6 \\(\\limit \\pin x = \\pin\\) \\(\\limit \\pin x^n = (\\lim_{n \\rightarrow \\pin} x) \\cot (\\lim_{n \\rightarrow \\pin} x) \\cdot ...\\) (questo \u00e8 il teorema su prodotto di limiti) \\(=(\\pin)\\cdot (\\pin) \\cdot ... = \\pin\\) \\(\\limit \\pin \\frac 1 x = \\frac 1 \\pin = 0\\) \\(\\limit \\pin \\frac 1 {x^n} = 0\\) Limiti di poliniomi \u00b6 Un polinomio di grado n \u00e8 qualcosa del tipo \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0\\) Dove \\(a_0, a_1, ..., a_n\\) sono i coefficienti del polinomio e sono numeri reali ( \\(a_0, a_1, ..., a_n \\in \\reals\\) ). n \u00e8 invece il grado del polinomio ( \\(n \\in \\naturals\\) ). Esempio di risoluzione di una forma indeterminata Il limite ad infinito di un polinomio \u00e8 spesso una forma indeterminata: \\(\\lim \\pin 3x^2 - 7x + 1 = \\pin \\min + 1\\) Questa \u00e8 quindi una forma indeterminata. Per eliminarla: \\[ \\displaylines{ \\limit \\pin 3x^2(1 - \\frac 7x {3x^2} + \\frac 1 {3x^2}) = \\\\ = \\limit \\pin 3x^2(1- \\frac 7 {3x} + \\frac 1 {3x^2}) = \\\\ = \\pin(1- \\frac 7 \\pin + \\frac 1 \\pin) = \\\\ = \\pin (1 - 0 - 0) = \\pin } \\] Raccogliamo quindi il \\(3x^2\\) e poi dividiamo, facendo infine il limite. Dato un polinomio possiamo quindi sempre raccogliere il monomio di grado pi\u00f9 grande e poi dividere per lo stesso. \\[ \\displaylines{ p(x) = a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\\\ = a_nx^n (1 + \\frac {a_{n-1}} {a_n} \\cdot \\frac {x^{n-1}} {x^n} + ... + \\frac {a_1} {a_n} \\cdot \\frac x {x^n} + \\frac {a_0} {a_n} \\cdot \\frac 1 {x^n}) } \\] A questo punto ho tutti termini che tendono a 0 se x tende a \\(\\pin\\) (o anche se x tende a \\(\\min\\) ). Quello che ottendo quindi \u00e8 che \\(\\limit \\pin a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\limit \\pin a_nx^n\\) . Lo stesso discorso vale anche per quando x tende a \\(\\min\\) . Quindi quando la variabile x tende a \\(\\pm \\infty\\) , il polinomio si comporta come si comporterebbe il monomio di grado pi\u00f9 grande. Esempio di comportamento del poliniomio rispetto al suo grado maggiore \\[ \\limit \\min -2x^5+3x^2 = \\limit \\min -2x^5 = -2(\\min)^5 = (-2)(\\min) = \\pin \\] Funzioni razionali \u00b6 Una funzione razionale \u00e8 una funzione \\(\\frac {p(x)} {q(x)}\\) dove p e q sono polinomi: \\[ \\displaylines{ p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0 \\\\ q(x) = b_m \\cdot x^m + b_{m-1} \\cdot x^{m-1} + ... + b_{1} \\cdot x + b_0 } \\] Quindi il limite della funzione sar\u00e0 equivalemtne al conto che si fa con i polinomi: \\[ \\displaylines{ \\limit {\\pm \\infty} \\frac {p(x)} {q(x)} = \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0} {b_mx^m + b_{m-1}x^{m-1} + ... + b_1x + b_0} \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n} {b_mx^m} } \\] Esempio di funzioni razionali \\[ \\displaylines{ \\limit \\pin \\frac {7x^4 + 5x^2} {-2x^3 + x} = \\\\ = \\limit \\pin \\frac {7x^4} {-2x^3} = \\\\ = \\limit \\pin \\frac {7x} {-2} = \\min } \\] In questo caso abbiamo un eccesso di grado al numeratore (al numeratore abbiamo un grado 4, al denominatore abbiamo un grado 3), quindi il limite va a \\(\\pm \\infty\\) a seconda del sengno dei coefficienti. Se fosse successo l'opposto (il grado del denominatore suepriore al grado del numeratore), il limite sarebbe andato a 0 Se invece il grado fosse stato lo stesso, il limite sarebbe andato al rapporto dei coefficenti tra i termini di grado maggiore. Altri limiti fondamentali \u00b6 \\[ \\displaylines{ \\limit \\pin e^x = \\pin \\\\ \\limit \\min e^x = 0^+ \\\\ \\limit {0^+} log(x) = \\min \\\\ \\limit \\pin log(x) = \\pin \\\\ } \\] Limiti notevoli \u00b6 \\(\\limit 0 \\frac {sin(x)} x = 1\\) Questo limite \u00e8 una forma indeterminata, in quanto il \\(\\limit 0 sin(x) = 0\\) , mentre il \\(\\limit 0 x = 0\\) , tuttavi si pu\u00f2 dimostrare che il limite faccia uno. Dimostrazione - Da fare //TODO - work in progress Guadando una circonferenza, pu\u00f2 essere facile dire che la tangente \u00e8 sempre pi\u00f9 grande del seno per lo stesso valore di x (per il primo quadrante). \\[ \\displaylines{ |sin(x)| \\le x \\le |tan(x)| = \\\\ = |sin(x)| \\le x \\le |\\frac {sin(x)}{cos(x)}| = \\quad (\\cdot \\frac 1 {|sin(x)|})\\\\ = \\frac {|sin(x)|} {|sin(x)|} \\le \\frac x {sin(x)} \\le \\frac {|sin(x)|}{|cos(x)|} \\cdot \\frac 1 {|sin(x)|} = \\\\ = 1 \\le \\frac x {sin(x)} \\le \\frac 1 {cos(x)} = \\quad \\text{ (inversione delle frazioni) }\\\\ = 1 \\ge \\frac {sin(x)} x \\ge cos(x) \\\\ \\\\ \\limit 0 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge \\limit 0 cos(x) = \\\\ = 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge 1 \\Rightarrow \\limit 0 \\frac {sin(x)} x = 1 } \\] Da questo limite se ne possono poi dimostrare altri: \\(\\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2\\) Dimostrazione \\[ \\displaylines{ \\frac {1 - cos(x)}{x^2} = \\frac {(1 - cos(x)) (1 + cos(x))}{x^2 (1 + cos(x))} \\\\ = \\frac {1 - cos^2 (x)} {x^2 (1 + cos(x))} = \\frac {sin^2 (x)}{x^2 1 + cos(x)} = \\\\ = \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} \\\\ \\\\ \\limit 0 \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} = 1 \\cdot 1 \\cdot \\frac 1 {1+1} = \\\\ = \\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2 } \\] \\(\\limit 0 \\frac {e^x -1} x = 1\\) \\(\\limit 0 \\frac {log(1 + x)} x = 1\\) \\(\\limit {0^+} x \\cdot \\log(x) = 0 \\cdot (\\min)\\) (forma indeterminata) Per questa si effettua il cambio di variabile, quindi \\(y=log(x), x = e^y\\) Se \\(x \\to 0^+ \\Rightarrow y = log(x) \\to \\min\\) \\(\\lim_{y \\to \\min} e^y \\cdot y\\) (questa \u00e8 ancora una forma indeterminata, \\(e^\\min \\cdot (\\min) = 0^+ \\cdot (\\min)\\) ) Quindi \u00e8 necessario fare un ulteriore cambio di variabile: \\(z = -y\\) , quindi se \\(y \\to \\min \\Rightarrow z \\to \\pin\\) \\(\\lim_{y \\to \\min} e^y \\cdot y = \\lim_{z \\to \\pin} e^{-z} \\cdot -z = \\lim_{z \\to \\pin} \\frac {-z} {e^z} = 0\\) \\(\\lim_{x \\to 0^+} x\\cdot log(x) = 0\\) \\(\\limit {0^+} x^\\alpha log(x)\\) (con \\(\\alpha > 0\\) ); Anche in questo caso dobbiamo ricorrere alla sostituzione: \\(y = x^\\alpha\\) , quindi \\(x = y^{\\frac 1 \\alpha}\\) Se \\(x \\to 0 \\Rightarrow y = x ^ \\alpha \\rightarrow 0\\) \\(\\limit {0^+} x^\\alpha log(x) = \\lim_{y \\to 0^+} y \\cdot log(y^{\\frac 1 \\alpha})\\) \\(= \\lim_{y \\to 0^+} y \\cdot \\frac 1 \\alpha log(y)\\) \\(= \\frac 1 \\alpha \\lim_{y \\to 0^+} y \\cdot log(y) = 0\\) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Dimostrazione \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = (1 + 0)^{\\frac 1 0^+ } = 1^\\pin\\) Questa \u00e8 una forma indeterminata: \\((1 + x)^{\\frac 1 x} = e^{log(1 + x)^{\\frac 1 x}} = e^{\\frac 1 x log(1+x)}\\) Da qui sostituiamo \\(y = \\frac 1 x log(1 + x)\\) Se \\(x \\to 0^+\\) , a quanto deve tendere y? \\(\\limit {0^+} \\frac 1 x log(1 + x) = 1\\) (Limite notevole) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Nuovi casi di indeterminazione \u00b6 \\(f(x) > 0, \\limit {x_0} f(x)^{g(x)}\\) . Quando questa \u00e8 una forma indeterminata? Possiamo manipolare il limite per rendere la domanda pi\u00f9 semplice: \\(f(x)^{g(x)}=e^{log(f(x)^{g(x)})} = e^{g(x) \\cdot log(f(x))}\\) Abbiamo quindi spostato la domanda: quando \u00e8 indeterminato il limite \\(\\limit {x_0} g(x) \\cdot log(f(x))\\) ? Abbiamo 3 casi: \\(g \\to 0, f \\to \\pin \\So log(f) \\to \\pin\\) \\(0 \\cdot \\pin\\) quindi \\((\\pin)^0\\) \u00e8 indeterminata \\(g \\to 0, f\\to 0^+ \\So \\log f \\to \\min\\) \\(\\So g \\cdot \\log(f) = 0 \\cdot (\\min)\\) \\(g \\to \\pm \\infty, f \\to 1\\) , quindi \\(log(f) \\to 0\\) \\(g \\cdot log(f) = \\pm \\infty \\cdot 0\\) \\((1)^{\\pm \\infty}\\) \u00e8 indeterminata Abbiamo quindi 4 nuove forme indeterminate: \\[ (\\pin)^0, \\qquad (0^+)^0, \\qquad (1)^{\\pin}, \\qquad (1)^{\\min} \\] Tutti e quattro i casi si risolvono riscrivendoli nella forma esponenziale Esempio $\\limit {0^+} x^x = \\limit {0^+} e {log(x x)} = $ \\(=\\limit {0^+} e^{x \\cdot log(x)} = e^0 = 1\\) Qui \u00e8 stato \"nascosto\" il cambio di variabile, che sarebbe stato \\(y = x \\cdot log(x)\\) , se \\(x \\to 0^+ \\So y \\to 0\\) \\(\\So \\lim_{y \\to 0} e^y = e^0 = 1\\) Esponenziale \u00b6 Dato \\(\\limit \\pin a^x\\) , ci sono 3 possibili soluzioni: \\[\\limit \\pin a^x = \\begin{cases} \\pin & \\text{ se } a > 1 1 & \\text{ se } a = 1 0^+ & \\text{ se } 0 < a < 1 \\end{cases} \\] Ovviamente a deve essere maggiore di 0 Se invece vogliamo far tendere \\(x \\to \\min\\) , possiamo effettuare un cambio variabile: \\(y = -x\\) , quindi se \\(x \\to \\min \\Rightarrow y \\to \\pin\\) . Di conseguenza: \\(\\limit \\min a^x = \\lim_{y \\to 1} a^-y = \\lim_{y \\to \\pin} \\frac 1 {a^y}\\) Quindi abbiamo di nuovo 3 casi: \\[ \\lim_{y \\to \\pin} \\frac 1 {a^y} = \\begin{cases} 0^+ & \\text{ se } a > 1 1 & \\text{ se } a = 1 \\pin & \\text{ se } 0 < a < 1 \\end{cases} \\] I risultati sono anche facilmente visibili: \\(a >1\\) \\(0<a<1\\) Potenze \u00b6 Consideriamo \\(\\alpha \\in \\reals\\) e quindi \\(x^\\alpha\\) Observation Notare che se si consdiera \\(x^\\alpha\\) con \\(\\alpha\\) non razionale, si \u00e8 forzati a prendere \\(x>0\\) (\u00e8 pari o dispari \\(\\pi\\) ?) Quindi, \\(\\limit \\pin x^\\alpha\\) vale: \\[ \\limit \\pin x^\\alpha = \\begin{cases} \\pin & \\text{ se } \\alpha > 0 \\\\ 1 & \\text{ se } \\alpha = 0 \\\\ 0^+ & \\text{ se } \\alpha < 0 \\end{cases} \\] Limite della composizione di funzioni \u00b6 Teorema del Limite della composizione di funzioni \\(A, B \\subset \\reals, f: A \\rightarrow B, g: B \\rightarrow \\reals\\) \\(x_0 \\in Acc(A)\\) Se esiste \\(\\limit {x_0} f(x) = y_0\\) , e \\(y_0 \\in Acc(B)\\) e \\(\\exists \\lim_{y \\rightarrow y_0} g(y) = L \\in \\bar \\reals\\) E se \u00e8 verificata almeno una delle seguenti due ipotesi: \\(y_0 \\in B\\) e g \u00e8 continua in \\(y_0\\) \\(\\exists u\\) intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\ne y_0\\) Allora \\(\\limit {x_0} (g \\circ f)(x) = L\\) , dove L \u00e8 il limite di g Quindi \\(\\limit {x_0} (g \\circ f)(x) = \\lim_{y \\rightarrow y_0} g(y)\\) Esempio dell'uso del teorema Calcoliamo \\(\\limit \\min arctg(x^2)\\) Il limite \u00e8 una composizione: \\(f(x) = x^2\\) , \\(g(y) = arctg(y)\\) \\((g \\circ f)(x) = g(f(x)) = g(x^2) = arctg(x^2)\\) \\(x_0 = \\min\\) , \\(y_0 = \\limit {x_0} f(x) = \\limit \\min x^2 = \\pin\\) A questo punto dobbiamo rendeci conto del caso in cui ci troviamo: Il primo caso non \u00e8 verificato in quanto \\(y_0 = \\pin\\) e non appartiene al dominio di g Il secondo caso \u00e8 verificato, perch\u00e9 \\(f(x) \\ne y_0 \\Rightarrow f(x) \\ne \\pin\\) , che \u00e8 sempre vero. Procediamo quindi applicando il teorema: \\(\\lim_{y \\to y_0} g(y) = \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) Quindi \\(\\limit \\min arctg(x^2) = \\frac \\pi 2\\) Osservazione: la soluzione appena vista \u00e8 un teorema di cambiamento di variabile Riprendendo l'esempio appena visto, siamo partiti da \\(\\limit \\min arctg(x^2)\\) . Cambiamo poi variabile e poniamo \\(y=x^2\\) , tuttavia troviamo la x anche come argomento del limite (che tende a \\(\\min\\) ). Quindi se \\(x \\to \\min\\) a quanto tende y? Basta fare \\(\\limit \\min y = \\limit \\min x^2 = \\pin\\) Cambiando variabile otteniamo quindi: \\(\\limit \\min arctg(x^2) \\Rightarrow \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) La seconda ipotesi nel teorema necessaria perch\u00e9 se la composizione tra due funzioni va a toccare in modo insistente il punto limite, dato che il secondo limite non si interessa di quanto valga la funzione nel centro dell'intorno, e dato che la funzione f va solo nel centro dell'intorno \"non si pu\u00f2 accorgere di quel che sta succedendo(?)\" Uso dell'ipotesi due nel problema \\(f: \\reals \\to \\reals \\quad f(x) = 1 \\quad \\forall x \\in \\reals\\) \\(x_0 = 0\\) \\(g(x) = \\begin{cases} 3 \\text{ se } y=1 \\\\ 5 \\text{ se } y \\ne 1 \\\\ \\end{cases}\\) \\(g: \\reals \\to \\reals\\) \\((g \\circ f)(x) = g(f(x)) = g(1) = 3 \\forall x \\in \\reals\\) Quindi la funzione \\((g \\circ f)(x)\\) \u00e8 sempre 3. Il limite di una funzione costante \u00e8 quindi una costante: \\(\\limit 0 (g \\circ f)(x) = 3\\) Prendendo poi come \\(y_0 = \\limit {x_0} f(x) = \\limit 0 f(x) = 1\\) , e quindi: \\(\\limit {x_0} (g \\circ f)(x) \\ne \\lim_{y \\to y_0} g(y)\\) Per\u00f2 non vale nessuna delle due ipotesi Confronti tra infiniti \u00b6 Dato un limite del tipo \\(\\limit \\pin \\frac {a^x}{x^\\alpha}\\) , abbiamo: \\[\\limit \\pin \\frac {a^x}{x^\\alpha} = \\begin{cases} \\pin & \\text{ se } a > 1 0^+ & \\text{ se } 0< a < 1 \\end{cases} \\] Se \\(a=1 \\Rightarrow a^x = 1\\) , quindi \\(\\lim \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac 1 {x^\\alpha}\\) Quindi quello che domina i limite \u00e8 l'a al numeratore, ovvero l'esponenziale, che vince sulla potenza. L'unico caso in cui l'esponenziale non guida la funzione \u00e8 quando a \u00e8 pari ad 1. Esempio \\(a=\\frac 1 2 \\quad \\alpha = -3\\) \\[ \\limit \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac {(\\frac 1 2)^x} {x^{-3}} = \\limit \\pin \\frac {x^3}{2^x} = 0^+ \\] Anche in questo caso quello che domina il limite \u00e8 l'esponenziale (il \\(2^x\\) al denominatore), che \u00e8 molto pi\u00f9 veloce rispetto alla potenza Confronto tra logaritmo e potenza \u00b6 Quando abbiamo a che fare con un logaritmo, conviene usare il cambio di variabile e sostituirlo (come mostrato nell'esempio) Esempio: cambio di potenza del logaritmo \\(\\limit \\pin \\frac {log(x)} x\\) , quindi facciamo il cambio di variabile \\(y = log(x)\\) (e quindi \\(x = e^x\\) una volta effettuato il cambio variabile nel limite) Se \\(x \\to \\pin \\Rightarrow \\limit \\pin log(x) = \\pin\\) \\(( y = log(x) \\to \\pin)\\) \\(\\limit \\pin \\frac {log (x)} x = \\lim_{y \\to \\pin} \\frac y {e^y} = 0\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha}\\) , \\(\\alpha, \\beta \\in \\reals\\) , \\(\\alpha, \\beta > 0\\) Anche in questo caso iniziamo con il cambio di variabile \\(y = log(x) \\Rightarrow x=e^y\\) Quindi se \\(x \\to \\pin\\) (se x tende a \\(\\pin\\) ), \\(\\Rightarrow y \\to \\pin\\) (allora anche y tende a \\(\\pin\\) ) Risostituiamo inoltre x con \\(e^y\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^y)^\\alpha} =\\) \\(=\\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^{y \\cdot \\alpha}} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^\\alpha)^y} =\\) Assegnamo quindi ad \\(a = e^\\alpha\\) : \\(\\lim_{y \\to \\pin} \\frac {y^\\beta}{a^y}\\) Da qui sappiamo che \\(\\alpha > 0\\) e quindi \\(e^\\alpha > 1\\) Questo limite ha quindi come risultato 0, perch\u00e9 l'esponenziale al denominatore porta a 0 il denominatore","title":"Limiti"},{"location":"AnalisiI/limiti/#parallelismo-con-la-continuita","text":"Il concetto di limite \u00e8 molto simile a quello di continuit\u00e0. La differenza principale \u00e8 che: Nel limite non guardiamo il punto \\(x_0\\) ma il suo intorno. Inoltre consideriamo solo i punti di accumulazione (quindi anche punti esterni al dominio (come 0 con la funzione \\(\\frac 1 x\\) ). Inoltre non consideriamo i punti isolati in quanto non sono di accumulazione) Nella continuit\u00e0 guardiamo il valore \\(x_0\\) ed un suo intorno, considerando ogni punto nel domino (quindi anche i punti isolati) Inoltre nella continuit\u00e0 \\(x_0\\) pu\u00f2 essere uguale ad x, quindi \\(x_0 = x \\Rightarrow f(x) - f(x_0) = 0\\) La definizione di limite e continuit\u00e0 infine possono essere viste compatibili se (oltre al requisito \\(x \\ne x_0\\) ) si scambiano tra di loro L ed \\(x_0\\)","title":"Parallelismo con la continuit\u00e0"},{"location":"AnalisiI/limiti/#teorema-dellunicita-del-limite","text":"Teorema dell'unicit\u00e0 del limite Se il limite esiste, allora \u00e8 unico. Questo perch\u00e9 dire che una funzione tende ad un valore \\(L_1\\) per x che tende a \\(x_0\\) significa che si avvicina a quel valore quando x si avvicina a \\(x_0\\) , quindi non pu\u00f2 tendere contemporaneamente ad \\(L_2\\) perch\u00e9 non pu\u00f2 avvicinarsi a due valori distinti contemporaneamente.","title":"Teorema dell'unicit\u00e0 del limite"},{"location":"AnalisiI/limiti/#limiti-destri-e-sinistri","text":"Definzione di limite destro e sinistro \\(A \\subset \\reals, x_0 \\in Acc(A), x_0 in \\reals\\) \\(f: A \\rightarrow \\reals\\) , l in \\(\\bar \\reals\\) \u00e8 il limite di f(x) per x che tende a \\(x_0\\) da destra e si scrive \\[ \\lim_{x \\rightarrow x_0^+} f(x) =f \\] Se \\(\\forall V\\) intorno di l esiste \\(\\delta >0\\) tale che \\(x_0 < x < x_0 + \\delta, x \\in A \\Rightarrow f(x) \\in V\\) . Qui si possono notare due cose: Il fatto che x sia diverso da \\(x_0\\) si pu\u00f2 osservare dall'uso del minore stretto (quindi non mi interessa neanche in questo caso quanto vale la funzione del punto) Il motivo per il quale \\(x_0\\) \u00e8 finito (in \\(\\reals\\) ) \u00e8 perch\u00e9 non ha senso avvicinare \\(+\\infty\\) da destra Da sinistra, se \\(x_0 - \\delta < x < x_0, x \\in A \\Rightarrow f(x) \\in V\\) Questo significa che nella definizione di limite, si considerano solo i \" mezzi intorni \" a desta o a sinistra Esempio di limite da destra e da sinistra Prendendo la funone \\(f: (-\\infty, 0) \\cup (0, + \\infty) \\rightarrow \\reals\\) Definita come \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questo caso, il limite per x che tende a 0 da destra di f(x) vale 1 ( \\(\\lim_{x \\rightarrow 0^+} f(x) = 1\\) ) e quello che tende a 0 da sinistra -1 ( \\(\\lim_{x \\rightarrow 0^-} f(x) = -1\\) ). In questo caso non esiste il limite per f(x) che tende a 0, perch\u00e9 il limite che tende a 0 da destra \u00e8 diverso dal limite per x che tende a 0 da sinistra. Il limite esiste solo se i limiti da destra e da sinistra sono uguali \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\lim_{x \\rightarrow x_0^+} f(x) = \\lim_{x \\rightarrow x_0^-} f(x) = L \\] Nella definzione di limite destro si usa solo il \" mezzo intorno \" destro e stessa cosa con quello sinistro. Se vengono messi insieme si ottiene la definizione di limite.","title":"Limiti destri e sinistri"},{"location":"AnalisiI/limiti/#funzione-definitivamente-positiva-e-negativa","text":"Funzione definitivamente positiva e negativa \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Si dice che \\(\\lim_{x \\rightarrow x_0} f(x) = L^+\\) (con \\(L \\in \\reals\\) ), se: \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) Esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\{x_0\\} \\Rightarrow f(x) > L\\) Ci\u00f2 significa che la funzione \"tende\" al valore ma da 'sopra': La stessa definizione vale per \\(L^-\\) Esempio di limite positivo \\[ f(x) = \\frac 1 x \\qquad \\lim_{x \\rightarrow + \\infty} f(x) = 0^+ \\] Questo perch\u00e9 considerare la funzione vicino \\(+ \\infty\\) , la funzione tende a 0. Scegliendo una semiretta (e quindi un intervallo \\((a, + \\infty)\\) ) come intorno u \\(a > 0 \\Rightarrow f(x) > 0\\) (in questo caso 0=l), e quindi possiamo dire che la funzione \u00e8 definitivamente positiva In questo caso a noi interessa che la funzione sia positiva in un intorno del punto di cui calcoliamo il limite","title":"Funzione definitivamente positiva e negativa"},{"location":"AnalisiI/limiti/#teorema-della-permanenza-del-segno","text":"Teorema della permanenza del segno \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Se esisiste \\(\\lim_{x \\rightarrow x_0} f(x) = L \\in \\bar \\reals\\) e \\(L \\ne 0\\) allora esiste un intorno u di \\(x_0\\) tale che se \\(x \\in A \\cap u \\{x_0\\}\\) allora f ha lo stesso segno di L. [44:00]","title":"Teorema della permanenza del segno"},{"location":"AnalisiI/limiti/#continuita-di-una-funzione-a-destra-o-sinistra","text":"Funzione continua a destra o sinistra Dato \\(A \\subset \\reals, x+0 in A, x_0 \\in Acc(A)\\) Se \\(\\lim_{x \\rightarrow x_{0^+}} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a destra in \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_{0^0-} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a sinistra in \\(x_0\\) . Funzione continua a destra o sinistra Riprendendo l'esempio della funzione vista prima e modificandola appena, di d\u00e0 la seguente funzione: \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questa funzione, il limite per x che tende a \\(0^+\\) vale quanto la funzione a 0. Quando la funzine presenta questo comportamento, viene detta funzione continua a destra. Ovviamente lo stesso discorso vale anche per il discorso \"a sinistra\"","title":"Continuit\u00e0 di una funzione a destra o sinistra"},{"location":"AnalisiI/limiti/#teorema-di-confronto","text":"Teorema di confronto \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) Se esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x)\\) , allora \\(L_1 \\le L_2\\) . Ovvero, se si hanno due funzioni in cui nel grafico una delle due funzioni assume valori maggiori allo stesso punto, la disuguaglianza \" passa \" al limite. Nelle ipotesi corrette quindi: \\[ f(x) \\le g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x) \\] Il teorema non funziona con minore/maggiore stretto Se \\(f(x) > g(x)\\) potrei concludere che \\(\\lim_{x \\rightarrow x_0} f(x) < \\lim_{x \\rightarrow x_0} g(x)\\) ? No, perch\u00e9 prendendo ad esempio le funzioni \\(g(x) = \\frac 1 x\\) e \\(f(x) = - \\frac 1 x\\) su \\(x > 0\\) , entrame le funzioni tendono a 0; ed ecco che una disuguaglianza stretta diventa debole. Quindi \\(f(x) < g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x)\\) Le disuguaglianze passano quindi al limite ma diventano deboli.","title":"Teorema di confronto"},{"location":"AnalisiI/limiti/#teorema-dei-carabinieri","text":"Teorema di dei carabinieri \\(A \\subset \\reals, x_0 \\in Acc(A), f,g, h: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x)= L\\) e \\(\\lim_{x \\rightarrow x_0} h(x)= L\\) (L in questo caso ha lo stesso valore). Se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(x \\in A \\cap u \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x) \\le h(x)\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} g(x) = L\\) Ovvero, se abbiamo tre funzioni, dall'esistenza dei limiti di f ed h (uguali tra loro) deduco che esiste il limite di g. Rispetto al teorema di confronto, dove si sa che i limiti delle funzioni g ed h esistono, in questo caso non so se esiste il limite di G ma sapendo che la funzione \u00e8 compresa tra due funzioni ed il limite delle due funzioni \u00e8 L, deduco che il limite di g sia L. Uso di \"met\u00e0\" del teorema Se la funzione di sinistra va a \\(\\pin\\) , spinge a \\(\\pin\\) tutto quanto (quindi ogni funzione alla destra della disequazione non pu\u00f2 che essere qualcosa che va a pi\u00f9 infinito). Lo stesso concetto lo ho quando la parte della disequazione pi\u00f9 a sinistra va a \\(\\min\\) Ho bisogno di entrambe le met\u00e0 quando il limite \u00e8 un numero finito ed ho bisogno delle altre funzioni per \"schiaccia\" sia da sopra che da sotto la funzione in mezzo.","title":"Teorema dei carabinieri"},{"location":"AnalisiI/limiti/#teorema-di-somma-e-prodotto-di-limiti","text":"Teorema di somma e prodotto di limiti \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Supponiamo esistano i limiti \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) con \\(L_1, L_2 \\in \\bar \\reals\\) Allora: Se ha senso \\(L_1 + L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = L_1+L_2\\) Se ha senso \\(L_1 \\cdot L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = L_1 \\cdot L_2\\)","title":"Teorema di somma e prodotto di limiti"},{"location":"AnalisiI/limiti/#casi-di-indeterminazione","text":"Il \"Se ha senso\" nella definizione precedente serve per escludere i casi di indeterminazione : \\(+ \\infty \\cdot - \\infty\\) e viceversa \\(\\pm \\infty \\cdot 0\\)","title":"Casi di indeterminazione"},{"location":"AnalisiI/limiti/#esempi-di-casi-di-indeterminazione","text":"Somma di \\(+ \\infty\\) con \\(- \\infty\\) Ponendo \\(f(x) = 2x\\) e \\(g(x) = -x\\) Le due funzioni hanno i limiti che a \\(+ \\infty\\) valgono rispettivamente \\(+ \\infty\\) e \\(- \\infty\\) . La loro somma \u00e8 quindi questa: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (2x - x) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = + \\infty\\) Se invece prendo \\(f(x) = \\frac x 2\\) e \\(g(x) = -x\\) , allora i rispettivi termini per x che tende a \\(+ \\infty\\) varranno \\(+ \\infty\\) e \\(- \\infty\\) Ma se proviamo a fare il discorso che abbiamo appena fatto: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac x 2 - x) = \\lim_{x \\rightarrow + \\infty} - \\frac x 2 = - \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = - \\infty\\) Dato che il risultato di una somma deve essere costante, scegliamo di trattare le operazioni tra infiniti come casi particolari e quindi di non risolverle algebricamente. Non ha senso parlare di somma. Per questo motivo \\((+ \\infty) + (- \\infty)\\) non ha senso e si dice che il limite \u00e8 indeterminato. Il prodotto \\(0 * + \\infty\\) si considera allo stesso modo rispetto alla somma: Considerando la funzione \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x) = \\lim_{x \\rightarrow + \\infty} 1 = 1 \\] Ed in questo caso avremmo \\((0) \\cdot (+ \\infty) = 1\\) Prendendo invece \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x^2\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (f \\cdot g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x^2) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] Quindi avremmo \\(0 \\cdot (+ \\infty) = + \\infty\\) . Quindi \\(0 \\cdot (+ \\infty)\\) non ha senso.","title":"Esempi di casi di indeterminazione"},{"location":"AnalisiI/limiti/#risoluzione-dei-casi-di-indeterminazione","text":"Una funzione che tende ad un numero finito \u00e8 limitata \\(A \\subset \\reals, x_0 \\in Acc(A), f: A \\rightarrow \\reals\\) Se esiste \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) ( \\(L\\) non \u00e8 \\(\\pm \\infty\\) ), allora f \u00e8 limitata in un intorno di \\(x_0\\) . Ovvero esiste un intorno \\(u\\) di \\(x_0\\) ed \\(\\exists M \\in R, M > 0\\) tale che \\(x \\in u \\cap A \\Rightarrow |f(x)| \\le M\\) Quindi una funzione che tende ad un numero finito, vicino al punto deve essere finita (limitata). Esempio di funzione limitata che tende a 0 \\(f(x) = \\frac 1 x\\) \u00e8 limitata in un intorno di \\(+ \\infty\\) perch\u00e9 ( \\(\\lim_{x \\rightarrow + \\infty} f(x) = 0\\) E da un certo punto in poi la funzione sta tra \\(\\pm M\\) , dato che la funzione tende ad un numero finito (e quindi da un certo punto in poi \u00e8 finita, essendo la funzione limitata)","title":"Risoluzione dei casi di indeterminazione"},{"location":"AnalisiI/limiti/#funzione-infinitesima","text":"Funzione infinitesima, divergente e convergente Se \\(\\lim_{x \\rightarrow x_0} f(x) = 0\\) , allora si dice che f \u00e8 infinitesima per x che tende a \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = + \\infty\\) , si dice che f diverge positivamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = - \\infty\\) , si dice che f diverge negativamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) , f converge a L per x che tende ad \\(x_0\\) . Se f \u00e8 limitata inferiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = + \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = + \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = - \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = - \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = 0\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = 0\\) . Una funzione infinitestima per una limitata \u00e8 una funzione infinitesima La somma f + g \u00e8 indeterminata quando una funzione va a + infinito ed una a - infinito; quindi mi basta che la funzione sia limitata inferiormente (perch\u00e9 \u00e8 un caso in cui la funzione non va a - infinito) per dire che la somma va a pi\u00f9 infinito (e viceversa). Nel caso di prodotto di una funzione limitata per una infinitesima: per rimuovere l'indeterminazione mi \"basta dire\" che la seconda funzione \u00e8 limitata. Tutte queste cose appena evidenziate derivano dal teorema dei carabinieri Esempio: Applicazione del teorema sul limite della somma con funzioni senza limite Prendendo la funzione \\(\\limit {+ \\infty} x + sin(x)\\) , possiamo scomporla in due: \\(\\limit {+ \\infty} x = + \\infty\\) \\(\\limit {+ \\infty} sin(x)\\) che non esiste In questo caso non si pu\u00f2 applicare il teorema sul limite della somma (che richede che entrambi i limiti esistano). Tuttavia sin(x) \u00e8 una funzione limitata inferiormente; Quindi: \\[ \\limit \\pin x + sin(x) = \\pin \\] Questo perch\u00e9 \\(x-1 \\le x+sin(x)\\) (perch\u00e9 \\(sin(x)\\) \u00e8 limitat inferiormente): per il teorema dei carabinieri \\(x-1\\) tende a \\(\\pin\\) , quindi anche \\(x + sin(x)\\) tende a \\(\\pin\\) .","title":"Funzione infinitesima"},{"location":"AnalisiI/limiti/#limite-del-reciproco","text":"Limiti dei reciproci Se \\(\\limit {x_0} f(x)= 0^+\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\pin\\) Se \\(\\limit {x_0} f(x) = 0^-\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\min\\) Se \\(\\limit {x_0} f(x) = \\pin\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^+\\) Se \\(\\limit {x_0} f(x) = \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^-\\) Se \\(\\limit {x_0} f(x) = L\\) con \\(L \\ne 0, \\pin, \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\frac 1 L\\) Questa proposizione ci dice che il limite del reciproco di una funzione (ammesso che sia definita), \u00e8 il reciproco del limite: Se f tende a L, \\(\\frac 1 f\\) tende a \\(\\frac 1 L\\) \\[ \\displaylines{ f \\rightarrow L \\Rightarrow \\frac 1 f \\rightarrow \\frac 1 L \\\\ \\frac 1 {0^+} = \\pin, \\quad \\frac 1 {0^-} = \\min, \\quad \\frac 1 \\pin = 0^+, \\quad \\frac 1 \\min = 0^- } \\]","title":"Limite del reciproco"},{"location":"AnalisiI/limiti/#esistenza-dei-limiti-per-funzioni-monotone","text":"Esistenza dei limiti per funzioni monotone \\(a, b \\in \\bar \\reals, f: (a,b) \\rightarrow \\reals\\) con f debolmente crescente . In tal caso esistono: \\(\\limit {a^+} f(x) = \\inf_{x \\in (a,b)} f(x)\\) \\(\\limit {b^-} f(x) = \\sup_{x \\in (a,b)} f(x)\\) L'opposto vale quando la funzione \u00e8 debolmente decrescente (invertendo estremo superiore ed inferiore) Avevamo visto che le funzioni monotone assumono massimo e minimo in un intervallo a destra se il dominio ha massimo ed il minimo a sinistra se il dominio ha minimo Questo teorema ci dice che in una funzione monotona i limiti esistono sempre. Esempio \\[ \\displaylines{ f:(0,\\pin) \\rightarrow \\reals \\quad f(x) = - \\frac 1 x \\\\ \\limit {0^+} - \\frac 1 x = \\min = \\inf(f) \\\\ \\limit \\pin - \\frac 1 x = 0 = \\sup(f) } \\]","title":"Esistenza dei limiti per funzioni monotone"},{"location":"AnalisiI/limiti/#cambio-di-variabile","text":"Per risolvere alcuni limiti che si presenteranno, pu\u00f2 essere necessario effettuare un cambio di variabile. Un cambio di variabile \u00e8 fatto quando si sostituisce una funzione (ad esempio \\(e^x\\) con una variabile come \\(y\\) ) Quando questo accade, \u00e8 necessario cambiare anche il limite, per far s\u00ec che non perda di significato: \\[ \\lim \\pin e^x = \\lim_{y \\to \\pin} y \\]","title":"Cambio di variabile"},{"location":"AnalisiI/limiti/#limiti-fondamentali","text":"Esistono alcuni limiti fondamentali:","title":"Limiti fondamentali"},{"location":"AnalisiI/limiti/#somma-e-prodotto-di-limiti","text":"\\(\\limit \\pin x = \\pin\\) \\(\\limit \\pin x^n = (\\lim_{n \\rightarrow \\pin} x) \\cot (\\lim_{n \\rightarrow \\pin} x) \\cdot ...\\) (questo \u00e8 il teorema su prodotto di limiti) \\(=(\\pin)\\cdot (\\pin) \\cdot ... = \\pin\\) \\(\\limit \\pin \\frac 1 x = \\frac 1 \\pin = 0\\) \\(\\limit \\pin \\frac 1 {x^n} = 0\\)","title":"Somma e prodotto di limiti"},{"location":"AnalisiI/limiti/#limiti-di-poliniomi","text":"Un polinomio di grado n \u00e8 qualcosa del tipo \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0\\) Dove \\(a_0, a_1, ..., a_n\\) sono i coefficienti del polinomio e sono numeri reali ( \\(a_0, a_1, ..., a_n \\in \\reals\\) ). n \u00e8 invece il grado del polinomio ( \\(n \\in \\naturals\\) ). Esempio di risoluzione di una forma indeterminata Il limite ad infinito di un polinomio \u00e8 spesso una forma indeterminata: \\(\\lim \\pin 3x^2 - 7x + 1 = \\pin \\min + 1\\) Questa \u00e8 quindi una forma indeterminata. Per eliminarla: \\[ \\displaylines{ \\limit \\pin 3x^2(1 - \\frac 7x {3x^2} + \\frac 1 {3x^2}) = \\\\ = \\limit \\pin 3x^2(1- \\frac 7 {3x} + \\frac 1 {3x^2}) = \\\\ = \\pin(1- \\frac 7 \\pin + \\frac 1 \\pin) = \\\\ = \\pin (1 - 0 - 0) = \\pin } \\] Raccogliamo quindi il \\(3x^2\\) e poi dividiamo, facendo infine il limite. Dato un polinomio possiamo quindi sempre raccogliere il monomio di grado pi\u00f9 grande e poi dividere per lo stesso. \\[ \\displaylines{ p(x) = a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\\\ = a_nx^n (1 + \\frac {a_{n-1}} {a_n} \\cdot \\frac {x^{n-1}} {x^n} + ... + \\frac {a_1} {a_n} \\cdot \\frac x {x^n} + \\frac {a_0} {a_n} \\cdot \\frac 1 {x^n}) } \\] A questo punto ho tutti termini che tendono a 0 se x tende a \\(\\pin\\) (o anche se x tende a \\(\\min\\) ). Quello che ottendo quindi \u00e8 che \\(\\limit \\pin a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\limit \\pin a_nx^n\\) . Lo stesso discorso vale anche per quando x tende a \\(\\min\\) . Quindi quando la variabile x tende a \\(\\pm \\infty\\) , il polinomio si comporta come si comporterebbe il monomio di grado pi\u00f9 grande. Esempio di comportamento del poliniomio rispetto al suo grado maggiore \\[ \\limit \\min -2x^5+3x^2 = \\limit \\min -2x^5 = -2(\\min)^5 = (-2)(\\min) = \\pin \\]","title":"Limiti di poliniomi"},{"location":"AnalisiI/limiti/#funzioni-razionali","text":"Una funzione razionale \u00e8 una funzione \\(\\frac {p(x)} {q(x)}\\) dove p e q sono polinomi: \\[ \\displaylines{ p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0 \\\\ q(x) = b_m \\cdot x^m + b_{m-1} \\cdot x^{m-1} + ... + b_{1} \\cdot x + b_0 } \\] Quindi il limite della funzione sar\u00e0 equivalemtne al conto che si fa con i polinomi: \\[ \\displaylines{ \\limit {\\pm \\infty} \\frac {p(x)} {q(x)} = \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0} {b_mx^m + b_{m-1}x^{m-1} + ... + b_1x + b_0} \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n} {b_mx^m} } \\] Esempio di funzioni razionali \\[ \\displaylines{ \\limit \\pin \\frac {7x^4 + 5x^2} {-2x^3 + x} = \\\\ = \\limit \\pin \\frac {7x^4} {-2x^3} = \\\\ = \\limit \\pin \\frac {7x} {-2} = \\min } \\] In questo caso abbiamo un eccesso di grado al numeratore (al numeratore abbiamo un grado 4, al denominatore abbiamo un grado 3), quindi il limite va a \\(\\pm \\infty\\) a seconda del sengno dei coefficienti. Se fosse successo l'opposto (il grado del denominatore suepriore al grado del numeratore), il limite sarebbe andato a 0 Se invece il grado fosse stato lo stesso, il limite sarebbe andato al rapporto dei coefficenti tra i termini di grado maggiore.","title":"Funzioni razionali"},{"location":"AnalisiI/limiti/#altri-limiti-fondamentali","text":"\\[ \\displaylines{ \\limit \\pin e^x = \\pin \\\\ \\limit \\min e^x = 0^+ \\\\ \\limit {0^+} log(x) = \\min \\\\ \\limit \\pin log(x) = \\pin \\\\ } \\]","title":"Altri limiti fondamentali"},{"location":"AnalisiI/limiti/#limiti-notevoli","text":"\\(\\limit 0 \\frac {sin(x)} x = 1\\) Questo limite \u00e8 una forma indeterminata, in quanto il \\(\\limit 0 sin(x) = 0\\) , mentre il \\(\\limit 0 x = 0\\) , tuttavi si pu\u00f2 dimostrare che il limite faccia uno. Dimostrazione - Da fare //TODO - work in progress Guadando una circonferenza, pu\u00f2 essere facile dire che la tangente \u00e8 sempre pi\u00f9 grande del seno per lo stesso valore di x (per il primo quadrante). \\[ \\displaylines{ |sin(x)| \\le x \\le |tan(x)| = \\\\ = |sin(x)| \\le x \\le |\\frac {sin(x)}{cos(x)}| = \\quad (\\cdot \\frac 1 {|sin(x)|})\\\\ = \\frac {|sin(x)|} {|sin(x)|} \\le \\frac x {sin(x)} \\le \\frac {|sin(x)|}{|cos(x)|} \\cdot \\frac 1 {|sin(x)|} = \\\\ = 1 \\le \\frac x {sin(x)} \\le \\frac 1 {cos(x)} = \\quad \\text{ (inversione delle frazioni) }\\\\ = 1 \\ge \\frac {sin(x)} x \\ge cos(x) \\\\ \\\\ \\limit 0 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge \\limit 0 cos(x) = \\\\ = 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge 1 \\Rightarrow \\limit 0 \\frac {sin(x)} x = 1 } \\] Da questo limite se ne possono poi dimostrare altri: \\(\\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2\\) Dimostrazione \\[ \\displaylines{ \\frac {1 - cos(x)}{x^2} = \\frac {(1 - cos(x)) (1 + cos(x))}{x^2 (1 + cos(x))} \\\\ = \\frac {1 - cos^2 (x)} {x^2 (1 + cos(x))} = \\frac {sin^2 (x)}{x^2 1 + cos(x)} = \\\\ = \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} \\\\ \\\\ \\limit 0 \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} = 1 \\cdot 1 \\cdot \\frac 1 {1+1} = \\\\ = \\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2 } \\] \\(\\limit 0 \\frac {e^x -1} x = 1\\) \\(\\limit 0 \\frac {log(1 + x)} x = 1\\) \\(\\limit {0^+} x \\cdot \\log(x) = 0 \\cdot (\\min)\\) (forma indeterminata) Per questa si effettua il cambio di variabile, quindi \\(y=log(x), x = e^y\\) Se \\(x \\to 0^+ \\Rightarrow y = log(x) \\to \\min\\) \\(\\lim_{y \\to \\min} e^y \\cdot y\\) (questa \u00e8 ancora una forma indeterminata, \\(e^\\min \\cdot (\\min) = 0^+ \\cdot (\\min)\\) ) Quindi \u00e8 necessario fare un ulteriore cambio di variabile: \\(z = -y\\) , quindi se \\(y \\to \\min \\Rightarrow z \\to \\pin\\) \\(\\lim_{y \\to \\min} e^y \\cdot y = \\lim_{z \\to \\pin} e^{-z} \\cdot -z = \\lim_{z \\to \\pin} \\frac {-z} {e^z} = 0\\) \\(\\lim_{x \\to 0^+} x\\cdot log(x) = 0\\) \\(\\limit {0^+} x^\\alpha log(x)\\) (con \\(\\alpha > 0\\) ); Anche in questo caso dobbiamo ricorrere alla sostituzione: \\(y = x^\\alpha\\) , quindi \\(x = y^{\\frac 1 \\alpha}\\) Se \\(x \\to 0 \\Rightarrow y = x ^ \\alpha \\rightarrow 0\\) \\(\\limit {0^+} x^\\alpha log(x) = \\lim_{y \\to 0^+} y \\cdot log(y^{\\frac 1 \\alpha})\\) \\(= \\lim_{y \\to 0^+} y \\cdot \\frac 1 \\alpha log(y)\\) \\(= \\frac 1 \\alpha \\lim_{y \\to 0^+} y \\cdot log(y) = 0\\) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Dimostrazione \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = (1 + 0)^{\\frac 1 0^+ } = 1^\\pin\\) Questa \u00e8 una forma indeterminata: \\((1 + x)^{\\frac 1 x} = e^{log(1 + x)^{\\frac 1 x}} = e^{\\frac 1 x log(1+x)}\\) Da qui sostituiamo \\(y = \\frac 1 x log(1 + x)\\) Se \\(x \\to 0^+\\) , a quanto deve tendere y? \\(\\limit {0^+} \\frac 1 x log(1 + x) = 1\\) (Limite notevole) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\)","title":"Limiti notevoli"},{"location":"AnalisiI/limiti/#nuovi-casi-di-indeterminazione","text":"\\(f(x) > 0, \\limit {x_0} f(x)^{g(x)}\\) . Quando questa \u00e8 una forma indeterminata? Possiamo manipolare il limite per rendere la domanda pi\u00f9 semplice: \\(f(x)^{g(x)}=e^{log(f(x)^{g(x)})} = e^{g(x) \\cdot log(f(x))}\\) Abbiamo quindi spostato la domanda: quando \u00e8 indeterminato il limite \\(\\limit {x_0} g(x) \\cdot log(f(x))\\) ? Abbiamo 3 casi: \\(g \\to 0, f \\to \\pin \\So log(f) \\to \\pin\\) \\(0 \\cdot \\pin\\) quindi \\((\\pin)^0\\) \u00e8 indeterminata \\(g \\to 0, f\\to 0^+ \\So \\log f \\to \\min\\) \\(\\So g \\cdot \\log(f) = 0 \\cdot (\\min)\\) \\(g \\to \\pm \\infty, f \\to 1\\) , quindi \\(log(f) \\to 0\\) \\(g \\cdot log(f) = \\pm \\infty \\cdot 0\\) \\((1)^{\\pm \\infty}\\) \u00e8 indeterminata Abbiamo quindi 4 nuove forme indeterminate: \\[ (\\pin)^0, \\qquad (0^+)^0, \\qquad (1)^{\\pin}, \\qquad (1)^{\\min} \\] Tutti e quattro i casi si risolvono riscrivendoli nella forma esponenziale Esempio $\\limit {0^+} x^x = \\limit {0^+} e {log(x x)} = $ \\(=\\limit {0^+} e^{x \\cdot log(x)} = e^0 = 1\\) Qui \u00e8 stato \"nascosto\" il cambio di variabile, che sarebbe stato \\(y = x \\cdot log(x)\\) , se \\(x \\to 0^+ \\So y \\to 0\\) \\(\\So \\lim_{y \\to 0} e^y = e^0 = 1\\)","title":"Nuovi casi di indeterminazione"},{"location":"AnalisiI/limiti/#esponenziale","text":"Dato \\(\\limit \\pin a^x\\) , ci sono 3 possibili soluzioni: \\[\\limit \\pin a^x = \\begin{cases} \\pin & \\text{ se } a > 1 1 & \\text{ se } a = 1 0^+ & \\text{ se } 0 < a < 1 \\end{cases} \\] Ovviamente a deve essere maggiore di 0 Se invece vogliamo far tendere \\(x \\to \\min\\) , possiamo effettuare un cambio variabile: \\(y = -x\\) , quindi se \\(x \\to \\min \\Rightarrow y \\to \\pin\\) . Di conseguenza: \\(\\limit \\min a^x = \\lim_{y \\to 1} a^-y = \\lim_{y \\to \\pin} \\frac 1 {a^y}\\) Quindi abbiamo di nuovo 3 casi: \\[ \\lim_{y \\to \\pin} \\frac 1 {a^y} = \\begin{cases} 0^+ & \\text{ se } a > 1 1 & \\text{ se } a = 1 \\pin & \\text{ se } 0 < a < 1 \\end{cases} \\] I risultati sono anche facilmente visibili: \\(a >1\\) \\(0<a<1\\)","title":"Esponenziale"},{"location":"AnalisiI/limiti/#potenze","text":"Consideriamo \\(\\alpha \\in \\reals\\) e quindi \\(x^\\alpha\\) Observation Notare che se si consdiera \\(x^\\alpha\\) con \\(\\alpha\\) non razionale, si \u00e8 forzati a prendere \\(x>0\\) (\u00e8 pari o dispari \\(\\pi\\) ?) Quindi, \\(\\limit \\pin x^\\alpha\\) vale: \\[ \\limit \\pin x^\\alpha = \\begin{cases} \\pin & \\text{ se } \\alpha > 0 \\\\ 1 & \\text{ se } \\alpha = 0 \\\\ 0^+ & \\text{ se } \\alpha < 0 \\end{cases} \\]","title":"Potenze"},{"location":"AnalisiI/limiti/#limite-della-composizione-di-funzioni","text":"Teorema del Limite della composizione di funzioni \\(A, B \\subset \\reals, f: A \\rightarrow B, g: B \\rightarrow \\reals\\) \\(x_0 \\in Acc(A)\\) Se esiste \\(\\limit {x_0} f(x) = y_0\\) , e \\(y_0 \\in Acc(B)\\) e \\(\\exists \\lim_{y \\rightarrow y_0} g(y) = L \\in \\bar \\reals\\) E se \u00e8 verificata almeno una delle seguenti due ipotesi: \\(y_0 \\in B\\) e g \u00e8 continua in \\(y_0\\) \\(\\exists u\\) intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\ne y_0\\) Allora \\(\\limit {x_0} (g \\circ f)(x) = L\\) , dove L \u00e8 il limite di g Quindi \\(\\limit {x_0} (g \\circ f)(x) = \\lim_{y \\rightarrow y_0} g(y)\\) Esempio dell'uso del teorema Calcoliamo \\(\\limit \\min arctg(x^2)\\) Il limite \u00e8 una composizione: \\(f(x) = x^2\\) , \\(g(y) = arctg(y)\\) \\((g \\circ f)(x) = g(f(x)) = g(x^2) = arctg(x^2)\\) \\(x_0 = \\min\\) , \\(y_0 = \\limit {x_0} f(x) = \\limit \\min x^2 = \\pin\\) A questo punto dobbiamo rendeci conto del caso in cui ci troviamo: Il primo caso non \u00e8 verificato in quanto \\(y_0 = \\pin\\) e non appartiene al dominio di g Il secondo caso \u00e8 verificato, perch\u00e9 \\(f(x) \\ne y_0 \\Rightarrow f(x) \\ne \\pin\\) , che \u00e8 sempre vero. Procediamo quindi applicando il teorema: \\(\\lim_{y \\to y_0} g(y) = \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) Quindi \\(\\limit \\min arctg(x^2) = \\frac \\pi 2\\) Osservazione: la soluzione appena vista \u00e8 un teorema di cambiamento di variabile Riprendendo l'esempio appena visto, siamo partiti da \\(\\limit \\min arctg(x^2)\\) . Cambiamo poi variabile e poniamo \\(y=x^2\\) , tuttavia troviamo la x anche come argomento del limite (che tende a \\(\\min\\) ). Quindi se \\(x \\to \\min\\) a quanto tende y? Basta fare \\(\\limit \\min y = \\limit \\min x^2 = \\pin\\) Cambiando variabile otteniamo quindi: \\(\\limit \\min arctg(x^2) \\Rightarrow \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) La seconda ipotesi nel teorema necessaria perch\u00e9 se la composizione tra due funzioni va a toccare in modo insistente il punto limite, dato che il secondo limite non si interessa di quanto valga la funzione nel centro dell'intorno, e dato che la funzione f va solo nel centro dell'intorno \"non si pu\u00f2 accorgere di quel che sta succedendo(?)\" Uso dell'ipotesi due nel problema \\(f: \\reals \\to \\reals \\quad f(x) = 1 \\quad \\forall x \\in \\reals\\) \\(x_0 = 0\\) \\(g(x) = \\begin{cases} 3 \\text{ se } y=1 \\\\ 5 \\text{ se } y \\ne 1 \\\\ \\end{cases}\\) \\(g: \\reals \\to \\reals\\) \\((g \\circ f)(x) = g(f(x)) = g(1) = 3 \\forall x \\in \\reals\\) Quindi la funzione \\((g \\circ f)(x)\\) \u00e8 sempre 3. Il limite di una funzione costante \u00e8 quindi una costante: \\(\\limit 0 (g \\circ f)(x) = 3\\) Prendendo poi come \\(y_0 = \\limit {x_0} f(x) = \\limit 0 f(x) = 1\\) , e quindi: \\(\\limit {x_0} (g \\circ f)(x) \\ne \\lim_{y \\to y_0} g(y)\\) Per\u00f2 non vale nessuna delle due ipotesi","title":"Limite della composizione di funzioni"},{"location":"AnalisiI/limiti/#confronti-tra-infiniti","text":"Dato un limite del tipo \\(\\limit \\pin \\frac {a^x}{x^\\alpha}\\) , abbiamo: \\[\\limit \\pin \\frac {a^x}{x^\\alpha} = \\begin{cases} \\pin & \\text{ se } a > 1 0^+ & \\text{ se } 0< a < 1 \\end{cases} \\] Se \\(a=1 \\Rightarrow a^x = 1\\) , quindi \\(\\lim \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac 1 {x^\\alpha}\\) Quindi quello che domina i limite \u00e8 l'a al numeratore, ovvero l'esponenziale, che vince sulla potenza. L'unico caso in cui l'esponenziale non guida la funzione \u00e8 quando a \u00e8 pari ad 1. Esempio \\(a=\\frac 1 2 \\quad \\alpha = -3\\) \\[ \\limit \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac {(\\frac 1 2)^x} {x^{-3}} = \\limit \\pin \\frac {x^3}{2^x} = 0^+ \\] Anche in questo caso quello che domina il limite \u00e8 l'esponenziale (il \\(2^x\\) al denominatore), che \u00e8 molto pi\u00f9 veloce rispetto alla potenza","title":"Confronti tra infiniti"},{"location":"AnalisiI/limiti/#confronto-tra-logaritmo-e-potenza","text":"Quando abbiamo a che fare con un logaritmo, conviene usare il cambio di variabile e sostituirlo (come mostrato nell'esempio) Esempio: cambio di potenza del logaritmo \\(\\limit \\pin \\frac {log(x)} x\\) , quindi facciamo il cambio di variabile \\(y = log(x)\\) (e quindi \\(x = e^x\\) una volta effettuato il cambio variabile nel limite) Se \\(x \\to \\pin \\Rightarrow \\limit \\pin log(x) = \\pin\\) \\(( y = log(x) \\to \\pin)\\) \\(\\limit \\pin \\frac {log (x)} x = \\lim_{y \\to \\pin} \\frac y {e^y} = 0\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha}\\) , \\(\\alpha, \\beta \\in \\reals\\) , \\(\\alpha, \\beta > 0\\) Anche in questo caso iniziamo con il cambio di variabile \\(y = log(x) \\Rightarrow x=e^y\\) Quindi se \\(x \\to \\pin\\) (se x tende a \\(\\pin\\) ), \\(\\Rightarrow y \\to \\pin\\) (allora anche y tende a \\(\\pin\\) ) Risostituiamo inoltre x con \\(e^y\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^y)^\\alpha} =\\) \\(=\\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^{y \\cdot \\alpha}} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^\\alpha)^y} =\\) Assegnamo quindi ad \\(a = e^\\alpha\\) : \\(\\lim_{y \\to \\pin} \\frac {y^\\beta}{a^y}\\) Da qui sappiamo che \\(\\alpha > 0\\) e quindi \\(e^\\alpha > 1\\) Questo limite ha quindi come risultato 0, perch\u00e9 l'esponenziale al denominatore porta a 0 il denominatore","title":"Confronto tra logaritmo e potenza"},{"location":"AnalisiI/prerequisiti/","text":"Calcolo differenziale - funzioni Insiemi numerici \u00b6 Introduciamo il concectto di insiemi numerici; In questo caso ci limitiamo a trattarne 4: \\(\\mathbb N\\) : Numeri interi non negativi (0, 1, 2, 3, ...) \\(\\mathbb Z\\) : Numeri interi positivi e negativi (-2, -1, 0, 1, 2, ...) \\(\\mathbb Q\\) : Numeri razionali (classi di equivalenza di frazioni \\(\\frac{p}{q}\\) con \\(p,q \\in \\mathbb Z, q \\ne 0\\) ) \\(\\mathbb R\\) : Numeri reali. Razionali e \"non\" (e.g. \\(\\sqrt 2, \\pi, e\\) ) Intervalli \u00b6 Intervalli di \\(\\mathbb R\\) \\(I \\in \\mathbb R\\) si dice intervallo se \\(\\forall x,y \\in I\\) con \\(x < y\\) , dato \\(z\\) tale che \\(x < z < y\\) risulta che \\(z \\in I\\) Ovvero dati due elementi, \u00e8 possibile trovare un elemento \"in mezzo\" ai due, che a sua volta far\u00e0 parte dell'intervallo. Tipi di intervallo \u00b6 Ci possono essere diversi tipi di intervallo Aperto \u00b6 In un intervallo aperto, scritto come (a,b) , gli estremi sono esclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a < x < b \\}\\) Chiuso \u00b6 In un intervallo chiuso, scritto come (a,b) , gli estremi sono inclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a \\le x \\le b \\}\\) Semiaperto/semichiuso \u00b6 Un intervallo semiaperto o semichiuso \u00e8 un mix dei due tipi appena descritti, in cui i due estremi sono discordi: \\([a,b) = \\{ x \\in \\mathbb R | a \\le x < b \\}\\) \\((a,b] = \\{ x \\in \\mathbb R | a < x \\le b \\}\\) Semiretta \u00b6 Esiste poi un ulteriore tipo di intervallo, chiamato semiretta, che include l'infinito come uno dei due estremi. Anche questo pu\u00f2 essere sia chiuso, che aperto, e possono essere sia a destra che a sinistra. Una semiretta \u00e8 aperta o chiusa si riferisce al termine razionale: Una semiretta chiusa a destra : \\([a, + \\infty ) = \\{ x \\in \\mathbb R | a \\le x \\}\\) Una semiretta aperta a sinistra : \\((- \\infty, a) = \\{ x \\in \\mathbb R | a > x \\}\\) Con il simbolo \\((- \\infty, + \\infty)\\) si intende tutta la retta reale. Funzioni \u00b6 Una funzione \u00e8 una terna di oggetti \\((A,B,f)\\) , dove: A e B sono insiemi e, A si dice dominio, B si dice codominio ed f \u00e8 una legge che lega gli elementi di A a quelli di B. Il simbolo matematico \u00e8 \\(f: A \\rightarrow B\\) F mette in corrispondenza ogni elemento di A con uno ed un solo elemento di B. Immagine attraverso f Data una funzione \\(f: A \\rightarrow B\\) e \\(D \\subset A\\) e \\(f(D) = \\{ f(x) : x \\in D \\}\\) \\(f(D)\\) si dice immagine di D attraverso f. \\(f(D) \\subset B\\) Immagine Quando si parla invece di immagine (di f), si intende immagine di tutto il dominio, quindi: \\(Imm(f) = f(A)\\) Funzioni surgettive ed iniettive \u00b6 Vediamo quindi i concetti di surgettivit\u00e0 ed iniettivit\u00e0: Surgettivit\u00e0 \u00b6 Surgettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice surgettiva se \\(\\forall y \\in \\exists \\text{ almeno un elemento } x \\in A\\) tale che (t.c.) \\(f(x) = y\\) . Che significa che ogni elemento nel codominio \"proviene\" da un elemento del dominio (nel codominio non ci sono elementi \"scoperti\") Cambiamento del dominio per rendere una funzione surgettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 surgettiva. Questo perch\u00e9 nessun numero razionale elevato al quadrato restituir\u00e0 un valore negativo. La funzione non \u00e8 quindi surgettiva La stessa funzione ma definita come \\(g: \\mathbb R \\rightarrow [0, + \\infty )\\) \u00e8 surgettiva. Possiamo quindi dire che una funzione \u00e8 surgettiva solo se la sua immagine coincide con il codominio. Per capire velocemente da un grafico se una funzione \u00e8 surgettiva, possiamo pensare di tracciare una linea orizzontale, se non intercetta almeno una volta la funzione, questa non \u00e8 surgettiva: La funzione NON \u00e8 surgettiva poich\u00e9 la retta orizzontale blu ( \\(y=2\\) ) non intercetta mai la funzione ( \\(y=|x|\\) ) Iniettivit\u00e0 \u00b6 Iniettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice iniettiva se \\(\\forall x_1,x_2 \\in A \\text{ con } x_1 \\ne x_2 \\text{ risulta che } f(x_1) \\ne f(x_2)\\) La funzione \u00e8 monotona (cresce o decresce e basta; Non si \"appiattisce) Se una funzione non \u00e8 iniettiva, ci possono comunque essere dei \"trucchi\" che ci consentono di farla diventare iniettiva, ad esempio scartando parte del dominio. Cambiamento del dominio per rendere una funzione iniettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 iniettiva. La stessa funzione ma definita come \\(g: [0, + \\infty ) \\rightarrow \\mathbb R\\) \u00e8 iniettiva. Per capire velocemente da un grafico se una funzione \u00e8 iniettiva, possiamo pensare di tracciare una linea orizzontale, se questa intercetta pi\u00f9 di una volta la funzione, questa non \u00e8 iniettiva: La funzione NON \u00e8 iniettiva poich\u00e9 la retta orizzontale blu ( \\(y=5\\) ) intercetta pi\u00f9 volte la funzione ( \\(y=x\\cdot |sin(x)|\\) ) Funzione bigettiva \u00b6 Funzione bigettiva una funzione \\(f\\) si dice bigettiva/biunivoca/invertibile se \u00e8 sia iniettiva che surgettiva Se una funzione \u00e8 bigettiva posso costruire la funzione inversa \\(f^{-1}: B \\rightarrow A\\) . Datp un elemento \\(b \\in B\\) esiste un elemento \\(a \\in A\\) tale che \\(f(a) = b\\) (perch\u00e9 f \u00e8 surgettiva). L'elemento a \u00e8 unico perch\u00e9 f \u00e8 iniettiva quindi \\(f^{-1}(b)=a \\Leftrightarrow f(a) = b\\) La radice quadrata \u00e8 la funzione inversa di f(x) = x^2 qunado dominio e codominio sono entrambi [0,+ \\infty) Che \u00e8 come mai \\sqrt 2 = 2 (che \u00e8 diverso da dire che x^2 =4, che ha due soluzioni) Per questo motivo \\sqrt {x^2} = |x| Propriet\u00e0 dai grafici \u00b6 Tralaslazione \u00b6 Possiamo traslare le funzioni sul grafico in ogni modo vogliamo: Prendendo una funzione come \\((\\frac{1}{2}x)^2\\) : Possiamo effettuare ogni traslazione desiderata: Traslazione verso l'alto : Abbiamo una traslazione verso l'alto quando al valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) + n \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x)^2+5\\) ) Traslazione verso il basso : Abbiamo una traslazione verso il basso quando al valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) - n \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x)^2-5\\) ) Traslazione verso sinistra : Abbiamo una traslazione verso sinistra quando all'argomento/valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x+n) \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x+5)^2\\) ) Traslazione verso destra : Abbiamo una traslazione verso destra quando all'argomento/valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x-n) \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x-5)^2\\) ) Valore assoluto \u00b6 Il valore assoluto coincide con la funzione \\(f\\) dove \\(f\\) \u00e8 positiva ed \u00e8 l'opposto dove \\(f\\) \u00e8 negativa: \\[ |f(x)| = \\begin{equation} \\begin{cases} f(x) \\text{ quando } x \\ge 0 \\\\ -f(x) \\text{ altrimenti} \\end{cases}\\,. \\end{equation} \\] Specchiamento \u00b6 \u00c8 possibile specchiare una funzione sia rispetto all'ascisse (sempre) che rispetto all'ordinata (quando il dominio \u00e8 simmetrico rispetto all'origine). Specchiamento Rispetto all'ascisse Rispetto all'ordinata Grafico Funzione \\(-f(x)\\) \\(f(-x)\\) Esempio nel grafico \\(y=-((0.5 \\cdot x+2)^2+2)\\) \\(y=(0.5 \\cdot -x+2)^2+2\\) Notare che nello specchiamento rispetto all'ordinata, il dominio deve essere simmetrico rispetto all'origine, e quindi permettere lo specchiamento. Funzioni invertibili \u00b6 Se f \u00e8 una funzione invertibile, i grafici di \\(f\\) e \\(f^{-1}\\) sono simmetrici rispetto alla retta \\(y=x\\) In questo esempio, possiamo vedere come la funzione blu ( \\(x^2\\) ) e la funzione verde ( \\(\\sqrt{2}\\) ) sono simmetriche rispetto alla retta gialla ( \\(y=x\\) ) Se il punto (2,4) appartiene al grafico di f, allora il punto (4,2) appartiene al grafico di g Funzioni m\u00f2n\u00f3t\u00f2ne \u00b6 La monotonia \u00e8 una propriet\u00e0 che riguarda strettamente la crescenza o la decrescenza delle funzioni Funzione monotona Dati \\(A, B \\subset \\mathbb R \\text{ e } x_1,x_2 \\in A \\text{ con } x_1 < x_2\\) Se \\(\\forall x_1,x_2\\) risulta che: \\(f(x_1) < f(f_2)\\) : f si dice strettamente crescente \\(f(x_1) \\le f(f_2)\\) : f si dice debolmente crescente \\(f(x_1) > f(f_2)\\) : f si dice strettamente decrescente \\(f(x_1) \\ge f(f_2)\\) : f si dice debolmente decrescente Se si verificano il caso 1 o 3, f si dice strettamente m\u00f2n\u00f3t\u00f2na Se si verificano il caso 2 o 4, f si dice debolmente m\u00f2n\u00f3t\u00f2na Una funzione (debolmente) crescente quindi, aumenter\u00e0 sempre di valore (o comunque non diminuir\u00e0) man mano che \\(x\\) cresce. Per essere strettamente crescente, la funzione non deve avere mai due soluzioni uguali in due punti diversi. Per una funzione decrescente, vale lo stesso discorso, ma \\(x\\) diminuir\u00e0 sempre di valore invece di crescere. Se una funzione ha un tratto \"orizzontale\", quella funzione non sar\u00e0 strettamente monotona. Se una funzione \u00e8 strettamente crescente/decrescente, lo sar\u00e0 anche debolmente. Rapporto incrementale \\(f\\) \u00e8 strettamente crescente se e solo se \\(\\frac{f(x_1) - f(x_2)}{x_1 - x_2} > 0\\) (questo \u00e8 il rapporto incrementale, \\(\\frac{\\Delta X}{\\Delta Y}\\) , che misura quanto \\(f\\) si \u00e8 spostata in rapporto a quanto \u00e8 stata spostata l'ascissa in orizzontale). Ovviamente con \\(x_1 \\neq x_2\\) . Dire che una funzione \u00e8 crescente significa dire che i rapporti incrementali sono positivi, e quindi che sia numeratore che denominatore sono concordi in segno. (Per lo \"strettamente\", occorre che il \\(\\Delta Y\\) sia diverso da 0). L'opposto vale per essere decrescente. Quando abbiamo una funzione come \\(\\frac 1 x\\) , come definiamo la funzione? Nel caso della funzione \\(\\frac 1 x\\) (un ramo di iperbole), in alcuni punti della funzione le coppie \\(x_1\\) , \\(x_2\\) mantengono l'ordinamento (ad esempio con \\(x_2 = 10\\) e \\(x_1 = 5\\) , \\(f(x_1)>f(x_2)\\) ), facendo risultare la funzione decrescente; in altre lo invertono (ad esempio per \\(x_2 = 20\\) e \\(x_1 = -20\\) , avendo quindi \\(f(x_1) < f(x_2)\\) ). Questo significa che questa funzione non \u00e8 globalmente monotona, ma \u00e8 decrescente su due intervalli: \\(f\\) \u00e8 decrescente \\((- \\infty, 0)\\) e in \\((0, \\infty)\\) , ma non in tutto il suo dominio ( \\(\\mathbb R \\backslash \\{0\\}\\) ). Composizione di funzioni monotone \u00b6 Proposizione Avendo: \\(A,B,C \\subset \\mathbb R\\) \\(f: A \\rightarrow B\\) \\(g: B \\rightarrow C\\) Allora: Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e \\(g\\) \u00e8 crescente \\(\\nearrow\\) , allora \\(g \\circ f\\) (g composto f) \u00e8 crescente \\(\\nearrow\\) Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e g \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 decrescente \\(\\searrow\\) (e viceversa) Se \\(f\\) \u00e8 decrescente \\(\\searrow\\) e \\(g\\) \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 crescente \\(\\nearrow\\) Quindi: \\(\\nearrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\nearrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) Insieme di definizione L'insieme di definizione (o dominio naturale) di una funzione \u00e8 il pi\u00f9 grande sottoinsieme di \\(\\mathbb R\\) dove ha senso scrivere la funzione Ad esempio nel caso di \\(\\frac 1 x\\) il dominio di definizione \u00e8 \\(\\mathbb \\backslash \\{0\\}\\) Funzione pari e dispari Se \\(f(x) = f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice pari. Se \\(f(x) = -f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice dispari. Questa definizione implica che il dominio di f sia tale che se x appartiene al dominio, allora anche -x appartiene al dominio (\u00e8 simmetrico rispetto allo 0). Funzione periodica \\(f\\) si dice periodica di periodo \\(p\\) con \\(p \\in \\mathbb R\\) se \\(\\forall x, f(x+p) = f(x)\\) Un esempio di una funzione periodica sono le funzioni trigonometriche (seno, coseno, tangente, etc...) Funzioni elementari \u00b6 Retta \u00b6 La retta \u00e8 scritta nella forma \\(f(x) = a \\cdot x + b \\text { con } a,b \\in \\mathbb R\\) a \u00e8 chiamato coefficiente angolare, b \u00e8 chiamato termine noto. Funzione potenza \u00b6 In N \u00b6 \\(f(x) = x^k, k \\in \\mathbb N\\) k pari, grafici sono una parabola (con la sola velocit\u00e0 di crescita che cambia). k dispari, grafici sono una \\(f\\) \u00e8 una funzine pari se \\(k\\) \u00e8 pari ed \u00e8 dispari se \\(k\\) \u00e8 dispari. (questo perch\u00e9 \\(-1^2 = 1\\) e \\(-1^3 = -1\\) ). In Z con k negativo \u00b6 \\(f(x) = x^k \\ k\\in \\mathbb Z; k < 0\\) k dispari iperbole equilatera (primo e terzo quadrante) k pari iperbole (primo e secondo quadrante) anche qui la funzione \u00e8 pari per k pari e dispari per k dispari In R \u00b6 \\(f(x) = x^\\frac p q ; p,q \\in \\mathbb N \\ q \\ne 0\\) La funzione f ha come dominio naturale Quando abbiamo \\(p = 1\\) (quindi \\(x^\\frac 1 q = sqrt[q]{x}\\) , inversa della funzione \\(x^q\\) ) Se q \u00e8 pari, il dominio \u00e8 \\(x \\ge 0\\) (possiamo fare la radice quadrata solo di un positivi), quindi \u00e8 invertibile solo come funzione da [0,+inf] -> [0, +inf] Se q \u00e8 dispari, il dominio \u00e8 \\(\\mathbb R\\) (possiamo fare la radice cubica di un negativo). x^3 \u00e8 una funzione invertibile su tutto R In R e non in Q (irrazionale) \u00b6 \\(f(x) = x^\\alpha, \\alpha \\in \\mathbb R \\ e \\ \\alpha \\notin \\mathbb Q\\) (quindi ad esempio \\(x^{\\sqrt 2}\\) oppure \\(x^\\pi\\) ) \\(x^\\alpha = e^{\\alpha \\cdot log(x)} \\ \\text{ definita per } x>0\\) Questo perch\u00e9: \\(e^{\\alpha log (x)} = (e^{log(x)})^\\alpha = x^\\alpha\\) Per definizione dobbiamo passare attraverso il logaritmo. Il dominio naturale \u00e8 \\((0, +\\infty)\\) Esponenziale \u00b6 con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione esponenziale \u00e8 \\(f(x) = a^x\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente In entrambi i casi la funzione intercetta il punto 1 delle ordinate e sono sempre positive: \\[ a^x > 0 \\forall x \\in \\mathbb R \\] Entrambi le funzioni sono invertibili, poich\u00e9 stettamente crescenti o decrescenti, quindi monotone, quindi iniettive e surgettive. Logaritmo in base a \u00b6 con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione logaritmica \u00e8 \\(f(x) = log_a(x)\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente Intercetta l'ascissa sempre ad 1 e presenta una simmetria (\u00e8 specchiata) rispetto alla bisettrice (y=x) del grafico dell'esponenziale Funzione esponenziale (in base e) \u00b6 Funzione esponenziale con \\(a = e \\cong 2,71\\) \u00e8 invertibile e la sua inversa si chiama logaritmo naturale. (Se la base non \u00e8 specificata, in matematica si intende in base e). Cambio di base del logaritmo \u00b6 Possiamo facilmente effettuare un cambio della base del logaritmo facendo uso di alcune regole matematiche: Il logaritmo \u00e8 la potenza che dobbiamo assegnare ad a per ottenere x: \\(log_a (x) = y \\Leftrightarrow a^y = x\\) Il logaritmo naturale dell'equazione dell'identit\u00e0 \u00e8: \\(log(a^y) = log(x) \\Leftrightarrow y \\cdot log(a) = log(x)\\) , ed abbiamo gi\u00e0 visto y: \\(y = log_a (x)\\) Quindi possiamo sostituire y, per poi semplificarla: \\(log_a (x) \\cdot log (a) = log(x) \\Rightarrow log_a (x) = \\frac{log(x)}{log(a)}\\) Funzioni trigonometriche \u00b6 Seno \u00b6 Il seno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) \\(f(x)=sin \\ x \\qquad f: \\mathbb R \\rightarrow [-1, 1]\\) perch\u00e9 \\(-1 \\le sin(x) \\le 1\\) . La funzione \u00e8 surgettiba se per codominio prendiamo \\([-1, 1]\\) Essendo periodica, \\(sin(x+2 \\pi) = sin(x) \\quad \\forall x \\in \\mathbb R\\) . Essendo il seno sull'asse delle orinate, il cerchio con angolo 0 ha valore 0 sulle ordinate, quindi \\(sin(0) = 0\\) . La funzione \u00e8 invertibile modificando dominio e codominio (quando la funzione \u00e8 definita come \\(f: [ -\\frac \\pi 2 , \\frac \\pi 2 ] \\rightarrow [-1, 1]\\) . f risulta quindi strettamente crescente (quindi monotona, quindi essendo continua, iniettiva) e surgettiva.) Dispari Arcoseno \u00b6 Funzione inversa del seno, definita come \\(f: [-1, 1] \\rightarrow [ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) La funzione arcsin \u00e8 quindi l'inversa del seno quando il dominio \u00e8 \\([ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) ed il codominio \u00e8 \\([-1, 1]\\) Se cos\u00ec non fosse la funzione seno non \u00e8 n\u00e9 iniettiva n\u00e9 surgettiva, e quindi non \u00e8 invertibile. Coseno \u00b6 Il coseno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) La funzione \u00e8 il seno, ma traslata di \\(\\frac \\pi 2\\) (quindi \\(cos(0) = 1\\) ) Pari Arcocoseno \u00b6 Se vogliamo invertire dobbiamo scegliere un intervallo dove la funzione \u00e8 monotona. Possiamo quindi definire il dominio naturle come \\(cos(x): [0, \\pi] \\rightarrow [-1, 1]\\) . Tangente \u00b6 \\(tg (x) = \\frac {sin(x)} {cos(x)}\\) , che quindi non \u00e8 definita se \\(cos(x) = 0\\) . Il dominio \u00e8 quindi \\(\\{ x \\in \\mathbb R: x \\ne \\frac \\pi 2 + k \\cdot \\pi, k \\in \\mathbb Z \\}\\) , composto da infiniti intervalli disgiunti. \u00c8 periodica di periodo \\(\\pi\\) \u00c8 invertibile quando \\(f: (-\\frac \\pi 2 , \\frac \\pi 2 ) \\rightarrow \\mathbb R\\) \u00c8 inoltre dispari Arcotangente \u00b6 \u00c8 l'inversa della tangente \\(arctan: \\mathbb \\rightarrow (-\\frac \\pi 2 , \\frac \\pi 2 )\\) Strettamente crescente nel suo dominio. (Da non invertire con la cotangente)","title":"Funzioni ed introduzione"},{"location":"AnalisiI/prerequisiti/#insiemi-numerici","text":"Introduciamo il concectto di insiemi numerici; In questo caso ci limitiamo a trattarne 4: \\(\\mathbb N\\) : Numeri interi non negativi (0, 1, 2, 3, ...) \\(\\mathbb Z\\) : Numeri interi positivi e negativi (-2, -1, 0, 1, 2, ...) \\(\\mathbb Q\\) : Numeri razionali (classi di equivalenza di frazioni \\(\\frac{p}{q}\\) con \\(p,q \\in \\mathbb Z, q \\ne 0\\) ) \\(\\mathbb R\\) : Numeri reali. Razionali e \"non\" (e.g. \\(\\sqrt 2, \\pi, e\\) )","title":"Insiemi numerici"},{"location":"AnalisiI/prerequisiti/#intervalli","text":"Intervalli di \\(\\mathbb R\\) \\(I \\in \\mathbb R\\) si dice intervallo se \\(\\forall x,y \\in I\\) con \\(x < y\\) , dato \\(z\\) tale che \\(x < z < y\\) risulta che \\(z \\in I\\) Ovvero dati due elementi, \u00e8 possibile trovare un elemento \"in mezzo\" ai due, che a sua volta far\u00e0 parte dell'intervallo.","title":"Intervalli"},{"location":"AnalisiI/prerequisiti/#tipi-di-intervallo","text":"Ci possono essere diversi tipi di intervallo","title":"Tipi di intervallo"},{"location":"AnalisiI/prerequisiti/#aperto","text":"In un intervallo aperto, scritto come (a,b) , gli estremi sono esclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a < x < b \\}\\)","title":"Aperto"},{"location":"AnalisiI/prerequisiti/#chiuso","text":"In un intervallo chiuso, scritto come (a,b) , gli estremi sono inclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a \\le x \\le b \\}\\)","title":"Chiuso"},{"location":"AnalisiI/prerequisiti/#semiapertosemichiuso","text":"Un intervallo semiaperto o semichiuso \u00e8 un mix dei due tipi appena descritti, in cui i due estremi sono discordi: \\([a,b) = \\{ x \\in \\mathbb R | a \\le x < b \\}\\) \\((a,b] = \\{ x \\in \\mathbb R | a < x \\le b \\}\\)","title":"Semiaperto/semichiuso"},{"location":"AnalisiI/prerequisiti/#semiretta","text":"Esiste poi un ulteriore tipo di intervallo, chiamato semiretta, che include l'infinito come uno dei due estremi. Anche questo pu\u00f2 essere sia chiuso, che aperto, e possono essere sia a destra che a sinistra. Una semiretta \u00e8 aperta o chiusa si riferisce al termine razionale: Una semiretta chiusa a destra : \\([a, + \\infty ) = \\{ x \\in \\mathbb R | a \\le x \\}\\) Una semiretta aperta a sinistra : \\((- \\infty, a) = \\{ x \\in \\mathbb R | a > x \\}\\) Con il simbolo \\((- \\infty, + \\infty)\\) si intende tutta la retta reale.","title":"Semiretta"},{"location":"AnalisiI/prerequisiti/#funzioni","text":"Una funzione \u00e8 una terna di oggetti \\((A,B,f)\\) , dove: A e B sono insiemi e, A si dice dominio, B si dice codominio ed f \u00e8 una legge che lega gli elementi di A a quelli di B. Il simbolo matematico \u00e8 \\(f: A \\rightarrow B\\) F mette in corrispondenza ogni elemento di A con uno ed un solo elemento di B. Immagine attraverso f Data una funzione \\(f: A \\rightarrow B\\) e \\(D \\subset A\\) e \\(f(D) = \\{ f(x) : x \\in D \\}\\) \\(f(D)\\) si dice immagine di D attraverso f. \\(f(D) \\subset B\\) Immagine Quando si parla invece di immagine (di f), si intende immagine di tutto il dominio, quindi: \\(Imm(f) = f(A)\\)","title":"Funzioni"},{"location":"AnalisiI/prerequisiti/#funzioni-surgettive-ed-iniettive","text":"Vediamo quindi i concetti di surgettivit\u00e0 ed iniettivit\u00e0:","title":"Funzioni surgettive ed iniettive"},{"location":"AnalisiI/prerequisiti/#surgettivita","text":"Surgettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice surgettiva se \\(\\forall y \\in \\exists \\text{ almeno un elemento } x \\in A\\) tale che (t.c.) \\(f(x) = y\\) . Che significa che ogni elemento nel codominio \"proviene\" da un elemento del dominio (nel codominio non ci sono elementi \"scoperti\") Cambiamento del dominio per rendere una funzione surgettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 surgettiva. Questo perch\u00e9 nessun numero razionale elevato al quadrato restituir\u00e0 un valore negativo. La funzione non \u00e8 quindi surgettiva La stessa funzione ma definita come \\(g: \\mathbb R \\rightarrow [0, + \\infty )\\) \u00e8 surgettiva. Possiamo quindi dire che una funzione \u00e8 surgettiva solo se la sua immagine coincide con il codominio. Per capire velocemente da un grafico se una funzione \u00e8 surgettiva, possiamo pensare di tracciare una linea orizzontale, se non intercetta almeno una volta la funzione, questa non \u00e8 surgettiva: La funzione NON \u00e8 surgettiva poich\u00e9 la retta orizzontale blu ( \\(y=2\\) ) non intercetta mai la funzione ( \\(y=|x|\\) )","title":"Surgettivit\u00e0"},{"location":"AnalisiI/prerequisiti/#iniettivita","text":"Iniettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice iniettiva se \\(\\forall x_1,x_2 \\in A \\text{ con } x_1 \\ne x_2 \\text{ risulta che } f(x_1) \\ne f(x_2)\\) La funzione \u00e8 monotona (cresce o decresce e basta; Non si \"appiattisce) Se una funzione non \u00e8 iniettiva, ci possono comunque essere dei \"trucchi\" che ci consentono di farla diventare iniettiva, ad esempio scartando parte del dominio. Cambiamento del dominio per rendere una funzione iniettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 iniettiva. La stessa funzione ma definita come \\(g: [0, + \\infty ) \\rightarrow \\mathbb R\\) \u00e8 iniettiva. Per capire velocemente da un grafico se una funzione \u00e8 iniettiva, possiamo pensare di tracciare una linea orizzontale, se questa intercetta pi\u00f9 di una volta la funzione, questa non \u00e8 iniettiva: La funzione NON \u00e8 iniettiva poich\u00e9 la retta orizzontale blu ( \\(y=5\\) ) intercetta pi\u00f9 volte la funzione ( \\(y=x\\cdot |sin(x)|\\) )","title":"Iniettivit\u00e0"},{"location":"AnalisiI/prerequisiti/#funzione-bigettiva","text":"Funzione bigettiva una funzione \\(f\\) si dice bigettiva/biunivoca/invertibile se \u00e8 sia iniettiva che surgettiva Se una funzione \u00e8 bigettiva posso costruire la funzione inversa \\(f^{-1}: B \\rightarrow A\\) . Datp un elemento \\(b \\in B\\) esiste un elemento \\(a \\in A\\) tale che \\(f(a) = b\\) (perch\u00e9 f \u00e8 surgettiva). L'elemento a \u00e8 unico perch\u00e9 f \u00e8 iniettiva quindi \\(f^{-1}(b)=a \\Leftrightarrow f(a) = b\\) La radice quadrata \u00e8 la funzione inversa di f(x) = x^2 qunado dominio e codominio sono entrambi [0,+ \\infty) Che \u00e8 come mai \\sqrt 2 = 2 (che \u00e8 diverso da dire che x^2 =4, che ha due soluzioni) Per questo motivo \\sqrt {x^2} = |x|","title":"Funzione bigettiva"},{"location":"AnalisiI/prerequisiti/#proprieta-dai-grafici","text":"","title":"Propriet\u00e0 dai grafici"},{"location":"AnalisiI/prerequisiti/#tralaslazione","text":"Possiamo traslare le funzioni sul grafico in ogni modo vogliamo: Prendendo una funzione come \\((\\frac{1}{2}x)^2\\) : Possiamo effettuare ogni traslazione desiderata: Traslazione verso l'alto : Abbiamo una traslazione verso l'alto quando al valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) + n \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x)^2+5\\) ) Traslazione verso il basso : Abbiamo una traslazione verso il basso quando al valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) - n \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x)^2-5\\) ) Traslazione verso sinistra : Abbiamo una traslazione verso sinistra quando all'argomento/valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x+n) \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x+5)^2\\) ) Traslazione verso destra : Abbiamo una traslazione verso destra quando all'argomento/valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x-n) \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x-5)^2\\) )","title":"Tralaslazione"},{"location":"AnalisiI/prerequisiti/#valore-assoluto","text":"Il valore assoluto coincide con la funzione \\(f\\) dove \\(f\\) \u00e8 positiva ed \u00e8 l'opposto dove \\(f\\) \u00e8 negativa: \\[ |f(x)| = \\begin{equation} \\begin{cases} f(x) \\text{ quando } x \\ge 0 \\\\ -f(x) \\text{ altrimenti} \\end{cases}\\,. \\end{equation} \\]","title":"Valore assoluto"},{"location":"AnalisiI/prerequisiti/#specchiamento","text":"\u00c8 possibile specchiare una funzione sia rispetto all'ascisse (sempre) che rispetto all'ordinata (quando il dominio \u00e8 simmetrico rispetto all'origine). Specchiamento Rispetto all'ascisse Rispetto all'ordinata Grafico Funzione \\(-f(x)\\) \\(f(-x)\\) Esempio nel grafico \\(y=-((0.5 \\cdot x+2)^2+2)\\) \\(y=(0.5 \\cdot -x+2)^2+2\\) Notare che nello specchiamento rispetto all'ordinata, il dominio deve essere simmetrico rispetto all'origine, e quindi permettere lo specchiamento.","title":"Specchiamento"},{"location":"AnalisiI/prerequisiti/#funzioni-invertibili","text":"Se f \u00e8 una funzione invertibile, i grafici di \\(f\\) e \\(f^{-1}\\) sono simmetrici rispetto alla retta \\(y=x\\) In questo esempio, possiamo vedere come la funzione blu ( \\(x^2\\) ) e la funzione verde ( \\(\\sqrt{2}\\) ) sono simmetriche rispetto alla retta gialla ( \\(y=x\\) ) Se il punto (2,4) appartiene al grafico di f, allora il punto (4,2) appartiene al grafico di g","title":"Funzioni invertibili"},{"location":"AnalisiI/prerequisiti/#funzioni-monotone","text":"La monotonia \u00e8 una propriet\u00e0 che riguarda strettamente la crescenza o la decrescenza delle funzioni Funzione monotona Dati \\(A, B \\subset \\mathbb R \\text{ e } x_1,x_2 \\in A \\text{ con } x_1 < x_2\\) Se \\(\\forall x_1,x_2\\) risulta che: \\(f(x_1) < f(f_2)\\) : f si dice strettamente crescente \\(f(x_1) \\le f(f_2)\\) : f si dice debolmente crescente \\(f(x_1) > f(f_2)\\) : f si dice strettamente decrescente \\(f(x_1) \\ge f(f_2)\\) : f si dice debolmente decrescente Se si verificano il caso 1 o 3, f si dice strettamente m\u00f2n\u00f3t\u00f2na Se si verificano il caso 2 o 4, f si dice debolmente m\u00f2n\u00f3t\u00f2na Una funzione (debolmente) crescente quindi, aumenter\u00e0 sempre di valore (o comunque non diminuir\u00e0) man mano che \\(x\\) cresce. Per essere strettamente crescente, la funzione non deve avere mai due soluzioni uguali in due punti diversi. Per una funzione decrescente, vale lo stesso discorso, ma \\(x\\) diminuir\u00e0 sempre di valore invece di crescere. Se una funzione ha un tratto \"orizzontale\", quella funzione non sar\u00e0 strettamente monotona. Se una funzione \u00e8 strettamente crescente/decrescente, lo sar\u00e0 anche debolmente. Rapporto incrementale \\(f\\) \u00e8 strettamente crescente se e solo se \\(\\frac{f(x_1) - f(x_2)}{x_1 - x_2} > 0\\) (questo \u00e8 il rapporto incrementale, \\(\\frac{\\Delta X}{\\Delta Y}\\) , che misura quanto \\(f\\) si \u00e8 spostata in rapporto a quanto \u00e8 stata spostata l'ascissa in orizzontale). Ovviamente con \\(x_1 \\neq x_2\\) . Dire che una funzione \u00e8 crescente significa dire che i rapporti incrementali sono positivi, e quindi che sia numeratore che denominatore sono concordi in segno. (Per lo \"strettamente\", occorre che il \\(\\Delta Y\\) sia diverso da 0). L'opposto vale per essere decrescente. Quando abbiamo una funzione come \\(\\frac 1 x\\) , come definiamo la funzione? Nel caso della funzione \\(\\frac 1 x\\) (un ramo di iperbole), in alcuni punti della funzione le coppie \\(x_1\\) , \\(x_2\\) mantengono l'ordinamento (ad esempio con \\(x_2 = 10\\) e \\(x_1 = 5\\) , \\(f(x_1)>f(x_2)\\) ), facendo risultare la funzione decrescente; in altre lo invertono (ad esempio per \\(x_2 = 20\\) e \\(x_1 = -20\\) , avendo quindi \\(f(x_1) < f(x_2)\\) ). Questo significa che questa funzione non \u00e8 globalmente monotona, ma \u00e8 decrescente su due intervalli: \\(f\\) \u00e8 decrescente \\((- \\infty, 0)\\) e in \\((0, \\infty)\\) , ma non in tutto il suo dominio ( \\(\\mathbb R \\backslash \\{0\\}\\) ).","title":"Funzioni m\u00f2n\u00f3t\u00f2ne"},{"location":"AnalisiI/prerequisiti/#composizione-di-funzioni-monotone","text":"Proposizione Avendo: \\(A,B,C \\subset \\mathbb R\\) \\(f: A \\rightarrow B\\) \\(g: B \\rightarrow C\\) Allora: Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e \\(g\\) \u00e8 crescente \\(\\nearrow\\) , allora \\(g \\circ f\\) (g composto f) \u00e8 crescente \\(\\nearrow\\) Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e g \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 decrescente \\(\\searrow\\) (e viceversa) Se \\(f\\) \u00e8 decrescente \\(\\searrow\\) e \\(g\\) \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 crescente \\(\\nearrow\\) Quindi: \\(\\nearrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\nearrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) Insieme di definizione L'insieme di definizione (o dominio naturale) di una funzione \u00e8 il pi\u00f9 grande sottoinsieme di \\(\\mathbb R\\) dove ha senso scrivere la funzione Ad esempio nel caso di \\(\\frac 1 x\\) il dominio di definizione \u00e8 \\(\\mathbb \\backslash \\{0\\}\\) Funzione pari e dispari Se \\(f(x) = f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice pari. Se \\(f(x) = -f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice dispari. Questa definizione implica che il dominio di f sia tale che se x appartiene al dominio, allora anche -x appartiene al dominio (\u00e8 simmetrico rispetto allo 0). Funzione periodica \\(f\\) si dice periodica di periodo \\(p\\) con \\(p \\in \\mathbb R\\) se \\(\\forall x, f(x+p) = f(x)\\) Un esempio di una funzione periodica sono le funzioni trigonometriche (seno, coseno, tangente, etc...)","title":"Composizione di funzioni monotone"},{"location":"AnalisiI/prerequisiti/#funzioni-elementari","text":"","title":"Funzioni elementari"},{"location":"AnalisiI/prerequisiti/#retta","text":"La retta \u00e8 scritta nella forma \\(f(x) = a \\cdot x + b \\text { con } a,b \\in \\mathbb R\\) a \u00e8 chiamato coefficiente angolare, b \u00e8 chiamato termine noto.","title":"Retta"},{"location":"AnalisiI/prerequisiti/#funzione-potenza","text":"","title":"Funzione potenza"},{"location":"AnalisiI/prerequisiti/#in-n","text":"\\(f(x) = x^k, k \\in \\mathbb N\\) k pari, grafici sono una parabola (con la sola velocit\u00e0 di crescita che cambia). k dispari, grafici sono una \\(f\\) \u00e8 una funzine pari se \\(k\\) \u00e8 pari ed \u00e8 dispari se \\(k\\) \u00e8 dispari. (questo perch\u00e9 \\(-1^2 = 1\\) e \\(-1^3 = -1\\) ).","title":"In N"},{"location":"AnalisiI/prerequisiti/#in-z-con-k-negativo","text":"\\(f(x) = x^k \\ k\\in \\mathbb Z; k < 0\\) k dispari iperbole equilatera (primo e terzo quadrante) k pari iperbole (primo e secondo quadrante) anche qui la funzione \u00e8 pari per k pari e dispari per k dispari","title":"In Z con k negativo"},{"location":"AnalisiI/prerequisiti/#in-r","text":"\\(f(x) = x^\\frac p q ; p,q \\in \\mathbb N \\ q \\ne 0\\) La funzione f ha come dominio naturale Quando abbiamo \\(p = 1\\) (quindi \\(x^\\frac 1 q = sqrt[q]{x}\\) , inversa della funzione \\(x^q\\) ) Se q \u00e8 pari, il dominio \u00e8 \\(x \\ge 0\\) (possiamo fare la radice quadrata solo di un positivi), quindi \u00e8 invertibile solo come funzione da [0,+inf] -> [0, +inf] Se q \u00e8 dispari, il dominio \u00e8 \\(\\mathbb R\\) (possiamo fare la radice cubica di un negativo). x^3 \u00e8 una funzione invertibile su tutto R","title":"In R"},{"location":"AnalisiI/prerequisiti/#in-r-e-non-in-q-irrazionale","text":"\\(f(x) = x^\\alpha, \\alpha \\in \\mathbb R \\ e \\ \\alpha \\notin \\mathbb Q\\) (quindi ad esempio \\(x^{\\sqrt 2}\\) oppure \\(x^\\pi\\) ) \\(x^\\alpha = e^{\\alpha \\cdot log(x)} \\ \\text{ definita per } x>0\\) Questo perch\u00e9: \\(e^{\\alpha log (x)} = (e^{log(x)})^\\alpha = x^\\alpha\\) Per definizione dobbiamo passare attraverso il logaritmo. Il dominio naturale \u00e8 \\((0, +\\infty)\\)","title":"In R e non in Q (irrazionale)"},{"location":"AnalisiI/prerequisiti/#esponenziale","text":"con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione esponenziale \u00e8 \\(f(x) = a^x\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente In entrambi i casi la funzione intercetta il punto 1 delle ordinate e sono sempre positive: \\[ a^x > 0 \\forall x \\in \\mathbb R \\] Entrambi le funzioni sono invertibili, poich\u00e9 stettamente crescenti o decrescenti, quindi monotone, quindi iniettive e surgettive.","title":"Esponenziale"},{"location":"AnalisiI/prerequisiti/#logaritmo-in-base-a","text":"con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione logaritmica \u00e8 \\(f(x) = log_a(x)\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente Intercetta l'ascissa sempre ad 1 e presenta una simmetria (\u00e8 specchiata) rispetto alla bisettrice (y=x) del grafico dell'esponenziale","title":"Logaritmo in base a"},{"location":"AnalisiI/prerequisiti/#funzione-esponenziale-in-base-e","text":"Funzione esponenziale con \\(a = e \\cong 2,71\\) \u00e8 invertibile e la sua inversa si chiama logaritmo naturale. (Se la base non \u00e8 specificata, in matematica si intende in base e).","title":"Funzione esponenziale (in base e)"},{"location":"AnalisiI/prerequisiti/#cambio-di-base-del-logaritmo","text":"Possiamo facilmente effettuare un cambio della base del logaritmo facendo uso di alcune regole matematiche: Il logaritmo \u00e8 la potenza che dobbiamo assegnare ad a per ottenere x: \\(log_a (x) = y \\Leftrightarrow a^y = x\\) Il logaritmo naturale dell'equazione dell'identit\u00e0 \u00e8: \\(log(a^y) = log(x) \\Leftrightarrow y \\cdot log(a) = log(x)\\) , ed abbiamo gi\u00e0 visto y: \\(y = log_a (x)\\) Quindi possiamo sostituire y, per poi semplificarla: \\(log_a (x) \\cdot log (a) = log(x) \\Rightarrow log_a (x) = \\frac{log(x)}{log(a)}\\)","title":"Cambio di base del logaritmo"},{"location":"AnalisiI/prerequisiti/#funzioni-trigonometriche","text":"","title":"Funzioni trigonometriche"},{"location":"AnalisiI/prerequisiti/#seno","text":"Il seno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) \\(f(x)=sin \\ x \\qquad f: \\mathbb R \\rightarrow [-1, 1]\\) perch\u00e9 \\(-1 \\le sin(x) \\le 1\\) . La funzione \u00e8 surgettiba se per codominio prendiamo \\([-1, 1]\\) Essendo periodica, \\(sin(x+2 \\pi) = sin(x) \\quad \\forall x \\in \\mathbb R\\) . Essendo il seno sull'asse delle orinate, il cerchio con angolo 0 ha valore 0 sulle ordinate, quindi \\(sin(0) = 0\\) . La funzione \u00e8 invertibile modificando dominio e codominio (quando la funzione \u00e8 definita come \\(f: [ -\\frac \\pi 2 , \\frac \\pi 2 ] \\rightarrow [-1, 1]\\) . f risulta quindi strettamente crescente (quindi monotona, quindi essendo continua, iniettiva) e surgettiva.) Dispari","title":"Seno"},{"location":"AnalisiI/prerequisiti/#arcoseno","text":"Funzione inversa del seno, definita come \\(f: [-1, 1] \\rightarrow [ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) La funzione arcsin \u00e8 quindi l'inversa del seno quando il dominio \u00e8 \\([ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) ed il codominio \u00e8 \\([-1, 1]\\) Se cos\u00ec non fosse la funzione seno non \u00e8 n\u00e9 iniettiva n\u00e9 surgettiva, e quindi non \u00e8 invertibile.","title":"Arcoseno"},{"location":"AnalisiI/prerequisiti/#coseno","text":"Il coseno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) La funzione \u00e8 il seno, ma traslata di \\(\\frac \\pi 2\\) (quindi \\(cos(0) = 1\\) ) Pari","title":"Coseno"},{"location":"AnalisiI/prerequisiti/#arcocoseno","text":"Se vogliamo invertire dobbiamo scegliere un intervallo dove la funzione \u00e8 monotona. Possiamo quindi definire il dominio naturle come \\(cos(x): [0, \\pi] \\rightarrow [-1, 1]\\) .","title":"Arcocoseno"},{"location":"AnalisiI/prerequisiti/#tangente","text":"\\(tg (x) = \\frac {sin(x)} {cos(x)}\\) , che quindi non \u00e8 definita se \\(cos(x) = 0\\) . Il dominio \u00e8 quindi \\(\\{ x \\in \\mathbb R: x \\ne \\frac \\pi 2 + k \\cdot \\pi, k \\in \\mathbb Z \\}\\) , composto da infiniti intervalli disgiunti. \u00c8 periodica di periodo \\(\\pi\\) \u00c8 invertibile quando \\(f: (-\\frac \\pi 2 , \\frac \\pi 2 ) \\rightarrow \\mathbb R\\) \u00c8 inoltre dispari","title":"Tangente"},{"location":"AnalisiI/prerequisiti/#arcotangente","text":"\u00c8 l'inversa della tangente \\(arctan: \\mathbb \\rightarrow (-\\frac \\pi 2 , \\frac \\pi 2 )\\) Strettamente crescente nel suo dominio. (Da non invertire con la cotangente)","title":"Arcotangente"},{"location":"FdI/","text":"","title":"Fondamenti di Informatica"},{"location":"FdI/calcoloCombinatorio/","text":"Il calcolo combinatorio \u00b6 Il calcolo combinatorio \u00e8 quella branca della matematica che studia i modi per raggruppare o ordinare secondo delle regole date gli elementi di un insieme finito di oggetti. Possiamo vedere un esempio per quanto riguarda la cardinalit\u00e0 di alcune operazioni che abbiamo visto fin'ora: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\backslash B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A|+|B|-|A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|A \\times B \\times C| = |A| \\cdot |B| \\times |C|\\) \\(|\\mathcal P (A)| = 2^{|A|}\\) \\(|\\mathcal P_k (A)| = \\bigl({|A| \\atop k}\\bigr)\\) (prodotto binomiale) = \\(\\bigl({n \\atop k}\\bigr)\\) = Composizione(n,k) = \\(\\frac{n!}{n!(n-k)!}\\) \\(|Rel(A,B)| = 2^{|A| \\cdot |B|}\\) \\(|Fun(A,B)| = |B|^{|A|}\\) \\(|Bii(A,B)| = \\begin{cases} 0 & \\text{ se } |A| \\neq |B| \\\\ |A|! & \\text{ se } |A| = |B| \\end{cases}\\) \\(|A^n| = |A|^n\\) Operazioni su insiemi e cardinalit\u00e0 \u00b6 Una tecnica per contare gli elementi in un insieme consiste nel partizionamento di un insieme, e la successiva conta di ogni elemento nella partizione, che sommato per ogni sottoinsieme restituir\u00e0 la cardinalit\u00e0 di dell'insieme. Ad esempio, dato un insieme \\(A\\) , \\(\\mathcal F = \\{A_i | i \\in I\\}\\) sar\u00e0 una famiglia di sottoinsiemi cui: \\(\\cup_{i \\in I} A_i = A\\) (copertura di A) Per ogni coppia di indici \\((i,j) \\in I\\) con \\(i \\ne j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (gli insiemi sono disgiunti) Allora \\(|A| = \\sum_{i \\in I} |A_i|\\) Notare che \\(\\mathcal F\\) non \u00e8 una partizione, in quanto possono esistere insiemi vuoti, che non andrebbero ad intaccare il risultato della cardinalit\u00e0. Il principio di inclusione-esclusione Presi r insiemi \\(S_1,S_2,...S_r\\) abbiamo la seguente uguaglianza, dove \\((-1)^i\\) vale 1 se i \u00e8 un numero pari e vale -1 se \u00e8 dispari: \\[ \\bigg| \\bigcup^r_{j=1}S_j \\bigg | = \\sum_{I \\subseteq \\{1,2,...,r\\}, I \\ne \\varnothing} (-1)^{|I| +1} \\bigg | \\bigcap_{i \\in I} S_i \\bigg | \\] Ci\u00f2 significa che per trovare la cardinalit\u00e0 dell'unione di R insiemi, calcoliamo la cardinalit\u00e0 di ogni insieme e le sommiamo tutte. Procediamo poi con il sottrarre la cardinalit\u00e0 delle intersezioni con tra insiemi quando il numero di insiemi nell'operazione di intersezione \u00e8 pari, mentre aggiungiamo i valori se il numero di insiemi coinvolti \u00e8 dispari. Quindi, se ad esempio abbiamo \\(|S_1 \\cap S_2|\\) , abbiamo due insiemi, che significa che andremo a sottrarre , essendo 2 pari. Al contrario, se abbiamo \\(|S_1 \\cap S_2 \\cap S_3|\\) , andremo ad aggiungere il valore, essendo 3 dispari. \\[ \\displaylines{ A = \\{a, b\\} \\\\ B = \\{b,c\\} \\\\ C = \\{c,d\\} \\\\\\\\ R = \\{A,B\\} \\\\ S = \\{A,B,C\\} \\\\ \\bigg| \\bigcup^r_{j=1}R_j \\bigg| = |A| + |B| - |A \\cap B| \\\\ \\bigg| \\bigcup^r_{j=1}S_j \\bigg| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C| } \\] Da rivedere se sono stato chiaro Relazioni e cardinalit\u00e0 \u00b6 Dato che ogni relazione \u00e8 un insieme, possiamo parlare di cardinalit\u00e0 delle relazioni. Possiamo ad esempio intuire che \\(|R| \\leq |A \\times B|\\) . Ma possiamo fare anche altre affermazioni sulla base della natura della relazione: Se \\(R\\) \u00e8 totale, allora \\(|A| \\leq |R|\\) Se \\(R\\) \u00e8 univalente, allora \\(|R| \\leq |A|\\) Se \\(R\\) \u00e8 surgettiva, allora \\(|B| \\leq |R|\\) Se \\(R\\) \u00e8 iniettiva, allora \\(|R| \\leq |B|\\) Quindi, se \\(R: A \\rightarrow B\\) \u00e8 una funzione, allora \\(|R| = |A|\\) . Principio delle buche e dei piccioni / pidgen principle Dati due insiemi \\(P\\) e \\(C\\) , se \\(|P| > |C|\\) , non esiste nessuna relazione \\(R: P \\leftrightarrow C\\) che sia totale ed iniettiva: infatti abbiamo pi\u00f9 elementi nel dominio che nel codominio, ed almeno una eventuale relazione dovr\u00e0 per forza essere non essere univalente Regola di biiezione \u00b6 Regola di biiezione Per tutti gli insiemi \\(A,B\\) , vale che se esiste una biiezione allora \\(|A| = |B|\\) Questa regola si pu\u00f2 verificare assumendo 2 insiemi A e B con cardinalit\u00e0 n. Per simmetria e transitivit\u00e0 di \\(\\cong\\) , possiamo dire che \\(|A|=|B|=n \\Rightarrow |A| \\cong n \\ e\\ |B| \\cong n \\Rightarrow A \\cong B\\) Grazie a questa regola possiamo verificare le regole sulla cardinalit\u00e0 in modo semplice: Cardinalit\u00e0 di Fun(A,B) Per ogni coppia di insiemi A e B vale che \\(|Fun(A,B)| = |B|^{|A|}\\) . Per verificare questa regola, ci basta verificare la biiezione. Permutazioni, disposizioni e combinazioni \u00b6 Permutazioni \u00b6 Le permutazioni ci permttono di studiare i possibili modi in cui gli elementi di un certo insieme si possono ordinare Permutazione Dato un insieme finito A con \\(|A| = n\\) , una permutazione di A \u00e8 una sequenza ordinata \\(a_1,...,a_n\\) dove tutti gli elementi di A appaiono esattamente una volta L'insieme di tutte le permutazioni di un dato insieme A con cardinalit\u00e0 maggiore di 0 si calcola come: \\[ P(n) = n! \\] Anagrammi e permutazioni con ripetizioni \u00b6 Un esempio interessante di permutazione \u00e8 un anagramma, dato che spesso possono verificarsi delle ripetizioni di una lettera. Il motivo \u00e8 che le parole non sono un ineieme di lettere, ma una sequenza o tupla di lettere, in cui la stessa lettera pi\u00f9 comparire pi\u00f9 volte. In questo caso il numero di permutazioni distinte si ottiene considerando le occorrenze di ogni singola lettera Permutazioni con ripetizione Sia \\(S = s_1,s_2,...,s_k\\) una sequenza di elementi di un insieme A di cardinalit\u00e0 n, ogni elementi di A pu\u00f2 comparire una o pi\u00f9 volte in S. Per ogni \\(i \\in \\{1,2,...,n\\}\\) , \\(c_i\\) \u00e8 il numero di volte che l'elemento \\(a_i\\) compare nella sequenza S. Il numero di permutazioni con ripetizione \u00e8 dato quindi dalla formula \\[ \\frac{n!}{c_1! \\cdot c_2! \\cdot ... \\cdot c_n!} \\] Disposizioni \u00b6 Disposizioni Dato un insieme finito A con \\(|A| = n\\) ed un intero \\(k \\leq n\\) , una disposizione degli elementi di A in k posti \u00e8 una sequenza ordinata \\(a_1,...,a_k\\) Il suo valore \u00e8 calcolato con la formula: \\[ D(n,k) = \\frac{n!}{(n-k)!} \\] Combinazioni \u00b6 Combinazioni Sia \\(A\\) un insieme di cardinalit\u00e0 \\(n\\) e sia \\(k\\) un naturale tale che \\(k \\leq n\\) . Una combinazione di k elementi di A \u00e8 un k- insieme , ovvero un sottoinsieme di A con cardinalit\u00e0 K. L'insieme di tutte le combinazioni \u00e8 quindi denotato come \\(\\mathcal P_k(A)\\) . Il numero di combinazioni di k elementi in un insieme di cardinalit\u00e0 n \u00e8 chiamato coefficiente binomiale ed \u00e8 indicato come \\(({n \\atop k})\\) . La formula \u00e8 denominata anche formula dei tre fattoriali : \\[ \\bigg({n \\atop k}\\bigg) = \\frac{n!}{k!(n-k)!} \\] La formula delle combinazioni pu\u00f2 anche essere vista in funzione delle disposizioni, e quindi delle permutazioni: \\[ C(n,k) = \\bigg({n \\atop k}\\bigg) = \\frac{D(n,k)}{P(k)} = \\frac{\\frac{P(n)}{(n-k)!}}{k!} = \\frac{\\frac{n!}{(n-k)!}}{k!} = \\frac{n!}{k!(n-k)!} \\] Contare nei grafi \u00b6 Contare negli alberi \u00b6 Un albero pieno di altezza \\(h\\) ha \\(2^h\\) foglie e \\(2^h-1\\) nodi interni, per un totale di \\(2^{h+1}-1\\) nodi. Un nodo (radice compresa) si dice unario quando ha solo un figlio. Il numero di nodi non unari in T \u00e8 al massimo \\(f-1\\) (dove f \u00e8 il numero di foglie). Quanti grafi non orientati esistono? \u00b6 Contare il numero di grafi possibile corrisponde a prendere un sottoinsieme dei possibili archi \\(E = V \\times V\\) . Tuttavia essendo i grafi non orientati, si presentano delle restizioni nella scelta: Non possiamo scegliere dei cappi Un arco \\(\\{x,y\\}\\) \u00e8 del tutto equivalente ad un arco \\(\\{y,x\\}\\) Il numero di archi possibili \u00e8 quindi \\(m_{max} = \\frac{n(n-1)}{2}\\) Per ogni elemento \\(i =\\{0,...,m_{max}\\}\\) , il numero di grafi su n nodi con i archi corrisponde al numero di sottoinsiemi di i archi grandi. Ricordiamo che tutti i sottoinsiemi di cardinalit\u00e0 k \u00e8 uguale all'insieme delle parti \\(\\mathcal P(k)\\) . La cardinalit\u00e0 di \\(\\mathcal P(k)\\) , ovvero il numero di sottoinsiemi, corrisponde a tutti i modi di scegliere quali elementi includere: per ogni arco in \\(V \\times V\\) poissiamo scegliere se includerlo o no, ottenendo quindi \\(2^k\\) possibili combinazioni. \\[ \\mathcal P(m_{max}) = \\sum_{i \\in \\{0,...,m_{max}\\}} \\cb{m_{max}}{i} = 2^{m_{max}} = 2^{\\frac{n(n-1)}{2}} \\] \u00c8 importante tuttavia notare che alcuni di questi grafi risultano isomorfi . Non abbiamo modo di determinare quindi quanti grafi non isomorfi tra di loro abbiamo dato un certo insieme di grafi. Abbiamo inoltre potuto osservare un'importante conseguenza della sommatoria con il coefficiente binomiale: \\[ \\sum_{i\\in \\{0,...,k\\}} \\cb{k}{i} \\text { e quindi } \\forall k>0,i\\ge 0 . \\cb{k}{i} < 2^k \\] Quanti grafi orientati esistono? \u00b6 Rispondere a questa domanda diventa livemente pi\u00f9 semplice in quanto non abbiamo pi\u00f9 le restrizioni imposte dai grafi non orientati: Abbiamo quindi \\(|V \\times V| = n^2\\) possibili archi. Dato che come abbiamo detto, ogni arco pu\u00f2 far parte o meno del grafo, otteniamo che il numero di grafi possibili sar\u00e0 quindi \\(2^{n^2}\\) . Complemento di un grafo \u00b6 Dato un grafo, possiamo definire il suo complemento \\(H = (V,E^{'})\\) che ha come archi solo quelli che mancano in G. In formule quindi, il complemento di \\(G=(V,E)\\) \u00e8 \\(H = (V,E^{'})\\) , dove \\(E^{'}\\) \u00e8 definito come \\(E^{'} = \\{ xy \\in V\\times V | xy \\notin E\\}\\) . Notiamo che ogni grafo ha un complemento e la relazione complemento \\(C \\subseteq G_n \\times G_n\\) \u00e8 una biiezione. Osserviamo che \\(C^{-1} = C\\) Contare cammini in grafi notevoli \u00b6 Cammini in una cricca \u00b6 Definiznione di cricca Una cricca di n nodi \u00e8 un grafo dove ogni coppia di nodi \u00e8 connessa. La cricca biene anche denotata come \\(K_n\\) e grafo completo In una circca avremo quindi che il path pi\u00f9 corto tra due nodi \u00e8 di lunghezza 1. Inoltre ogni sequenza di nodi senza ripetizioni corrisponde ad un path. Qualunque permutazione \\(V!\\) dei nodi corrisponde quindi ad un path hamiltoniano . Ma dato che ogni nodo \u00e8 connesso a tutti gli altri, ne deriva che ogni path hamiltoniano \u00e8 anche un ciclo hamiltoniano. Tuttavia un ciclo come \\(1,2,3,4\\) , \u00e8 l'opposto del ciclo \\(4,3,2,1\\) , ma rappresentano lo stesso ciclo. Allo stesso modo, ripetendo due volte il cliclo \\(1,2,3,4,1,2,3,4\\) , iniziando da qualunque altro nodo che non sia il primo permetter\u00e0 di ottenere un nuovo ciclo hamiltoniano basato sugli stessi archi (chiameremo questo nuovo ciclo rotazione ). Per ottenere quindi il numero di cicli tra loro non equivalenti, dovremo dividere per i casi opposti (2) e per il numero di possibili rotazioni. Abbiamo quindi che \\(K_n\\) ha \\(\\frac{n!}{2n}\\) cicli hamiltoniani non equivalenti. Inoltre il numero di sequenze di lunghezza k sar\u00e0 pari al prodotto binomiale del numero dei nodi su k \\(\\cb{n}{k}\\) Cammini nel grafo bipartito completo \u00b6 Grafo bipartito Un grafo si dive bipartito se almeno una condizione \u00e8 vera (le condizioni sono equivalenti): G non contiene cicli di lunghezza dispari Esiste una patizione \\(V_1, V_2\\) di V tale che non esistono archi tra nodi nella stessa partizione. Per ogni arco \\(xy \\in E\\) vale che \\(x \\in v_1 \\Rightarrow y \\in V_2\\) Dati due colori, \u00e8 possibile colorare ogni nodo di G con un colore in modo che i due estremi di ongi acrvo abbiano sempre colori diversi (2-colorazione) Gli alberi non sono cicli, e quindi non possono avere cicli dispari. Di conseguenza ogni albero \u00e8 un grafo bipartito. Inoltre dato un grafo bipartito esiste una sola bipartizione \\(v_1, v_2\\)","title":"Calcolo Combinatorio"},{"location":"FdI/calcoloCombinatorio/#il-calcolo-combinatorio","text":"Il calcolo combinatorio \u00e8 quella branca della matematica che studia i modi per raggruppare o ordinare secondo delle regole date gli elementi di un insieme finito di oggetti. Possiamo vedere un esempio per quanto riguarda la cardinalit\u00e0 di alcune operazioni che abbiamo visto fin'ora: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\backslash B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A|+|B|-|A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|A \\times B \\times C| = |A| \\cdot |B| \\times |C|\\) \\(|\\mathcal P (A)| = 2^{|A|}\\) \\(|\\mathcal P_k (A)| = \\bigl({|A| \\atop k}\\bigr)\\) (prodotto binomiale) = \\(\\bigl({n \\atop k}\\bigr)\\) = Composizione(n,k) = \\(\\frac{n!}{n!(n-k)!}\\) \\(|Rel(A,B)| = 2^{|A| \\cdot |B|}\\) \\(|Fun(A,B)| = |B|^{|A|}\\) \\(|Bii(A,B)| = \\begin{cases} 0 & \\text{ se } |A| \\neq |B| \\\\ |A|! & \\text{ se } |A| = |B| \\end{cases}\\) \\(|A^n| = |A|^n\\)","title":"Il calcolo combinatorio"},{"location":"FdI/calcoloCombinatorio/#operazioni-su-insiemi-e-cardinalita","text":"Una tecnica per contare gli elementi in un insieme consiste nel partizionamento di un insieme, e la successiva conta di ogni elemento nella partizione, che sommato per ogni sottoinsieme restituir\u00e0 la cardinalit\u00e0 di dell'insieme. Ad esempio, dato un insieme \\(A\\) , \\(\\mathcal F = \\{A_i | i \\in I\\}\\) sar\u00e0 una famiglia di sottoinsiemi cui: \\(\\cup_{i \\in I} A_i = A\\) (copertura di A) Per ogni coppia di indici \\((i,j) \\in I\\) con \\(i \\ne j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (gli insiemi sono disgiunti) Allora \\(|A| = \\sum_{i \\in I} |A_i|\\) Notare che \\(\\mathcal F\\) non \u00e8 una partizione, in quanto possono esistere insiemi vuoti, che non andrebbero ad intaccare il risultato della cardinalit\u00e0. Il principio di inclusione-esclusione Presi r insiemi \\(S_1,S_2,...S_r\\) abbiamo la seguente uguaglianza, dove \\((-1)^i\\) vale 1 se i \u00e8 un numero pari e vale -1 se \u00e8 dispari: \\[ \\bigg| \\bigcup^r_{j=1}S_j \\bigg | = \\sum_{I \\subseteq \\{1,2,...,r\\}, I \\ne \\varnothing} (-1)^{|I| +1} \\bigg | \\bigcap_{i \\in I} S_i \\bigg | \\] Ci\u00f2 significa che per trovare la cardinalit\u00e0 dell'unione di R insiemi, calcoliamo la cardinalit\u00e0 di ogni insieme e le sommiamo tutte. Procediamo poi con il sottrarre la cardinalit\u00e0 delle intersezioni con tra insiemi quando il numero di insiemi nell'operazione di intersezione \u00e8 pari, mentre aggiungiamo i valori se il numero di insiemi coinvolti \u00e8 dispari. Quindi, se ad esempio abbiamo \\(|S_1 \\cap S_2|\\) , abbiamo due insiemi, che significa che andremo a sottrarre , essendo 2 pari. Al contrario, se abbiamo \\(|S_1 \\cap S_2 \\cap S_3|\\) , andremo ad aggiungere il valore, essendo 3 dispari. \\[ \\displaylines{ A = \\{a, b\\} \\\\ B = \\{b,c\\} \\\\ C = \\{c,d\\} \\\\\\\\ R = \\{A,B\\} \\\\ S = \\{A,B,C\\} \\\\ \\bigg| \\bigcup^r_{j=1}R_j \\bigg| = |A| + |B| - |A \\cap B| \\\\ \\bigg| \\bigcup^r_{j=1}S_j \\bigg| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C| } \\] Da rivedere se sono stato chiaro","title":"Operazioni su insiemi e cardinalit\u00e0"},{"location":"FdI/calcoloCombinatorio/#relazioni-e-cardinalita","text":"Dato che ogni relazione \u00e8 un insieme, possiamo parlare di cardinalit\u00e0 delle relazioni. Possiamo ad esempio intuire che \\(|R| \\leq |A \\times B|\\) . Ma possiamo fare anche altre affermazioni sulla base della natura della relazione: Se \\(R\\) \u00e8 totale, allora \\(|A| \\leq |R|\\) Se \\(R\\) \u00e8 univalente, allora \\(|R| \\leq |A|\\) Se \\(R\\) \u00e8 surgettiva, allora \\(|B| \\leq |R|\\) Se \\(R\\) \u00e8 iniettiva, allora \\(|R| \\leq |B|\\) Quindi, se \\(R: A \\rightarrow B\\) \u00e8 una funzione, allora \\(|R| = |A|\\) . Principio delle buche e dei piccioni / pidgen principle Dati due insiemi \\(P\\) e \\(C\\) , se \\(|P| > |C|\\) , non esiste nessuna relazione \\(R: P \\leftrightarrow C\\) che sia totale ed iniettiva: infatti abbiamo pi\u00f9 elementi nel dominio che nel codominio, ed almeno una eventuale relazione dovr\u00e0 per forza essere non essere univalente","title":"Relazioni e cardinalit\u00e0"},{"location":"FdI/calcoloCombinatorio/#regola-di-biiezione","text":"Regola di biiezione Per tutti gli insiemi \\(A,B\\) , vale che se esiste una biiezione allora \\(|A| = |B|\\) Questa regola si pu\u00f2 verificare assumendo 2 insiemi A e B con cardinalit\u00e0 n. Per simmetria e transitivit\u00e0 di \\(\\cong\\) , possiamo dire che \\(|A|=|B|=n \\Rightarrow |A| \\cong n \\ e\\ |B| \\cong n \\Rightarrow A \\cong B\\) Grazie a questa regola possiamo verificare le regole sulla cardinalit\u00e0 in modo semplice: Cardinalit\u00e0 di Fun(A,B) Per ogni coppia di insiemi A e B vale che \\(|Fun(A,B)| = |B|^{|A|}\\) . Per verificare questa regola, ci basta verificare la biiezione.","title":"Regola di biiezione"},{"location":"FdI/calcoloCombinatorio/#permutazioni-disposizioni-e-combinazioni","text":"","title":"Permutazioni, disposizioni e combinazioni"},{"location":"FdI/calcoloCombinatorio/#permutazioni","text":"Le permutazioni ci permttono di studiare i possibili modi in cui gli elementi di un certo insieme si possono ordinare Permutazione Dato un insieme finito A con \\(|A| = n\\) , una permutazione di A \u00e8 una sequenza ordinata \\(a_1,...,a_n\\) dove tutti gli elementi di A appaiono esattamente una volta L'insieme di tutte le permutazioni di un dato insieme A con cardinalit\u00e0 maggiore di 0 si calcola come: \\[ P(n) = n! \\]","title":"Permutazioni"},{"location":"FdI/calcoloCombinatorio/#anagrammi-e-permutazioni-con-ripetizioni","text":"Un esempio interessante di permutazione \u00e8 un anagramma, dato che spesso possono verificarsi delle ripetizioni di una lettera. Il motivo \u00e8 che le parole non sono un ineieme di lettere, ma una sequenza o tupla di lettere, in cui la stessa lettera pi\u00f9 comparire pi\u00f9 volte. In questo caso il numero di permutazioni distinte si ottiene considerando le occorrenze di ogni singola lettera Permutazioni con ripetizione Sia \\(S = s_1,s_2,...,s_k\\) una sequenza di elementi di un insieme A di cardinalit\u00e0 n, ogni elementi di A pu\u00f2 comparire una o pi\u00f9 volte in S. Per ogni \\(i \\in \\{1,2,...,n\\}\\) , \\(c_i\\) \u00e8 il numero di volte che l'elemento \\(a_i\\) compare nella sequenza S. Il numero di permutazioni con ripetizione \u00e8 dato quindi dalla formula \\[ \\frac{n!}{c_1! \\cdot c_2! \\cdot ... \\cdot c_n!} \\]","title":"Anagrammi e permutazioni con ripetizioni"},{"location":"FdI/calcoloCombinatorio/#disposizioni","text":"Disposizioni Dato un insieme finito A con \\(|A| = n\\) ed un intero \\(k \\leq n\\) , una disposizione degli elementi di A in k posti \u00e8 una sequenza ordinata \\(a_1,...,a_k\\) Il suo valore \u00e8 calcolato con la formula: \\[ D(n,k) = \\frac{n!}{(n-k)!} \\]","title":"Disposizioni"},{"location":"FdI/calcoloCombinatorio/#combinazioni","text":"Combinazioni Sia \\(A\\) un insieme di cardinalit\u00e0 \\(n\\) e sia \\(k\\) un naturale tale che \\(k \\leq n\\) . Una combinazione di k elementi di A \u00e8 un k- insieme , ovvero un sottoinsieme di A con cardinalit\u00e0 K. L'insieme di tutte le combinazioni \u00e8 quindi denotato come \\(\\mathcal P_k(A)\\) . Il numero di combinazioni di k elementi in un insieme di cardinalit\u00e0 n \u00e8 chiamato coefficiente binomiale ed \u00e8 indicato come \\(({n \\atop k})\\) . La formula \u00e8 denominata anche formula dei tre fattoriali : \\[ \\bigg({n \\atop k}\\bigg) = \\frac{n!}{k!(n-k)!} \\] La formula delle combinazioni pu\u00f2 anche essere vista in funzione delle disposizioni, e quindi delle permutazioni: \\[ C(n,k) = \\bigg({n \\atop k}\\bigg) = \\frac{D(n,k)}{P(k)} = \\frac{\\frac{P(n)}{(n-k)!}}{k!} = \\frac{\\frac{n!}{(n-k)!}}{k!} = \\frac{n!}{k!(n-k)!} \\]","title":"Combinazioni"},{"location":"FdI/calcoloCombinatorio/#contare-nei-grafi","text":"","title":"Contare nei grafi"},{"location":"FdI/calcoloCombinatorio/#contare-negli-alberi","text":"Un albero pieno di altezza \\(h\\) ha \\(2^h\\) foglie e \\(2^h-1\\) nodi interni, per un totale di \\(2^{h+1}-1\\) nodi. Un nodo (radice compresa) si dice unario quando ha solo un figlio. Il numero di nodi non unari in T \u00e8 al massimo \\(f-1\\) (dove f \u00e8 il numero di foglie).","title":"Contare negli alberi"},{"location":"FdI/calcoloCombinatorio/#quanti-grafi-non-orientati-esistono","text":"Contare il numero di grafi possibile corrisponde a prendere un sottoinsieme dei possibili archi \\(E = V \\times V\\) . Tuttavia essendo i grafi non orientati, si presentano delle restizioni nella scelta: Non possiamo scegliere dei cappi Un arco \\(\\{x,y\\}\\) \u00e8 del tutto equivalente ad un arco \\(\\{y,x\\}\\) Il numero di archi possibili \u00e8 quindi \\(m_{max} = \\frac{n(n-1)}{2}\\) Per ogni elemento \\(i =\\{0,...,m_{max}\\}\\) , il numero di grafi su n nodi con i archi corrisponde al numero di sottoinsiemi di i archi grandi. Ricordiamo che tutti i sottoinsiemi di cardinalit\u00e0 k \u00e8 uguale all'insieme delle parti \\(\\mathcal P(k)\\) . La cardinalit\u00e0 di \\(\\mathcal P(k)\\) , ovvero il numero di sottoinsiemi, corrisponde a tutti i modi di scegliere quali elementi includere: per ogni arco in \\(V \\times V\\) poissiamo scegliere se includerlo o no, ottenendo quindi \\(2^k\\) possibili combinazioni. \\[ \\mathcal P(m_{max}) = \\sum_{i \\in \\{0,...,m_{max}\\}} \\cb{m_{max}}{i} = 2^{m_{max}} = 2^{\\frac{n(n-1)}{2}} \\] \u00c8 importante tuttavia notare che alcuni di questi grafi risultano isomorfi . Non abbiamo modo di determinare quindi quanti grafi non isomorfi tra di loro abbiamo dato un certo insieme di grafi. Abbiamo inoltre potuto osservare un'importante conseguenza della sommatoria con il coefficiente binomiale: \\[ \\sum_{i\\in \\{0,...,k\\}} \\cb{k}{i} \\text { e quindi } \\forall k>0,i\\ge 0 . \\cb{k}{i} < 2^k \\]","title":"Quanti grafi non orientati esistono?"},{"location":"FdI/calcoloCombinatorio/#quanti-grafi-orientati-esistono","text":"Rispondere a questa domanda diventa livemente pi\u00f9 semplice in quanto non abbiamo pi\u00f9 le restrizioni imposte dai grafi non orientati: Abbiamo quindi \\(|V \\times V| = n^2\\) possibili archi. Dato che come abbiamo detto, ogni arco pu\u00f2 far parte o meno del grafo, otteniamo che il numero di grafi possibili sar\u00e0 quindi \\(2^{n^2}\\) .","title":"Quanti grafi orientati esistono?"},{"location":"FdI/calcoloCombinatorio/#complemento-di-un-grafo","text":"Dato un grafo, possiamo definire il suo complemento \\(H = (V,E^{'})\\) che ha come archi solo quelli che mancano in G. In formule quindi, il complemento di \\(G=(V,E)\\) \u00e8 \\(H = (V,E^{'})\\) , dove \\(E^{'}\\) \u00e8 definito come \\(E^{'} = \\{ xy \\in V\\times V | xy \\notin E\\}\\) . Notiamo che ogni grafo ha un complemento e la relazione complemento \\(C \\subseteq G_n \\times G_n\\) \u00e8 una biiezione. Osserviamo che \\(C^{-1} = C\\)","title":"Complemento di un grafo"},{"location":"FdI/calcoloCombinatorio/#contare-cammini-in-grafi-notevoli","text":"","title":"Contare cammini in grafi notevoli"},{"location":"FdI/calcoloCombinatorio/#cammini-in-una-cricca","text":"Definiznione di cricca Una cricca di n nodi \u00e8 un grafo dove ogni coppia di nodi \u00e8 connessa. La cricca biene anche denotata come \\(K_n\\) e grafo completo In una circca avremo quindi che il path pi\u00f9 corto tra due nodi \u00e8 di lunghezza 1. Inoltre ogni sequenza di nodi senza ripetizioni corrisponde ad un path. Qualunque permutazione \\(V!\\) dei nodi corrisponde quindi ad un path hamiltoniano . Ma dato che ogni nodo \u00e8 connesso a tutti gli altri, ne deriva che ogni path hamiltoniano \u00e8 anche un ciclo hamiltoniano. Tuttavia un ciclo come \\(1,2,3,4\\) , \u00e8 l'opposto del ciclo \\(4,3,2,1\\) , ma rappresentano lo stesso ciclo. Allo stesso modo, ripetendo due volte il cliclo \\(1,2,3,4,1,2,3,4\\) , iniziando da qualunque altro nodo che non sia il primo permetter\u00e0 di ottenere un nuovo ciclo hamiltoniano basato sugli stessi archi (chiameremo questo nuovo ciclo rotazione ). Per ottenere quindi il numero di cicli tra loro non equivalenti, dovremo dividere per i casi opposti (2) e per il numero di possibili rotazioni. Abbiamo quindi che \\(K_n\\) ha \\(\\frac{n!}{2n}\\) cicli hamiltoniani non equivalenti. Inoltre il numero di sequenze di lunghezza k sar\u00e0 pari al prodotto binomiale del numero dei nodi su k \\(\\cb{n}{k}\\)","title":"Cammini in una cricca"},{"location":"FdI/calcoloCombinatorio/#cammini-nel-grafo-bipartito-completo","text":"Grafo bipartito Un grafo si dive bipartito se almeno una condizione \u00e8 vera (le condizioni sono equivalenti): G non contiene cicli di lunghezza dispari Esiste una patizione \\(V_1, V_2\\) di V tale che non esistono archi tra nodi nella stessa partizione. Per ogni arco \\(xy \\in E\\) vale che \\(x \\in v_1 \\Rightarrow y \\in V_2\\) Dati due colori, \u00e8 possibile colorare ogni nodo di G con un colore in modo che i due estremi di ongi acrvo abbiano sempre colori diversi (2-colorazione) Gli alberi non sono cicli, e quindi non possono avere cicli dispari. Di conseguenza ogni albero \u00e8 un grafo bipartito. Inoltre dato un grafo bipartito esiste una sola bipartizione \\(v_1, v_2\\)","title":"Cammini nel grafo bipartito completo"},{"location":"FdI/cheatsheet/","text":"Relazione Descrizione Totale Per ogni elemento in A, c'\u00e8 una connessione con almeno un elemento in B Univalente Per ogni elemento in A, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in B Surgettiva Per ogni elemento in B, c'\u00e8 una connessione con almeno un elemento in A Iniettiva Per ogni elemento in B, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in A Biietiva Tutte le precedenti Riflessiva Ogni elemento \u00e8 in relazione con s\u00e9 stesso (ha un cappio) (l'identit\u00e0 \u00e8 contenuta nella relazione) Transitiva Se esiste una relazione (a,b), e (b,c), esiste anche una relazione (a,c) Include anche la relazione vuota Antisimmetrica Non c'\u00e8 mai una relazione che va da a a b e contemporaneamente da b ad a (Non ci sono mai frecce opposte) \u00c8 tollerato lo stesso elemento (cappio) Simmetrica Per ogni relazione (a,b) , esiste una relazione (b,a) Per ogni elemento, ci sono 2 archi, uno da ed uno verso un altro elemento Composizione 2 relazioni sono composte quando l'elemento di arrivo per la prima diventa l'elemento di partenza per la seconda Avendo (a,b) e (b,c) in R, R composto R ( R;R ) \u00e8 ((a,b),c) , ovvero (a,c) R*, chiusura di Kleene La composizione di una relazione con s\u00e9 stessa infinite volte (zero incluso) \u00c8 riflessiva e transitiva Contiene l'identit\u00e0 (R0) R+, chiusura positiva R* ma senza 0 incluso Chiusura riflessiva Data una relazione R ed un insieme A, \u00e8 l'unione dell'identit\u00e0 di A con la relazione R Chiusura simmetrica Data una relazione R, \u00e8 l'unione di R ed R opposto Chiusura transitiva Data una relazione R, si unisce a questa la chiusura positiva fino a far diventare la funzione transitiva Ordinamento parziale Una relazione Riflessiva, Transitiva ed Antisimmetrica Ordinamento totale Ordinamento parziale + ogni (a, b) appartenente al prodotto cartesiano; (a,b) o (b,a) appartiene ad R Ogni coppia di elementi appartiene alla relazione R: ogni elemento \u00e8 in relazione con ogni altro elemento; C'\u00e8 una freccia per ogni elemento su ogni elemento Se \u00e8 totale, non \u00e8 parziale Grafo Relazione Descrizione Walk/Cammino Un collegamento da un nodo di partenza ad uno di arrivo Trail Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso arco (o collegamento) Path Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso NODO (o pallino/elemento) Non si deve passare 2 volte per lo stesso elemento Walk chiuso Un walk che permette di partire da un nodo e ritornare allo stesso ed ha lunghezza maggiore di 0 Circuito \u00c8 un walk chiuso che \u00e8 anche un trail (non si passa per lo stesso arco 2 volte) Ciclo \u00c8 un circuito che \u00e8 anche un path (non si passa per lo stesso nodo 2 volte) Aciclico Quando il grafo NON presenta un ciclo Connesso Quando ogni nodo \u00e8 \"raggiunto\" da almeno un arco (se \u00e8 orientato: sia in uscita che in entrata) Fortemente connesso Da ogni nodo, esiste un walk verso ogni altro nodo Componenti fortemente connesse Sottografi fortemente connessi (notare che ogni nodo pu\u00f2 arrivare a s\u00e9 stesso, quindi ogni nodo preso singolarmente \u00e8 una componente fortemente connessa) Universale Quando un nodo \u00e8 vicino a tutti gli altri DAG Grafo Aciclico Orientato Induzione (pecch\u00e9 non bastava prima)","title":"Cheatsheet"},{"location":"FdI/grafi/","text":"I grafi e gli alberi \u00b6 I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme. Grafi orientati \u00b6 Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) . Le propriet\u00e0 TUSI \u00b6 Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\) Rappresentazione dei grafi orientati \u00b6 Esistono diversi modi per rappresentare i grafi orientati Matrice di adiacenza \u00b6 La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra. Liste di adiacenza \u00b6 Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\) Grafi etichettati e pesati \u00b6 Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche: Cammini, cicli e connettivit\u00e0 \u00b6 In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path. Cicli nei grafi orientati \u00b6 walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\) Connettivit\u00e0 \u00b6 Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y. Grafi orientati aciclici \u00b6 Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico. Grafi non orientati \u00b6 Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari. Cammini, cicli e connettivit\u00e0 sui grafi non orientati \u00b6 La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path. Cicli nei grafi non orientati \u00b6 \u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente. Connettivit\u00e0 \u00b6 Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa Alberi \u00b6 Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa. Cammini euleriani ed hamiltoniani \u00b6 Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi) Cammini euleriani (archi) \u00b6 Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\) Cammini hamiltoniani (nodi) \u00b6 Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G Il problema del commesso viaggiatore \u00b6 Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\] Distanza su grafi \u00b6 Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi. Isomorfismo \u00b6 L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi. Altri grafi noti \u00b6 Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Grafi"},{"location":"FdI/grafi/#i-grafi-e-gli-alberi","text":"I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme.","title":"I grafi e gli alberi"},{"location":"FdI/grafi/#grafi-orientati","text":"Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) .","title":"Grafi orientati"},{"location":"FdI/grafi/#le-proprieta-tusi","text":"Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\)","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/grafi/#rappresentazione-dei-grafi-orientati","text":"Esistono diversi modi per rappresentare i grafi orientati","title":"Rappresentazione dei grafi orientati"},{"location":"FdI/grafi/#matrice-di-adiacenza","text":"La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra.","title":"Matrice di adiacenza"},{"location":"FdI/grafi/#liste-di-adiacenza","text":"Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\)","title":"Liste di adiacenza"},{"location":"FdI/grafi/#grafi-etichettati-e-pesati","text":"Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche:","title":"Grafi etichettati e pesati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita","text":"In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path.","title":"Cammini, cicli e connettivit\u00e0"},{"location":"FdI/grafi/#cicli-nei-grafi-orientati","text":"walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\)","title":"Cicli nei grafi orientati"},{"location":"FdI/grafi/#connettivita","text":"Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y.","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#grafi-orientati-aciclici","text":"Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico.","title":"Grafi orientati aciclici"},{"location":"FdI/grafi/#grafi-non-orientati","text":"Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari.","title":"Grafi non orientati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita-sui-grafi-non-orientati","text":"La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path.","title":"Cammini, cicli e connettivit\u00e0 sui grafi non orientati"},{"location":"FdI/grafi/#cicli-nei-grafi-non-orientati","text":"\u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente.","title":"Cicli nei grafi non orientati"},{"location":"FdI/grafi/#connettivita_1","text":"Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#alberi","text":"Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa.","title":"Alberi"},{"location":"FdI/grafi/#cammini-euleriani-ed-hamiltoniani","text":"Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi)","title":"Cammini euleriani ed hamiltoniani"},{"location":"FdI/grafi/#cammini-euleriani-archi","text":"Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\)","title":"Cammini euleriani (archi)"},{"location":"FdI/grafi/#cammini-hamiltoniani-nodi","text":"Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G","title":"Cammini hamiltoniani (nodi)"},{"location":"FdI/grafi/#il-problema-del-commesso-viaggiatore","text":"Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\]","title":"Il problema del commesso viaggiatore"},{"location":"FdI/grafi/#distanza-su-grafi","text":"Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi.","title":"Distanza su grafi"},{"location":"FdI/grafi/#isomorfismo","text":"L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi.","title":"Isomorfismo"},{"location":"FdI/grafi/#altri-grafi-noti","text":"Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Altri grafi noti"},{"location":"FdI/induzione/","text":"Induzione matematica \u00b6 L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme. Definizione induttiva \u00b6 Definizione induttiva di un insieme \u00b6 Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via. Definizione induttiva di una funzione \u00b6 La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\) Principio di induzione sui naturali \u00b6 Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\] Principio di induzione forte sui naturali \u00b6 In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Induzione Matematica"},{"location":"FdI/induzione/#induzione-matematica","text":"L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme.","title":"Induzione matematica"},{"location":"FdI/induzione/#definizione-induttiva","text":"","title":"Definizione induttiva"},{"location":"FdI/induzione/#definizione-induttiva-di-un-insieme","text":"Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via.","title":"Definizione induttiva di un insieme"},{"location":"FdI/induzione/#definizione-induttiva-di-una-funzione","text":"La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\)","title":"Definizione induttiva di una funzione"},{"location":"FdI/induzione/#principio-di-induzione-sui-naturali","text":"Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\]","title":"Principio di induzione sui naturali"},{"location":"FdI/induzione/#principio-di-induzione-forte-sui-naturali","text":"In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Principio di induzione forte sui naturali"},{"location":"FdI/induzioneRicorsione/","text":"Induzione strutturale e ricorsione \u00b6 La maggior pparte degli oggetti nell'informatica sono definiti induttivamente, ovvero su istanze pi\u00f9 piccole di loro stessi. Le definizione induttive garantiscono la correttezza di una tecnica di dimostrazione chiamata principio di induzione strutturale. Le definizione induttive sono un caso specifico di definizioni ricorsive, che permettono di di definire una funzione in termini del suo valore su oggetti arbitrari (non necessariamente pi\u00f9 piccoli). Liste \u00b6 Le liste sono sequenze di dati di lunghezza variabile, tipicamente di valore omogeneo. Gli oggetti sono in genere denotati tra parentesi quadre [ e ] . La lista buona \u00e8 denotata dal simbolo [] e rappresenta una sequenza senza elementi. Una cosa importante \u00e8 che le liste sono sempre sequenze finite . Cos\u00ec come tutti i numeri naturali possono essere formati partendo da 0 e facendo uso dell'operazione _ + 1 , possiamo fare lo stesso partendo dalla lista vuota [] usando l'operazione a:_ , che aggiunge un elemento \\(a \\in A\\) in testa alla lista. Lista [1,1,2,3] La lista [1,1,2,3] \u00e8 ottenibile come \\(1:(1:(2:(3:[])))\\) . Definizione di lista (induttiva) L'insieme \\(L_A\\) delle liste degli elementi di A \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Clausola base: \\([] \\in L_A\\) (la lista vuota) Passo induttivo: Per ogni \\(a \\in A\\) se \\(lst \\in L_A\\) , allora \\(a:lst \\in L_A\\) (se la lista appartiene a \\(L_A\\) , continuer\u00e0 ad appartenere aggiungendo un nuovo elemento in A) Funzioni su liste \u00b6 \u00c8 possibile sfruttare la definizione induttiva di lista per definire induttivamente funzioni su \\(L_A\\) . Definizione di lunghezza La funzione \\(les: |L_A \\rightarrow \\mathbb N\\) \u00e8 definita per induzione come: Clausola base: \\(len([]) =0\\) Clausola induttiva: \\(len(a:lst) = len(lst) + 1\\) per ogni \\(a \\in A\\) Definizione di somma su lista La funzione \\(sunList(lst): L_{\\mathbb N} \\rightarrow \\mathbb N\\) \u00e8 definita induttivamente come: Clausola base: \\(sumList([]) = 0\\) Clausola induttiva: \\(sumList(n:lst) = sumList(lst) + n\\) per ogni \\(n \\in \\mathbb N\\) Definizione di appartenenza ad una lista Le funzione \\(belList: L_A \\times A \\rightarrow Bool\\) \u00e8 definita (induttivamente) come: Caso base: \\(belList([],b) = f\\) per ogni \\(b \\in A\\) \\(belList(a:lst, b) = t\\) per ogni \\(a,b \\in A\\) tali che \\(a=b\\) \\(belList(a:lst, b) = belList(lst,b)\\) per ogni \\(a,b \\in A\\) tali che \\(a \\ne b\\) Questo algoritmo appena descritto si pu\u00f2 pensare come ad un algoritmo che controlla la lista da sinistra a destra e restituisce t appena trova l'elemento, altrimenti continua fino ad esaurire gli elementi della lista. Concatenazione La funzione \\(app: L_A \\times L_A \\rightarrow L_A\\) si pu\u00f2 definire come: \\(app([], lst_2) = lst_2\\) \\(app(a:lst_1, lst_2) = a:app(lst_1, lst_2)\\) Inversione di liste La funzione \\(rev: L_A \\rightarrow L_A\\) si definisce come: \\(rev([]) = []\\) $rev(a:lst) = app(rev(lst), a:[]) Il principio di induzione sulle liste \u00b6 Il principio di induzione sulle liste Il principio di induzione sulle liste stabilisce che: Caso base: se \\(P([])\\) \u00e8 vera, e Passo induttivo: per ogni \\(a \\in A\\) , per ogni lista \\(lst^{'} \\in L_A\\) se \\(P(lst^{'})\\) \u00e8 vera, allora anche \\(P(a:lst^{'})\\) \u00e8 vera. Allora \\(P(lst)\\) \u00e8 vera per ogni lista in A. Possiamo scrivere questo principio anche come formula di inferenza: \\[ \\frac{P([]) \\quad \\forall a \\in A.\\forall lst^{'} \\in L_A.P(lst^{'}) \\Rightarrow P(a:lst^{'})}{\\forall lst \\in L_A.P(lst)} \\quad \\text{ P.I. su }L_A \\] Alberi binari \u00b6 Alberi binari L'insieme BT degli alberi binari \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda in BT\\) l'albero vuoto se \\(t_1,t_2 \\in BT\\) allora \\(N(t_1,t_2) \\in BT\\) , un nodo con due sottoalberi I due sottoalberi \\(t_1\\) e \\(t_2\\) sono chiami sottoalbero sinistro e sottoalbero destro. Un nodo \u00e8 una foglia se entrambi i suoi sottoalberi sono vuoti, altrimeni \u00e8 un nodo interno. Un esempio di albero binario \u00e8 il seguente: \\[ t = \\underbrace{N}_\\text{radice}(N(\\lambda,N(\\lambda,\\lambda)),N(N(\\lambda,N(\\lambda,\\lambda)), N(\\lambda,\\lambda))) \\] Funzioni su alberi binari \u00b6 Come per le liste, possiamo sfruttare la definizione induttiva degli alberi binari per generare le funzioni. Dimensione La funzione \\(size: BT \\rightarrow \\mathbb N\\) \u00e8 definita come: \\(size(0) = 0\\) $size(N(t_1, t_2)) = size(t_1) + size(t_2) + 1 La funzione size associa ad ogni albero la sua dimensione (ovvero il numero di nodi) Altezza La funzione \\(height: BT \\rightarrow \\mathbb N \\cup \\{-1\\}\\) \u00e8 definita come: \\(height(\\lambda) = -1\\) $height(N(t_1, t_2)) = max(height(t_1), height(t_2)) + 1 La funzione height associa ad ogni albero la sua altezza, ovvero la lunghezza massima di un tral che vada dall radice al nodo pi\u00f9 distante Principio di induzione sugli alberi binari \u00b6 Principio di induzione sugli alberi binari Il principio di induzione sugli alberi binari stabilisce che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(t_1, t_2 \\in BT\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall t_1,t_2 \\in BT.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,t_2)))}{\\forall t \\in BT. P(t)} \\text{ P.I. su BT} \\] Per tutti gli alberi, height(t) <= size(t) Caso base: t = \\(\\lambda\\) \\(height(\\lambda) = -1\\) (clausola base height) \\(-1 \\leq 0\\) \\(= size(\\lambda)\\) Passo induttivo: \\(height(N(t_1, t_2)) = max(height(t_1), height(t_2)) +1\\) (Clausola induttiva height) \\(\\leq max(size(t_1), size(t_2)) +1\\) (Ipotesi induttiva) \\(\\leq size(t_1) + size(t_2) + 1\\) \\(= size(N(t_1, t_2))\\) (Clausola induttiva size) Alberi binari etichettati \u00b6 Definizione strutturale di alberi binari etichettati L'insieme \\(BT_A\\) degli alberi binari etichettati con elementi di un dato insieme A, \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda \\in BT_A\\) (L'albero vuoto) se \\(t_1,t_2 \\in BT_A\\) allora \\(N(t_1, a, t_2) \\in BT_A\\) per ogni \\(a \\in A\\) Funzioni su alberi binari etichettati \u00b6 Appartenenza ad un albero La funzione \\(belBT: BT_A \\times A \\rightarrow Bool\\) \u00e8 definita come: $belBT(\\lambda,b) =f $ \\(belBT(N(t_1,a, t_2),b) = t\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) \\(belBT(N(t_1,a,t_2),b) = belBT(t_1,b) \\lor belBT(t_2,b)\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) Somma su albero La funzione \\(sumBT: BT_N \\rightarrow \\mathcal N\\) \u00e8 definita come induzione come \\(sumBT(\\lambda) = 0\\) \\(sumBT(N(t_1,n,T_2)) = sumBT(t_1) + sumBT(t_2) + n\\) Questa funzione prende l'etichetta \\(n\\) in ogni nodo e la somma con tutti gli altri nodi Visita di un albero in ordine simmetrico La funzione \\(visit: BT_A \\rightarrow L_A\\) \u00e8 definita come: \\(visit(\\lambda)=[\\ ]\\) visit(N(t_1,n,t_2)) = app(visit(t_1),a,visit(t_2)) Questa funzione visita l'albero in ordine simmetrico da sinistra a destra, dato ch eper ogni nodo viene prima visitato il figlio sinistro, poi il nodo stesso e poi il nodo destro. L'ordine della visione pu\u00f2 essere modificato attraverso l'ordine dei parametri della seconda funzione. Principio di induzione sugli alberi binari etichettati \u00b6 Principio di induzione sugli alberi binari etichettati Il principio di induzione sugli alberi binari stabilisce un concetto simile a quello che vale per gli alberi binari, con l'unica accortezza di ferificare P su che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(a \\in A\\) , per ogni \\(t_1, t_2 \\in BT_A\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,a,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT_A\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall a \\in A, \\forall t_1,t_2 \\in BT_A.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,a,t_2)))}{\\forall t \\in BT_A. P(t)} \\text{ P.I. su } BT_A \\] L'induzione strutturale \u00b6 L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\] Rappresentazione grafica dei termini \u00b6 \u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) . Alberi \u00b6 TODO Rappresentazione di alberi binari come termini \u00b6 Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Liste \u00b6 TODO Rappresentazione di liste come termini \u00b6 Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\) Naturali \u00b6 Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Funzioni su termini \u00b6 \u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm \\times \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base) Il principio di Induzione Strutturale \u00b6 Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene Funzioni ricorsive \u00b6 Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita. Relazione di precedenza indotta da una funzione ricorsiva Data una definizione ricordiva di \\(rec: A \\rightarrow B\\) , la lreazione di precedenza indotta \u00e8 la relazione \\(\\prec_{rec} \\in Rel(A,A)\\) definita come: Per ogni \\(x,y \\in A, x \\prec_{rec} y\\) se e solo se \\(rec(y)\\) \u00e8 definita direttamente in termini di \\(rec(x)\\) Questa definizione non \u00e8 necessariamente aciclica Quindi, data la definizione di precedenza, possiamo presentare alcune relazioni di precedenza: \\(\\prec_{due} \\in Rel(\\mathbb N,\\mathbb N)\\) , definita come \\(n+1 \\prec_{due}n\\) se \\(n \\leq 100\\) \\(\\prec_g \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(n+1\\prec_g n\\) se \\(n > 0\\) \\(\\prec_f \\in Rel(\\mathbb Z,\\mathbb Z)\\) definita come \\(n-1 \\prec_f n\\) se \\(n \\in \\mathbb Z\\) \\(\\prec_h \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(\\prec_h = \\{ (n-2,n) | n \\geq 2 \\} \\cup \\{(3,1)\\}\\) Quindi, se \\(b \\prec_{rec} a\\) , devo valutare \\(rec(b)\\) per poter valutare \\(rec(a)\\) . Ma se una funzione \u00e8 definita solamente in termin di s\u00e9 stessa, la valutazione non termina mai. Relazione ben fondata Una relazione \\(\\sqsubset\\) su un insieme A, definita come \\(\\sqsubset \\in Rel(A,A)\\) , si dice ben fondata se non esiste una catena infinita decrescente \\[ a_1 \\sqsupset a_2 \\sqsupset a_3 \\sqsupset ... \\] di elementi \\(a_i\\) su A Possiamo quindi dire che una funzione non \u00e8 ben fondata quando \u00e8 definita infinite volte su se stessa. Al contrario, una definizione ricorsiva di \\(rec: A \\rightarrow B\\) \u00e8 ben data (ovvero \u00e8 totale ed univalente) quando: Per ogni elemento \\(a \\in A\\) c'\u00e8 esattamente una clausola della definizione applicabile per valutare \\(rec(a)\\) La relazione \\(\\prec_{rec}\\) \u00e8 ben fondata Le definizioni induttive sono sempre ben date: relazioni di precedenza indotta da definizione induttiva Data una definizione induttiva di un insieme A, la relazione di precedenza indotta \u00e8 \\(\\prec_A \\in Rel(A,A)\\) . Questo \u00e8 dato dal fatto che, se per la clausola induttiva l'elemento a appartiene all'insieme ci appartengono \\(a_1,...,a_n\\) : \\(a_1 \\prec_A a,a_2 \\prec_A a,...,a_k \\prec_A a\\) Questa definizione pu\u00f2 essere applicata a qualunque definizione induttiva, mantenuta cos\u00ec generale grazie al concetto di f-termine : Per ogni \\(n \\geq 1\\) , per ogni \\(f \\in \\mathbb F\\) , \\(t_1 \\prec f(t_1, ...,t_2), \\quad t_2 \\prec f(t_1,...,t_2),..., t_n \\prec f(t_1,...,t_n)\\) Quindi una relazione definita tramite induttiva \u00e8 ben data poihc\u00e9 l'insieme caratterizzato \u00e8 il pi\u00f9 piccolo che soddisfa clausola base e passo induttivo: ogni elemento dell'insieme appartiene ad una sequenza finita di di applicazioni della clausola induttiva, che garantisce che la relazione \\(\\prec\\) \u00e8 ben fondata. Possiamo quindi determinare delle propriet\u00e0: Se \\(\\sqsubset\\) \u00e8 ben fondata, e \\(\\sqsubset_1 \\subseteq \\sqsubset\\) , allora anche \\(\\sqsubset_1\\) \u00e8 ben fondata. Una relazione \\(\\sqsubset\\) \u00e8 ben fondata solo se lo \u00e8 la sua chiusura transitiva \\(\\sqsubset^+\\) La congettura di Collatz \u00b6 La congettura di Collatz afferma che una funzione come questa: \\[ f(n) = \\begin{cases} 1 & \\text{ se } n \\leq 1 \\\\ f(n/2) & \\text{ se } n >1 \\text { ed \u00e8 pari} \\\\ f(3 \\cdot n+1) & \\text{ se } n>1 \\text { ed \u00e8 dispari} \\end{cases} \\] \u00e8 totale, tuttavia non \u00e8 stato determinato se \u00e8 cos\u00ec per ogni valore \\(k \\in \\mathbb N\\) Tipologie di ricorsione \u00b6 Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta Ricorsione annidata \u00b6 Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata Un esempio di ricorsione annidata \u00e8 data dall'equazione di McCarthy: \\[ f(n) = \\begin{cases} n-10 & \\text{ se } n>100 \\\\ f(f(n+11)) & \\text{ se } n \\leq 100 \\end{cases} \\] Ricorsione mutua \u00b6 La recusione si dice mutua quando la chiamata avviene indirettamente, ovvero da parte di una seconda funzione chiamata a suoa volta direttamente o indirettamente dalla prima. Esempio di ricosione mutua $$ ping(n) = \\begin{cases} 0 & \\text{ se } n=0 \\ pong(n-1) & \\text{ altrimenti } \\end{cases} pong(n) = \\begin{cases} 0 & \\text{ se } n=100 \\ ping(n-1) & \\text{ altrimenti } \\end{cases} $$ Ricorsione procedurale \u00b6 Le ricorsioni procedurali sono funzioni scritte attraverso linguaggi di programmazione, che possono avere collaterali come input, output, stampa a schermo ecc... void stampa_array ( int a [], int i , int n ){ if ( i < n ){ // Clausola ricorsiva: c'\u00e8 andora qulcosa da stampare printf ( \"%d\" , a [ i ]); stampa_array ( a , i + 1 , n ); } //Clausola base: i == n; l'array a[i..n-1] \u00e8 vuoto, la procedura termina }","title":"Induzione Strutturale e Ricorsione"},{"location":"FdI/induzioneRicorsione/#induzione-strutturale-e-ricorsione","text":"La maggior pparte degli oggetti nell'informatica sono definiti induttivamente, ovvero su istanze pi\u00f9 piccole di loro stessi. Le definizione induttive garantiscono la correttezza di una tecnica di dimostrazione chiamata principio di induzione strutturale. Le definizione induttive sono un caso specifico di definizioni ricorsive, che permettono di di definire una funzione in termini del suo valore su oggetti arbitrari (non necessariamente pi\u00f9 piccoli).","title":"Induzione strutturale e ricorsione"},{"location":"FdI/induzioneRicorsione/#liste","text":"Le liste sono sequenze di dati di lunghezza variabile, tipicamente di valore omogeneo. Gli oggetti sono in genere denotati tra parentesi quadre [ e ] . La lista buona \u00e8 denotata dal simbolo [] e rappresenta una sequenza senza elementi. Una cosa importante \u00e8 che le liste sono sempre sequenze finite . Cos\u00ec come tutti i numeri naturali possono essere formati partendo da 0 e facendo uso dell'operazione _ + 1 , possiamo fare lo stesso partendo dalla lista vuota [] usando l'operazione a:_ , che aggiunge un elemento \\(a \\in A\\) in testa alla lista. Lista [1,1,2,3] La lista [1,1,2,3] \u00e8 ottenibile come \\(1:(1:(2:(3:[])))\\) . Definizione di lista (induttiva) L'insieme \\(L_A\\) delle liste degli elementi di A \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Clausola base: \\([] \\in L_A\\) (la lista vuota) Passo induttivo: Per ogni \\(a \\in A\\) se \\(lst \\in L_A\\) , allora \\(a:lst \\in L_A\\) (se la lista appartiene a \\(L_A\\) , continuer\u00e0 ad appartenere aggiungendo un nuovo elemento in A)","title":"Liste"},{"location":"FdI/induzioneRicorsione/#funzioni-su-liste","text":"\u00c8 possibile sfruttare la definizione induttiva di lista per definire induttivamente funzioni su \\(L_A\\) . Definizione di lunghezza La funzione \\(les: |L_A \\rightarrow \\mathbb N\\) \u00e8 definita per induzione come: Clausola base: \\(len([]) =0\\) Clausola induttiva: \\(len(a:lst) = len(lst) + 1\\) per ogni \\(a \\in A\\) Definizione di somma su lista La funzione \\(sunList(lst): L_{\\mathbb N} \\rightarrow \\mathbb N\\) \u00e8 definita induttivamente come: Clausola base: \\(sumList([]) = 0\\) Clausola induttiva: \\(sumList(n:lst) = sumList(lst) + n\\) per ogni \\(n \\in \\mathbb N\\) Definizione di appartenenza ad una lista Le funzione \\(belList: L_A \\times A \\rightarrow Bool\\) \u00e8 definita (induttivamente) come: Caso base: \\(belList([],b) = f\\) per ogni \\(b \\in A\\) \\(belList(a:lst, b) = t\\) per ogni \\(a,b \\in A\\) tali che \\(a=b\\) \\(belList(a:lst, b) = belList(lst,b)\\) per ogni \\(a,b \\in A\\) tali che \\(a \\ne b\\) Questo algoritmo appena descritto si pu\u00f2 pensare come ad un algoritmo che controlla la lista da sinistra a destra e restituisce t appena trova l'elemento, altrimenti continua fino ad esaurire gli elementi della lista. Concatenazione La funzione \\(app: L_A \\times L_A \\rightarrow L_A\\) si pu\u00f2 definire come: \\(app([], lst_2) = lst_2\\) \\(app(a:lst_1, lst_2) = a:app(lst_1, lst_2)\\) Inversione di liste La funzione \\(rev: L_A \\rightarrow L_A\\) si definisce come: \\(rev([]) = []\\) $rev(a:lst) = app(rev(lst), a:[])","title":"Funzioni su liste"},{"location":"FdI/induzioneRicorsione/#il-principio-di-induzione-sulle-liste","text":"Il principio di induzione sulle liste Il principio di induzione sulle liste stabilisce che: Caso base: se \\(P([])\\) \u00e8 vera, e Passo induttivo: per ogni \\(a \\in A\\) , per ogni lista \\(lst^{'} \\in L_A\\) se \\(P(lst^{'})\\) \u00e8 vera, allora anche \\(P(a:lst^{'})\\) \u00e8 vera. Allora \\(P(lst)\\) \u00e8 vera per ogni lista in A. Possiamo scrivere questo principio anche come formula di inferenza: \\[ \\frac{P([]) \\quad \\forall a \\in A.\\forall lst^{'} \\in L_A.P(lst^{'}) \\Rightarrow P(a:lst^{'})}{\\forall lst \\in L_A.P(lst)} \\quad \\text{ P.I. su }L_A \\]","title":"Il principio di induzione sulle liste"},{"location":"FdI/induzioneRicorsione/#alberi-binari","text":"Alberi binari L'insieme BT degli alberi binari \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda in BT\\) l'albero vuoto se \\(t_1,t_2 \\in BT\\) allora \\(N(t_1,t_2) \\in BT\\) , un nodo con due sottoalberi I due sottoalberi \\(t_1\\) e \\(t_2\\) sono chiami sottoalbero sinistro e sottoalbero destro. Un nodo \u00e8 una foglia se entrambi i suoi sottoalberi sono vuoti, altrimeni \u00e8 un nodo interno. Un esempio di albero binario \u00e8 il seguente: \\[ t = \\underbrace{N}_\\text{radice}(N(\\lambda,N(\\lambda,\\lambda)),N(N(\\lambda,N(\\lambda,\\lambda)), N(\\lambda,\\lambda))) \\]","title":"Alberi binari"},{"location":"FdI/induzioneRicorsione/#funzioni-su-alberi-binari","text":"Come per le liste, possiamo sfruttare la definizione induttiva degli alberi binari per generare le funzioni. Dimensione La funzione \\(size: BT \\rightarrow \\mathbb N\\) \u00e8 definita come: \\(size(0) = 0\\) $size(N(t_1, t_2)) = size(t_1) + size(t_2) + 1 La funzione size associa ad ogni albero la sua dimensione (ovvero il numero di nodi) Altezza La funzione \\(height: BT \\rightarrow \\mathbb N \\cup \\{-1\\}\\) \u00e8 definita come: \\(height(\\lambda) = -1\\) $height(N(t_1, t_2)) = max(height(t_1), height(t_2)) + 1 La funzione height associa ad ogni albero la sua altezza, ovvero la lunghezza massima di un tral che vada dall radice al nodo pi\u00f9 distante","title":"Funzioni su alberi binari"},{"location":"FdI/induzioneRicorsione/#principio-di-induzione-sugli-alberi-binari","text":"Principio di induzione sugli alberi binari Il principio di induzione sugli alberi binari stabilisce che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(t_1, t_2 \\in BT\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall t_1,t_2 \\in BT.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,t_2)))}{\\forall t \\in BT. P(t)} \\text{ P.I. su BT} \\] Per tutti gli alberi, height(t) <= size(t) Caso base: t = \\(\\lambda\\) \\(height(\\lambda) = -1\\) (clausola base height) \\(-1 \\leq 0\\) \\(= size(\\lambda)\\) Passo induttivo: \\(height(N(t_1, t_2)) = max(height(t_1), height(t_2)) +1\\) (Clausola induttiva height) \\(\\leq max(size(t_1), size(t_2)) +1\\) (Ipotesi induttiva) \\(\\leq size(t_1) + size(t_2) + 1\\) \\(= size(N(t_1, t_2))\\) (Clausola induttiva size)","title":"Principio di induzione sugli alberi binari"},{"location":"FdI/induzioneRicorsione/#alberi-binari-etichettati","text":"Definizione strutturale di alberi binari etichettati L'insieme \\(BT_A\\) degli alberi binari etichettati con elementi di un dato insieme A, \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda \\in BT_A\\) (L'albero vuoto) se \\(t_1,t_2 \\in BT_A\\) allora \\(N(t_1, a, t_2) \\in BT_A\\) per ogni \\(a \\in A\\)","title":"Alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#funzioni-su-alberi-binari-etichettati","text":"Appartenenza ad un albero La funzione \\(belBT: BT_A \\times A \\rightarrow Bool\\) \u00e8 definita come: $belBT(\\lambda,b) =f $ \\(belBT(N(t_1,a, t_2),b) = t\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) \\(belBT(N(t_1,a,t_2),b) = belBT(t_1,b) \\lor belBT(t_2,b)\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) Somma su albero La funzione \\(sumBT: BT_N \\rightarrow \\mathcal N\\) \u00e8 definita come induzione come \\(sumBT(\\lambda) = 0\\) \\(sumBT(N(t_1,n,T_2)) = sumBT(t_1) + sumBT(t_2) + n\\) Questa funzione prende l'etichetta \\(n\\) in ogni nodo e la somma con tutti gli altri nodi Visita di un albero in ordine simmetrico La funzione \\(visit: BT_A \\rightarrow L_A\\) \u00e8 definita come: \\(visit(\\lambda)=[\\ ]\\) visit(N(t_1,n,t_2)) = app(visit(t_1),a,visit(t_2)) Questa funzione visita l'albero in ordine simmetrico da sinistra a destra, dato ch eper ogni nodo viene prima visitato il figlio sinistro, poi il nodo stesso e poi il nodo destro. L'ordine della visione pu\u00f2 essere modificato attraverso l'ordine dei parametri della seconda funzione.","title":"Funzioni su alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#principio-di-induzione-sugli-alberi-binari-etichettati","text":"Principio di induzione sugli alberi binari etichettati Il principio di induzione sugli alberi binari stabilisce un concetto simile a quello che vale per gli alberi binari, con l'unica accortezza di ferificare P su che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(a \\in A\\) , per ogni \\(t_1, t_2 \\in BT_A\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,a,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT_A\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall a \\in A, \\forall t_1,t_2 \\in BT_A.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,a,t_2)))}{\\forall t \\in BT_A. P(t)} \\text{ P.I. su } BT_A \\]","title":"Principio di induzione sugli alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#linduzione-strutturale","text":"L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\]","title":"L'induzione strutturale"},{"location":"FdI/induzioneRicorsione/#rappresentazione-grafica-dei-termini","text":"\u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) .","title":"Rappresentazione grafica dei termini"},{"location":"FdI/induzioneRicorsione/#alberi","text":"TODO","title":"Alberi"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-alberi-binari-come-termini","text":"Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\]","title":"Rappresentazione di alberi binari come termini"},{"location":"FdI/induzioneRicorsione/#liste_1","text":"TODO","title":"Liste"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-liste-come-termini","text":"Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\)","title":"Rappresentazione di liste come termini"},{"location":"FdI/induzioneRicorsione/#naturali","text":"Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\]","title":"Naturali"},{"location":"FdI/induzioneRicorsione/#funzioni-su-termini","text":"\u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm \\times \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base)","title":"Funzioni su termini"},{"location":"FdI/induzioneRicorsione/#il-principio-di-induzione-strutturale","text":"Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene","title":"Il principio di Induzione Strutturale"},{"location":"FdI/induzioneRicorsione/#funzioni-ricorsive","text":"Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita. Relazione di precedenza indotta da una funzione ricorsiva Data una definizione ricordiva di \\(rec: A \\rightarrow B\\) , la lreazione di precedenza indotta \u00e8 la relazione \\(\\prec_{rec} \\in Rel(A,A)\\) definita come: Per ogni \\(x,y \\in A, x \\prec_{rec} y\\) se e solo se \\(rec(y)\\) \u00e8 definita direttamente in termini di \\(rec(x)\\) Questa definizione non \u00e8 necessariamente aciclica Quindi, data la definizione di precedenza, possiamo presentare alcune relazioni di precedenza: \\(\\prec_{due} \\in Rel(\\mathbb N,\\mathbb N)\\) , definita come \\(n+1 \\prec_{due}n\\) se \\(n \\leq 100\\) \\(\\prec_g \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(n+1\\prec_g n\\) se \\(n > 0\\) \\(\\prec_f \\in Rel(\\mathbb Z,\\mathbb Z)\\) definita come \\(n-1 \\prec_f n\\) se \\(n \\in \\mathbb Z\\) \\(\\prec_h \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(\\prec_h = \\{ (n-2,n) | n \\geq 2 \\} \\cup \\{(3,1)\\}\\) Quindi, se \\(b \\prec_{rec} a\\) , devo valutare \\(rec(b)\\) per poter valutare \\(rec(a)\\) . Ma se una funzione \u00e8 definita solamente in termin di s\u00e9 stessa, la valutazione non termina mai. Relazione ben fondata Una relazione \\(\\sqsubset\\) su un insieme A, definita come \\(\\sqsubset \\in Rel(A,A)\\) , si dice ben fondata se non esiste una catena infinita decrescente \\[ a_1 \\sqsupset a_2 \\sqsupset a_3 \\sqsupset ... \\] di elementi \\(a_i\\) su A Possiamo quindi dire che una funzione non \u00e8 ben fondata quando \u00e8 definita infinite volte su se stessa. Al contrario, una definizione ricorsiva di \\(rec: A \\rightarrow B\\) \u00e8 ben data (ovvero \u00e8 totale ed univalente) quando: Per ogni elemento \\(a \\in A\\) c'\u00e8 esattamente una clausola della definizione applicabile per valutare \\(rec(a)\\) La relazione \\(\\prec_{rec}\\) \u00e8 ben fondata Le definizioni induttive sono sempre ben date: relazioni di precedenza indotta da definizione induttiva Data una definizione induttiva di un insieme A, la relazione di precedenza indotta \u00e8 \\(\\prec_A \\in Rel(A,A)\\) . Questo \u00e8 dato dal fatto che, se per la clausola induttiva l'elemento a appartiene all'insieme ci appartengono \\(a_1,...,a_n\\) : \\(a_1 \\prec_A a,a_2 \\prec_A a,...,a_k \\prec_A a\\) Questa definizione pu\u00f2 essere applicata a qualunque definizione induttiva, mantenuta cos\u00ec generale grazie al concetto di f-termine : Per ogni \\(n \\geq 1\\) , per ogni \\(f \\in \\mathbb F\\) , \\(t_1 \\prec f(t_1, ...,t_2), \\quad t_2 \\prec f(t_1,...,t_2),..., t_n \\prec f(t_1,...,t_n)\\) Quindi una relazione definita tramite induttiva \u00e8 ben data poihc\u00e9 l'insieme caratterizzato \u00e8 il pi\u00f9 piccolo che soddisfa clausola base e passo induttivo: ogni elemento dell'insieme appartiene ad una sequenza finita di di applicazioni della clausola induttiva, che garantisce che la relazione \\(\\prec\\) \u00e8 ben fondata. Possiamo quindi determinare delle propriet\u00e0: Se \\(\\sqsubset\\) \u00e8 ben fondata, e \\(\\sqsubset_1 \\subseteq \\sqsubset\\) , allora anche \\(\\sqsubset_1\\) \u00e8 ben fondata. Una relazione \\(\\sqsubset\\) \u00e8 ben fondata solo se lo \u00e8 la sua chiusura transitiva \\(\\sqsubset^+\\)","title":"Funzioni ricorsive"},{"location":"FdI/induzioneRicorsione/#la-congettura-di-collatz","text":"La congettura di Collatz afferma che una funzione come questa: \\[ f(n) = \\begin{cases} 1 & \\text{ se } n \\leq 1 \\\\ f(n/2) & \\text{ se } n >1 \\text { ed \u00e8 pari} \\\\ f(3 \\cdot n+1) & \\text{ se } n>1 \\text { ed \u00e8 dispari} \\end{cases} \\] \u00e8 totale, tuttavia non \u00e8 stato determinato se \u00e8 cos\u00ec per ogni valore \\(k \\in \\mathbb N\\)","title":"La congettura di Collatz"},{"location":"FdI/induzioneRicorsione/#tipologie-di-ricorsione","text":"Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta","title":"Tipologie di ricorsione"},{"location":"FdI/induzioneRicorsione/#ricorsione-annidata","text":"Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata Un esempio di ricorsione annidata \u00e8 data dall'equazione di McCarthy: \\[ f(n) = \\begin{cases} n-10 & \\text{ se } n>100 \\\\ f(f(n+11)) & \\text{ se } n \\leq 100 \\end{cases} \\]","title":"Ricorsione annidata"},{"location":"FdI/induzioneRicorsione/#ricorsione-mutua","text":"La recusione si dice mutua quando la chiamata avviene indirettamente, ovvero da parte di una seconda funzione chiamata a suoa volta direttamente o indirettamente dalla prima. Esempio di ricosione mutua $$ ping(n) = \\begin{cases} 0 & \\text{ se } n=0 \\ pong(n-1) & \\text{ altrimenti } \\end{cases} pong(n) = \\begin{cases} 0 & \\text{ se } n=100 \\ ping(n-1) & \\text{ altrimenti } \\end{cases} $$","title":"Ricorsione mutua"},{"location":"FdI/induzioneRicorsione/#ricorsione-procedurale","text":"Le ricorsioni procedurali sono funzioni scritte attraverso linguaggi di programmazione, che possono avere collaterali come input, output, stampa a schermo ecc... void stampa_array ( int a [], int i , int n ){ if ( i < n ){ // Clausola ricorsiva: c'\u00e8 andora qulcosa da stampare printf ( \"%d\" , a [ i ]); stampa_array ( a , i + 1 , n ); } //Clausola base: i == n; l'array a[i..n-1] \u00e8 vuoto, la procedura termina }","title":"Ricorsione procedurale"},{"location":"FdI/insiemi/","text":"Gli insiemi \u00b6 Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti Definizione di insiemi \u00b6 Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole. Definzione per Enumerazione \u00b6 L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale ! L'insieme vuoto \u00b6 L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\) Definizione per Propriet\u00e0 \u00b6 \u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\) I paradossi \u00b6 In base alle definizioni date, si possono verificare dei paradossi. Il paradosso di Russel \u00b6 Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato Diagrammi di Eulero-Venn \u00b6 I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 I confronti tra insiemi \u00b6 Uguaglianza \u00b6 Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ). Inclusione \u00b6 Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) . Operazioni su insiemi \u00b6 Unione \u00b6 Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) . Intersezione \u00b6 Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\) Differenza \u00b6 Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\) Complemento \u00b6 Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\] Operatori booleani \u00b6 I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica . Le leggi \u00b6 Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali. Dimostrazioni \u00b6 Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive Dimostrazione grafica \u00b6 La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo. Dimostrazione per sostituzione \u00b6 Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0) Dimostrazione discorsive \u00b6 Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente Insiemi di insiemi \u00b6 Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\) Famiglie di insiemi \u00b6 Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\) Partizioni \u00b6 Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\") Numeri naturali come insiemi \u00b6 \u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\) Il prodotto cartesiano \u00b6 Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) ) La cardinalit\u00e0 \u00b6 La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\) Propriet\u00e0 \u00b6 Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Insiemi"},{"location":"FdI/insiemi/#gli-insiemi","text":"Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti","title":"Gli insiemi"},{"location":"FdI/insiemi/#definizione-di-insiemi","text":"Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole.","title":"Definizione di insiemi"},{"location":"FdI/insiemi/#definzione-per-enumerazione","text":"L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale !","title":"Definzione per Enumerazione"},{"location":"FdI/insiemi/#linsieme-vuoto","text":"L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\)","title":"L'insieme vuoto"},{"location":"FdI/insiemi/#definizione-per-proprieta","text":"\u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\)","title":"Definizione per Propriet\u00e0"},{"location":"FdI/insiemi/#i-paradossi","text":"In base alle definizioni date, si possono verificare dei paradossi.","title":"I paradossi"},{"location":"FdI/insiemi/#il-paradosso-di-russel","text":"Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato","title":"Il paradosso di Russel"},{"location":"FdI/insiemi/#diagrammi-di-eulero-venn","text":"I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Diagrammi di Eulero-Venn"},{"location":"FdI/insiemi/#i-confronti-tra-insiemi","text":"","title":"I confronti tra insiemi"},{"location":"FdI/insiemi/#uguaglianza","text":"Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ).","title":"Uguaglianza"},{"location":"FdI/insiemi/#inclusione","text":"Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) .","title":"Inclusione"},{"location":"FdI/insiemi/#operazioni-su-insiemi","text":"","title":"Operazioni su insiemi"},{"location":"FdI/insiemi/#unione","text":"Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) .","title":"Unione"},{"location":"FdI/insiemi/#intersezione","text":"Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\)","title":"Intersezione"},{"location":"FdI/insiemi/#differenza","text":"Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\)","title":"Differenza"},{"location":"FdI/insiemi/#complemento","text":"Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\]","title":"Complemento"},{"location":"FdI/insiemi/#operatori-booleani","text":"I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica .","title":"Operatori booleani"},{"location":"FdI/insiemi/#le-leggi","text":"Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali.","title":"Le leggi"},{"location":"FdI/insiemi/#dimostrazioni","text":"Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive","title":"Dimostrazioni"},{"location":"FdI/insiemi/#dimostrazione-grafica","text":"La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo.","title":"Dimostrazione grafica"},{"location":"FdI/insiemi/#dimostrazione-per-sostituzione","text":"Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0)","title":"Dimostrazione per sostituzione"},{"location":"FdI/insiemi/#dimostrazione-discorsive","text":"Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente","title":"Dimostrazione discorsive"},{"location":"FdI/insiemi/#insiemi-di-insiemi","text":"Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\)","title":"Insiemi di insiemi"},{"location":"FdI/insiemi/#famiglie-di-insiemi","text":"Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\)","title":"Famiglie di insiemi"},{"location":"FdI/insiemi/#partizioni","text":"Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\")","title":"Partizioni"},{"location":"FdI/insiemi/#numeri-naturali-come-insiemi","text":"\u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\)","title":"Numeri naturali come insiemi"},{"location":"FdI/insiemi/#il-prodotto-cartesiano","text":"Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) )","title":"Il prodotto cartesiano"},{"location":"FdI/insiemi/#la-cardinalita","text":"La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\)","title":"La cardinalit\u00e0"},{"location":"FdI/insiemi/#proprieta","text":"Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Propriet\u00e0"},{"location":"FdI/linguaggi/","text":"Linguaggi formali \u00b6 Nei linugaggi dobbiamo distiguere due parti: Sintassi, che ha a che fare con la struttura Semantica, che ha a che fare con il significato delle frasi esprimibili Partiamo con la definizione di linguaggio: Definiamo linugaggio come sinonimo di insieme di frasi sintatticamente ammissibili. Fissato un alfabeto di elementi base, detti simboli, il linguaggio \u00e8 un sottoinsieme di tutte le stringhe, ovvero sequenze di lunghezza arbitraria di simboli. Descriere un linguaggio, significa quindi (i due punti sono alternativi): - decidere quali srienghe farann part e dell'insieme o quali no - costuire l'insieme di stringhe enumerando le stringhe che lo compongono Abbiamo due modi di risovere il come identificare l'insieme dellle stringhe ammissibili che caratterizano un linguaggio: Usare usare un automa, uno strumento in grado di riconoscere tutte e sole le stringhe che fanno parte di un linguaggio Usare una grammatica, che \u00e8 in grado di costruire o generare tutte le stringhe che fanno parte del linugaggio Alfabeti, Parole e Linguaggi \u00b6 Definizione di Alfabeto Un alfabeto \u00e8 un insieme finito. I suoi elementi sono detti simboli Definizione di stringhe Dato un alfabeto \\(A\\) , l'insieme \\(A^*\\) delle stringhe su \\(A\\) rappresenta il pi\u00f9 piccolo insieme che soddisfa: (Clausola base): \\(\\varepsilon \\in A^*\\) , dove \\(\\varepsilon\\) \u00e8 la stringa vuota (Clausola induttiva): Se \\(\\omega \\in A^*\\) e \\(a \\in A\\) , allora \\(a\\omega \\in A^*\\) Notare che l'insieme delle liste \\(L_A\\) e l'insieme \\(A*\\) sono in biiezione. Concatenazione di stringhe La concatenazione di stringhe \u00e8 una funzione \\(\\_ \\cdot \\_: A^* \\times A^* \\rightarrow A^*\\) , definita per tutte le stringhe \\(u,v \\in A^*\\) come \\(u \\times v = uv\\) Linugaggio Un linguaggio su A \u00e8 un insieme \\(L \\subseteq A^*\\) . L'insieme di tutti i linguaggi \u00e8 denotato come \\(\\mathcal P(A^*)\\) Operazioni su lunguaggi \u00b6 Per ogni alfabeto A, esistono sempre: Il linguaggio vuoto \\(\\varnothing = \\{\\}\\) Il linguaggio che contiene solo la stringa vuota \\({\\varepsilon}\\) Il linguaggio completo \\(A^*\\) I linguaggi possono essere combinate come con le operazioni insiemistiche. Concatenazione di linguaggi La funzione \\(\\_ \\cdot \\_: \\mathcal P(A^*) \\times \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) \u00e8 definita per tutti i linguaggi \\(L_1, L_2 \\in \\mathcal P(A^*)\\) come \\(L_1 \\cdot L_2 = \\{ \\omega \\in A^* | \\text{ esistono } \\omega_1 \\in L_1, \\omega_2 \\in L_2 \\text { tali che } \\omega = \\omega_1 \\cdot \\omega_2 \\}\\) Concatenazione n-aria di linguaggi Dato un insieme A ed un linguaggio \\(L \\in \\mathcal P(A)\\) , per ogni numero naturale \\(n \\in \\mathbb N\\) , definiamo \\(L^n\\) induttivamente: \\(L^0 = \\{ \\varepsilon \\}\\) \\(L^{n+1} = L \\cdot L^{n}\\) Stella di Kleene La stella di Kleene \u00e8 una funzione \\((_)^*: \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) per tutti i linguaggi \\(L \\in \\mathcal P(A^*)\\) definita come: \\[ \\bigcup _{n \\in \\mathbb N} L^n \\] Automi \u00b6 Gli automi sono chiamati anche macchine a stati, e vengono descritti attraverso transizioni di stato, letture in input e produzioni in output. Gli automi sono alberi i cui nodi rappresentano gli stati e gli archi i simboli la cui lettura \u00e8 necessarie per innescare la transizione. Automa Un automa sull'alfabeto A \u00e8 una tripla \\(A=(S,T,F)\\) , dove: S \u00e8 un insieme, detto insieme degli stati \\(T \\subseteq (A \\times S) \\times S\\) \u00e8 una relazione in \\(Rel(A \\times S,S)\\) detta relazione di transizione, che associa ad ogni lettera dell'alfabeto \\(a \\in A\\) ad ogni stato di partenza \\(x \\in S\\) zero o pi\u00f9 stati di destinazione \\(F \\subseteq S\\) \u00e8 l'insieme degli stati finali (o stati di accettazione) L'automa \\(\\mathcal A\\) si dice a stati finiti se l'insieme degli stati S \u00e8 finito Raggiungibilit\u00e0 negli automi Sia A = (S,T,F) un automa sull'alfabeto A, per ogni \\(a \\in A\\) si definisce la relazione \\(T_a \\in Rel(S,S)\\) come \\(T_a = \\{ (x,y) | ((a,x),y) \\in T \\}\\) Per ogni stringa in \\(\\omega \\in A^*\\) , defianio per induzione \\(T_w \\in Rel(S,S)\\) come: \\(T_\\omega = id_S\\) \\(T_{aw} = T_a;T_w\\) Lo stato y \\((x,y) \\in T_\\omega\\) si dice raggiungibile da x con la stringa \\(\\omega\\) Linguaggio accettato Sia A = (S,T,F) un automa a stati finiti, la funzione \\(\\langle \\langle \\cdot \\rangle \\rangle: S \\rightarrow \\mathcal P(A)\\) \u00e8 definita per ogni stato \\(x \\in S\\) come \\[ \\langle \\langle x \\rangle \\rangle = \\{ \\omega \\in A^* | \\text{ esiste } y \\in F \\text{ tale che } (x,y) \\in T_\\omega \\} \\] Il linguaggio \\(\\langle \\langle x \\rangle \\rangle\\) \u00e8 detto il linguaggio accettato da x. Se \\(\\omega \\in \\langle \\langle x \\rangle \\rangle\\) si dice che la stringa \\(\\omega\\) \u00e8 accettata dallo stato x Automi deterministici e non \u00b6 Automa deterministico Un automa \\(A=(S,T,F)\\) si dice deterministico se l'operazione di transizione \\(T \\in Rel(A \\times S, S)\\) \u00e8 una funzione Costruzione dei sottoinsiemi \u00b6 Grammatiche libere da contesto \u00b6","title":"Linguaggi Formali"},{"location":"FdI/linguaggi/#linguaggi-formali","text":"Nei linugaggi dobbiamo distiguere due parti: Sintassi, che ha a che fare con la struttura Semantica, che ha a che fare con il significato delle frasi esprimibili Partiamo con la definizione di linguaggio: Definiamo linugaggio come sinonimo di insieme di frasi sintatticamente ammissibili. Fissato un alfabeto di elementi base, detti simboli, il linguaggio \u00e8 un sottoinsieme di tutte le stringhe, ovvero sequenze di lunghezza arbitraria di simboli. Descriere un linguaggio, significa quindi (i due punti sono alternativi): - decidere quali srienghe farann part e dell'insieme o quali no - costuire l'insieme di stringhe enumerando le stringhe che lo compongono Abbiamo due modi di risovere il come identificare l'insieme dellle stringhe ammissibili che caratterizano un linguaggio: Usare usare un automa, uno strumento in grado di riconoscere tutte e sole le stringhe che fanno parte di un linguaggio Usare una grammatica, che \u00e8 in grado di costruire o generare tutte le stringhe che fanno parte del linugaggio","title":"Linguaggi formali"},{"location":"FdI/linguaggi/#alfabeti-parole-e-linguaggi","text":"Definizione di Alfabeto Un alfabeto \u00e8 un insieme finito. I suoi elementi sono detti simboli Definizione di stringhe Dato un alfabeto \\(A\\) , l'insieme \\(A^*\\) delle stringhe su \\(A\\) rappresenta il pi\u00f9 piccolo insieme che soddisfa: (Clausola base): \\(\\varepsilon \\in A^*\\) , dove \\(\\varepsilon\\) \u00e8 la stringa vuota (Clausola induttiva): Se \\(\\omega \\in A^*\\) e \\(a \\in A\\) , allora \\(a\\omega \\in A^*\\) Notare che l'insieme delle liste \\(L_A\\) e l'insieme \\(A*\\) sono in biiezione. Concatenazione di stringhe La concatenazione di stringhe \u00e8 una funzione \\(\\_ \\cdot \\_: A^* \\times A^* \\rightarrow A^*\\) , definita per tutte le stringhe \\(u,v \\in A^*\\) come \\(u \\times v = uv\\) Linugaggio Un linguaggio su A \u00e8 un insieme \\(L \\subseteq A^*\\) . L'insieme di tutti i linguaggi \u00e8 denotato come \\(\\mathcal P(A^*)\\)","title":"Alfabeti, Parole e Linguaggi"},{"location":"FdI/linguaggi/#operazioni-su-lunguaggi","text":"Per ogni alfabeto A, esistono sempre: Il linguaggio vuoto \\(\\varnothing = \\{\\}\\) Il linguaggio che contiene solo la stringa vuota \\({\\varepsilon}\\) Il linguaggio completo \\(A^*\\) I linguaggi possono essere combinate come con le operazioni insiemistiche. Concatenazione di linguaggi La funzione \\(\\_ \\cdot \\_: \\mathcal P(A^*) \\times \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) \u00e8 definita per tutti i linguaggi \\(L_1, L_2 \\in \\mathcal P(A^*)\\) come \\(L_1 \\cdot L_2 = \\{ \\omega \\in A^* | \\text{ esistono } \\omega_1 \\in L_1, \\omega_2 \\in L_2 \\text { tali che } \\omega = \\omega_1 \\cdot \\omega_2 \\}\\) Concatenazione n-aria di linguaggi Dato un insieme A ed un linguaggio \\(L \\in \\mathcal P(A)\\) , per ogni numero naturale \\(n \\in \\mathbb N\\) , definiamo \\(L^n\\) induttivamente: \\(L^0 = \\{ \\varepsilon \\}\\) \\(L^{n+1} = L \\cdot L^{n}\\) Stella di Kleene La stella di Kleene \u00e8 una funzione \\((_)^*: \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) per tutti i linguaggi \\(L \\in \\mathcal P(A^*)\\) definita come: \\[ \\bigcup _{n \\in \\mathbb N} L^n \\]","title":"Operazioni su lunguaggi"},{"location":"FdI/linguaggi/#automi","text":"Gli automi sono chiamati anche macchine a stati, e vengono descritti attraverso transizioni di stato, letture in input e produzioni in output. Gli automi sono alberi i cui nodi rappresentano gli stati e gli archi i simboli la cui lettura \u00e8 necessarie per innescare la transizione. Automa Un automa sull'alfabeto A \u00e8 una tripla \\(A=(S,T,F)\\) , dove: S \u00e8 un insieme, detto insieme degli stati \\(T \\subseteq (A \\times S) \\times S\\) \u00e8 una relazione in \\(Rel(A \\times S,S)\\) detta relazione di transizione, che associa ad ogni lettera dell'alfabeto \\(a \\in A\\) ad ogni stato di partenza \\(x \\in S\\) zero o pi\u00f9 stati di destinazione \\(F \\subseteq S\\) \u00e8 l'insieme degli stati finali (o stati di accettazione) L'automa \\(\\mathcal A\\) si dice a stati finiti se l'insieme degli stati S \u00e8 finito Raggiungibilit\u00e0 negli automi Sia A = (S,T,F) un automa sull'alfabeto A, per ogni \\(a \\in A\\) si definisce la relazione \\(T_a \\in Rel(S,S)\\) come \\(T_a = \\{ (x,y) | ((a,x),y) \\in T \\}\\) Per ogni stringa in \\(\\omega \\in A^*\\) , defianio per induzione \\(T_w \\in Rel(S,S)\\) come: \\(T_\\omega = id_S\\) \\(T_{aw} = T_a;T_w\\) Lo stato y \\((x,y) \\in T_\\omega\\) si dice raggiungibile da x con la stringa \\(\\omega\\) Linguaggio accettato Sia A = (S,T,F) un automa a stati finiti, la funzione \\(\\langle \\langle \\cdot \\rangle \\rangle: S \\rightarrow \\mathcal P(A)\\) \u00e8 definita per ogni stato \\(x \\in S\\) come \\[ \\langle \\langle x \\rangle \\rangle = \\{ \\omega \\in A^* | \\text{ esiste } y \\in F \\text{ tale che } (x,y) \\in T_\\omega \\} \\] Il linguaggio \\(\\langle \\langle x \\rangle \\rangle\\) \u00e8 detto il linguaggio accettato da x. Se \\(\\omega \\in \\langle \\langle x \\rangle \\rangle\\) si dice che la stringa \\(\\omega\\) \u00e8 accettata dallo stato x","title":"Automi"},{"location":"FdI/linguaggi/#automi-deterministici-e-non","text":"Automa deterministico Un automa \\(A=(S,T,F)\\) si dice deterministico se l'operazione di transizione \\(T \\in Rel(A \\times S, S)\\) \u00e8 una funzione","title":"Automi deterministici e non"},{"location":"FdI/linguaggi/#costruzione-dei-sottoinsiemi","text":"","title":"Costruzione dei sottoinsiemi"},{"location":"FdI/linguaggi/#grammatiche-libere-da-contesto","text":"","title":"Grammatiche libere da contesto"},{"location":"FdI/logica/","text":"La logica \u00b6 La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ). Il calcolo proposizionale \u00b6 Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali) Composizione di proposizioni \u00b6 Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici . Sintassi del calcolo proposizionale \u00b6 Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali I connettivi logici \u00b6 Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) . La formalizzazione di proposizioni \u00b6 Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\) La semantica \u00b6 La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\] Le tavole di verit\u00e0 \u00b6 \u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\) Il concetto di Tautologia \u00b6 Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso. Dimostrazioni nel calcolo proposizionale \u00b6 Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) . Formalizzazione di inferenze e tautologie \u00b6 \u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Sistema di dimostrazioni Dato un insieme di formule \\(\\Delta\\) , un sistema di dimostrazioni (o proof system) per \\(\\Delta\\) \u00e8 un insieme di regole di interenza \\(\\cal R\\) . Una reola di inferenza \\(r \\in \\cal R\\) ha la struttura: \\[ \\frac{P_1 \\ \\cdots P_n}{P} [r] \\] Dove P \u00e8 la conseguenza e \\(P_1 \\ \\cdots P_n\\) sono le premesse. Se \\(n=0\\) la regola si chiama assioma. Dimostrazione Una dimostrazione in un proof system \\(\\cal R\\) di una formula \\(Q \\in \\Delta\\) in un insieme di premesse \\(\\Gamma \\in \\Delta\\) \u00e8 una sequenza di formule \\(Q_1,...,Q_n\\) , dove: Ogni formula \\(Q\\) \u00e8 un elemento di \\(\\Gamma\\) oppure \u00e8 ottenuta applicando una regola di inferenza di \\(\\cal R\\) a partire dalle formule in \\(\\Gamma\\) o in \\(Q_i,...,Q_{i-1}\\) \\(Q_n\\) \u00e8 proprio \\(Q\\) Se esiste una dimostrazione scriveremo: \\[ \\Gamma \\vdash _{\\cal R} Q \\quad \\text{Q \u00e8 dimostrabile da }\\Gamma \\] Correttezza e completezza \\[ \\Gamma \\vdash _{\\cal R} P \\ \\text{ implica } \\ \\Gamma \\vDash P \\text{ (correttezza)} \\] Dimostrazioni per sostituzione di tautologie \u00b6 Rimpiazzamento \u00b6 Principio di sostituzione \u00b6 \u00b6 Logica dei predicati \u00b6","title":"Logica Matematica"},{"location":"FdI/logica/#la-logica","text":"La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ).","title":"La logica"},{"location":"FdI/logica/#il-calcolo-proposizionale","text":"Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali)","title":"Il calcolo proposizionale"},{"location":"FdI/logica/#composizione-di-proposizioni","text":"Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici .","title":"Composizione di proposizioni"},{"location":"FdI/logica/#sintassi-del-calcolo-proposizionale","text":"Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali","title":"Sintassi del calcolo proposizionale"},{"location":"FdI/logica/#i-connettivi-logici","text":"Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) .","title":"I connettivi logici"},{"location":"FdI/logica/#la-formalizzazione-di-proposizioni","text":"Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\)","title":"La formalizzazione di proposizioni"},{"location":"FdI/logica/#la-semantica","text":"La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\]","title":"La semantica"},{"location":"FdI/logica/#le-tavole-di-verita","text":"\u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\)","title":"Le tavole di verit\u00e0"},{"location":"FdI/logica/#il-concetto-di-tautologia","text":"Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso.","title":"Il concetto di Tautologia"},{"location":"FdI/logica/#dimostrazioni-nel-calcolo-proposizionale","text":"Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) .","title":"Dimostrazioni nel calcolo proposizionale"},{"location":"FdI/logica/#formalizzazione-di-inferenze-e-tautologie","text":"\u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Sistema di dimostrazioni Dato un insieme di formule \\(\\Delta\\) , un sistema di dimostrazioni (o proof system) per \\(\\Delta\\) \u00e8 un insieme di regole di interenza \\(\\cal R\\) . Una reola di inferenza \\(r \\in \\cal R\\) ha la struttura: \\[ \\frac{P_1 \\ \\cdots P_n}{P} [r] \\] Dove P \u00e8 la conseguenza e \\(P_1 \\ \\cdots P_n\\) sono le premesse. Se \\(n=0\\) la regola si chiama assioma. Dimostrazione Una dimostrazione in un proof system \\(\\cal R\\) di una formula \\(Q \\in \\Delta\\) in un insieme di premesse \\(\\Gamma \\in \\Delta\\) \u00e8 una sequenza di formule \\(Q_1,...,Q_n\\) , dove: Ogni formula \\(Q\\) \u00e8 un elemento di \\(\\Gamma\\) oppure \u00e8 ottenuta applicando una regola di inferenza di \\(\\cal R\\) a partire dalle formule in \\(\\Gamma\\) o in \\(Q_i,...,Q_{i-1}\\) \\(Q_n\\) \u00e8 proprio \\(Q\\) Se esiste una dimostrazione scriveremo: \\[ \\Gamma \\vdash _{\\cal R} Q \\quad \\text{Q \u00e8 dimostrabile da }\\Gamma \\] Correttezza e completezza \\[ \\Gamma \\vdash _{\\cal R} P \\ \\text{ implica } \\ \\Gamma \\vDash P \\text{ (correttezza)} \\]","title":"Formalizzazione di inferenze e tautologie"},{"location":"FdI/logica/#dimostrazioni-per-sostituzione-di-tautologie","text":"","title":"Dimostrazioni per sostituzione di tautologie"},{"location":"FdI/logica/#rimpiazzamento","text":"","title":"Rimpiazzamento"},{"location":"FdI/logica/#principio-di-sostituzione","text":"","title":"Principio di sostituzione"},{"location":"FdI/logica/#_1","text":"","title":""},{"location":"FdI/logica/#logica-dei-predicati","text":"","title":"Logica dei predicati"},{"location":"FdI/relazioni/","text":"Relazioni \u00b6 Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\) Operazioni su relazioni \u00b6 Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\) Composizione \u00b6 Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C Quantificatori \u00b6 Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica Relazione opposta \u00b6 La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\) Leggi \u00b6 Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\) Propriet\u00e0 di relazioni \u00b6 Le propriet\u00e0 TUSI \u00b6 In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva Risultati di dualit\u00e0 \u00b6 Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\) Teorema di caratterizzazione \u00b6 Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\) Chiusura per composizione \u00b6 \u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva Funzioni \u00b6 Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ). Propriet\u00e0 \u00b6 Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) . Composizione di funzioni \u00b6 Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\) Teorema di caratterizzazione \u00b6 Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\) Funzioni parziali \u00b6 Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale. Funzioni surgettive ed iniettive \u00b6 Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0. Biiezioni \u00b6 Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione. Caratterizzazione attraverso relazioni invertibili \u00b6 Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile Insiemi in biiezione \u00b6 Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0. n-uple e sequenze \u00b6 Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"Relazioni"},{"location":"FdI/relazioni/#relazioni","text":"Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\)","title":"Relazioni"},{"location":"FdI/relazioni/#operazioni-su-relazioni","text":"Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\)","title":"Operazioni su relazioni"},{"location":"FdI/relazioni/#composizione","text":"Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C","title":"Composizione"},{"location":"FdI/relazioni/#quantificatori","text":"Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica","title":"Quantificatori"},{"location":"FdI/relazioni/#relazione-opposta","text":"La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\)","title":"Relazione opposta"},{"location":"FdI/relazioni/#leggi","text":"Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\)","title":"Leggi"},{"location":"FdI/relazioni/#proprieta-di-relazioni","text":"","title":"Propriet\u00e0 di relazioni"},{"location":"FdI/relazioni/#le-proprieta-tusi","text":"In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/relazioni/#risultati-di-dualita","text":"Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\)","title":"Risultati di dualit\u00e0"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione","text":"Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#chiusura-per-composizione","text":"\u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva","title":"Chiusura per composizione"},{"location":"FdI/relazioni/#funzioni","text":"Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ).","title":"Funzioni"},{"location":"FdI/relazioni/#proprieta","text":"Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) .","title":"Propriet\u00e0"},{"location":"FdI/relazioni/#composizione-di-funzioni","text":"Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\)","title":"Composizione di funzioni"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione_1","text":"Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#funzioni-parziali","text":"Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale.","title":"Funzioni parziali"},{"location":"FdI/relazioni/#funzioni-surgettive-ed-iniettive","text":"Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0.","title":"Funzioni surgettive ed iniettive"},{"location":"FdI/relazioni/#biiezioni","text":"Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione.","title":"Biiezioni"},{"location":"FdI/relazioni/#caratterizzazione-attraverso-relazioni-invertibili","text":"Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile","title":"Caratterizzazione attraverso relazioni invertibili"},{"location":"FdI/relazioni/#insiemi-in-biiezione","text":"Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0.","title":"Insiemi in biiezione"},{"location":"FdI/relazioni/#n-uple-e-sequenze","text":"Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"n-uple e sequenze"},{"location":"FdI/relazioniInsiemi/","text":"Relazioni su insiemi \u00b6 Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi . Propriet\u00e0 di relazioni su un insieme \u00b6 Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ). Teorema di caratterizzazione \u00b6 Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\) Le chiusure \u00b6 Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta Chiusura riflessiva \u00b6 Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme. Chiusura simmetrica \u00b6 Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta Chiusura transitiva \u00b6 La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\) La stella di Kleene \u00b6 Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\) Relazioni di equivalenza \u00b6 Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza. Kernel di una funzione \u00b6 Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa. Relazioni di equivalenza e partizioni \u00b6 Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\] Relazioni di ordinamento \u00b6 Relazione di ordinamento parziale \u00b6 Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) . Relazione di ordinamento \u00b6 Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\) Ordinamento lessicografico \u00b6 Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#relazioni-su-insiemi","text":"Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi .","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#proprieta-di-relazioni-su-un-insieme","text":"Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ).","title":"Propriet\u00e0 di relazioni su un insieme"},{"location":"FdI/relazioniInsiemi/#teorema-di-caratterizzazione","text":"Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioniInsiemi/#le-chiusure","text":"Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta","title":"Le chiusure"},{"location":"FdI/relazioniInsiemi/#chiusura-riflessiva","text":"Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme.","title":"Chiusura riflessiva"},{"location":"FdI/relazioniInsiemi/#chiusura-simmetrica","text":"Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta","title":"Chiusura simmetrica"},{"location":"FdI/relazioniInsiemi/#chiusura-transitiva","text":"La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\)","title":"Chiusura transitiva"},{"location":"FdI/relazioniInsiemi/#la-stella-di-kleene","text":"Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\)","title":"La stella di Kleene"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza","text":"Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza.","title":"Relazioni di equivalenza"},{"location":"FdI/relazioniInsiemi/#kernel-di-una-funzione","text":"Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa.","title":"Kernel di una funzione"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza-e-partizioni","text":"Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\]","title":"Relazioni di equivalenza e partizioni"},{"location":"FdI/relazioniInsiemi/#relazioni-di-ordinamento","text":"","title":"Relazioni di ordinamento"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento-parziale","text":"Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) .","title":"Relazione di ordinamento parziale"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento","text":"Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\)","title":"Relazione di ordinamento"},{"location":"FdI/relazioniInsiemi/#ordinamento-lessicografico","text":"Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Ordinamento lessicografico"},{"location":"LabI/","text":"I mean... Javascript...","title":"Laboratorio I"},{"location":"ProAlgo/","text":"document.location=\"introduzione\" Vai all'introduzione","title":"Index"},{"location":"ProAlgo/checklist/","text":"Sintassi e grammatiche Definizione di grammatica Una grammatica \u00e8 una quadrupla \\(G = \\langle N, \\Sigma, P, S \\rangle\\) Dove: \\(N\\) sono i simboli non terminali \\(\\Sigma\\) sono i simboli terminali \\(P\\) sono le produzioni \\(S\\) \u00e8 il simbolo iniziale Definizione di linguaggio Un linguaggio \u00e8 l'insieme delle stringhe ammissibili (in base al linguaggio, che pu\u00f2 essere generativo, riconoscitivo o algebrico), sottoinsieme della chiusura positiva dell'alfabeto Le fasi di un compilatore Analizzatore lessicale/lexer/scanner Analizzatore sintattico/parser Analizzatore semantico Eventuale passaggio di ottimizzazione del codice Generatore del codice oggetto Linker BNF e sintassi di un linguaggio di programmazione Backus-Naur form, \u00e8 una sintassi per esprimere in modo conciso le produzioni di una grammatica in funzione dei simboli non terminali. La sintassi \u00e8 \\(N ::= (N) | NN\\) ,dove N \u00e8 un non terminale ed i caratteri esempio ( e ) fanno parte dei terminali. Pi\u00f9 produzioni sono separate da una barra verticale ( | ) Linguaggio L (vedi LinguaggioL-CheatSheet) BNF e Sintassi Regole semantica statica Espressioni Comandi Dichiarazioni Funzioni: dichiarazione e chiamata Funzioni ricorsive (dichiarazione e chiamata) Scoping e blocchi (identificatori liberi e legati) Record di attivazione Regole semantica dinamica Espressioni Comandi Dichiarazioni Funzioni: dichiarazione (lambda astrazione e chiusure) e chiamata Funzioni ricorsive (dichiarazione e chiamata) Complessit\u00e0 degli algoritmi Definizione formale di O, \u03a9, \u0398, o, \u03c9 (vedi Cormen) Algoritmi di ordinamento Ordinamento per confronti Insertion e Selection sort Dimostrazione di correttezza e complessit\u00e0 (vedi Cormen) Mergesort Dimostrazione di correttezza e complessit\u00e0 (vedi Cormen) Quicksort (vedi Cormen) Dimostrazione di correttezza Complessit\u00e0 al caso peggiore Dimostrazione complessit\u00e0 al caso medio Dimostrazione lower bound \u03a9(n log n) problema di ordinamento per confronti Ordinamenti senza confronti (vedi Cormen e appunti) Counting sort Radix sort Divide-et-impera: definizione e problemi Il problema delle selezione: selezione randomizzata (vedi Cormen) Equazioni di ricorrenza e loro risoluzione (vedi Cormen) Metodo iterativo Risoluzione mediante albero Master Theorem Enunciato Dimostrazione Ricerca di un elemento in una collezione Ricerca lineare (progettazione algoritmo, correttezza, limite inferiore al problema e complessit\u00e0 della soluzione progettata) Ricerca binaria mediante divide-et-impera (progettazione algoritmo, correttezza e complessit\u00e0) Heap Propriet\u00e0 strutturale e sulle informazioni (di massimo e di minimo) Albero quasi-completo e i cui nodi non foglie hanno una chiave di valore maggiore (quando di massimo) rispetto ai due figli Costruire uno heap (correttezza e complessit\u00e0) Richiede uso di heapify, ha costo O(altezza) Inserimento di un nodo e estrazione della radice Inserimento: Si inserisce una nuova foglia a sinistra e si procede con un heapify Estrazione della radice: Si sostituisce l'ultima foglia con la radice, si elimina la radice e si procede con il max-heapify Heapsort (correttezza e complessit\u00e0) Tabelle e funzioni hash (vedi Cormen) Gestione collisioni Chaining (liste di trabocco) Probing-Open hash (lineare, quadratico, doppio hash) Costi e complessit\u00e0 (dimostrazioni al caso medio, almeno l\u2019idea intuitiva) Alberi binari Definizione, e altezza nel caso peggiore e ottimo Visite: simmetrica, anticipata e posticipata Alberi Binari di Ricerca (vedi Cormen) Definizione, e altezza nel caso peggiore e ottimo Interrogazioni (ricerca, Min, Max, Successore, Predecessore) e operazioni di modifica (inserimento, cancellazione) e loro costi 2-3 Alberi (dispensa di Pino Italiano, su Classroom alla Lezione 46 - 2022) Definizione, e altezza nel caso peggiore e ottimo Operazioni di ricerca, inserimento e cancellazione e loro costi Programmazione dinamica Longest Common Subsequence Edit Distance Zaino Greedy (zaino frazionario) Grafi BFS (vedi Cormen, con dimostrazione di: Lemma 22.1, 22.2, e Teorema 22.5, almeno l\u2019idea intuitiva) DFS (vedi Cormen, con dimostrazione dei Teoremi 22.7, 22.8 e 22.10, almeno l\u2019idea intuitiva) Topological sort (vedi Cormen, con dimostrazione del Lemma 22.11 e del Teorema 22.12) P - NP (vedi appunti) Definizioni di P, NP, NP-arduo, NP-completo Esempio di riduzione 3SAT","title":"Checklist"},{"location":"ProAlgo/grafi/","text":"","title":"Grafi"},{"location":"ProAlgo/grammatiche/","text":"Grammatiche \u00b6 Una grammatica \u00e8 una notazione concisa per descrivere la sintassi (una frase ben formata) di un linguaggio. Sono costituite da produzioni Definizione di Grammatica Una grammatica \u00e8 una quadrupla \\(G = \\langle N, \\Sigma, P, S \\rangle\\) Dove: \\(N\\) sono i simboli non terminali \\(\\Sigma\\) sono i simboli terminali \\(P\\) sono le produzioni \\(S\\) \u00e8 il simbolo iniziale Detto informalmente, una grammatica \u00e8 quindi un insieme di regole che permette di costruire frasi corrette in un linguaggio. Componenti di una grammatica \u00b6 Simboli non terminali \u00b6 Caratteri che NON compaiono nelle frasi finali . ( \\(N \\neq \\varnothing\\) ) Simboli terminali \u00b6 Caratteri che compaiono nelle stringhe delle linguaggio (elementi dell'alfabeto) Produzioni \u00b6 Le produzioni sono un sottoinsieme del prodotto tra la chiusura di Kleene e la chiusura positiva: \\(P \\subseteq (N \\cup \\Sigma)^+ \\times (N \\cup \\Sigma)^\\star\\) Sono quindi funzioni o relazioni \\(N \\cup \\Sigma \\cup P \\rightarrow N \\cup P\\) Una produzione \u00e8 formalizzata attraverso una notazione a coppia, dove al primo elemento si trova la categoria sintattica (o simbolo non terminale) e al secondo si trova uno o pi\u00f9 simboli terminali o non. L'insieme delle produzioni permettono quindi di esprimere qualunque stringa nel linguaggio. Simbolo iniziale \u00b6 Simbolo che rappresenta l'inizio della grammatica, ovvero il simbolo da cui si parte per creare la frase. Esempio di una grammatica \u00b6 Esempio di una grammatica \\(\\langle \\underbrace{\\{D\\}}_{\\text{ Non terminali }}, \\underbrace{\\{0,...,9\\}}_{\\text{Terminali}}, \\underbrace{\\{(D,0),(D,1),...,(D,9),(D,0D),...,(D,9D) \\}}_{\\text{Produzioni}}, \\underbrace{D}_{\\text{Simbolo iniziale}} \\rangle\\) In questo esempio, G \u00e8 una grammatica che ci permette di esprimere ogni numero nei reali. Il linguaggio generato da un grammatica G \u00e8 l'insieme delle stringhe di caratteri terminali che si possono ottenere applicando un numero qualsiasi di produzioni a partire dal simbolo iniziale: \\(L(G) = \\{ \\omega | \\omega \\in \\Sigma^\\star \\land S \\rightarrow^\\star \\omega \\}\\) Che si legge che il linguaggio L data la grammatica G \u00e8 composto da stringhe ( \\(\\omega\\) ) fatte di terminali ( \\(\\omega \\in \\Sigma^\\star\\) ) e derivabili in un numero arbitrario di passi, partendo dal simbolo iniziale ( \\(S \\rightarrow^\\star \\omega\\) ) Espressibilit\u00e0 di un linguaggio \u00b6 \u00c8 possibile classificare le grammatiche basandosi sul tipo di produzioni che permettono di fare. Qui di seguito troviamo diverse grammatiche, scritte in ordine dalla meno alla pi\u00f9 specifica: Notare che con A si intende, nel contesto di una produzione, la categoria sintattica (o simbolo non terminale) e con B si intende il simbolo terminale o non terminale derivato dalla produzione. In termini di notazione invece: $\\Sigma $ (sigma) \u00e8 l'alfabeto e N \u00e8 l'insieme dei non terminali. \\(\\delta \\in (N \\cup \\Sigma)^+\\) (delta) \u00e8 una stringa non vuota di caratteri terminali e non terminali \\(\\gamma \\in (N \\cup \\Sigma)^\\star\\) \u00e8 una stringa di caratteri terminali e non terminali \\(\\delta\\) derivativo immediato di \\(\\gamma\\) ( \\(\\gamma \\to \\delta\\) ) \\(\\Leftrightarrow\\) \\(\\delta\\) si pu\u00f2 ottenere da \\(\\gamma\\) applicando una produzione della grammatica \\(\\delta\\) derivativo di \\(\\gamma\\) ( \\(\\gamma \\to^\\star \\delta\\) ) significa applicare un numero qualsiasi di produzioni Derivazione canonica destra: Simbolo non terminale ad essere sostituito \u00e8 quello pi\u00f9 a destra nella stringa Derivazione canonica sinistra: simbolo non terminale ad essere sostituito \u00e8 quello pi\u00f9 a sinistra nella stringa Tipi di grammatiche \u00b6 Grammatica di tipo 0 Una grammatica di tipo 0 \u00e8 associabile ad una macchina di Turing (essere pi\u00f9 specifici qui) \\((\\alpha, \\beta), \\alpha \\in (N \\cup \\Sigma)^+, \\beta \\in (N \\cup \\Sigma)^\\star\\) Grammatica dipendente dal contesto \\((\\gamma A \\delta, \\gamma \\ro \\delta), \\gamma, \\gamma \\in (N \\cup \\Sigma)^\\star, \\ro \\in (N \\cup \\Sigma)^+\\) In questa categoria possiamo trovare gli automi lineari Grammatica libera da contesto In questa categoria troviamo i linguaggi di programmazione comuni Hanno una forma del tipo \\((A, \\Beta), \\Beta \\in (N \\cup \\Sigma)^+\\) Automi a pila forma delle produzioni Non ho un consto e a sinistra posso solo non avere terminali (L4 13:57) Stringa len \\ge 1 destra Grammatica regolare o lineare destra \\((A,b), (A, bA)\\) Automa a stati finiti Backus-Naur Form \u00b6 \u00c8 facilmente riconoscibile il fatto che scrivere grammatiche come quadruple \u00e8 molto oneroso in termini di spazio e non risultando comunque chiarissime. Per questo \u00e8 stata inventa la Backus-Naur Form (abbreviata a BNF ) Una produzione in questa forma ha questo aspetto: \\(E ::= E+E | E-E | E * E | ...| I | V\\) Dove il primo carattere E rappresenta il simbolo iniziale (o categoria sintattica) e le produzioni sono separate dal trattino verticale A destra troviamo infatti sia simboli terminali (come +, - e *) che non terminali (come E, I e V, che saranno poi scritte in altre produzioni) Il \"corpo\" della produzione \u00e8 quindi l'insieme dei simboli che compaiono a destra dell'uguaglianza Principio di corrispondenza \u00b6 La dichiarazione di corrispondenza \u00e8 il riuso della sintassi per cose svolgono lo stesso compito. Questo permette di avere una maggiore facilit\u00e0 di apprendimento ed interpretazione, anche tra vari linguaggi. L'idea \u00e8 che se per un array in un linguaggio, accendiamo alle celle indicando l'indice tra parentesi quadre, probabilmente non vogliamo progettare un linguaggio in cui dobbiamo inserire un indice tra due punti e virgola. Linguaggi \u00b6 Identificatori \u00b6 Gli identificatori servono per identificare delle zone di memoria. Vengono Possono essere liberi o legati. La differenza \u00e8 che un identificatore legato risulta in un ambiente, e quindi ha un corrispettivo valore o punta ad una locazione di memoria. Un identificatore libero, \u00e8 un identificatore che viene usato all'interno del codice, tuttavia non risultando nell'ambiente non \u00e8 possibile correlarlo ad un valore, rendendo la sua valutazione impossibile. Avere identificatori liberi nel codice di un programma \u00e8 quindi un errore, che tendenzialmente porta il programma a non poter essere eseguito correttamente. Si collocano in un ambiente, ovvero una funzione che ci permette di \"mappare\" gli identificatori con i rispettivi valori (nel caso di costanti) o locazioni di memoria (nel caso di variabili e funzioni) Un identificatore si dice essere in posizione (o occorrenza) di legame quando abbiamo una definizione, e quindi leghiamo l'identificatore (il nome) ad una locazione di memoria. Principio di Astrazione \u00b6 Il principio di astrazione permette di ridurre la duplicazione di informazione nei programmi (quindi scrivere meno codice codice) usando (e riusando) sia funzioni definite dal programmatore che rese disponibili dal linguaggio (per non reinventare la ruota ) \u00c8 un principio che quindi ci invita a generalizzare il codice per evitare di copiarlo e incollarlo Il sottoproblema dovrebbe poi essere decomposto in sotto funzioni (ove necessario), riapplicando il principio Scrivere funzioni permette di aumentare la correttezza, in quanto una volta scritta e verificata, quella parte di codice \u00e8 corretta Ovviamente il linguaggio deve permettere di definirle e usarle Funzioni \u00b6 Quasi tutti i linguaggi moderni fanno uso delle funzioni. Una funzione in un linguaggio di programmazione prende il concetto da una funzione matematica: permette di mappare uno o pi\u00f9 parametri (che chiameremo formali) in un valore. Le funzioni ci permettono di non ripetere codice, ma di renderlo invece modulare, permettendoci di creare sottoprogrammi che svolgono un compito specifico, garantendoci una miglior mantenibilit\u00e0. Grazie a questo aspetto, le funzioni ci permettono inoltre di avere una maggior confidenza nel codice, data dall'aumento della correttezza del codice: una volta che una funzione \u00e8 garantita essere corretta, si pu\u00f2 presumere che quella parte di codice non dovr\u00e0 essere esaminata ulteriormente. Il tipo della funzione \u00e8 il tipo del valore che la funzione ritorner\u00e0 (il suo codominio). Una funzione ritorna spesso un valore (spesso proprio mediante la keyword return , seguita da un'espressione, che sar\u00e0 dello stesso tipo della funzione) Un'altra cosa univoca delle funzioni \u00e8 la signatura: la signatura pu\u00f2 essere vista come una tripla, che include l'identificatore della funzione (il suo nome), i suoi parametri formali (i valori che prende in ingresso) ed infine il tipo che ritorner\u00e0. Da un punto di vista sintattico, le funzioni vengono definite attraverso una dichiarazione. Possiamo aspettarci quindi che in un linguaggio (come L ) la funzione si trovi insieme alle dichiarazioni: D::= nil | const id[:T]=E | var id[:T]=E | D;D | function Id(form) -> T {C} (In questo caso Id \u00e8 l'identificatore della funzione, il suo nome, form \u00e8 l'elenco dei formali, T \u00e8 il tipo e C il corpo della funzione) Quando invece sono utilizzate, si dice che vengono invocate, e la loro invocazione rientra nei tipi delle espressioni. Una funzione avr\u00e0 quindi la seguente forma: function nome ( formali ...) tipo e sar\u00e0 invocata con una forma simile a questa: nome ( attuali ...) considerando gli attuali come una lista di espressioni. Sotto il punto di vista dell'invocazione, si pu\u00f2 pensare che una chiamata ad una funzione sospenda l'esecuzione del chiamate (da un punto di vista formale), in attesa che la funzione termini e restituisca il valore rispetto ai parametri attuali forniti (gli argomenti con cui la funzione \u00e8 stata chiamata). Formali ed attuali dovranno essere due liste di variabili con lo stesso numero di elementi e di tipi concordi. I controlli che verranno effettuati durante la compilazione saranno i seguenti: Assicurarsi che il numero di argomenti attuali (quelli forniti alla funzione) sia uguale al numero di argomenti attuali Assicurarsi che i nomi dei parametri formali siano distinti (altrimenti due parametri potrebbero avere lo stesso nome, generando confusione ed ambiguit\u00e0) Assicurarsi che i tipi dei parametri attuali e formali per la stessa posizione siano uguali (non ha senso dire che il valore \"ciao\" \u00e8 un numero) Assicurarsi che non ci siano variabili libere nel corpo della funzione Assicurarsi che la funzione abbia un return ed il tipo ritornato sia lo stesso dichiarato nella signatura Dato che una funzione \u00e8 una dichiarazione, l'ambiente viene esteso in seguito ad una dichiarazione. Ci\u00f2 significa che \u00e8 possibile usare una funzione nel suo stesso corpo. Questa tecnica \u00e8 detta ricorsione e ci permette di lavorare con strutture iterative come i grafi con estrema facilit\u00e0, rispetto ad un approccio pi\u00f9 tradizionale (iterativo), che \u00e8 pi\u00f9 difficile in fase di ragionamento e quindi pi\u00f9 soggetto ad errori (e pi\u00f9 lungo da scrivere ed ideare). Ovviamente questa tecnica non \u00e8 efficiente da un punto di vista della memoria, tuttavia \u00e8 un tradeoff che spesso vale la pena adottare. Segnatura di una funzione \u00b6 nome, parametri formali, e tipo di ritorno La dichiarazione richiede anche un corpo, in cui si ritorna anche il tipo Il record di attivazione \u00b6 Ogni volta che si invoca una funzione, viene generato un corrispettivo record di attivazione (o stack frame) Un record di attivazione \u00e8 una struttura dati che ci permette di tenere traccia dei dati necessari all'esecuzione delle funzioni. Un record di attivazione \u00e8 composto da 7 valori fondamentali: Puntatore alla catena dinamica La catena dinamica tiene traccia del record di attivazione della funzione chiamante. Quindi quando una funzione ne chiama una seconda, la seconda avr\u00e0 come puntatore nella catena dinamica il record di attivazione del chiamante Puntatore alla catena statica La catena statica punta al record di attivazione della funzione chiamante. Permette quindi di effettuare la risoluzione degli identificatori non presenti nel blocco corrente (con scoping statico) La catena statica \u00e8 visibile come un array di \"chiamate\" (e ci rientrano i parametri formali con cui sono state invocate le funzioni precedenti) Permette di vedere tutto ci\u00f2 che \u00e8 accessibile dall'ambiente in uno specifico momento Permette inoltre di effettuare information hiding: (dato come esempio un programma in cui la funzione A chiama la funzione B, che chiama a sua volta la funzione C) se un parametro formale della funzione B ha lo stesso nome di un parametro della funzione A, il parametro della funzione B prende precedenza e quindi non \u00e8 possibile accedere al parametro della funzione A. Vince l'ultima cosa dichiarata. Indirizzo di ritorno L'istruzione da eseguire al ritorno della funzione corrente Indirizzo del risultato L'indirizzo della locazione dove salvare il risultato che la funzione restituir\u00e0 Parametri (attuali e formali) Associazione dei parametri formali ed attuali Variabili locali L'ambiente dove risiederanno le variabili locali della funzione Risultati temporanei Uno spazio di memoria dove risiederanno le variabili temporanee generate dal compilatore Catena dinamica (call chain) La catena dinamica \u00e8 una sequenza di chiamate e serve per garantire l'ordine di esecuzione. \u00c8 una struttura dati di tipo LIFO (Last In, Fist Out), una pila catena statica (da rivedere) La catena statica si occupa di implementare lo scoping statico, ovvero individuare gli identificatori necessari in base alla visibilit\u00e0 \u00c8 quindi un ambiente derivato dalla dichiarazione di variabili e costanti Garantisce che i nomi siano referenziati rispetto alla visibilit\u00e0 di variabili e funzione","title":"Grammatiche e Linguaggi"},{"location":"ProAlgo/grammatiche/#grammatiche","text":"Una grammatica \u00e8 una notazione concisa per descrivere la sintassi (una frase ben formata) di un linguaggio. Sono costituite da produzioni Definizione di Grammatica Una grammatica \u00e8 una quadrupla \\(G = \\langle N, \\Sigma, P, S \\rangle\\) Dove: \\(N\\) sono i simboli non terminali \\(\\Sigma\\) sono i simboli terminali \\(P\\) sono le produzioni \\(S\\) \u00e8 il simbolo iniziale Detto informalmente, una grammatica \u00e8 quindi un insieme di regole che permette di costruire frasi corrette in un linguaggio.","title":"Grammatiche"},{"location":"ProAlgo/grammatiche/#componenti-di-una-grammatica","text":"","title":"Componenti di una grammatica"},{"location":"ProAlgo/grammatiche/#simboli-non-terminali","text":"Caratteri che NON compaiono nelle frasi finali . ( \\(N \\neq \\varnothing\\) )","title":"Simboli non terminali"},{"location":"ProAlgo/grammatiche/#simboli-terminali","text":"Caratteri che compaiono nelle stringhe delle linguaggio (elementi dell'alfabeto)","title":"Simboli terminali"},{"location":"ProAlgo/grammatiche/#produzioni","text":"Le produzioni sono un sottoinsieme del prodotto tra la chiusura di Kleene e la chiusura positiva: \\(P \\subseteq (N \\cup \\Sigma)^+ \\times (N \\cup \\Sigma)^\\star\\) Sono quindi funzioni o relazioni \\(N \\cup \\Sigma \\cup P \\rightarrow N \\cup P\\) Una produzione \u00e8 formalizzata attraverso una notazione a coppia, dove al primo elemento si trova la categoria sintattica (o simbolo non terminale) e al secondo si trova uno o pi\u00f9 simboli terminali o non. L'insieme delle produzioni permettono quindi di esprimere qualunque stringa nel linguaggio.","title":"Produzioni"},{"location":"ProAlgo/grammatiche/#simbolo-iniziale","text":"Simbolo che rappresenta l'inizio della grammatica, ovvero il simbolo da cui si parte per creare la frase.","title":"Simbolo iniziale"},{"location":"ProAlgo/grammatiche/#esempio-di-una-grammatica","text":"Esempio di una grammatica \\(\\langle \\underbrace{\\{D\\}}_{\\text{ Non terminali }}, \\underbrace{\\{0,...,9\\}}_{\\text{Terminali}}, \\underbrace{\\{(D,0),(D,1),...,(D,9),(D,0D),...,(D,9D) \\}}_{\\text{Produzioni}}, \\underbrace{D}_{\\text{Simbolo iniziale}} \\rangle\\) In questo esempio, G \u00e8 una grammatica che ci permette di esprimere ogni numero nei reali. Il linguaggio generato da un grammatica G \u00e8 l'insieme delle stringhe di caratteri terminali che si possono ottenere applicando un numero qualsiasi di produzioni a partire dal simbolo iniziale: \\(L(G) = \\{ \\omega | \\omega \\in \\Sigma^\\star \\land S \\rightarrow^\\star \\omega \\}\\) Che si legge che il linguaggio L data la grammatica G \u00e8 composto da stringhe ( \\(\\omega\\) ) fatte di terminali ( \\(\\omega \\in \\Sigma^\\star\\) ) e derivabili in un numero arbitrario di passi, partendo dal simbolo iniziale ( \\(S \\rightarrow^\\star \\omega\\) )","title":"Esempio di una grammatica"},{"location":"ProAlgo/grammatiche/#espressibilita-di-un-linguaggio","text":"\u00c8 possibile classificare le grammatiche basandosi sul tipo di produzioni che permettono di fare. Qui di seguito troviamo diverse grammatiche, scritte in ordine dalla meno alla pi\u00f9 specifica: Notare che con A si intende, nel contesto di una produzione, la categoria sintattica (o simbolo non terminale) e con B si intende il simbolo terminale o non terminale derivato dalla produzione. In termini di notazione invece: $\\Sigma $ (sigma) \u00e8 l'alfabeto e N \u00e8 l'insieme dei non terminali. \\(\\delta \\in (N \\cup \\Sigma)^+\\) (delta) \u00e8 una stringa non vuota di caratteri terminali e non terminali \\(\\gamma \\in (N \\cup \\Sigma)^\\star\\) \u00e8 una stringa di caratteri terminali e non terminali \\(\\delta\\) derivativo immediato di \\(\\gamma\\) ( \\(\\gamma \\to \\delta\\) ) \\(\\Leftrightarrow\\) \\(\\delta\\) si pu\u00f2 ottenere da \\(\\gamma\\) applicando una produzione della grammatica \\(\\delta\\) derivativo di \\(\\gamma\\) ( \\(\\gamma \\to^\\star \\delta\\) ) significa applicare un numero qualsiasi di produzioni Derivazione canonica destra: Simbolo non terminale ad essere sostituito \u00e8 quello pi\u00f9 a destra nella stringa Derivazione canonica sinistra: simbolo non terminale ad essere sostituito \u00e8 quello pi\u00f9 a sinistra nella stringa","title":"Espressibilit\u00e0 di un linguaggio"},{"location":"ProAlgo/grammatiche/#tipi-di-grammatiche","text":"Grammatica di tipo 0 Una grammatica di tipo 0 \u00e8 associabile ad una macchina di Turing (essere pi\u00f9 specifici qui) \\((\\alpha, \\beta), \\alpha \\in (N \\cup \\Sigma)^+, \\beta \\in (N \\cup \\Sigma)^\\star\\) Grammatica dipendente dal contesto \\((\\gamma A \\delta, \\gamma \\ro \\delta), \\gamma, \\gamma \\in (N \\cup \\Sigma)^\\star, \\ro \\in (N \\cup \\Sigma)^+\\) In questa categoria possiamo trovare gli automi lineari Grammatica libera da contesto In questa categoria troviamo i linguaggi di programmazione comuni Hanno una forma del tipo \\((A, \\Beta), \\Beta \\in (N \\cup \\Sigma)^+\\) Automi a pila forma delle produzioni Non ho un consto e a sinistra posso solo non avere terminali (L4 13:57) Stringa len \\ge 1 destra Grammatica regolare o lineare destra \\((A,b), (A, bA)\\) Automa a stati finiti","title":"Tipi di grammatiche"},{"location":"ProAlgo/grammatiche/#backus-naur-form","text":"\u00c8 facilmente riconoscibile il fatto che scrivere grammatiche come quadruple \u00e8 molto oneroso in termini di spazio e non risultando comunque chiarissime. Per questo \u00e8 stata inventa la Backus-Naur Form (abbreviata a BNF ) Una produzione in questa forma ha questo aspetto: \\(E ::= E+E | E-E | E * E | ...| I | V\\) Dove il primo carattere E rappresenta il simbolo iniziale (o categoria sintattica) e le produzioni sono separate dal trattino verticale A destra troviamo infatti sia simboli terminali (come +, - e *) che non terminali (come E, I e V, che saranno poi scritte in altre produzioni) Il \"corpo\" della produzione \u00e8 quindi l'insieme dei simboli che compaiono a destra dell'uguaglianza","title":"Backus-Naur Form"},{"location":"ProAlgo/grammatiche/#principio-di-corrispondenza","text":"La dichiarazione di corrispondenza \u00e8 il riuso della sintassi per cose svolgono lo stesso compito. Questo permette di avere una maggiore facilit\u00e0 di apprendimento ed interpretazione, anche tra vari linguaggi. L'idea \u00e8 che se per un array in un linguaggio, accendiamo alle celle indicando l'indice tra parentesi quadre, probabilmente non vogliamo progettare un linguaggio in cui dobbiamo inserire un indice tra due punti e virgola.","title":"Principio di corrispondenza"},{"location":"ProAlgo/grammatiche/#linguaggi","text":"","title":"Linguaggi"},{"location":"ProAlgo/grammatiche/#identificatori","text":"Gli identificatori servono per identificare delle zone di memoria. Vengono Possono essere liberi o legati. La differenza \u00e8 che un identificatore legato risulta in un ambiente, e quindi ha un corrispettivo valore o punta ad una locazione di memoria. Un identificatore libero, \u00e8 un identificatore che viene usato all'interno del codice, tuttavia non risultando nell'ambiente non \u00e8 possibile correlarlo ad un valore, rendendo la sua valutazione impossibile. Avere identificatori liberi nel codice di un programma \u00e8 quindi un errore, che tendenzialmente porta il programma a non poter essere eseguito correttamente. Si collocano in un ambiente, ovvero una funzione che ci permette di \"mappare\" gli identificatori con i rispettivi valori (nel caso di costanti) o locazioni di memoria (nel caso di variabili e funzioni) Un identificatore si dice essere in posizione (o occorrenza) di legame quando abbiamo una definizione, e quindi leghiamo l'identificatore (il nome) ad una locazione di memoria.","title":"Identificatori"},{"location":"ProAlgo/grammatiche/#principio-di-astrazione","text":"Il principio di astrazione permette di ridurre la duplicazione di informazione nei programmi (quindi scrivere meno codice codice) usando (e riusando) sia funzioni definite dal programmatore che rese disponibili dal linguaggio (per non reinventare la ruota ) \u00c8 un principio che quindi ci invita a generalizzare il codice per evitare di copiarlo e incollarlo Il sottoproblema dovrebbe poi essere decomposto in sotto funzioni (ove necessario), riapplicando il principio Scrivere funzioni permette di aumentare la correttezza, in quanto una volta scritta e verificata, quella parte di codice \u00e8 corretta Ovviamente il linguaggio deve permettere di definirle e usarle","title":"Principio di Astrazione"},{"location":"ProAlgo/grammatiche/#funzioni","text":"Quasi tutti i linguaggi moderni fanno uso delle funzioni. Una funzione in un linguaggio di programmazione prende il concetto da una funzione matematica: permette di mappare uno o pi\u00f9 parametri (che chiameremo formali) in un valore. Le funzioni ci permettono di non ripetere codice, ma di renderlo invece modulare, permettendoci di creare sottoprogrammi che svolgono un compito specifico, garantendoci una miglior mantenibilit\u00e0. Grazie a questo aspetto, le funzioni ci permettono inoltre di avere una maggior confidenza nel codice, data dall'aumento della correttezza del codice: una volta che una funzione \u00e8 garantita essere corretta, si pu\u00f2 presumere che quella parte di codice non dovr\u00e0 essere esaminata ulteriormente. Il tipo della funzione \u00e8 il tipo del valore che la funzione ritorner\u00e0 (il suo codominio). Una funzione ritorna spesso un valore (spesso proprio mediante la keyword return , seguita da un'espressione, che sar\u00e0 dello stesso tipo della funzione) Un'altra cosa univoca delle funzioni \u00e8 la signatura: la signatura pu\u00f2 essere vista come una tripla, che include l'identificatore della funzione (il suo nome), i suoi parametri formali (i valori che prende in ingresso) ed infine il tipo che ritorner\u00e0. Da un punto di vista sintattico, le funzioni vengono definite attraverso una dichiarazione. Possiamo aspettarci quindi che in un linguaggio (come L ) la funzione si trovi insieme alle dichiarazioni: D::= nil | const id[:T]=E | var id[:T]=E | D;D | function Id(form) -> T {C} (In questo caso Id \u00e8 l'identificatore della funzione, il suo nome, form \u00e8 l'elenco dei formali, T \u00e8 il tipo e C il corpo della funzione) Quando invece sono utilizzate, si dice che vengono invocate, e la loro invocazione rientra nei tipi delle espressioni. Una funzione avr\u00e0 quindi la seguente forma: function nome ( formali ...) tipo e sar\u00e0 invocata con una forma simile a questa: nome ( attuali ...) considerando gli attuali come una lista di espressioni. Sotto il punto di vista dell'invocazione, si pu\u00f2 pensare che una chiamata ad una funzione sospenda l'esecuzione del chiamate (da un punto di vista formale), in attesa che la funzione termini e restituisca il valore rispetto ai parametri attuali forniti (gli argomenti con cui la funzione \u00e8 stata chiamata). Formali ed attuali dovranno essere due liste di variabili con lo stesso numero di elementi e di tipi concordi. I controlli che verranno effettuati durante la compilazione saranno i seguenti: Assicurarsi che il numero di argomenti attuali (quelli forniti alla funzione) sia uguale al numero di argomenti attuali Assicurarsi che i nomi dei parametri formali siano distinti (altrimenti due parametri potrebbero avere lo stesso nome, generando confusione ed ambiguit\u00e0) Assicurarsi che i tipi dei parametri attuali e formali per la stessa posizione siano uguali (non ha senso dire che il valore \"ciao\" \u00e8 un numero) Assicurarsi che non ci siano variabili libere nel corpo della funzione Assicurarsi che la funzione abbia un return ed il tipo ritornato sia lo stesso dichiarato nella signatura Dato che una funzione \u00e8 una dichiarazione, l'ambiente viene esteso in seguito ad una dichiarazione. Ci\u00f2 significa che \u00e8 possibile usare una funzione nel suo stesso corpo. Questa tecnica \u00e8 detta ricorsione e ci permette di lavorare con strutture iterative come i grafi con estrema facilit\u00e0, rispetto ad un approccio pi\u00f9 tradizionale (iterativo), che \u00e8 pi\u00f9 difficile in fase di ragionamento e quindi pi\u00f9 soggetto ad errori (e pi\u00f9 lungo da scrivere ed ideare). Ovviamente questa tecnica non \u00e8 efficiente da un punto di vista della memoria, tuttavia \u00e8 un tradeoff che spesso vale la pena adottare.","title":"Funzioni"},{"location":"ProAlgo/grammatiche/#segnatura-di-una-funzione","text":"nome, parametri formali, e tipo di ritorno La dichiarazione richiede anche un corpo, in cui si ritorna anche il tipo","title":"Segnatura di una funzione"},{"location":"ProAlgo/grammatiche/#il-record-di-attivazione","text":"Ogni volta che si invoca una funzione, viene generato un corrispettivo record di attivazione (o stack frame) Un record di attivazione \u00e8 una struttura dati che ci permette di tenere traccia dei dati necessari all'esecuzione delle funzioni. Un record di attivazione \u00e8 composto da 7 valori fondamentali: Puntatore alla catena dinamica La catena dinamica tiene traccia del record di attivazione della funzione chiamante. Quindi quando una funzione ne chiama una seconda, la seconda avr\u00e0 come puntatore nella catena dinamica il record di attivazione del chiamante Puntatore alla catena statica La catena statica punta al record di attivazione della funzione chiamante. Permette quindi di effettuare la risoluzione degli identificatori non presenti nel blocco corrente (con scoping statico) La catena statica \u00e8 visibile come un array di \"chiamate\" (e ci rientrano i parametri formali con cui sono state invocate le funzioni precedenti) Permette di vedere tutto ci\u00f2 che \u00e8 accessibile dall'ambiente in uno specifico momento Permette inoltre di effettuare information hiding: (dato come esempio un programma in cui la funzione A chiama la funzione B, che chiama a sua volta la funzione C) se un parametro formale della funzione B ha lo stesso nome di un parametro della funzione A, il parametro della funzione B prende precedenza e quindi non \u00e8 possibile accedere al parametro della funzione A. Vince l'ultima cosa dichiarata. Indirizzo di ritorno L'istruzione da eseguire al ritorno della funzione corrente Indirizzo del risultato L'indirizzo della locazione dove salvare il risultato che la funzione restituir\u00e0 Parametri (attuali e formali) Associazione dei parametri formali ed attuali Variabili locali L'ambiente dove risiederanno le variabili locali della funzione Risultati temporanei Uno spazio di memoria dove risiederanno le variabili temporanee generate dal compilatore Catena dinamica (call chain) La catena dinamica \u00e8 una sequenza di chiamate e serve per garantire l'ordine di esecuzione. \u00c8 una struttura dati di tipo LIFO (Last In, Fist Out), una pila catena statica (da rivedere) La catena statica si occupa di implementare lo scoping statico, ovvero individuare gli identificatori necessari in base alla visibilit\u00e0 \u00c8 quindi un ambiente derivato dalla dichiarazione di variabili e costanti Garantisce che i nomi siano referenziati rispetto alla visibilit\u00e0 di variabili e funzione","title":"Il record di attivazione"},{"location":"ProAlgo/introduzione/","text":"Definizione di Algoritmo \u00b6 Questo corso tratta principalmente di algoritmi, quindi \u00e8 bene iniziare con una definizione formale di Algoritmo: Definizione di Algoritmo Un algoritmo \u00e8 una descrizione formale di una sequenza finita di azioni** elementari** e non ambigue , che prendono dei dati in input, vengono eseguite e producono dei dati in output. Gli algoritmi risolvono una classe di problemi . I dati in input determinano un'istanza della classe di problemi che si andr\u00e0 a risolvere. Basandoci su questa definizione, possiamo ora definire cosa significa programmare: Programmare Programmare \u00e8 l'atto di scrivere un documento che risolve un problema reale e che pu\u00f2 essere compreso ed eseguito da un computer. Idealmente il documento deve essere scritto usando la soluzione pi\u00f9 efficiente possibile. E quindi ora possiamo dire cos'\u00e8 un programma: Definizione di Programma \u00b6 Definizione di Programma Scrittura di un algoritmo in un linguaggio di programmazione Il linguaggio di programmazione \u00e8 quindi il linguaggio in cui si codifica l'algoritmo per renderlo poi interpretabile dal computer. Vale la pena notare che un linguaggio \u00e8 un insieme di regole finito che permette di modellare un dominio infinito di programmi scritti in maniera legale (seguendo le regole). Un linguaggio \u00e8 composto in 2 parti: sintassi e sematica . I due temi sono importantissimi e verranno trattati con maggiore dettaglio nella pagine successive. Brevemente, possiamo pensare alla sintassi come l'equivalente della correttezza grammaticale in un linguaggio naturale (come l'italiano). La semantica indica invece quali operazioni sono legali in un linguaggio: ad esempio non dovrebbe essere possibile associare ad un numero intero il valore \"stringa\" (che \u00e8 una parola e non un numero ). Il linguaggio si divide poi in due categorie: esistono linguaggi statici e linguaggi dinamici. A seconda del tipo, esistono diversi passaggi a cui il codice sorgente deve essere soggetto prima di poter essere compreso da un computer. I passaggi sono spesso composti da una semplificazione relativamente semplice (almeno in termini di concetto), che semplifica o tratta il codice \"abbassando\" il suo livello di complessit\u00e0. Ad esempio in un linguaggio statico, abbiamo diversi passaggi: Analizzatore lessicale/lexer/scanner Questo primo passaggio serve a scomporre il linguaggio in token o lexems . Quindi ad esempio il seguente codice: if ( true ){ a = 1 ; } Verranno individuati i token if , ( , true , ) , { a , = , 1 , ; , } Questo insieme di token viene poi passato all'analizzatore sintattico Analizzatore sintattico/parser L'analizzatore sintattico si occupa di assicurarsi che ogni token sia grammaticamente corretto (ad esempio if \u00e8 corretto, mentre fi no) Si occupa inoltre di assicurarsi che la \"frase\" abbia senso da un punto di vista grammaticale. L'esempio appena visto \u00e8 corretto, mentre uno snippet di codice come il seguente non lo \u00e8: if if ( true { Se tutto \u00e8 corretto, l'analizzatore sintattico restituir\u00e0 un albero di sintassi astratto , che rappresenter\u00e0 la \"frase\" del linguaggio strutturato Continuando con l'esempio precedente, quello che segue \u00e8 l'equivalente dell'albero di sintassi astratto (E sta per espressione): Analizzatore semantico/type checker L'analizzatore semantico si occupa di simulare l'esecuzione del programma per assicurarsi che non si presentino molteplici errori, come: Trovare nomi non dichiarati o dichiarazioni di nomi gi\u00e0 dichiarati Uso di operatori con tipi non compatibili (come ad esempio la somma tra \"a\" e 2), ed assicurarsi che l'uso dei tipi sia usato con coerenza Funzioni chiamate con numero e/o tipo sbagliato di argomenti o che ritornano un tipo non adatto Ed altre funzioni poi in base al linguaggio (come variabili non inizializzate o non usate, use after free e use before assignment, blocchi di codice non raggiungibili, funzioni mai invocate o senza effetti) Se \u00e8 tutto ok, quello che viene restituito \u00e8 quello che viene detto three-address code, un linguaggio intermediario che usa fino a tre indirizzi per rappresentare ogni istruzione. Eventuale passaggio di ottimizzazione del codice Esiste un eventuale passaggio di ottimizzazione che alcuni toolchain possono effettuare per migliorare le performances, restituendo una versione pi\u00f9 efficiente (sempre in three-address code) Generatore del codice oggetto Il generatore del codice oggetto si occupa di prendere three-address code ed avviare un primo stato di compilazione in codice oggetto (molto simile a codice macchina). Questo codice non \u00e8 ancora eseguibile, e non \u00e8 neppure necessariamente un singolo file. Linker Il linker \u00e8 l'ultimo passaggio della compilazione, e si occupa di prendere il risultato del generatore del codice oggetto (codice oggetto) e \"collegarlo\" con le librerie di cui il programma fa uso (ed inserire un loader). Il risultato del linker sar\u00e0 quindi un programma eseguibile dal computer. Pannello storico Nel '50 Hopper ha scritto il primo compilatore sperimentale Nel '57 Backus ha scritto il primo compilatore Architettura di von-Neumann \u00b6 Un programma viene eseguito in un computer, quindi ha senso parlare di cosa intendiamo per computer, per poter avere una buona astrazione sulla quale basarci poi. L'astrazione pi\u00f9 conosciuta di computer, \u00e8 il modello di Von Neumann ed \u00e8 composto da un bus (un canale di comunicazione), che connette memoria, processore, input ed output. Ciclo fetch-execute \u00b6 Il ciclo fetch-execute \u00e8 un paradigma su cui i processori si basano, ed \u00e8 composto da un ciclo in cui il processore prende costantemente delle istruzioni da eseguire dalla memoria principale, le decodifica e le esegue, per poi ripetere il ciclo nuovamente.","title":"Introduzione"},{"location":"ProAlgo/introduzione/#definizione-di-algoritmo","text":"Questo corso tratta principalmente di algoritmi, quindi \u00e8 bene iniziare con una definizione formale di Algoritmo: Definizione di Algoritmo Un algoritmo \u00e8 una descrizione formale di una sequenza finita di azioni** elementari** e non ambigue , che prendono dei dati in input, vengono eseguite e producono dei dati in output. Gli algoritmi risolvono una classe di problemi . I dati in input determinano un'istanza della classe di problemi che si andr\u00e0 a risolvere. Basandoci su questa definizione, possiamo ora definire cosa significa programmare: Programmare Programmare \u00e8 l'atto di scrivere un documento che risolve un problema reale e che pu\u00f2 essere compreso ed eseguito da un computer. Idealmente il documento deve essere scritto usando la soluzione pi\u00f9 efficiente possibile. E quindi ora possiamo dire cos'\u00e8 un programma:","title":"Definizione di Algoritmo"},{"location":"ProAlgo/introduzione/#definizione-di-programma","text":"Definizione di Programma Scrittura di un algoritmo in un linguaggio di programmazione Il linguaggio di programmazione \u00e8 quindi il linguaggio in cui si codifica l'algoritmo per renderlo poi interpretabile dal computer. Vale la pena notare che un linguaggio \u00e8 un insieme di regole finito che permette di modellare un dominio infinito di programmi scritti in maniera legale (seguendo le regole). Un linguaggio \u00e8 composto in 2 parti: sintassi e sematica . I due temi sono importantissimi e verranno trattati con maggiore dettaglio nella pagine successive. Brevemente, possiamo pensare alla sintassi come l'equivalente della correttezza grammaticale in un linguaggio naturale (come l'italiano). La semantica indica invece quali operazioni sono legali in un linguaggio: ad esempio non dovrebbe essere possibile associare ad un numero intero il valore \"stringa\" (che \u00e8 una parola e non un numero ). Il linguaggio si divide poi in due categorie: esistono linguaggi statici e linguaggi dinamici. A seconda del tipo, esistono diversi passaggi a cui il codice sorgente deve essere soggetto prima di poter essere compreso da un computer. I passaggi sono spesso composti da una semplificazione relativamente semplice (almeno in termini di concetto), che semplifica o tratta il codice \"abbassando\" il suo livello di complessit\u00e0. Ad esempio in un linguaggio statico, abbiamo diversi passaggi: Analizzatore lessicale/lexer/scanner Questo primo passaggio serve a scomporre il linguaggio in token o lexems . Quindi ad esempio il seguente codice: if ( true ){ a = 1 ; } Verranno individuati i token if , ( , true , ) , { a , = , 1 , ; , } Questo insieme di token viene poi passato all'analizzatore sintattico Analizzatore sintattico/parser L'analizzatore sintattico si occupa di assicurarsi che ogni token sia grammaticamente corretto (ad esempio if \u00e8 corretto, mentre fi no) Si occupa inoltre di assicurarsi che la \"frase\" abbia senso da un punto di vista grammaticale. L'esempio appena visto \u00e8 corretto, mentre uno snippet di codice come il seguente non lo \u00e8: if if ( true { Se tutto \u00e8 corretto, l'analizzatore sintattico restituir\u00e0 un albero di sintassi astratto , che rappresenter\u00e0 la \"frase\" del linguaggio strutturato Continuando con l'esempio precedente, quello che segue \u00e8 l'equivalente dell'albero di sintassi astratto (E sta per espressione): Analizzatore semantico/type checker L'analizzatore semantico si occupa di simulare l'esecuzione del programma per assicurarsi che non si presentino molteplici errori, come: Trovare nomi non dichiarati o dichiarazioni di nomi gi\u00e0 dichiarati Uso di operatori con tipi non compatibili (come ad esempio la somma tra \"a\" e 2), ed assicurarsi che l'uso dei tipi sia usato con coerenza Funzioni chiamate con numero e/o tipo sbagliato di argomenti o che ritornano un tipo non adatto Ed altre funzioni poi in base al linguaggio (come variabili non inizializzate o non usate, use after free e use before assignment, blocchi di codice non raggiungibili, funzioni mai invocate o senza effetti) Se \u00e8 tutto ok, quello che viene restituito \u00e8 quello che viene detto three-address code, un linguaggio intermediario che usa fino a tre indirizzi per rappresentare ogni istruzione. Eventuale passaggio di ottimizzazione del codice Esiste un eventuale passaggio di ottimizzazione che alcuni toolchain possono effettuare per migliorare le performances, restituendo una versione pi\u00f9 efficiente (sempre in three-address code) Generatore del codice oggetto Il generatore del codice oggetto si occupa di prendere three-address code ed avviare un primo stato di compilazione in codice oggetto (molto simile a codice macchina). Questo codice non \u00e8 ancora eseguibile, e non \u00e8 neppure necessariamente un singolo file. Linker Il linker \u00e8 l'ultimo passaggio della compilazione, e si occupa di prendere il risultato del generatore del codice oggetto (codice oggetto) e \"collegarlo\" con le librerie di cui il programma fa uso (ed inserire un loader). Il risultato del linker sar\u00e0 quindi un programma eseguibile dal computer. Pannello storico Nel '50 Hopper ha scritto il primo compilatore sperimentale Nel '57 Backus ha scritto il primo compilatore","title":"Definizione di Programma"},{"location":"ProAlgo/introduzione/#architettura-di-von-neumann","text":"Un programma viene eseguito in un computer, quindi ha senso parlare di cosa intendiamo per computer, per poter avere una buona astrazione sulla quale basarci poi. L'astrazione pi\u00f9 conosciuta di computer, \u00e8 il modello di Von Neumann ed \u00e8 composto da un bus (un canale di comunicazione), che connette memoria, processore, input ed output.","title":"Architettura di von-Neumann"},{"location":"ProAlgo/introduzione/#ciclo-fetch-execute","text":"Il ciclo fetch-execute \u00e8 un paradigma su cui i processori si basano, ed \u00e8 composto da un ciclo in cui il processore prende costantemente delle istruzioni da eseguire dalla memoria principale, le decodifica e le esegue, per poi ripetere il ciclo nuovamente.","title":"Ciclo fetch-execute"},{"location":"ProAlgo/l/","text":"Il linguaggio L \u00b6 Il linguaggio L \u00e8 un linguaggio teorico e usato solo per scopi educativi. Questo lo tratter\u00f2 poi, nel frattempo allego la pagina di appunti: Linguaggio L BNF \u00b6 Semantica statica \u00b6 Espressioni \u00b6 Assiomi \u00b6 \\(\\varnothing \\vdash_e i: Int\\) Questo assioma ci indica che senza un ambiente, possiamo dire che un'espressione fatta da simbolo appartenente alla categoria sintattica degli interi, \u00e8 di tipo Int Ad esempio, 5 \u00e8 un intero, e non ci serve un'ambiente per dirlo \\(\\varnothing \\vdash_e d: Double\\) \\(\\varnothing \\vdash_e b: Bool\\) \\(\\varnothing \\vdash_e s: String\\) Regole \u00b6 R1 \u00b6 \\[ (R1) \\frac {(\\Delta (Id) = \\tau \\lor \\Delta (Id) = \\tau Loc)} {\\Delta \\vdash_e Id: \\tau} \\] Questa regola di inferenza si pu\u00f2 leggere come: Se, dato un ambiente, possiamo trovare l'identificatore nell'ambiente e questo identificatore ha tipo \\(\\tau\\) o \\(\\tau Loc\\) , allora l'identificatore ha tipo \\(\\tau\\) R2 \u00b6 \\[ (R2) \\frac {\\Delta \\vdash_e E_1 : \\tau_1, \\operatorname{uop}: \\tau_1 \\to \\tau} {\\Delta \\vdash_e \\operatorname{uop} E_1: \\tau} \\] Se, partendo dall'ambiente \\(\\Delta\\) , l'espressione \u00e8 di tipo \\(\\tau_1\\) e l'operatore unario prende un tipo \\(\\tau_1\\) e lo trasforma in \\(\\tau\\) , l'espressione uop E1 \u00e8 di tipo \\(\\tau\\) . (Notare che uop \u00e8 la categoria sintattica degli operatori unari, come ad esempio ! , ovvero la negazione) Esempio Possiamo gi\u00e0 fare un'esempio con queste due regole appena viste: Prendendo un ambiente con una variabile x intera (quindi \\(\\Delta = [(x, Int)]\\) ) possiamo gi\u00e0 valutare -x : \\[ \\frac { \\frac {\\Delta(x) = Int} {\\Delta \\vdash_e x:Int}, -: Int \\to Int} {\\Delta \\vdash_e -x: Int} \\] In questo esempio, per valutare l'espressione -x (e quindi determinarne il tipo), dividiamo innanzitutto l'espressione (quindi valutando il tipo dell'espressione x ed assicurandosi che sia compatibile con l'operatore unario - ) Ci assicuriamo quindi che x sia presente nell'ambiente, e ne determiniamo che il tipo \u00e8 Int . Procediamo quindi assicurandoci che l'operatore unario - prenda in input un Int e restituisca un int, e cos\u00ec \u00e8. Possiamo dunque dire che l'espressione -x \u00e8 di tipo Int. R3 \u00b6 \\[ (R3) \\frac {\\Delta \\vdash_e E_1: \\tau_1, \\; \\Delta \\vdash_e E_2: \\tau_2, \\; \\operatorname{bop}: \\tau_1 \\times \\tau_2 \\to \\tau} {\\Delta \\vdash_e \\tau_1 \\ \\operatorname{bop} \\ \\tau_2:\\tau } \\] Questa regola \u00e8 molto simile alla precedente, con la differenza che stavolta valutiamo anche una seconda espressione \\(E_2\\) , essendo bop la categoria sintattica degli operatori binari, e ci assicuriamo quindi che i due tipi (delle due espressioni \\(E_1\\) ed \\(E_2\\) ) siano compatibili tra di loro. R4 \u00b6 \\[ (R4) \\frac {\\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_e (E): \\tau} \\] Questa regola ci permette di \"eliminare\" le parentesi che racchiudono un'espressione, permettendoci di valutare l'espressione. Comandi \u00b6 I comandi (che ricordiamo, si Eseguono ) non hanno tipi, in quanto i comandi non rappresentano un valore. Assiomi \u00b6 Tra i comandi troviamo un solo assioma: \\(\\varnothing \\vdash_c nil\\) Che ci dice che da un ambiente vuoto non c'\u00e8 nulla che possiamo concludere Regole \u00b6 R5 \u00b6 \\[ (R5) \\frac {\\Delta(Id) = \\tau Loc, \\; \\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_c Id=E} \\] Questa regola ci dice che, per assegnare un'espressione ad una variabile, devo assicurarmi che il tipo dell'espressione e quello della variabile sono concordi R7 \u00b6 \\[ (R7) \\frac {\\Delta \\vdash_e E: Bool, \\; \\Delta \\vdash_c C_1, \\; \\Delta \\vdash_c C_2} {if\\ (E)\\{C_1\\}\\ else\\ \\{C_2\\}} \\] Questa regola pu\u00f2 essere un pelo pi\u00f9 complicata da decodificare; Partendo quindi dalle assunzioni (e tenendo presente che \u00e8 una clausola if): Se l'espressione E \u00e8 ben formata ed ha tipo Bool, il comando \\(C_1\\) \u00e8 ben formato ed il comando \\(C_2\\) \u00e8 ben formato, allora l'If \u00e8 ben formato (sempre in termini di tipi). R8 \u00b6 \\[ (R8) \\frac {\\Delta \\vdash_e E:Bool, \\; \\Delta \\vdash_c C} {\\Delta \\vdash_c while(E){C}} \\] Come nell'if, questa formula ci permette di dire che il comando while \u00e8 ben formato se l'espressione E \u00e8 ben formata ed ha tipo Bool, e se il comando C (che \u00e8 il corpo del while) \u00e8 ben formato. Teniamo a mente che questo controllo non valuta se il while termina, questa \u00e8 semantica statica, quindi stiamo solo controllando i tipi. R9 \u00b6 \\[ (R9) \\frac {\\Delta \\vdash_d D: \\Delta', \\Delta[\\Delta'] \\vdash_c C} {\\Delta \\vdash_c D;C} \\] Anche questa regola pu\u00f2 essere un attimo pi\u00f9 complicata da leggere, quindi anche in questo caso partiamo dalle premesse, tenendo a mente che stiamo valutando un comando (che \u00e8 composto da una dichiarazione D ed un comando C): La prima premessa ci dice che se la dichiarazione \u00e8 ben formata, la dichiarazione restituisce un ambiente \\(\\Delta'\\) , ovvero un ambiente in cui troviamo solamente la dichiarazione appena fatta. In questo caso, procediamo quindi ad estendere l'ambiente \\(\\Delta\\) con \\(\\Delta'\\) , e con l'ambiente risultante (che non \u00e8 altro che una concatenazione di funzioni) procediamo con l'esecuzione del comando C. Se il comando C \u00e8 valido (e quindi ben formato), la dichiarazione D;C \u00e8 ben formata. L'estensione dell'ambiente possiamo vederla in questo modo: \\(\\Delta[\\Delta'](x) = \\begin{cases} \\Delta'(x) & \\text{ se } \\Delta'(x) \\text{ \u00e8 definito} \\\\ \\Delta(x) & \\text{ altrimenti} \\end{cases}\\) Possiamo quindi vedere dalla formula che l'estensione NON sovrascrive l'ambiente, bens\u00ec oscura (ove necessario) degli identificatori Esempio se definiamo in \\(\\Delta\\) un identificatore X e poi lo ridefiniamo in \\(\\Delta'\\) , allora quando andremo a \"risolvere\" l'identificatore X nell'ambiente \\(\\Delta[\\Delta']\\) , risolveremo X per l'ambiente \\(\\Delta'\\) , che \u00e8 il pi\u00f9 \"recente\", oscurando di fatto l'identificatore nell'ambiente \\(\\Delta\\) ) Questo ci fa inoltre capire che nel linguaggio L \u00e8 possibile ridichiarare le variabili. Quindi, ricapitolando, se da \\(\\Delta\\) \u00e8 possibile associare a D l'ambiente statico \\(\\Delta'\\) , E da \\(\\Delta\\) esteso con i legami di \\(\\Delta'\\) posso dimostrare che C \u00e8 ben formato, il comando D;C \u00e8 ben formato. Dichiarazioni \u00b6 Una dichiarazione \u00e8 ben formata se a partire dall'ambiente statico \\(\\Delta\\) \u00e8 possibile associare un ambiente statico che contiene i legami per i nomi definiti in D. Notare che il \"risultato\" delle dichiarazioni \u00e8 espresso dopo i due punti : Assiomi \u00b6 \\(\\varnothing \\vdash_d nil: \\varnothing\\) Regole \u00b6 R10 \u00b6 \\[ (R10) \\frac {\\Delta \\vdash_e E:\\tau, \\; T == \\tau} {\\Delta \\vdash_d const \\ Id:T = E: [(Id, \\tau)]} \\] In questa prima dichiarazione di costante, possiamo vedere come il controllo sia basato sull'assicurarsi che il tipo dell'identificatore (o variabile , in questo caso) sia lo stesso del tipo dell'espressione. Quindi quando viene dichiara una costante, \u00e8 possibile dire che \u00e8 ben formata quando l'espressione \u00e8 ben formata ed il tipo di \\(\\tau\\) \u00e8 di tipo T e viene prodotto l'ambiente \\(\\Delta'\\) , rappresentato da \\([(Id, \\tau)]\\) R11 \u00b6 \\[ (R11) \\frac {\\Delta \\vdash_e E: \\tau, \\ T == \\tau} {\\Delta \\vdash_d var Id:T = E: [(Id, \\tau Loc)]} \\] Possiamo vedere che per la variabile vale lo stesso discorso della costante appena vista, con l'unica differenza che una variabile ha tipo \\(\\tau Loc\\) , dove Loc identifica che il tipo \u00e8 presente in una certa locazione di memoria, in quanto \u00e8 una variabile e non una costante R12 \u00b6 \\[ (R12) \\frac {\\Delta \\vdash_d D_1: \\Delta', \\; \\Delta[\\Delta'] \\vdash_d D_2: \\Delta''} {\\Delta \\vdash_d D_1;D_2: \\Delta'[\\Delta'']} \\] Quest'ultima regola ci permette di validare due dichiarazioni consecutive. La regola si pu\u00f2 leggere in questo modo: Se da \\(\\Delta\\) , \\(D_1\\) \u00e8 in grado di generare l'ambiente statico \\(\\Delta'\\) e da \\(\\Delta\\) esteso con \\(\\Delta'\\) , \\(D_2\\) genera l'ambiente \\(\\Delta''\\) , Allora da \\(\\Delta\\) , l'espressione genera l'ambiente statico \\(\\Delta'\\) esteso con \\(\\Delta''\\) e la dichiarazione \u00e8 ben formata Esempio di Semantica statica Possiamo vedere qui di seguito l'applicazione delle regole sopra definite, partendo dalle due dichiarazioni var x:Int = 3; var y:Int = x \\[ (R12) \\frac {(R5) \\frac {\\varnothing \\vdash_e 3:Int, Int == IntLoc} {\\varnothing \\vdash_d var\\ x:Int = 3: \\Delta'} (R5) \\frac {(R1) \\frac {\\varnothing[\\Delta'](x) = IntLoc} {\\varnothing[\\Delta'] \\vdash_e x:Int}, \\varnothing [\\Delta'] \\vdash_d y:Int = x: \\Delta'' } {\\varnothing[\\Delta'] \\vdash_d var\\ y:Int=x: \\Delta''} } {\\varnothing \\vdash_d var\\ x:Int=3;var\\ y:Int=x;} \\] Avremo quindi che \\(\\Delta'=[(x, IntLoc)]\\) e \\(\\Delta''=[(y, IntLoc)]\\) In questo esempio abbiamo applicato la regola R12 per dividere le due dichiarazioni. Separatamente poi, per la prima dichiarazione abbiamo applicato la R5, (seguita dal primo assioma che abbiamo visto, che ci dice che 3 \u00e8 un Intero) Per la seconda dichiarazione, abbiamo applicato la regola R5 come prima, con la differenza che stavolta l'espressione non era un numero, ma un'identificatore. Abbiamo quindi risolto l'identificatore contenuto nell'espressione (x) grazie all'ambiente \\(\\Delta\\) . Una volta verificato che espressione e variabile erano dello stesso tipo, \u00e8 possibile dire che il comando \u00e8 corretto. Semantica statica delle funzioni \u00b6 FS1 \u00b6 \\[ (FS1) \\dfrac {\\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_c \\text{return } E} \\] Se da \\(\\Delta\\) \u00e8 possibile associare il tipo \\(\\tau\\) all'espressione E, il return ha tipo E. FS2 \u00b6 \\[ (FS2) \\dfrac {from: \\Delta_0, \\Delta[\\Delta_0] \\vdash_c C; \\text{return }E, \\Delta[\\Delta'] \\vdash_e E:\\tau} {\\Delta \\vdash_d \\text{func } Id(form) \\to \\tau \\{C;\\text{return }E\\}: \\Tau(Id,\\tau(form) \\to \\tau)} \\] Dove la funzione \\(\\Tau\\) \u00e8 definita cos\u00ec: \\(\\Tau(form) = \\begin{cases} \\Tau(nil) & = nil \\\\ \\Tau(const ~ Id:\\tau, form') & = \\tau, \\Tau(form') \\\\ \\Tau(var ~ Id: \\tau, form') & = \\tau, \\Tau(form') \\end{cases}\\) Quindi: \\(\\Tau(form) = \\Tau(var ~ id:\\tau = E; form') = \\tau, \\Tau(form')\\) form \u00e8 una lista di formali (da vedere come \\([H,T]\\) , testa (H) e coda (T) della lista) Questa formula ci permette di \"srotolare\" la lista, valutando il tipo di ogni parametro (grazie alla funzione \\(\\Tau\\) ) in maniera ricorsiva. Notare che nella definizione di \\(\\Tau\\) , il tipo nil \u00e8 usato solo internamente, non fa parte del linguaggio (non esiste un tipo nil). Questa regola si compone quindi in 3 parti: Srotolando i formali, questi formano un ambiente \\(\\Delta'\\) Con \\(\\Delta'\\) , controlliamo se il corpo della funzione (ed il return) sono ben formati Se, estendendo l'ambiente \\(\\Delta\\) con \\(\\Delta'\\) l'espressione di return \u00e8 ben formata e di tipo \\(\\tau\\) Allora la dichiarazione di funzione \u00e8 ben formata, e nell'ambiente si aggiunge la coppia Nome funzione , lista dei formali e tipo di ritorno della funzione ( \\(\\Tau(form) \\to \\tau\\) ) FS3 \u00b6 (FS3) \\(nil: \\varnothing\\) , \\(\\dfrac {form: \\Delta_0, Id \\notin \\Delta_0}{const ~ Id:\\tau, form: \\Delta_0[(Id, \\tau)]}\\) , \\(\\quad \\dfrac {form: \\Delta_0, Id \\notin \\Delta_0}{var ~ Id:\\tau, form: \\Delta_0[(Id, \\tau Loc)]}\\) Questa regola serve per assegnare i tipi ai signoli parametri formali che vengono valutati dalla regola FS2. In questo caso \u00e8 necessario controllare che il nome dell'identificatore non sia gi\u00e0 usato nella lista dei formali (altrimenti sarebbe alquanto ambiguo l'uso dell'identificatore nel corpo della funzione) FS4 \u00b6 \\[ (FS4) \\dfrac {\\Delta \\vdash_{ae} ae:aet, \\Delta(Id) = aet \\to \\tau} {\\Delta \\vdash_e Id(ae): \\tau} \\] \\(\\begin{cases} \\Delta \\vdash_{ae} nil \\\\ \\dfrac{\\Delta \\vdash_e E:\\tau, \\Delta \\vdash_{ae}:aet}{\\Delta \\vdash_{ae}E, ae:\\tau, aet} \\end{cases}\\) Se la lista degli attuali ae corrisponde ad una lista di tipi (aet) e nell'ambiente ho una lista di tipi (uguale ad aet) che restituiscono tau, allora l'espressione \u00e8 ben formata Semantica statica delle funzioni ricorsive \u00b6 RS1 \u00b6 \\[ (RS1) \\dfrac {\\Delta[\\Delta'_{|I_0}]\\vdash D:\\Delta'} {\\Delta \\vdash_{rec} D:\\Delta'}, I_0 = FI(D) \\cap BI(D) \\] Con \\(\\Delta'=[(fact,Int \\to Int)] = \\Delta_{|I_0}'\\) Estendendo \\(\\Delta\\) con l'intersezione di intersezione tra identificatori liberi e legati ($I_0) si pu\u00f2 dire che la dichiarazione \u00e8 ben formata. In questo caso, il nome della funzione \u00e8 legato, mentre un'eventuale riferimento all'interno del corpo della funzione sarebbe libero. La cosa si pu\u00f2 semplificare con questa regola: \\[ (RS1') \\dfrac {\\vdash_d D:\\Delta} {\\vdash_d rec ~ D:\\Delta} \\] Questa regola (che richiama FS2') ci viene in contro se la funzione non ha dichiarazioni ricorsive al suo interno \\[ (RS1'')\\dfrac {\\vdash_d D:\\Delta', \\Delta[\\Delta'_{|I_0}] \\vdash_d D} {\\Delta \\vdash_d rec ~ D}, I_0 = FI(D) \\cap BI(D) \\] In questo caso FI \u00e8 una funzione che individua gli identificatori liberi. \\(FI(func) = FI(C) - FI(form)\\) Che significa che gli identificatori liberi di uan funzione sono gli identificatori liberi del corpo meno gli identificatori liberi dei formali (ovvero nessuno, essendo tutti legati) Richiama RS1' RS2 \u00b6 \\[ (RS2'') \\dfrac {FS' | FS2''}{\\Delta \\vdash_d rec ~ D } \\] FS2(?) \u00b6 \\[ (FS2) \\dfrac {form:\\Delta_0,\\Delta[\\Delta_0]\\vdash_c var ~ res:\\tau=E;C;return ~ res, \\Delta[\\Delta_0][(res,\\tau Loc)] \\vdash_e E:\\tau} {\\Delta \\vdash_d func ~ Id(form) \\to \\tau \\{ var ~ res:\\tau;C;return ~ res\\}: [(Id, \\Tau(form) \\to \\tau )]} \\] Per semplificare le funzioni, assumiamo che la funzione inizi con una dichiarazione di variabile che sar\u00e0 il valore che verr\u00e0 restituito Semantica dinamica \u00b6 In L un identificatore contiene lettere, cifre e _ . Inoltre non inizia con una cifra. Semantica dinamica delle espressioni \u00b6 Le regole che seguono ci permettono di definire un modello di valutazione delle espressioni ID1 \u00b6 \\[ (Id_1) \\dfrac {\\rho(Id)=v \\lor (\\rho(Id)=L \\in Loc \\land \\sigma(L)=V)} {\\anglebr{Id, \\rho, \\sigma} \\to_e V} \\] Partiamo quindi dal controllare le premesse: se da \\(\\rho\\) posso associare ad Id un valore, o se da \\(\\rho\\) posso associare ad Id una locazione L e alla locazione L \u00e8 memorizzato un valore V Allora da \\(\\rho\\) e \\(\\sigma\\) , Id viene valutato v in un passo di valutazione UOP1 \u00b6 $$ (uop1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e \\anglebr{E', \\rho, \\sigma}} {\\anglebr{uop ~ E, \\rho, \\sigma} \\to_e \\anglebr{uop ~ E', \\rho, \\sigma}} $$\\ Se in un passo di valuazione, a partire da \\(\\rho\\) e \\(\\sigma\\) , E si trasforma in E', da \\(\\rho\\) e \\(\\sigma\\) uop E si trasforma in uop E' in un passo di valutazione. UOP2 \u00b6 \\[ (uop2) \\anglebr{uop ~ v, \\rho, \\sigma} \\to_e v'= uop ~ v \\] Dopo aver valutato ripetutamente v mediante uop1, si raggiunge \\(uop ~ v\\) (ovvero il membro a destra della formula) e si pu\u00f2 concludere la valutazione. BOP \u00b6 \\[ (bop1) \\dfrac {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E^'_1 ~ bop ~ E_2, \\rho, \\sigma}} {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E^'_1 ~ bop ~ E_2, \\rho, \\sigma}} \\] \\[ (bop2) \\dfrac {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E_1 ~ bop ~ E_2^', \\rho, \\sigma}} {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E_1 ~ bop ~ E_2^', \\rho, \\sigma}} \\] \\[ (bop3) \\anglebr{v_1 ~ bop ~ v_2, \\rho, \\sigma} \\to_e v=v_1 ~ bop ~ v_2 \\] Dopo aver valutato correttamente entrambi i membri delle espressioni (con rispettivamente BOP1 e BOP2), si raggiunge la configurazione \\(v_1 ~ bop ~ v_2\\) , che si pu\u00f2 valutare a v Semantica dinamica dei comandi \u00b6 ID2 \u00b6 \\[ (id2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star v} {\\anglebr{Id = E, \\rho, \\sigma}\\to_c \\anglebr{Id=v, \\rho, \\sigma}} \\] Se, partendo da \\(\\rho\\) e \\(\\sigma\\) , l'espressione E (dopo un certo numero di passi) viene valutata ad un valore V L'assegnamento pu\u00f2 essere riscritto come Id=v (senza toccare \\(\\rho\\) e \\(\\sigma\\) , dato che la valutazione non li modifica). ID3 \u00b6 \\[ (id3) \\anglebr{Id=v, \\rho, \\sigma} \\to_e \\sigma[\\rho(Id)=v] \\] L'esecuzione dell'assegnamento lascia inalterato l'ambiente, modificando solo la locazione di memoria \\(\\rho(Id)\\) con v SEQ \u00b6 \\[ (seq1) \\dfrac {\\anglebr{C_1, \\rho, \\sigma} \\to_c \\anglebr{C^'_1, \\rho, \\sigma^'}} {\\anglebr{C_1;C_2, \\rho, \\sigma} \\to_c \\anglebr{C^'_1;C_2, \\rho, \\sigma^'}} \\] Se da \\(\\rho\\) e \\(\\sigma\\) un passo di \\(C_1\\) lo trasforma in \\(C^'_1\\) con la nuova configurazione della memoria \\(\\theta^'\\) Allora \\(C_1;C_2\\) pu\u00f2 essere riscritto come \\(C^'_1;C_2\\) con configurazione della memoria \\(\\sigma^'\\) \\[ (seq2) \\dfrac {\\anglebr{C_1, \\rho, \\sigma} \\to_c \\sigma^'} {\\anglebr{C_1;C_2, \\rho, \\sigma} \\to_c \\anglebr{C_2, \\rho, \\sigma^'}} \\] IF \u00b6 \\[ (if1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star true} {\\anglebr{if(E)\\{C_1\\}else\\{C_2\\}, \\rho, \\sigma} \\to_c \\anglebr{C_1, \\rho, \\sigma}} \\] \\[ (if2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star false} {\\anglebr{if(E)\\{C_1\\}else\\{C_2\\}, \\rho, \\sigma} \\to_c \\anglebr{C_2, \\rho, \\sigma}} \\] A seconda di come viene valutata l'espressione (true o false) si eseguono i rispettivi comandi ( \\(C_1\\) o \\(C_2\\) ) con la stessa memoria con cui si \u00e8 iniziata l'esecuzione dell'if. REP1 \u00b6 \\[ (rep1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star true} {\\anglebr{while(E)\\{C\\}, \\rho, \\sigma} \\to_c \\anglebr{C;while(E)\\{C\\}, \\rho, \\sigma}} \\] Se l'espressione viene valutata true, si esegue il corpo C del while e poi si torna ad eseguire nuovamente il while, per valutare se sia il caso di eseguire una nuova operazione REP2 \u00b6 \\[ (rep2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star false} {\\anglebr{while(E)\\{C\\}, \\rho, \\sigma} \\to \\sigma} \\] Se la guardia viene valutata false, non si deve eseguire il corpo C E si pu\u00f2 restituire la memoria in cui \u00e8 eseguito il while. B1 \u00b6 \\[ (b1) \\dfrac {\\anglebr{D, \\rho, \\sigma} \\to_d^\\star \\anglebr{\\rho', \\sigma'}} {\\anglebr{D;C, \\rho, \\sigma} \\to_c \\anglebr{C, \\rho[\\rho'], \\sigma[\\sigma']}} \\] Se la dichiarazione genere un nuovo ambiente e memoria Allora il comando C si esegue nell'ambiente e nella memoria correnti, estesi con quelli generati da D Semantica dinamica delle dichiarazioni \u00b6 CONST1 \u00b6 \\[ (const1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star V} {\\anglebr{const ~ Id:T=E, \\rho, \\sigma} \\to_d \\anglebr{[(Id,v)], \\sigma}} \\] Se da \\(\\rho\\) e \\(\\sigma\\) in un certo numero di passi (da qui la stellina), l'espressione E viene valutata ad un valore v La dichiarazione di costante associa nell'ambiente generato ( \\([(Id,v)]\\) ) l'identificatore Id con v, lasciando inalterata la memoria. VAR1 \u00b6 \\[ (var1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star v} {\\anglebr{var ~ Id:T=E, \\rho, \\sigma} \\to_d \\anglebr{[Id, newL], [(L,v)]}} \\] Se in un certo numero di passi, l'espressione viene valutata ad un valore v La dichiarazione ( var Id:T=E ) associa all'ambiente generato l'identificatore ad una nuova locazione newL (mai usata prima) ed aggiorna la memoria scrivendo il valore v alla locazione appena creata. DD1 \u00b6 \\[ (dd1) \\dfrac {\\anglebr{D_1, \\rho, \\sigma} \\to_d \\anglebr{D'_1, \\rho', \\sigma'}} {\\anglebr{D_1;D_2, \\rho, \\sigma} \\to_d \\anglebr{D'_1; D_2, \\rho', \\sigma'}} \\] Se, partendo da \\(\\rho\\) e \\(\\sigma\\) , la dichiarazione \\(D_1\\) conduce allo stato \\(\\anglebr{D'_1, \\rho, \\sigma}\\) Allora la dichiarazione sequenziale conduce a \\(D'_1\\) , con \\(\\rho'\\) e \\(\\sigma'\\) DD2 \u00b6 \\[ (dd2) \\dfrac {\\anglebr{D_2, \\rho[\\textcolor{cyan}{\\rho_1}], \\sigma} \\to_d \\anglebr{D'_2, \\rho[\\textcolor{cyan}{\\rho_1}]', \\sigma'}} {\\anglebr{\\textcolor{cyan}{\\rho_1};D_2, \\rho[\\rho_1], \\sigma} \\to_d \\anglebr{\\rho_1;D'_2, \\rho[\\textcolor{cyan}{\\rho_1}]', \\sigma' }} \\] Continuando dalla regola precedente, se da \\(\\rho\\) e \\(\\sigma\\) , \\(D_2\\) conduce a \\(D'_2\\) La dichiarazione pu\u00f2 effettuare lo stesso passo per \\(D_2\\) La sintassi del nostro linguaggio non permette di scrivere un ambiente nel codice (quello evidenziato in ciano). Facciamo questa forzatura per permettere al compilatore di funzione. L'utente non pu\u00f2 comunque inserire un ambiente nel codice sorgente, \u00e8 una forzatura adottabile solo dal compilatore. DD3 \u00b6 \\[ (dd3) \\anglebr{\\rho_1;\\rho_2, \\rho, \\sigma} \\to_d \\anglebr{\\rho_1[\\rho_2], \\sigma} \\] Anche questa formula riprende dalla precedente e ci permette di estendere i due ambienti derivati dalle due dichiarazioni in sequenza. Semantica dinamica delle funzioni \u00b6 Non trascritte Pagine 31,...,37,72,73,74 degli appunti","title":"Linguaggio L"},{"location":"ProAlgo/l/#il-linguaggio-l","text":"Il linguaggio L \u00e8 un linguaggio teorico e usato solo per scopi educativi. Questo lo tratter\u00f2 poi, nel frattempo allego la pagina di appunti: Linguaggio L","title":"Il linguaggio L"},{"location":"ProAlgo/l/#bnf","text":"","title":"BNF"},{"location":"ProAlgo/l/#semantica-statica","text":"","title":"Semantica statica"},{"location":"ProAlgo/l/#espressioni","text":"","title":"Espressioni"},{"location":"ProAlgo/l/#assiomi","text":"\\(\\varnothing \\vdash_e i: Int\\) Questo assioma ci indica che senza un ambiente, possiamo dire che un'espressione fatta da simbolo appartenente alla categoria sintattica degli interi, \u00e8 di tipo Int Ad esempio, 5 \u00e8 un intero, e non ci serve un'ambiente per dirlo \\(\\varnothing \\vdash_e d: Double\\) \\(\\varnothing \\vdash_e b: Bool\\) \\(\\varnothing \\vdash_e s: String\\)","title":"Assiomi"},{"location":"ProAlgo/l/#regole","text":"","title":"Regole"},{"location":"ProAlgo/l/#r1","text":"\\[ (R1) \\frac {(\\Delta (Id) = \\tau \\lor \\Delta (Id) = \\tau Loc)} {\\Delta \\vdash_e Id: \\tau} \\] Questa regola di inferenza si pu\u00f2 leggere come: Se, dato un ambiente, possiamo trovare l'identificatore nell'ambiente e questo identificatore ha tipo \\(\\tau\\) o \\(\\tau Loc\\) , allora l'identificatore ha tipo \\(\\tau\\)","title":"R1"},{"location":"ProAlgo/l/#r2","text":"\\[ (R2) \\frac {\\Delta \\vdash_e E_1 : \\tau_1, \\operatorname{uop}: \\tau_1 \\to \\tau} {\\Delta \\vdash_e \\operatorname{uop} E_1: \\tau} \\] Se, partendo dall'ambiente \\(\\Delta\\) , l'espressione \u00e8 di tipo \\(\\tau_1\\) e l'operatore unario prende un tipo \\(\\tau_1\\) e lo trasforma in \\(\\tau\\) , l'espressione uop E1 \u00e8 di tipo \\(\\tau\\) . (Notare che uop \u00e8 la categoria sintattica degli operatori unari, come ad esempio ! , ovvero la negazione) Esempio Possiamo gi\u00e0 fare un'esempio con queste due regole appena viste: Prendendo un ambiente con una variabile x intera (quindi \\(\\Delta = [(x, Int)]\\) ) possiamo gi\u00e0 valutare -x : \\[ \\frac { \\frac {\\Delta(x) = Int} {\\Delta \\vdash_e x:Int}, -: Int \\to Int} {\\Delta \\vdash_e -x: Int} \\] In questo esempio, per valutare l'espressione -x (e quindi determinarne il tipo), dividiamo innanzitutto l'espressione (quindi valutando il tipo dell'espressione x ed assicurandosi che sia compatibile con l'operatore unario - ) Ci assicuriamo quindi che x sia presente nell'ambiente, e ne determiniamo che il tipo \u00e8 Int . Procediamo quindi assicurandoci che l'operatore unario - prenda in input un Int e restituisca un int, e cos\u00ec \u00e8. Possiamo dunque dire che l'espressione -x \u00e8 di tipo Int.","title":"R2"},{"location":"ProAlgo/l/#r3","text":"\\[ (R3) \\frac {\\Delta \\vdash_e E_1: \\tau_1, \\; \\Delta \\vdash_e E_2: \\tau_2, \\; \\operatorname{bop}: \\tau_1 \\times \\tau_2 \\to \\tau} {\\Delta \\vdash_e \\tau_1 \\ \\operatorname{bop} \\ \\tau_2:\\tau } \\] Questa regola \u00e8 molto simile alla precedente, con la differenza che stavolta valutiamo anche una seconda espressione \\(E_2\\) , essendo bop la categoria sintattica degli operatori binari, e ci assicuriamo quindi che i due tipi (delle due espressioni \\(E_1\\) ed \\(E_2\\) ) siano compatibili tra di loro.","title":"R3"},{"location":"ProAlgo/l/#r4","text":"\\[ (R4) \\frac {\\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_e (E): \\tau} \\] Questa regola ci permette di \"eliminare\" le parentesi che racchiudono un'espressione, permettendoci di valutare l'espressione.","title":"R4"},{"location":"ProAlgo/l/#comandi","text":"I comandi (che ricordiamo, si Eseguono ) non hanno tipi, in quanto i comandi non rappresentano un valore.","title":"Comandi"},{"location":"ProAlgo/l/#assiomi_1","text":"Tra i comandi troviamo un solo assioma: \\(\\varnothing \\vdash_c nil\\) Che ci dice che da un ambiente vuoto non c'\u00e8 nulla che possiamo concludere","title":"Assiomi"},{"location":"ProAlgo/l/#regole_1","text":"","title":"Regole"},{"location":"ProAlgo/l/#r5","text":"\\[ (R5) \\frac {\\Delta(Id) = \\tau Loc, \\; \\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_c Id=E} \\] Questa regola ci dice che, per assegnare un'espressione ad una variabile, devo assicurarmi che il tipo dell'espressione e quello della variabile sono concordi","title":"R5"},{"location":"ProAlgo/l/#r7","text":"\\[ (R7) \\frac {\\Delta \\vdash_e E: Bool, \\; \\Delta \\vdash_c C_1, \\; \\Delta \\vdash_c C_2} {if\\ (E)\\{C_1\\}\\ else\\ \\{C_2\\}} \\] Questa regola pu\u00f2 essere un pelo pi\u00f9 complicata da decodificare; Partendo quindi dalle assunzioni (e tenendo presente che \u00e8 una clausola if): Se l'espressione E \u00e8 ben formata ed ha tipo Bool, il comando \\(C_1\\) \u00e8 ben formato ed il comando \\(C_2\\) \u00e8 ben formato, allora l'If \u00e8 ben formato (sempre in termini di tipi).","title":"R7"},{"location":"ProAlgo/l/#r8","text":"\\[ (R8) \\frac {\\Delta \\vdash_e E:Bool, \\; \\Delta \\vdash_c C} {\\Delta \\vdash_c while(E){C}} \\] Come nell'if, questa formula ci permette di dire che il comando while \u00e8 ben formato se l'espressione E \u00e8 ben formata ed ha tipo Bool, e se il comando C (che \u00e8 il corpo del while) \u00e8 ben formato. Teniamo a mente che questo controllo non valuta se il while termina, questa \u00e8 semantica statica, quindi stiamo solo controllando i tipi.","title":"R8"},{"location":"ProAlgo/l/#r9","text":"\\[ (R9) \\frac {\\Delta \\vdash_d D: \\Delta', \\Delta[\\Delta'] \\vdash_c C} {\\Delta \\vdash_c D;C} \\] Anche questa regola pu\u00f2 essere un attimo pi\u00f9 complicata da leggere, quindi anche in questo caso partiamo dalle premesse, tenendo a mente che stiamo valutando un comando (che \u00e8 composto da una dichiarazione D ed un comando C): La prima premessa ci dice che se la dichiarazione \u00e8 ben formata, la dichiarazione restituisce un ambiente \\(\\Delta'\\) , ovvero un ambiente in cui troviamo solamente la dichiarazione appena fatta. In questo caso, procediamo quindi ad estendere l'ambiente \\(\\Delta\\) con \\(\\Delta'\\) , e con l'ambiente risultante (che non \u00e8 altro che una concatenazione di funzioni) procediamo con l'esecuzione del comando C. Se il comando C \u00e8 valido (e quindi ben formato), la dichiarazione D;C \u00e8 ben formata. L'estensione dell'ambiente possiamo vederla in questo modo: \\(\\Delta[\\Delta'](x) = \\begin{cases} \\Delta'(x) & \\text{ se } \\Delta'(x) \\text{ \u00e8 definito} \\\\ \\Delta(x) & \\text{ altrimenti} \\end{cases}\\) Possiamo quindi vedere dalla formula che l'estensione NON sovrascrive l'ambiente, bens\u00ec oscura (ove necessario) degli identificatori Esempio se definiamo in \\(\\Delta\\) un identificatore X e poi lo ridefiniamo in \\(\\Delta'\\) , allora quando andremo a \"risolvere\" l'identificatore X nell'ambiente \\(\\Delta[\\Delta']\\) , risolveremo X per l'ambiente \\(\\Delta'\\) , che \u00e8 il pi\u00f9 \"recente\", oscurando di fatto l'identificatore nell'ambiente \\(\\Delta\\) ) Questo ci fa inoltre capire che nel linguaggio L \u00e8 possibile ridichiarare le variabili. Quindi, ricapitolando, se da \\(\\Delta\\) \u00e8 possibile associare a D l'ambiente statico \\(\\Delta'\\) , E da \\(\\Delta\\) esteso con i legami di \\(\\Delta'\\) posso dimostrare che C \u00e8 ben formato, il comando D;C \u00e8 ben formato.","title":"R9"},{"location":"ProAlgo/l/#dichiarazioni","text":"Una dichiarazione \u00e8 ben formata se a partire dall'ambiente statico \\(\\Delta\\) \u00e8 possibile associare un ambiente statico che contiene i legami per i nomi definiti in D. Notare che il \"risultato\" delle dichiarazioni \u00e8 espresso dopo i due punti :","title":"Dichiarazioni"},{"location":"ProAlgo/l/#assiomi_2","text":"\\(\\varnothing \\vdash_d nil: \\varnothing\\)","title":"Assiomi"},{"location":"ProAlgo/l/#regole_2","text":"","title":"Regole"},{"location":"ProAlgo/l/#r10","text":"\\[ (R10) \\frac {\\Delta \\vdash_e E:\\tau, \\; T == \\tau} {\\Delta \\vdash_d const \\ Id:T = E: [(Id, \\tau)]} \\] In questa prima dichiarazione di costante, possiamo vedere come il controllo sia basato sull'assicurarsi che il tipo dell'identificatore (o variabile , in questo caso) sia lo stesso del tipo dell'espressione. Quindi quando viene dichiara una costante, \u00e8 possibile dire che \u00e8 ben formata quando l'espressione \u00e8 ben formata ed il tipo di \\(\\tau\\) \u00e8 di tipo T e viene prodotto l'ambiente \\(\\Delta'\\) , rappresentato da \\([(Id, \\tau)]\\)","title":"R10"},{"location":"ProAlgo/l/#r11","text":"\\[ (R11) \\frac {\\Delta \\vdash_e E: \\tau, \\ T == \\tau} {\\Delta \\vdash_d var Id:T = E: [(Id, \\tau Loc)]} \\] Possiamo vedere che per la variabile vale lo stesso discorso della costante appena vista, con l'unica differenza che una variabile ha tipo \\(\\tau Loc\\) , dove Loc identifica che il tipo \u00e8 presente in una certa locazione di memoria, in quanto \u00e8 una variabile e non una costante","title":"R11"},{"location":"ProAlgo/l/#r12","text":"\\[ (R12) \\frac {\\Delta \\vdash_d D_1: \\Delta', \\; \\Delta[\\Delta'] \\vdash_d D_2: \\Delta''} {\\Delta \\vdash_d D_1;D_2: \\Delta'[\\Delta'']} \\] Quest'ultima regola ci permette di validare due dichiarazioni consecutive. La regola si pu\u00f2 leggere in questo modo: Se da \\(\\Delta\\) , \\(D_1\\) \u00e8 in grado di generare l'ambiente statico \\(\\Delta'\\) e da \\(\\Delta\\) esteso con \\(\\Delta'\\) , \\(D_2\\) genera l'ambiente \\(\\Delta''\\) , Allora da \\(\\Delta\\) , l'espressione genera l'ambiente statico \\(\\Delta'\\) esteso con \\(\\Delta''\\) e la dichiarazione \u00e8 ben formata Esempio di Semantica statica Possiamo vedere qui di seguito l'applicazione delle regole sopra definite, partendo dalle due dichiarazioni var x:Int = 3; var y:Int = x \\[ (R12) \\frac {(R5) \\frac {\\varnothing \\vdash_e 3:Int, Int == IntLoc} {\\varnothing \\vdash_d var\\ x:Int = 3: \\Delta'} (R5) \\frac {(R1) \\frac {\\varnothing[\\Delta'](x) = IntLoc} {\\varnothing[\\Delta'] \\vdash_e x:Int}, \\varnothing [\\Delta'] \\vdash_d y:Int = x: \\Delta'' } {\\varnothing[\\Delta'] \\vdash_d var\\ y:Int=x: \\Delta''} } {\\varnothing \\vdash_d var\\ x:Int=3;var\\ y:Int=x;} \\] Avremo quindi che \\(\\Delta'=[(x, IntLoc)]\\) e \\(\\Delta''=[(y, IntLoc)]\\) In questo esempio abbiamo applicato la regola R12 per dividere le due dichiarazioni. Separatamente poi, per la prima dichiarazione abbiamo applicato la R5, (seguita dal primo assioma che abbiamo visto, che ci dice che 3 \u00e8 un Intero) Per la seconda dichiarazione, abbiamo applicato la regola R5 come prima, con la differenza che stavolta l'espressione non era un numero, ma un'identificatore. Abbiamo quindi risolto l'identificatore contenuto nell'espressione (x) grazie all'ambiente \\(\\Delta\\) . Una volta verificato che espressione e variabile erano dello stesso tipo, \u00e8 possibile dire che il comando \u00e8 corretto.","title":"R12"},{"location":"ProAlgo/l/#semantica-statica-delle-funzioni","text":"","title":"Semantica statica delle funzioni"},{"location":"ProAlgo/l/#fs1","text":"\\[ (FS1) \\dfrac {\\Delta \\vdash_e E:\\tau} {\\Delta \\vdash_c \\text{return } E} \\] Se da \\(\\Delta\\) \u00e8 possibile associare il tipo \\(\\tau\\) all'espressione E, il return ha tipo E.","title":"FS1"},{"location":"ProAlgo/l/#fs2","text":"\\[ (FS2) \\dfrac {from: \\Delta_0, \\Delta[\\Delta_0] \\vdash_c C; \\text{return }E, \\Delta[\\Delta'] \\vdash_e E:\\tau} {\\Delta \\vdash_d \\text{func } Id(form) \\to \\tau \\{C;\\text{return }E\\}: \\Tau(Id,\\tau(form) \\to \\tau)} \\] Dove la funzione \\(\\Tau\\) \u00e8 definita cos\u00ec: \\(\\Tau(form) = \\begin{cases} \\Tau(nil) & = nil \\\\ \\Tau(const ~ Id:\\tau, form') & = \\tau, \\Tau(form') \\\\ \\Tau(var ~ Id: \\tau, form') & = \\tau, \\Tau(form') \\end{cases}\\) Quindi: \\(\\Tau(form) = \\Tau(var ~ id:\\tau = E; form') = \\tau, \\Tau(form')\\) form \u00e8 una lista di formali (da vedere come \\([H,T]\\) , testa (H) e coda (T) della lista) Questa formula ci permette di \"srotolare\" la lista, valutando il tipo di ogni parametro (grazie alla funzione \\(\\Tau\\) ) in maniera ricorsiva. Notare che nella definizione di \\(\\Tau\\) , il tipo nil \u00e8 usato solo internamente, non fa parte del linguaggio (non esiste un tipo nil). Questa regola si compone quindi in 3 parti: Srotolando i formali, questi formano un ambiente \\(\\Delta'\\) Con \\(\\Delta'\\) , controlliamo se il corpo della funzione (ed il return) sono ben formati Se, estendendo l'ambiente \\(\\Delta\\) con \\(\\Delta'\\) l'espressione di return \u00e8 ben formata e di tipo \\(\\tau\\) Allora la dichiarazione di funzione \u00e8 ben formata, e nell'ambiente si aggiunge la coppia Nome funzione , lista dei formali e tipo di ritorno della funzione ( \\(\\Tau(form) \\to \\tau\\) )","title":"FS2"},{"location":"ProAlgo/l/#fs3","text":"(FS3) \\(nil: \\varnothing\\) , \\(\\dfrac {form: \\Delta_0, Id \\notin \\Delta_0}{const ~ Id:\\tau, form: \\Delta_0[(Id, \\tau)]}\\) , \\(\\quad \\dfrac {form: \\Delta_0, Id \\notin \\Delta_0}{var ~ Id:\\tau, form: \\Delta_0[(Id, \\tau Loc)]}\\) Questa regola serve per assegnare i tipi ai signoli parametri formali che vengono valutati dalla regola FS2. In questo caso \u00e8 necessario controllare che il nome dell'identificatore non sia gi\u00e0 usato nella lista dei formali (altrimenti sarebbe alquanto ambiguo l'uso dell'identificatore nel corpo della funzione)","title":"FS3"},{"location":"ProAlgo/l/#fs4","text":"\\[ (FS4) \\dfrac {\\Delta \\vdash_{ae} ae:aet, \\Delta(Id) = aet \\to \\tau} {\\Delta \\vdash_e Id(ae): \\tau} \\] \\(\\begin{cases} \\Delta \\vdash_{ae} nil \\\\ \\dfrac{\\Delta \\vdash_e E:\\tau, \\Delta \\vdash_{ae}:aet}{\\Delta \\vdash_{ae}E, ae:\\tau, aet} \\end{cases}\\) Se la lista degli attuali ae corrisponde ad una lista di tipi (aet) e nell'ambiente ho una lista di tipi (uguale ad aet) che restituiscono tau, allora l'espressione \u00e8 ben formata","title":"FS4"},{"location":"ProAlgo/l/#semantica-statica-delle-funzioni-ricorsive","text":"","title":"Semantica statica delle funzioni ricorsive"},{"location":"ProAlgo/l/#rs1","text":"\\[ (RS1) \\dfrac {\\Delta[\\Delta'_{|I_0}]\\vdash D:\\Delta'} {\\Delta \\vdash_{rec} D:\\Delta'}, I_0 = FI(D) \\cap BI(D) \\] Con \\(\\Delta'=[(fact,Int \\to Int)] = \\Delta_{|I_0}'\\) Estendendo \\(\\Delta\\) con l'intersezione di intersezione tra identificatori liberi e legati ($I_0) si pu\u00f2 dire che la dichiarazione \u00e8 ben formata. In questo caso, il nome della funzione \u00e8 legato, mentre un'eventuale riferimento all'interno del corpo della funzione sarebbe libero. La cosa si pu\u00f2 semplificare con questa regola: \\[ (RS1') \\dfrac {\\vdash_d D:\\Delta} {\\vdash_d rec ~ D:\\Delta} \\] Questa regola (che richiama FS2') ci viene in contro se la funzione non ha dichiarazioni ricorsive al suo interno \\[ (RS1'')\\dfrac {\\vdash_d D:\\Delta', \\Delta[\\Delta'_{|I_0}] \\vdash_d D} {\\Delta \\vdash_d rec ~ D}, I_0 = FI(D) \\cap BI(D) \\] In questo caso FI \u00e8 una funzione che individua gli identificatori liberi. \\(FI(func) = FI(C) - FI(form)\\) Che significa che gli identificatori liberi di uan funzione sono gli identificatori liberi del corpo meno gli identificatori liberi dei formali (ovvero nessuno, essendo tutti legati) Richiama RS1'","title":"RS1"},{"location":"ProAlgo/l/#rs2","text":"\\[ (RS2'') \\dfrac {FS' | FS2''}{\\Delta \\vdash_d rec ~ D } \\]","title":"RS2"},{"location":"ProAlgo/l/#fs2_1","text":"\\[ (FS2) \\dfrac {form:\\Delta_0,\\Delta[\\Delta_0]\\vdash_c var ~ res:\\tau=E;C;return ~ res, \\Delta[\\Delta_0][(res,\\tau Loc)] \\vdash_e E:\\tau} {\\Delta \\vdash_d func ~ Id(form) \\to \\tau \\{ var ~ res:\\tau;C;return ~ res\\}: [(Id, \\Tau(form) \\to \\tau )]} \\] Per semplificare le funzioni, assumiamo che la funzione inizi con una dichiarazione di variabile che sar\u00e0 il valore che verr\u00e0 restituito","title":"FS2(?)"},{"location":"ProAlgo/l/#semantica-dinamica","text":"In L un identificatore contiene lettere, cifre e _ . Inoltre non inizia con una cifra.","title":"Semantica dinamica"},{"location":"ProAlgo/l/#semantica-dinamica-delle-espressioni","text":"Le regole che seguono ci permettono di definire un modello di valutazione delle espressioni","title":"Semantica dinamica delle espressioni"},{"location":"ProAlgo/l/#id1","text":"\\[ (Id_1) \\dfrac {\\rho(Id)=v \\lor (\\rho(Id)=L \\in Loc \\land \\sigma(L)=V)} {\\anglebr{Id, \\rho, \\sigma} \\to_e V} \\] Partiamo quindi dal controllare le premesse: se da \\(\\rho\\) posso associare ad Id un valore, o se da \\(\\rho\\) posso associare ad Id una locazione L e alla locazione L \u00e8 memorizzato un valore V Allora da \\(\\rho\\) e \\(\\sigma\\) , Id viene valutato v in un passo di valutazione","title":"ID1"},{"location":"ProAlgo/l/#uop1","text":"$$ (uop1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e \\anglebr{E', \\rho, \\sigma}} {\\anglebr{uop ~ E, \\rho, \\sigma} \\to_e \\anglebr{uop ~ E', \\rho, \\sigma}} $$\\ Se in un passo di valuazione, a partire da \\(\\rho\\) e \\(\\sigma\\) , E si trasforma in E', da \\(\\rho\\) e \\(\\sigma\\) uop E si trasforma in uop E' in un passo di valutazione.","title":"UOP1"},{"location":"ProAlgo/l/#uop2","text":"\\[ (uop2) \\anglebr{uop ~ v, \\rho, \\sigma} \\to_e v'= uop ~ v \\] Dopo aver valutato ripetutamente v mediante uop1, si raggiunge \\(uop ~ v\\) (ovvero il membro a destra della formula) e si pu\u00f2 concludere la valutazione.","title":"UOP2"},{"location":"ProAlgo/l/#bop","text":"\\[ (bop1) \\dfrac {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E^'_1 ~ bop ~ E_2, \\rho, \\sigma}} {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E^'_1 ~ bop ~ E_2, \\rho, \\sigma}} \\] \\[ (bop2) \\dfrac {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E_1 ~ bop ~ E_2^', \\rho, \\sigma}} {\\anglebr{E_1 ~ bop ~ E_2, \\rho, \\sigma} \\to_e \\anglebr{E_1 ~ bop ~ E_2^', \\rho, \\sigma}} \\] \\[ (bop3) \\anglebr{v_1 ~ bop ~ v_2, \\rho, \\sigma} \\to_e v=v_1 ~ bop ~ v_2 \\] Dopo aver valutato correttamente entrambi i membri delle espressioni (con rispettivamente BOP1 e BOP2), si raggiunge la configurazione \\(v_1 ~ bop ~ v_2\\) , che si pu\u00f2 valutare a v","title":"BOP"},{"location":"ProAlgo/l/#semantica-dinamica-dei-comandi","text":"","title":"Semantica dinamica dei comandi"},{"location":"ProAlgo/l/#id2","text":"\\[ (id2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star v} {\\anglebr{Id = E, \\rho, \\sigma}\\to_c \\anglebr{Id=v, \\rho, \\sigma}} \\] Se, partendo da \\(\\rho\\) e \\(\\sigma\\) , l'espressione E (dopo un certo numero di passi) viene valutata ad un valore V L'assegnamento pu\u00f2 essere riscritto come Id=v (senza toccare \\(\\rho\\) e \\(\\sigma\\) , dato che la valutazione non li modifica).","title":"ID2"},{"location":"ProAlgo/l/#id3","text":"\\[ (id3) \\anglebr{Id=v, \\rho, \\sigma} \\to_e \\sigma[\\rho(Id)=v] \\] L'esecuzione dell'assegnamento lascia inalterato l'ambiente, modificando solo la locazione di memoria \\(\\rho(Id)\\) con v","title":"ID3"},{"location":"ProAlgo/l/#seq","text":"\\[ (seq1) \\dfrac {\\anglebr{C_1, \\rho, \\sigma} \\to_c \\anglebr{C^'_1, \\rho, \\sigma^'}} {\\anglebr{C_1;C_2, \\rho, \\sigma} \\to_c \\anglebr{C^'_1;C_2, \\rho, \\sigma^'}} \\] Se da \\(\\rho\\) e \\(\\sigma\\) un passo di \\(C_1\\) lo trasforma in \\(C^'_1\\) con la nuova configurazione della memoria \\(\\theta^'\\) Allora \\(C_1;C_2\\) pu\u00f2 essere riscritto come \\(C^'_1;C_2\\) con configurazione della memoria \\(\\sigma^'\\) \\[ (seq2) \\dfrac {\\anglebr{C_1, \\rho, \\sigma} \\to_c \\sigma^'} {\\anglebr{C_1;C_2, \\rho, \\sigma} \\to_c \\anglebr{C_2, \\rho, \\sigma^'}} \\]","title":"SEQ"},{"location":"ProAlgo/l/#if","text":"\\[ (if1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star true} {\\anglebr{if(E)\\{C_1\\}else\\{C_2\\}, \\rho, \\sigma} \\to_c \\anglebr{C_1, \\rho, \\sigma}} \\] \\[ (if2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star false} {\\anglebr{if(E)\\{C_1\\}else\\{C_2\\}, \\rho, \\sigma} \\to_c \\anglebr{C_2, \\rho, \\sigma}} \\] A seconda di come viene valutata l'espressione (true o false) si eseguono i rispettivi comandi ( \\(C_1\\) o \\(C_2\\) ) con la stessa memoria con cui si \u00e8 iniziata l'esecuzione dell'if.","title":"IF"},{"location":"ProAlgo/l/#rep1","text":"\\[ (rep1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star true} {\\anglebr{while(E)\\{C\\}, \\rho, \\sigma} \\to_c \\anglebr{C;while(E)\\{C\\}, \\rho, \\sigma}} \\] Se l'espressione viene valutata true, si esegue il corpo C del while e poi si torna ad eseguire nuovamente il while, per valutare se sia il caso di eseguire una nuova operazione","title":"REP1"},{"location":"ProAlgo/l/#rep2","text":"\\[ (rep2) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star false} {\\anglebr{while(E)\\{C\\}, \\rho, \\sigma} \\to \\sigma} \\] Se la guardia viene valutata false, non si deve eseguire il corpo C E si pu\u00f2 restituire la memoria in cui \u00e8 eseguito il while.","title":"REP2"},{"location":"ProAlgo/l/#b1","text":"\\[ (b1) \\dfrac {\\anglebr{D, \\rho, \\sigma} \\to_d^\\star \\anglebr{\\rho', \\sigma'}} {\\anglebr{D;C, \\rho, \\sigma} \\to_c \\anglebr{C, \\rho[\\rho'], \\sigma[\\sigma']}} \\] Se la dichiarazione genere un nuovo ambiente e memoria Allora il comando C si esegue nell'ambiente e nella memoria correnti, estesi con quelli generati da D","title":"B1"},{"location":"ProAlgo/l/#semantica-dinamica-delle-dichiarazioni","text":"","title":"Semantica dinamica delle dichiarazioni"},{"location":"ProAlgo/l/#const1","text":"\\[ (const1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star V} {\\anglebr{const ~ Id:T=E, \\rho, \\sigma} \\to_d \\anglebr{[(Id,v)], \\sigma}} \\] Se da \\(\\rho\\) e \\(\\sigma\\) in un certo numero di passi (da qui la stellina), l'espressione E viene valutata ad un valore v La dichiarazione di costante associa nell'ambiente generato ( \\([(Id,v)]\\) ) l'identificatore Id con v, lasciando inalterata la memoria.","title":"CONST1"},{"location":"ProAlgo/l/#var1","text":"\\[ (var1) \\dfrac {\\anglebr{E, \\rho, \\sigma} \\to_e^\\star v} {\\anglebr{var ~ Id:T=E, \\rho, \\sigma} \\to_d \\anglebr{[Id, newL], [(L,v)]}} \\] Se in un certo numero di passi, l'espressione viene valutata ad un valore v La dichiarazione ( var Id:T=E ) associa all'ambiente generato l'identificatore ad una nuova locazione newL (mai usata prima) ed aggiorna la memoria scrivendo il valore v alla locazione appena creata.","title":"VAR1"},{"location":"ProAlgo/l/#dd1","text":"\\[ (dd1) \\dfrac {\\anglebr{D_1, \\rho, \\sigma} \\to_d \\anglebr{D'_1, \\rho', \\sigma'}} {\\anglebr{D_1;D_2, \\rho, \\sigma} \\to_d \\anglebr{D'_1; D_2, \\rho', \\sigma'}} \\] Se, partendo da \\(\\rho\\) e \\(\\sigma\\) , la dichiarazione \\(D_1\\) conduce allo stato \\(\\anglebr{D'_1, \\rho, \\sigma}\\) Allora la dichiarazione sequenziale conduce a \\(D'_1\\) , con \\(\\rho'\\) e \\(\\sigma'\\)","title":"DD1"},{"location":"ProAlgo/l/#dd2","text":"\\[ (dd2) \\dfrac {\\anglebr{D_2, \\rho[\\textcolor{cyan}{\\rho_1}], \\sigma} \\to_d \\anglebr{D'_2, \\rho[\\textcolor{cyan}{\\rho_1}]', \\sigma'}} {\\anglebr{\\textcolor{cyan}{\\rho_1};D_2, \\rho[\\rho_1], \\sigma} \\to_d \\anglebr{\\rho_1;D'_2, \\rho[\\textcolor{cyan}{\\rho_1}]', \\sigma' }} \\] Continuando dalla regola precedente, se da \\(\\rho\\) e \\(\\sigma\\) , \\(D_2\\) conduce a \\(D'_2\\) La dichiarazione pu\u00f2 effettuare lo stesso passo per \\(D_2\\) La sintassi del nostro linguaggio non permette di scrivere un ambiente nel codice (quello evidenziato in ciano). Facciamo questa forzatura per permettere al compilatore di funzione. L'utente non pu\u00f2 comunque inserire un ambiente nel codice sorgente, \u00e8 una forzatura adottabile solo dal compilatore.","title":"DD2"},{"location":"ProAlgo/l/#dd3","text":"\\[ (dd3) \\anglebr{\\rho_1;\\rho_2, \\rho, \\sigma} \\to_d \\anglebr{\\rho_1[\\rho_2], \\sigma} \\] Anche questa formula riprende dalla precedente e ci permette di estendere i due ambienti derivati dalle due dichiarazioni in sequenza.","title":"DD3"},{"location":"ProAlgo/l/#semantica-dinamica-delle-funzioni","text":"Non trascritte Pagine 31,...,37,72,73,74 degli appunti","title":"Semantica dinamica delle funzioni"},{"location":"ProAlgo/pnp/","text":"Problemi computazionali \u00b6 Come abbiamo visto, i problemi si basano su un modello computazionale (che in genere assimiliamo alla macchina di Turing), degli algoritmi e delle strutture dati. Tendenzialmente abbiamo 3 macrocategorie di problemi, in ordine di complessit\u00e0: Decisioni/soddisfacibilit\u00e0 (SAT/B-SAT) Un problema decisionale \u00e8 un problema il cui codominio \u00e8 un valore booleano ( \\(\\{true, false\\}\\) ) Ricerca Un problema di ricerca \u00e8 un problema il cui codominio \u00e8 un numero. Ci aspettiamo quindi che il programma restituisca un numero Ottimizzazione Un problema di ottimizzazione si occupa di trovare la migliore soluzione. Risolvere un problema di ottimizzazione \u00e8 almeno tanto difficile quanto risolvere un problema decisionale. Il problema di P=NP (dove NP \u00e8 Nondetermistic Polynomial-time) si basa sul fatto che nessuno ha provato che il limite inferiore di un problema NP \u00e8 maggiore dall'essere polinomiale. Possiamo trovare quindi diverse classi di problemi: Classe P (SoT): Appartengono alla classe dei problemi polinomiali tutti quei problemi il cui numero di passi elementari per giungere alla soluzione sono al pi\u00f9 (dati \\(c,n_0 > 0\\) ) \\(n^c \\forall n > n_0\\) . Sono quindi quei problemi risolvibili in un tempo polinomiale Classe NP I problemi nella classe NP (Nondetermistic Polynomial-time) sono problemi di decisione che sono verificabili in tempo polinomiale . Un esempio pu\u00f2 essere dato dal trovare i due numeri primi dato il prodotto tra i due: un'operazione estremamente difficile da effettuare ma banale nella verifica Classe NP-Hard Questa classe pu\u00f2 essere pensata in modo informale come \"tutti i problemi almeno difficili quanto i problemi pi\u00f9 difficili in NP\" Questo tipo di problema pu\u00f2 essere pensato come ad un insieme di sottoproblemi in cui se uno di questi sottoproblemi potesse essere calcolato in tempo costante , renderebbe l'algoritmo polinomiale. Classe NP-completi I problemi NP-complete sono i pi\u00f9 difficili problemi per i quali una soluzione pu\u00f2 essere verificata in fretta (in tempo polinomiale). Un problema \u00e8 NP-completo se \u00e8 NP e NP-Hard","title":"Problemi computazionali"},{"location":"ProAlgo/pnp/#problemi-computazionali","text":"Come abbiamo visto, i problemi si basano su un modello computazionale (che in genere assimiliamo alla macchina di Turing), degli algoritmi e delle strutture dati. Tendenzialmente abbiamo 3 macrocategorie di problemi, in ordine di complessit\u00e0: Decisioni/soddisfacibilit\u00e0 (SAT/B-SAT) Un problema decisionale \u00e8 un problema il cui codominio \u00e8 un valore booleano ( \\(\\{true, false\\}\\) ) Ricerca Un problema di ricerca \u00e8 un problema il cui codominio \u00e8 un numero. Ci aspettiamo quindi che il programma restituisca un numero Ottimizzazione Un problema di ottimizzazione si occupa di trovare la migliore soluzione. Risolvere un problema di ottimizzazione \u00e8 almeno tanto difficile quanto risolvere un problema decisionale. Il problema di P=NP (dove NP \u00e8 Nondetermistic Polynomial-time) si basa sul fatto che nessuno ha provato che il limite inferiore di un problema NP \u00e8 maggiore dall'essere polinomiale. Possiamo trovare quindi diverse classi di problemi: Classe P (SoT): Appartengono alla classe dei problemi polinomiali tutti quei problemi il cui numero di passi elementari per giungere alla soluzione sono al pi\u00f9 (dati \\(c,n_0 > 0\\) ) \\(n^c \\forall n > n_0\\) . Sono quindi quei problemi risolvibili in un tempo polinomiale Classe NP I problemi nella classe NP (Nondetermistic Polynomial-time) sono problemi di decisione che sono verificabili in tempo polinomiale . Un esempio pu\u00f2 essere dato dal trovare i due numeri primi dato il prodotto tra i due: un'operazione estremamente difficile da effettuare ma banale nella verifica Classe NP-Hard Questa classe pu\u00f2 essere pensata in modo informale come \"tutti i problemi almeno difficili quanto i problemi pi\u00f9 difficili in NP\" Questo tipo di problema pu\u00f2 essere pensato come ad un insieme di sottoproblemi in cui se uno di questi sottoproblemi potesse essere calcolato in tempo costante , renderebbe l'algoritmo polinomiale. Classe NP-completi I problemi NP-complete sono i pi\u00f9 difficili problemi per i quali una soluzione pu\u00f2 essere verificata in fretta (in tempo polinomiale). Un problema \u00e8 NP-completo se \u00e8 NP e NP-Hard","title":"Problemi computazionali"},{"location":"ProAlgo/programmazioneDinamica/","text":"Programmazione dinamica \u00b6 La programmazione dinamica \u00e8 una tecnica algoritmica che ci permette di operare su dati non disgiunti (a differenza di quello che pu\u00f2 essere la ricorsione). Questo significa che quello che viene fatto \u00e8 ottimizzare ogni sottoproblema al pi\u00f9 una volta (mentre in un algoritmo ricorsivo, \u00e8 possibile trovarsi a risolvere pi\u00f9 volte lo stesso problema) Un problema risolvibile in programmazione dinamica \u00e8 simile ad un algoritmo di ricorsione, in cui per\u00f2 si presentano pochi sottoproblemi diversi che si presentano pi\u00f9 volte. \u00c8 quindi un problema di ottimizzazione. La soluzione ai problemi che si ripresentano pi\u00f9 volte viene quindi salvata per quando servir\u00e0 nuovamente il risultato. Questo ci permettere di risolvere ogni sottoproblema una ed una sola volta. Si pu\u00f2 pensare alla ricorsione come un approccio top-down, mentre alla dinamica come un approccio bottom-up. I problemi risolvibili attraverso la programmazione dinamica: Devono avere sotto struttura ottima La soluzione ottima del problema deriva dalle soluzioni ottime dei sottoproblemi I problemi devono essere sovrapponibili (si ripetono) Il problema deve presentare pochi sottoproblemi ripetuti pi\u00f9 volte. La soluzione deve essere polinomiale nella dimensione dell'input La struttura di una soluzione scritta in programmazione dinamica \u00e8 divisa in 4 fasi: Definizione dei sotto problemi e dimensionamento della tabelle Soluzione dei sottoproblemi e memorizzazione della soluzione nella tabella Definizione delle regole di riempimento della tabella (in che modo mettiamo i valori nella tabella) Regole di ricorsione per ottenere la soluzione di un sottoproblema a partire dalle soluzioni dei sottoproblemi gi\u00e0 risolti Restituzione del risultato relativo al problema originale Esempi \u00b6 Longest Common Subsequence \u00b6 Date 2 stringhe di caratteri, trovare la sotto sequenza comune pi\u00f9 lunga Edit distance \u00b6 \u00c8 un algoritmo che minimizza la 'distanza' (in termini di operazioni) per trasformare una stringa in un'altra. Zaino \u00b6 \u00c8 un esempio di un algoritmo che trova l'ottimo globale attraverso una sottostruttura ottima La strategia \u00e8 greedy/euristica: Ad ogni passo, si effettua una scelta localmente ottima per trovare l'ottimo globale. Algoritmo euristico L'euristica \u00e8 una tecnica che non garantisce che la strategia sia ottima e quindi conduca alla miglior soluzione auspicabile. Il problema dello zaino \u00e8 pseudo-polinomiale Algoritmo pseudo-polinomiale Un algoritmo pseudopolinomiale \u00e8 un algoritmo il cui costo \u00e8 polinomiale nel numero delle operazioni, ma esponenziale nello spazio (nel caso dello zaino, \u00e8 esponenziale nel numero di bit memorizzati)","title":"Programmazione dinamica"},{"location":"ProAlgo/programmazioneDinamica/#programmazione-dinamica","text":"La programmazione dinamica \u00e8 una tecnica algoritmica che ci permette di operare su dati non disgiunti (a differenza di quello che pu\u00f2 essere la ricorsione). Questo significa che quello che viene fatto \u00e8 ottimizzare ogni sottoproblema al pi\u00f9 una volta (mentre in un algoritmo ricorsivo, \u00e8 possibile trovarsi a risolvere pi\u00f9 volte lo stesso problema) Un problema risolvibile in programmazione dinamica \u00e8 simile ad un algoritmo di ricorsione, in cui per\u00f2 si presentano pochi sottoproblemi diversi che si presentano pi\u00f9 volte. \u00c8 quindi un problema di ottimizzazione. La soluzione ai problemi che si ripresentano pi\u00f9 volte viene quindi salvata per quando servir\u00e0 nuovamente il risultato. Questo ci permettere di risolvere ogni sottoproblema una ed una sola volta. Si pu\u00f2 pensare alla ricorsione come un approccio top-down, mentre alla dinamica come un approccio bottom-up. I problemi risolvibili attraverso la programmazione dinamica: Devono avere sotto struttura ottima La soluzione ottima del problema deriva dalle soluzioni ottime dei sottoproblemi I problemi devono essere sovrapponibili (si ripetono) Il problema deve presentare pochi sottoproblemi ripetuti pi\u00f9 volte. La soluzione deve essere polinomiale nella dimensione dell'input La struttura di una soluzione scritta in programmazione dinamica \u00e8 divisa in 4 fasi: Definizione dei sotto problemi e dimensionamento della tabelle Soluzione dei sottoproblemi e memorizzazione della soluzione nella tabella Definizione delle regole di riempimento della tabella (in che modo mettiamo i valori nella tabella) Regole di ricorsione per ottenere la soluzione di un sottoproblema a partire dalle soluzioni dei sottoproblemi gi\u00e0 risolti Restituzione del risultato relativo al problema originale","title":"Programmazione dinamica"},{"location":"ProAlgo/programmazioneDinamica/#esempi","text":"","title":"Esempi"},{"location":"ProAlgo/programmazioneDinamica/#longest-common-subsequence","text":"Date 2 stringhe di caratteri, trovare la sotto sequenza comune pi\u00f9 lunga","title":"Longest Common Subsequence"},{"location":"ProAlgo/programmazioneDinamica/#edit-distance","text":"\u00c8 un algoritmo che minimizza la 'distanza' (in termini di operazioni) per trasformare una stringa in un'altra.","title":"Edit distance"},{"location":"ProAlgo/programmazioneDinamica/#zaino","text":"\u00c8 un esempio di un algoritmo che trova l'ottimo globale attraverso una sottostruttura ottima La strategia \u00e8 greedy/euristica: Ad ogni passo, si effettua una scelta localmente ottima per trovare l'ottimo globale. Algoritmo euristico L'euristica \u00e8 una tecnica che non garantisce che la strategia sia ottima e quindi conduca alla miglior soluzione auspicabile. Il problema dello zaino \u00e8 pseudo-polinomiale Algoritmo pseudo-polinomiale Un algoritmo pseudopolinomiale \u00e8 un algoritmo il cui costo \u00e8 polinomiale nel numero delle operazioni, ma esponenziale nello spazio (nel caso dello zaino, \u00e8 esponenziale nel numero di bit memorizzati)","title":"Zaino"},{"location":"ProAlgo/semantica/","text":"Semantica \u00b6 La semantica \u00e8 lo studio del significato dei programmi ed \u00e8 formalizzato nei termini delle azioni che il modello deve compiere. La semantica \u00e8 una funzione che permette di associare (attraverso un' interpretazione semantica ) ad un programma (dato il suo dominio sintattico) un corrispondente significato, dato dall'interpretazione (dominio semantico). Ne esistono di due tipi: - Denotazionale Simile ai linguaggi funzionali, descrive i programmi sulla base dei passi che la macchina astratta deve compiere. - Operazionale Permette di descrivere i programmi sulla base di istruzioni atomiche che modificano lo stato della macchina astratta (inteso come codice sorgente, dati dell'elaborazione e memoria): se durante la processazione del codice non \u00e8 possibile trovare una regola che permetta il cambio di stato, c'\u00e8 un errore nel programma. Si divide in Statica (denotazionale) La semantica statica non coinvolge l'esecuzione e riguarda propriet\u00e0 che possono essere dedotte dalla rappresentazione del programma Nella pratica, effettua un controllo sui tipi e se questi vengono usati coerentemente nel resto del programma (associa ad ogni identificatore (variabile) un tipo) Dinamica (operazionale) La semantica dinamica si occupa di simulare l'esecuzione del programma: come agisce un'istruzione in memoria in una macchina astratta Si occupa quindi di mappare un'identificatore ed il suo valore su T: \\[ \\underbrace{\\text{ambiente statico } \\Delta}_{\\text{funzione}}: \\underbrace{id}_{identificatore} \\cup Val \\to \\underbrace{T}_{\\text{tipo }} \\cup T_{\\text{loc}} \\] Tipi di comandi \u00b6 Comando \u00b6 Un comando non ha effetti sull'ambiente (che a questo punto pu\u00f2 essere pensato come alla memoria) Un comando ben formato ha la forma \\(C: \\Delta \\vdash_C C\\) Espressione \u00b6 Un'espressione porta ad un valore, che ha quindi anche un tipo. Se un'espressione \u00e8 ben formata, posso determinarne il tipo. Un'espressione ben formata ha la forma \\(E: \\Delta \\vdash_e E : \\tau\\) (dove tau ( \\(\\tau\\) ) \u00e8 il tipo) (e si legge \"Un'espressione \u00e8 ben formata se partendo da un certo ambiente statico alla mia espressione posso associare un tipo tau) Una volta associata la semantica statica delle espressioni, diventa possibile associare un tipo ad ogni espressione corretta, operando per induzione sulla struttura della grammatica. Dichiarazione \u00b6 Una dichiarazione ha un'effetto sull'ambiente, in quanto quando si dichiara qualcosa, l'ambiente ( \\(\\Delta\\) ) cresce Ha la forma \\(D: \\Delta \\vdash_D D : \\Delta^I\\) Dove \\(\\Delta\\) \u00e8 l'ambiente, D \u00e8 la dichiarazione e \\(\\Delta^I\\) \u00e8 il nuovo ambiente, esteso dopo la dichiarazione Semantica Statica \u00b6 La semantica statica si occupa di verificare formalmente un programma dal punto di vista della sintassi e delle regole dei tipi utilizzati, considerando quindi le sue espressioni. Le regole della semantica statica sono codificate sotto forma di regole d'inferenza, in cui se una serie di premesse risulta essere soddisfatta, allora ci\u00f2 implica una conclusione . Un'espressione si dice ben formata quando, partendo da un certo ambiente statico, all'espressione posso associare un tipo \\(\\tau\\) (letto tao) Un'espressione \u00e8 inoltre composta da letterali (come costanti, identificatori, etc...), che a loro volta sono composti da operatori unari e binari (e simboli dell'alfabeto) Si basa su tre principi: Regole di inferenza (scritte come \\(\\frac{\\text{premesse}}{\\text{conclusione}}\\) ) Una regola di inferenza ci permette di dire che se \u00e8 vera la premessa, allora \u00e8 vera anche la conclusione: \\(\\frac{A_1,...,A_n}{B}\\) equivale a \\(A_1 \\land ... \\land A_n \\then B\\) Se ogni premessa \\(A_i\\) \u00e8 vera, allora B \u00e8 vera Assioma (regole di inferenza senza premessa, quindi sempre vere) \\(\\frac{\\varnothing}{B} \\equiv \\frac{}{B} \\equiv \\varnothing \\to \\varnothing \\So \\bar B\\) Dimostrazione Si effettua con un albero, in cui ogni componente \u00e8 una parte della regola da dimostrare: La radice \u00e8 l'asserzione da dimostrare Le foglie sono assiomi I nodi intermedi sono costruiti applicando le regole semantiche (regole di inferenza) Principio della composizionalit\u00e0 \u00b6 Una definizione semantica deve poter essere composizionale: il suo significato deve essere fornito in termini di significato base dei suoi componenti elementari (finiti). Componenti elementari Produzioni della grammatica associate a regole semantiche Composizione Composizione, che permette di arrivare alla sematica di tutte le espressioni possibili: Il significato di un'espressione \u00e8 una funzione del significato dei suoi componenti elementari Principio di oscuramento ed estensione \u00b6 Oscuramento in semantica ed estensione \\[ \\Delta \\underbrace{[\\Delta^I]}_{\\text{Esteso}} (x) = \\begin{cases} \\Delta^I(x) & \\text{ se } \\Delta^I(x) \u00e8 definito \\\\ \\Delta(x) & \\text{ altrimenti} \\end{cases} \\] Scoping \u00b6 Lo scope \u00e8 la porzione di un programma in cui l'identificatore pu\u00f2 essere referenziato. Un identificatore si dice legato se esiste una dichiarazione a cui si \"appoggia\". Non \u00e8 legato ( libero ) quando l'identificatore non \u00e8 presente nell'ambiente \\(\\Delta\\) . Un identificatore usato senza essere stato definito o al di fuori dello scope di dichiarazione si dice libero. Se esistono occorrenze di identificatori liberi, il programma non \u00e8 corretto staticamente. Quando un identificatore \u00e8 definito, si dice che \u00e8 un posizione di definizione e costituisce quindi un' occorrenza di legame per le altre occorrenze nello scope. Quando l'identificatore viene usato all'interno dello scope di definizione, si dice legato dalla sua occorrenza di legame corrispondente. Block scope \u00b6 Il block scope delimita il campo d'azione dello scope basandosi su blocchi di codice. Una valora \u00e8 visibile solo nella parte di blocco seguente a quella in cui \u00e8 stata definita (ed eventuali blocchi annidati a quello corrente e successivi alla dichiarazione). La vita di una variabile inizia quindi quando viene dichiarata, e termina quando il blocco di definizione termina. Information hiding \u00b6 Un identificatore definito in un blocco annidato interno, nasconde/oscura la visibilit\u00e0 dell'identificatore con lo stesso nome ma definito nel blocco pi\u00f9 esterno Scoping Statico \u00b6 Lo scoping statico ci permettere di vedere tutti gli identificatori a cui \u00e8 possibile accedere nell'ambiente in un dato momento. \u00c8 anche ci\u00f2 che ci permette di avere information hiding. Lo scoping statico permette inoltre di vedere la vita dell'identificatore a tempo di compilazione attraverso l'albero sintattico e permette di decidere se un identificatore \u00e8 legato e, nel caso, da quale occorrenza di legame dell'albero di sintassi \u00c8 utile aggiungere inoltre che lo scoping statico si riferisce alla catena statica (si sta parlando dello stack di esecuzione/stack frame, ed \u00e8 visibile come un array) dove rientrano i parametri formali A tempo di compilazione, le variabili libere del corpo vengono legate, costruendo delle chiusure. Chiusura Una chiusura \u00e8 un blocco che lega le variabili libere di una funzione, usando l'ambiente dinamico al momento della dichiarazione. ha un formato di tipo D;C Si creano quindi della lambda-astrazioni che registrano i parametri formali che verranno poi associati ad una chiamata di funzione. La dichiarazione della funzione genera nell'ambiente dinamico un legame tra l'identificatore della funzione e la sua \\(\\lambda -astrazione\\) Scoping Dinamico \u00b6 Non \u00e8 ricavabile a tempo di compilazione. Le variabili libere sono legate solo al momento di esecuzione. Questo significa che quando la funzione viene dichiarata, nella chiusura viene registrato solo il corpo della funzione. Non vengono legati i parametri. Principio del privilegio minimo \u00b6 Ogni versione del programma deve avere i privilegi necessari per accedere alle risorse ed identificatori minimi necessari per svolgere il sui compito Type checking \u00b6 Riceve un albero di sintassi le cui foglie sono le stringhe del linguaggio Funziona tra due insiemi, che associa significati e simboli Il dominio sintattico non \u00e8 finito Indicare i componenti elementari ( for , while , + , * ) Il significato di una qualunque frase viene fornito in componenti elementari Serve una caratterizzazione formale e finita del dominio semantico Semantica dinamica \u00b6 La semantica dinamica si occupa di determinare gli step del programma quando questo viene eseguito. Si tratta quindi di un procedimento che emula l'esecuzione. La semantica dinamica si basa su funzioni che specificano i passi elementari: Esecuzione dei comandi Valutazione delle espressioni Elaborazione delle dichiarazioni In genera la parte della semantica dinamica \u00e8 gestita dal Loader (che quindi si pu\u00f2 vedere come una funzione \\(Loader: nome \\to address\\) ) Come abbiamo detto precedentemente, un identificatore \u00e8 una sequenza di caratteri (una stringa). In L, un identificatore contiene lettere, cifre e _ . Inoltre non inizia con una cifra. Come con la semantica statica, abbiamo a che fare con un ambiente, che stavolta chiameremo \\(\\rho\\) . In aggiunta avremo anche a che fare con una memoria, che esprimeremo come \\(\\sigma\\) . \\(\\rho\\) Ambiente: una funzione che associa nomi mnemonici a locazioni di memoria. \\(\\sigma\\) Memoria: una funzione che associa locazioni a valori. Essendoci una memoria che viene modificata con il passare del tempo (e l'esecuzione del programma), ci sono delle transizioni di stato. Per esprimere questi avvenimenti, abbiamo due strumenti: Transizioni di stato \u00b6 Le transizione di stato sono rappresentati come blocchi ed includono molteplici regole di inferenza tra una transizione e l'altra, rendendo lo strumento di facile comprensione e visibilit\u00e0 sui processi, a scapito di una minore formalit\u00e0. Come si vede dalla foto, ci possono essere 3 tipi di frecce, ognuna delle quali rappresenta il tipo di passaggio fatto (esecuzione, valutazione o dichiarazione) La freccia rappresenta una funzione di interpretazione sematica. Nel caso si vogliano rappresentare pi\u00f9 transizioni e quindi l'applicazioni di molteplici regole (ad esempio valutazioni), si pu\u00f2 usare una freccia con una stellina: \\(\\to^*_e\\) \\(\\anglebr{E, \\rho, \\theta} \\to_e \\anglebr {E^{'}, \\rho, \\theta}, Eval(E,\\rho,\\theta) = v \\in Val \\Leftrightarrow \\anglebr {E, \\rho, \\theta} \\to^*_e v\\) Le transizioni di stato fanno parte di un sistema di transizioni, una quadrupla \\(\\anglebr{S,T,F,S_0}\\) : \\[ \\begin{cases} S & stati & = \\{ \\anglebr{E, \\rho, \\theta} \\cup V | v\\ in Val_E \\} \\\\ T & transizioni & \\subseteq S \\times S, T=\\{ (S_1, S_2)|S_1, S_2 \\in S \\land S_1 \\to S_2 \\} \\\\ F & \\text{stati finali} & \\subseteq S, F=Val_E \\\\ S_0 & \\text{stato iniziale} & \\in S \\text{(espressione da valutare)} \\end{cases} \\] \\(\\{ \\anglebr{E, \\rho, \\theta} \\cup V | V \\in Val_E, \\underbrace{\\to_e}_{\\text{regola di inferenza}}, \\underbrace{Val_E}_{\\text{valore finale}}, \\underbrace{(Expr)}_{\\text{espressione da valutare}} \\}\\) Regole di inferenza \u00b6 Le regole di inferenza sono molto simili a alle regole di inferenza di semantica statica, con l'aggiunta della memoria e l'ambiente invece che mappare su tipi, mappa su locazioni di memoria.","title":"Semantica"},{"location":"ProAlgo/semantica/#semantica","text":"La semantica \u00e8 lo studio del significato dei programmi ed \u00e8 formalizzato nei termini delle azioni che il modello deve compiere. La semantica \u00e8 una funzione che permette di associare (attraverso un' interpretazione semantica ) ad un programma (dato il suo dominio sintattico) un corrispondente significato, dato dall'interpretazione (dominio semantico). Ne esistono di due tipi: - Denotazionale Simile ai linguaggi funzionali, descrive i programmi sulla base dei passi che la macchina astratta deve compiere. - Operazionale Permette di descrivere i programmi sulla base di istruzioni atomiche che modificano lo stato della macchina astratta (inteso come codice sorgente, dati dell'elaborazione e memoria): se durante la processazione del codice non \u00e8 possibile trovare una regola che permetta il cambio di stato, c'\u00e8 un errore nel programma. Si divide in Statica (denotazionale) La semantica statica non coinvolge l'esecuzione e riguarda propriet\u00e0 che possono essere dedotte dalla rappresentazione del programma Nella pratica, effettua un controllo sui tipi e se questi vengono usati coerentemente nel resto del programma (associa ad ogni identificatore (variabile) un tipo) Dinamica (operazionale) La semantica dinamica si occupa di simulare l'esecuzione del programma: come agisce un'istruzione in memoria in una macchina astratta Si occupa quindi di mappare un'identificatore ed il suo valore su T: \\[ \\underbrace{\\text{ambiente statico } \\Delta}_{\\text{funzione}}: \\underbrace{id}_{identificatore} \\cup Val \\to \\underbrace{T}_{\\text{tipo }} \\cup T_{\\text{loc}} \\]","title":"Semantica"},{"location":"ProAlgo/semantica/#tipi-di-comandi","text":"","title":"Tipi di comandi"},{"location":"ProAlgo/semantica/#comando","text":"Un comando non ha effetti sull'ambiente (che a questo punto pu\u00f2 essere pensato come alla memoria) Un comando ben formato ha la forma \\(C: \\Delta \\vdash_C C\\)","title":"Comando"},{"location":"ProAlgo/semantica/#espressione","text":"Un'espressione porta ad un valore, che ha quindi anche un tipo. Se un'espressione \u00e8 ben formata, posso determinarne il tipo. Un'espressione ben formata ha la forma \\(E: \\Delta \\vdash_e E : \\tau\\) (dove tau ( \\(\\tau\\) ) \u00e8 il tipo) (e si legge \"Un'espressione \u00e8 ben formata se partendo da un certo ambiente statico alla mia espressione posso associare un tipo tau) Una volta associata la semantica statica delle espressioni, diventa possibile associare un tipo ad ogni espressione corretta, operando per induzione sulla struttura della grammatica.","title":"Espressione"},{"location":"ProAlgo/semantica/#dichiarazione","text":"Una dichiarazione ha un'effetto sull'ambiente, in quanto quando si dichiara qualcosa, l'ambiente ( \\(\\Delta\\) ) cresce Ha la forma \\(D: \\Delta \\vdash_D D : \\Delta^I\\) Dove \\(\\Delta\\) \u00e8 l'ambiente, D \u00e8 la dichiarazione e \\(\\Delta^I\\) \u00e8 il nuovo ambiente, esteso dopo la dichiarazione","title":"Dichiarazione"},{"location":"ProAlgo/semantica/#semantica-statica","text":"La semantica statica si occupa di verificare formalmente un programma dal punto di vista della sintassi e delle regole dei tipi utilizzati, considerando quindi le sue espressioni. Le regole della semantica statica sono codificate sotto forma di regole d'inferenza, in cui se una serie di premesse risulta essere soddisfatta, allora ci\u00f2 implica una conclusione . Un'espressione si dice ben formata quando, partendo da un certo ambiente statico, all'espressione posso associare un tipo \\(\\tau\\) (letto tao) Un'espressione \u00e8 inoltre composta da letterali (come costanti, identificatori, etc...), che a loro volta sono composti da operatori unari e binari (e simboli dell'alfabeto) Si basa su tre principi: Regole di inferenza (scritte come \\(\\frac{\\text{premesse}}{\\text{conclusione}}\\) ) Una regola di inferenza ci permette di dire che se \u00e8 vera la premessa, allora \u00e8 vera anche la conclusione: \\(\\frac{A_1,...,A_n}{B}\\) equivale a \\(A_1 \\land ... \\land A_n \\then B\\) Se ogni premessa \\(A_i\\) \u00e8 vera, allora B \u00e8 vera Assioma (regole di inferenza senza premessa, quindi sempre vere) \\(\\frac{\\varnothing}{B} \\equiv \\frac{}{B} \\equiv \\varnothing \\to \\varnothing \\So \\bar B\\) Dimostrazione Si effettua con un albero, in cui ogni componente \u00e8 una parte della regola da dimostrare: La radice \u00e8 l'asserzione da dimostrare Le foglie sono assiomi I nodi intermedi sono costruiti applicando le regole semantiche (regole di inferenza)","title":"Semantica Statica"},{"location":"ProAlgo/semantica/#principio-della-composizionalita","text":"Una definizione semantica deve poter essere composizionale: il suo significato deve essere fornito in termini di significato base dei suoi componenti elementari (finiti). Componenti elementari Produzioni della grammatica associate a regole semantiche Composizione Composizione, che permette di arrivare alla sematica di tutte le espressioni possibili: Il significato di un'espressione \u00e8 una funzione del significato dei suoi componenti elementari","title":"Principio della composizionalit\u00e0"},{"location":"ProAlgo/semantica/#principio-di-oscuramento-ed-estensione","text":"Oscuramento in semantica ed estensione \\[ \\Delta \\underbrace{[\\Delta^I]}_{\\text{Esteso}} (x) = \\begin{cases} \\Delta^I(x) & \\text{ se } \\Delta^I(x) \u00e8 definito \\\\ \\Delta(x) & \\text{ altrimenti} \\end{cases} \\]","title":"Principio di oscuramento ed estensione"},{"location":"ProAlgo/semantica/#scoping","text":"Lo scope \u00e8 la porzione di un programma in cui l'identificatore pu\u00f2 essere referenziato. Un identificatore si dice legato se esiste una dichiarazione a cui si \"appoggia\". Non \u00e8 legato ( libero ) quando l'identificatore non \u00e8 presente nell'ambiente \\(\\Delta\\) . Un identificatore usato senza essere stato definito o al di fuori dello scope di dichiarazione si dice libero. Se esistono occorrenze di identificatori liberi, il programma non \u00e8 corretto staticamente. Quando un identificatore \u00e8 definito, si dice che \u00e8 un posizione di definizione e costituisce quindi un' occorrenza di legame per le altre occorrenze nello scope. Quando l'identificatore viene usato all'interno dello scope di definizione, si dice legato dalla sua occorrenza di legame corrispondente.","title":"Scoping"},{"location":"ProAlgo/semantica/#block-scope","text":"Il block scope delimita il campo d'azione dello scope basandosi su blocchi di codice. Una valora \u00e8 visibile solo nella parte di blocco seguente a quella in cui \u00e8 stata definita (ed eventuali blocchi annidati a quello corrente e successivi alla dichiarazione). La vita di una variabile inizia quindi quando viene dichiarata, e termina quando il blocco di definizione termina.","title":"Block scope"},{"location":"ProAlgo/semantica/#information-hiding","text":"Un identificatore definito in un blocco annidato interno, nasconde/oscura la visibilit\u00e0 dell'identificatore con lo stesso nome ma definito nel blocco pi\u00f9 esterno","title":"Information hiding"},{"location":"ProAlgo/semantica/#scoping-statico","text":"Lo scoping statico ci permettere di vedere tutti gli identificatori a cui \u00e8 possibile accedere nell'ambiente in un dato momento. \u00c8 anche ci\u00f2 che ci permette di avere information hiding. Lo scoping statico permette inoltre di vedere la vita dell'identificatore a tempo di compilazione attraverso l'albero sintattico e permette di decidere se un identificatore \u00e8 legato e, nel caso, da quale occorrenza di legame dell'albero di sintassi \u00c8 utile aggiungere inoltre che lo scoping statico si riferisce alla catena statica (si sta parlando dello stack di esecuzione/stack frame, ed \u00e8 visibile come un array) dove rientrano i parametri formali A tempo di compilazione, le variabili libere del corpo vengono legate, costruendo delle chiusure. Chiusura Una chiusura \u00e8 un blocco che lega le variabili libere di una funzione, usando l'ambiente dinamico al momento della dichiarazione. ha un formato di tipo D;C Si creano quindi della lambda-astrazioni che registrano i parametri formali che verranno poi associati ad una chiamata di funzione. La dichiarazione della funzione genera nell'ambiente dinamico un legame tra l'identificatore della funzione e la sua \\(\\lambda -astrazione\\)","title":"Scoping Statico"},{"location":"ProAlgo/semantica/#scoping-dinamico","text":"Non \u00e8 ricavabile a tempo di compilazione. Le variabili libere sono legate solo al momento di esecuzione. Questo significa che quando la funzione viene dichiarata, nella chiusura viene registrato solo il corpo della funzione. Non vengono legati i parametri.","title":"Scoping Dinamico"},{"location":"ProAlgo/semantica/#principio-del-privilegio-minimo","text":"Ogni versione del programma deve avere i privilegi necessari per accedere alle risorse ed identificatori minimi necessari per svolgere il sui compito","title":"Principio del privilegio minimo"},{"location":"ProAlgo/semantica/#type-checking","text":"Riceve un albero di sintassi le cui foglie sono le stringhe del linguaggio Funziona tra due insiemi, che associa significati e simboli Il dominio sintattico non \u00e8 finito Indicare i componenti elementari ( for , while , + , * ) Il significato di una qualunque frase viene fornito in componenti elementari Serve una caratterizzazione formale e finita del dominio semantico","title":"Type checking"},{"location":"ProAlgo/semantica/#semantica-dinamica","text":"La semantica dinamica si occupa di determinare gli step del programma quando questo viene eseguito. Si tratta quindi di un procedimento che emula l'esecuzione. La semantica dinamica si basa su funzioni che specificano i passi elementari: Esecuzione dei comandi Valutazione delle espressioni Elaborazione delle dichiarazioni In genera la parte della semantica dinamica \u00e8 gestita dal Loader (che quindi si pu\u00f2 vedere come una funzione \\(Loader: nome \\to address\\) ) Come abbiamo detto precedentemente, un identificatore \u00e8 una sequenza di caratteri (una stringa). In L, un identificatore contiene lettere, cifre e _ . Inoltre non inizia con una cifra. Come con la semantica statica, abbiamo a che fare con un ambiente, che stavolta chiameremo \\(\\rho\\) . In aggiunta avremo anche a che fare con una memoria, che esprimeremo come \\(\\sigma\\) . \\(\\rho\\) Ambiente: una funzione che associa nomi mnemonici a locazioni di memoria. \\(\\sigma\\) Memoria: una funzione che associa locazioni a valori. Essendoci una memoria che viene modificata con il passare del tempo (e l'esecuzione del programma), ci sono delle transizioni di stato. Per esprimere questi avvenimenti, abbiamo due strumenti:","title":"Semantica dinamica"},{"location":"ProAlgo/semantica/#transizioni-di-stato","text":"Le transizione di stato sono rappresentati come blocchi ed includono molteplici regole di inferenza tra una transizione e l'altra, rendendo lo strumento di facile comprensione e visibilit\u00e0 sui processi, a scapito di una minore formalit\u00e0. Come si vede dalla foto, ci possono essere 3 tipi di frecce, ognuna delle quali rappresenta il tipo di passaggio fatto (esecuzione, valutazione o dichiarazione) La freccia rappresenta una funzione di interpretazione sematica. Nel caso si vogliano rappresentare pi\u00f9 transizioni e quindi l'applicazioni di molteplici regole (ad esempio valutazioni), si pu\u00f2 usare una freccia con una stellina: \\(\\to^*_e\\) \\(\\anglebr{E, \\rho, \\theta} \\to_e \\anglebr {E^{'}, \\rho, \\theta}, Eval(E,\\rho,\\theta) = v \\in Val \\Leftrightarrow \\anglebr {E, \\rho, \\theta} \\to^*_e v\\) Le transizioni di stato fanno parte di un sistema di transizioni, una quadrupla \\(\\anglebr{S,T,F,S_0}\\) : \\[ \\begin{cases} S & stati & = \\{ \\anglebr{E, \\rho, \\theta} \\cup V | v\\ in Val_E \\} \\\\ T & transizioni & \\subseteq S \\times S, T=\\{ (S_1, S_2)|S_1, S_2 \\in S \\land S_1 \\to S_2 \\} \\\\ F & \\text{stati finali} & \\subseteq S, F=Val_E \\\\ S_0 & \\text{stato iniziale} & \\in S \\text{(espressione da valutare)} \\end{cases} \\] \\(\\{ \\anglebr{E, \\rho, \\theta} \\cup V | V \\in Val_E, \\underbrace{\\to_e}_{\\text{regola di inferenza}}, \\underbrace{Val_E}_{\\text{valore finale}}, \\underbrace{(Expr)}_{\\text{espressione da valutare}} \\}\\)","title":"Transizioni di stato"},{"location":"ProAlgo/semantica/#regole-di-inferenza","text":"Le regole di inferenza sono molto simili a alle regole di inferenza di semantica statica, con l'aggiunta della memoria e l'ambiente invece che mappare su tipi, mappa su locazioni di memoria.","title":"Regole di inferenza"},{"location":"ProAlgo/sintassi/","text":"La sintassi si occupa di controllare se una stringa \u00e8 legale (ovvero rispetta le regole della grammatica) Ogni elemento (o carattere) del codice di un programma \u00e8 un simbolo e fa parte della sintassi. La sematica (non la sintassi) si occupa di \"dare\" il significato ad ogni simbolo. La sintassi \u00e8 quindi la struttura dei costrutti di cui il linguaggio di programmazione far\u00e0 uso. La sintassi si basa sul lessico, e ci permette quindi di effettuare due operazioni: Analisi Lessicografica (controllare che i termini siano validi) Grammatiche (tutte le frasi legali che posso esprimere nel linguaggio che sto definendo) Ci permette quindi di: Definire un linguaggio durante la fase di creazione Leggere e studiare un nuovo linguaggio in fase di apprendimento Definizione di Alfabeto Insieme finito e non vuoto di simboli o caratteri Definizione di lessico Insieme delle parole del linguaggio composte a partire da un insieme di simboli atomici detti caratteri che rappresentano l' alfabeto del linguaggio. Le parole saranno poi utilizzate per formare frasi esprimibili in quel linguaggio Definizione di parola legale Le parole legali sono un sottoinsieme di tutte le parole che si possono costruire. Una parola legale sar\u00e0 quindi una parola appartenente a questo sottoinsieme Definizione di stringa Una stringa \u00e8 il risultato della concatenazione di elementi di un insieme (finito o vuoto) di simboli (un alfabeto) Linguaggio di Programmazione un linguaggio di programmazione \u00e8 l'insieme delle stringhe ammissibili, che prendono il nome di programmi. ASCII \u00e8 un alfabeto. La maggior parte dei linguaggi si basa su un sottoinsieme di questo alfabeto (insieme riferito come \"printable characters\" o caratteri stampabili, come quelli di cui \u00e8 composta questa pagina) Operazioni sui caratteri \u00b6 Concatenazione \u00b6 Operazione definita sui simboli di un alfabeto: \\(\\forall a,b \\in A . a \\cdot b = b a\\) Esponenziale \u00b6 Dato \\(x^0 = \\epsilon\\) (dove \\(\\epsilon\\) = stringa vuota), \\(x^n = x \\cdot x^{n-1}\\) Prefisso \u00b6 Stringa con uno scarto della coda Suffisso \u00b6 Stringa con uno scarto dalla testa Sottostringa \u00b6 Stringa senza prefisso e suffisso (prefisso e suffisso risultano cancellati) Lunghezza di una stringa \u00b6 Si indica con i trattini verticali (che richiamano alla cardinalit\u00e0) ed indicano il numero di elementi dell'alfabeto nella stringa: \\(|ciao| = 4\\) Chiusura di Kleene * \u00b6 Insieme di simboli contenente tutte le stringhe di tutte le lunghezze (0( \\(\\epsilon\\) ),1,2,3,...) formabili concatenando un alfabeto Chiusura positiva + \u00b6 Una chiusura positiva \u00e8 una chiusura di Kleene con lunghezza > 0 Ci permette di identificare un insieme non vuoto di tutte le stringhe possibili ottenibili concatenando un alfabeto. Linguaggi \u00b6 Linguaggio Un linguaggio \u00e8 un sottoinsieme della chiusura positiva dell'alfabeto \u00c8 l'insieme delle stringhe ammissibili (chiamati programmi) Linguaggio infinito \u00b6 Definibile attraverso 3 metodi ed \u00e8 definibile enumerando tutti i suoi elementi (ove non infiniti) Un linguaggio L su un alfabeto A \u00e8 un sottoinsieme della chiusura di Kleene (considerando insiemi non vuoti e non banali) Un linguaggio di programmazione classico pu\u00f2 essere pensato come un sottoinsieme di ASCII* Generativo \u00b6 Insieme delle stringhe generate (che seguono le regole) da una grammatica Riconoscitivo \u00b6 Insieme delle stringhe riconosciute ad un automa Algebrico \u00b6 Insieme delle stringhe soluzione di un sistema di equazioni algebriche Albero di derivazione \u00b6 L'albero di derivazione \u00e8 un albero radicato non vuoto in cui: La radice \u00e8 etichettata con il simbolo iniziale Ogni nodo interno \u00e8 etichettato con un simbolo non terminale e rappresenta l'applicazione di una produzione Ogni foglia \u00e8 etichettata con un simbolo terminale La stringa corrispondente ad un albero (di derivazione) si ottiene dalla frontiera, concatenando le etichette delle foglie da sinistra a destra Ogni sotto albero risulta essere l'applicazione di una produzione Ad ogni albero sono associate pi\u00f9 derivazioni, a seconda dell'ordine in cui vengono applicate le derivazioni. Esiste una corrispondenza biunivoca tra alberi di derivazione e derivazioni canoniche: se derivo sempre da destra (o sinistra), ottengo sempre lo stesso albero. Ci\u00f2 significa che se derivo sempre da destra (o sinistra) ottengo sempre lo stesso albero. Grammatica ambigua \u00b6 Lo stesso linguaggio si pu\u00f2 ottenere con 2 alberi diversi (ovvero, ci pu\u00f2 essere indecisione su quale pu\u00f2 essere l'albero da usare). La produzione non riesce a determinare una precedenza con gli operatori (questo perch\u00e9 dal punto di vista della sintassi tutti i simboli hanno uguale precedenza, non abbiamo ancora inserito una semantica che ci permette di attribuire un significato degli operatori (come addizione e moltiplicazione) e quindi una precedenza). Ci\u00f2 porta il parser a decidere arbitrariamente l'ordine degli operatori, prima di passare all'organizzatore semantico (che poi \u00e8 in grado di assegnare un significato ai simboli) La soluzione a questo problema ( disambiguazione ) \u00e8 data dall'aggiunta di operatori per non permettere alla scelta di poter esistere in primo luogo. Questo perch\u00e9 l'analizzatore sintattico (parser) usa grammatiche non ambigue per determinare la precedenza tra operatori. Se cos\u00ec non fosse, potrebbero verificarsi \"undefined behavior\" Albero di sintassi astratta \u00b6 Un albero di sintassi risulta essere una versione compatta dell'albero di derivazione, perch\u00e9 imporre la precedenza aumenta il numero di produzioni. Per ottimizzare quindi si mantiene la non ambiguit\u00e0, rimuovendo per\u00f2 tutti i nodi interni non terminali che non sono direttamente collegati a foglie. Esempio di albero di sintassi prendendo come regole scritte in BNF le seguenti produzioni: \\(E ::= E + T | T\\) \\(T ::= T \\star F | F\\) \\(F ::= a | b | c | (E)\\) Possiamo prendere la stringa \\(a \\star (b + c)\\) ed effettuare una trasformazione delle produzioni partendo da E come simbolo iniziale: \\(E \\to T \\to T \\star F \\to T \\star (E) \\to T \\star (E+T) \\to T \\star (E+F) \\to T \\star (E+c) \\to\\) \\(\\to T \\star (T+c) \\to T \\star (F+c) \\to T \\star (b+c) \\to F \\star (b+c) \\to a \\star (b+c)\\) In questo esempio la frontiera sono i nodi a , * , b , + , c Categorie sintattiche \u00b6 Dichiarazioni \u00b6 Comandi \u00b6 Espressioni \u00b6 Lessico \u00b6 Grammatica \u00b6","title":"Sintassi"},{"location":"ProAlgo/sintassi/#operazioni-sui-caratteri","text":"","title":"Operazioni sui caratteri"},{"location":"ProAlgo/sintassi/#concatenazione","text":"Operazione definita sui simboli di un alfabeto: \\(\\forall a,b \\in A . a \\cdot b = b a\\)","title":"Concatenazione"},{"location":"ProAlgo/sintassi/#esponenziale","text":"Dato \\(x^0 = \\epsilon\\) (dove \\(\\epsilon\\) = stringa vuota), \\(x^n = x \\cdot x^{n-1}\\)","title":"Esponenziale"},{"location":"ProAlgo/sintassi/#prefisso","text":"Stringa con uno scarto della coda","title":"Prefisso"},{"location":"ProAlgo/sintassi/#suffisso","text":"Stringa con uno scarto dalla testa","title":"Suffisso"},{"location":"ProAlgo/sintassi/#sottostringa","text":"Stringa senza prefisso e suffisso (prefisso e suffisso risultano cancellati)","title":"Sottostringa"},{"location":"ProAlgo/sintassi/#lunghezza-di-una-stringa","text":"Si indica con i trattini verticali (che richiamano alla cardinalit\u00e0) ed indicano il numero di elementi dell'alfabeto nella stringa: \\(|ciao| = 4\\)","title":"Lunghezza di una stringa"},{"location":"ProAlgo/sintassi/#chiusura-di-kleene","text":"Insieme di simboli contenente tutte le stringhe di tutte le lunghezze (0( \\(\\epsilon\\) ),1,2,3,...) formabili concatenando un alfabeto","title":"Chiusura di Kleene *"},{"location":"ProAlgo/sintassi/#chiusura-positiva","text":"Una chiusura positiva \u00e8 una chiusura di Kleene con lunghezza > 0 Ci permette di identificare un insieme non vuoto di tutte le stringhe possibili ottenibili concatenando un alfabeto.","title":"Chiusura positiva +"},{"location":"ProAlgo/sintassi/#linguaggi","text":"Linguaggio Un linguaggio \u00e8 un sottoinsieme della chiusura positiva dell'alfabeto \u00c8 l'insieme delle stringhe ammissibili (chiamati programmi)","title":"Linguaggi"},{"location":"ProAlgo/sintassi/#linguaggio-infinito","text":"Definibile attraverso 3 metodi ed \u00e8 definibile enumerando tutti i suoi elementi (ove non infiniti) Un linguaggio L su un alfabeto A \u00e8 un sottoinsieme della chiusura di Kleene (considerando insiemi non vuoti e non banali) Un linguaggio di programmazione classico pu\u00f2 essere pensato come un sottoinsieme di ASCII*","title":"Linguaggio infinito"},{"location":"ProAlgo/sintassi/#generativo","text":"Insieme delle stringhe generate (che seguono le regole) da una grammatica","title":"Generativo"},{"location":"ProAlgo/sintassi/#riconoscitivo","text":"Insieme delle stringhe riconosciute ad un automa","title":"Riconoscitivo"},{"location":"ProAlgo/sintassi/#algebrico","text":"Insieme delle stringhe soluzione di un sistema di equazioni algebriche","title":"Algebrico"},{"location":"ProAlgo/sintassi/#albero-di-derivazione","text":"L'albero di derivazione \u00e8 un albero radicato non vuoto in cui: La radice \u00e8 etichettata con il simbolo iniziale Ogni nodo interno \u00e8 etichettato con un simbolo non terminale e rappresenta l'applicazione di una produzione Ogni foglia \u00e8 etichettata con un simbolo terminale La stringa corrispondente ad un albero (di derivazione) si ottiene dalla frontiera, concatenando le etichette delle foglie da sinistra a destra Ogni sotto albero risulta essere l'applicazione di una produzione Ad ogni albero sono associate pi\u00f9 derivazioni, a seconda dell'ordine in cui vengono applicate le derivazioni. Esiste una corrispondenza biunivoca tra alberi di derivazione e derivazioni canoniche: se derivo sempre da destra (o sinistra), ottengo sempre lo stesso albero. Ci\u00f2 significa che se derivo sempre da destra (o sinistra) ottengo sempre lo stesso albero.","title":"Albero di derivazione"},{"location":"ProAlgo/sintassi/#grammatica-ambigua","text":"Lo stesso linguaggio si pu\u00f2 ottenere con 2 alberi diversi (ovvero, ci pu\u00f2 essere indecisione su quale pu\u00f2 essere l'albero da usare). La produzione non riesce a determinare una precedenza con gli operatori (questo perch\u00e9 dal punto di vista della sintassi tutti i simboli hanno uguale precedenza, non abbiamo ancora inserito una semantica che ci permette di attribuire un significato degli operatori (come addizione e moltiplicazione) e quindi una precedenza). Ci\u00f2 porta il parser a decidere arbitrariamente l'ordine degli operatori, prima di passare all'organizzatore semantico (che poi \u00e8 in grado di assegnare un significato ai simboli) La soluzione a questo problema ( disambiguazione ) \u00e8 data dall'aggiunta di operatori per non permettere alla scelta di poter esistere in primo luogo. Questo perch\u00e9 l'analizzatore sintattico (parser) usa grammatiche non ambigue per determinare la precedenza tra operatori. Se cos\u00ec non fosse, potrebbero verificarsi \"undefined behavior\"","title":"Grammatica ambigua"},{"location":"ProAlgo/sintassi/#albero-di-sintassi-astratta","text":"Un albero di sintassi risulta essere una versione compatta dell'albero di derivazione, perch\u00e9 imporre la precedenza aumenta il numero di produzioni. Per ottimizzare quindi si mantiene la non ambiguit\u00e0, rimuovendo per\u00f2 tutti i nodi interni non terminali che non sono direttamente collegati a foglie. Esempio di albero di sintassi prendendo come regole scritte in BNF le seguenti produzioni: \\(E ::= E + T | T\\) \\(T ::= T \\star F | F\\) \\(F ::= a | b | c | (E)\\) Possiamo prendere la stringa \\(a \\star (b + c)\\) ed effettuare una trasformazione delle produzioni partendo da E come simbolo iniziale: \\(E \\to T \\to T \\star F \\to T \\star (E) \\to T \\star (E+T) \\to T \\star (E+F) \\to T \\star (E+c) \\to\\) \\(\\to T \\star (T+c) \\to T \\star (F+c) \\to T \\star (b+c) \\to F \\star (b+c) \\to a \\star (b+c)\\) In questo esempio la frontiera sono i nodi a , * , b , + , c","title":"Albero di sintassi astratta"},{"location":"ProAlgo/sintassi/#categorie-sintattiche","text":"","title":"Categorie sintattiche"},{"location":"ProAlgo/sintassi/#dichiarazioni","text":"","title":"Dichiarazioni"},{"location":"ProAlgo/sintassi/#comandi","text":"","title":"Comandi"},{"location":"ProAlgo/sintassi/#espressioni","text":"","title":"Espressioni"},{"location":"ProAlgo/sintassi/#lessico","text":"","title":"Lessico"},{"location":"ProAlgo/sintassi/#grammatica","text":"","title":"Grammatica"},{"location":"ProAlgo/smarriti/","text":"Questa roba non so dove vada Funzioni \u00b6 Parametri formali Passaggio per riferimento e per valore Record di attivazione \u00b6 Contiene: Identit\u00e0 Chiamante A chi restituire Corpo della funzione corrente se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo Tipologia di linguaggi \u00b6 Linguaggio interpretato \u00b6 Linugaggio compilato \u00b6 Numeri pseudocasuali \u00b6 La generazione di numeri pseudocasuali riguarda un algoritmo in grado di generare ogni numero nel codominio della funzione equiprobabilmente. Da un seed si genera in maniera deterministica un numero.","title":"Smarriti"},{"location":"ProAlgo/smarriti/#funzioni","text":"Parametri formali Passaggio per riferimento e per valore","title":"Funzioni"},{"location":"ProAlgo/smarriti/#record-di-attivazione","text":"Contiene: Identit\u00e0 Chiamante A chi restituire Corpo della funzione corrente se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo","title":"Record di attivazione"},{"location":"ProAlgo/smarriti/#tipologia-di-linguaggi","text":"","title":"Tipologia di linguaggi"},{"location":"ProAlgo/smarriti/#linguaggio-interpretato","text":"","title":"Linguaggio interpretato"},{"location":"ProAlgo/smarriti/#linugaggio-compilato","text":"","title":"Linugaggio compilato"},{"location":"ProAlgo/smarriti/#numeri-pseudocasuali","text":"La generazione di numeri pseudocasuali riguarda un algoritmo in grado di generare ogni numero nel codominio della funzione equiprobabilmente. Da un seed si genera in maniera deterministica un numero.","title":"Numeri pseudocasuali"},{"location":"ProAlgo/strutture/","text":"Le strutture dati \u00b6 Le strutture dati sono costrutti usati per organizzare dati o valori da manipolare. L'organizzazione dei dati \u00e8 divisa in due: Struttura fisica La struttura fisica dei dati si occupa di rappresentare il modo in cui i dati sono fisicamente immagazzinati all'interno della memoria centrale del computer. Un esempio pu\u00f2 essere un array, che rappresenta Organizzazione logica Come i dati sono organizzati in maniera logica, ad esempio un grafo. Una struttura dati (ADS, Abstract Data Type) permette di legare la struttura fisica di un computer con un'organizzazione logica Le operazioni che un'ADS deve essere in grado di fare sono: Lettura Scrittura/modifica Eliminazione/aggiunta Alcune strutture di dati possono essere: Array Stack (pila) Coda Lista collegata Alberi e grafi Array \u00b6 Un array ha un'organizzazione logica che corrisponde a quella fisica: i valori sono in posizioni logicamente contigue e (spesso) in indirizzi contigui di memoria (a seconda del linguaggio e della sua implementazione 1 ). Permette quindi un accesso diretto ai valori, che permette di avere operazioni di accesso e modifica facili e veloci. Rende tuttavia complicate le operazioni di cancellazione ed inserimento, che dipendono poi dall'implementazioni Si pu\u00f2 quindi riassumere come una collezione ordinata in cui esiste un ordine posizionale Stack (pila) \u00b6 Logicamente i valori sono posizionati in celle logicamente contigue, in una struttura LIFO (Last In First Out), permettendo 3 metodi: Push (aggiunta di un elemento nella pila) Pop (rimozione di un elemento dalla pila ed ispezione del suo valore) Top (ispezione del prossimo valore senza rimuoverlo dalla struttura) Code \u00b6 Anche nelle code gli elementi sono logicamente contigui, mentre la struttura in questo caso \u00e8 FIFO (First In First Out). Permette operazioni di enqueue (messa in coda) e dequeue (rimozione dalla coda) Lista collegata \u00b6 La lista \u00e8 una struttura in cui gli elementi non sono contigui, quindi \u00e8 richiesto un modo per accedere al successivo (ed in caso al precedente). Lettura, inserimento, modifica e cancellazioni sono quasi banali e possono essere resi circolari (struttura ad anello. ) Grafi \u00b6 Un grafo \u00e8 una struttura dati visibile come una coppia di nodi ed archi. Algoritmi di ricerca \u00b6 In un grafo, per effettuare una ricerca, esistono numerose soluzioni. Lo scopo pu\u00f2 voler essere quello di mappare il grafo o cercare un nodo con un valore specifico. BFS \u00b6 L'algoritmo di Breadth First Search si occupa di ricercare prima i figli DFS \u00b6 La DFS (Depth First Search) esamina ogni figlio in profondit\u00e0 ed in maniera ricorsiva, per poi procedere con gli altri. Nel farlo, permette di costruire un \"albero\" (ovvero un DAG) ed eventuali archi che creano pi\u00f9 path per giungere ad un nodo. Questi archi sono: Tree Un arco di tipo tree \u00e8 visto come un \"normale\" nodo dell'albero. Back Un Back edge \u00e8 un arco che permette di arrivare ad un antenato del nodo, rispetto agli archi di tipo tree Forward Un Forward edge \u00e8 un arco che permette di arrivare ad un discendente attraversando meno archi rispetto a quanto si farebbe utilizzando un tree edge Cross Un Cross edge \u00e8 un arco che permette di attraversare l'albero per arrivare ad un fratello o ai suoi antenati/discendenti Topological sort (DAG) DFS \u00b6 Il topological sort \u00e8 un algoritmo basato su DFS che permette di stabilire un ordine delle dipendenze (ed \u00e8 infatti usato anche da software come package managers). Permette di fare un'ordinamento secondo la tipologia, seguendo l'ordine di scoperta dei nodi fatto dalla DFS Albero \u00b6 Un albero \u00e8 una struttura dati che si pu\u00f2 immaginare come un albero al contrario: in alto abbiamo la radice e sotto troviamo i figli Ogni nodo (o pallino) pu\u00f2 far parte o meno di un albero foresta Relazione gerarchica (padre, figlio, fratello, progenitore) foglie propriet\u00e0 strutturali Albero binario \u00b6 Un albero binario \u00e8 una struttura definita su un insieme di nodi Pu\u00f2 non contenere alcun nodo (albero vuoto), pu\u00f2 contenere un solo nodo detto radice, e pu\u00f2 contenere un sotto albero sinistro o destro della radice. In memoria \u00e8 rappresentato con nodo padre, il payload (quindi ad esempio chiave e valore), e puntatori al sotto albero sinistro e destro. Pu\u00f2 essere visitato in 3 diversi modi: Visita anticipata Prima viene visitato il nodo, e poi i suoi sotto alberi Visita simmetrica Prima viene visitato il figlio sinistro, a seguire il nodo, ed infine il figlio desto Visita posticipata Prima viene visitato il figlio sinistro, poi il figlio destro e solo infine il nodo Per quanto riguarda le propriet\u00e0 strutturali, possiamo facilmente individuare questi: Al pi\u00f9 \\(2^l\\) nodi al livello l Profondit\u00e0 la pi\u00f9 di \\(2^{d+1}-1\\) nodi Un albero con n nodi ha profondit\u00e0 almeno \\(\\log_2(n+1)-1\\) Ci sono diversi tipi di forme che possono assumere: Completo Tutte le foglie sono allo stesso livello e tutti i nodi interni hanno grado 2 Completamente bilanciato: \u00c8 un albero completo con tutte le foglie alla stessa profondit\u00e0 Bilanciato \u00c8 un albero di dimensione n ed altezza h, se \\(h=O(log(n))\\) Completo a sinistra/Quasi completo \u00c8 un albero completo tranne per l'ultimo, dove le foglie vanno da sinistra a destra. La prima non-foglia in un array si trova a \\(\\lower {\\frac n 2}\\) 1-bilanciato (bilanciato in altezza): L'altezza dei sotto-alberi destro e sinistro differiscono al pi\u00f9 di un'unit\u00e0 Il costo di una ricerca \u00e8 O(h) (in quanto per farlo tracciamo un percorso dalla radice alla nodo scendendo esclusivamente a sinistra o destra). Attenzione sul fatto che non essendoci un vincolo che mantiene l'albero bilanciato, h pu\u00f2 diventare lineare. \\(\\forall \\text{nodo x nell'albero T}\\) \\(\\forall \\text{nodo y nel sottoalbero sinistro}\\) \\(y.key < x.key\\) \\(\\forall \\text{nodo z nel sottoalbero destro}\\) \\(z.key > x.key\\) L'operazione di ricerca \\(T(n) = O(h)\\) , dove \\(h=O(log(n))\\) al caso medio/ottimo e \\(h=(O(n))\\) al caso pessimo. Anche le operazioni per trovare il valore minimo e massimo hanno tempo O(h): Minimo: Si ricerca il nodo pi\u00f9 profondo a sinistra senza figlio sinistro Massimo: Si ricerca il nodo pi\u00f9 profondo a destra senza figlio destro L'operazione successore (trovare il nodo y con la pi\u00f9 piccola chiave maggiore di x) invece \u00e8 un po' pi\u00f9 complicato: Se il nodo ha un sotto albero destro, si trova il minimo tra i nipoti destri Altrimenti, si trova l'antenato pi\u00f9 vicino ad x, ovvero che contiene x nel suo sottoalbero sinistro Anche questo ha come complessit\u00e0 \\(T(n)=O(h)\\) Notare che non ci serve comparare le chiavi, in quanto facciamo uso della propriet\u00e0 strutturale Inserimento \u00b6 I nuovi nodi sono aggiunti come foglie. La complessit\u00e0 \u00e8 quindi \\(T(n)=O(h)\\) Cancellazione \u00b6 Se il nodo \u00e8 una foglia, \u00e8 sufficiente eliminare la foglia Se il nodo \u00e8 interno ed ha un figlio, si collegano padre e figlio del nodo Se il nodo ha due figli, si sostituisce il successore (la foglia dx) con il nodo, e si elimina il nodo 2-3 alberi \u00b6 Un albero binario pu\u00f2 essere complicato da mantenere bilanciato, e si pu\u00f2 formare facilmente una catena, che fa deteriorare le prestazioni. Le propriet\u00e0 strutturali di un 2-3 albero puntano a mantenere un albero bilanciato: Ogni nodo ha almeno due figli e massimo tre Tutti i cammini radice-foglia hanno la stessa lunghezza (quindi \\(\\log_2(n) \\le n \\le log_3(n)\\) ) I dati sono tutti quanti memorizzati nelle foglie (in ordine crescente da sinistra verso destra) I noti intermedi contengono il massimo valore raggiungibile andando a sinistra (ed al centro nel caso il nodo abbia tre figli) Si usano i 2-3 alberi in quanto hanno prestazioni superiori agli ABR, che risultano essere lineari su h Ricerca \u00b6 La ricerca ha un tempo di \\(\\Theta(log(n))\\) , in quanto, grazie alle propriet\u00e0 strutturali, tutti i percorsi radice-foglia hanno uguale lunghezza. Inserimento \u00b6 L'inserimento di un nuovo valore si basa su alcuni step: Provo a cercare il valore nell'albero, per trovare la posizione pi\u00f9 adatta Se il nodo andrebbe in un nodo con due figli, si crea un nuovo figlio e si inserisce il valore del secondo figlio nel padre. Se il nodo ha tre figli, si effettua l'operazione di split : Viene creato un nuovo nodo con i primi due figli e si aggiunge il valore al nodo appena trovato. Se il genitore ha 4 figli si effettua una chiamata ricorsiva all'operazione di split La complessit\u00e0 \u00e8 \\(O(log(n))\\) Eliminazione \u00b6 Si riceraca il valore da eliminare nell'albero. Una volta trovato, se rimane un solo figlio, si deve ricorrere all'operazione di merge (che \u00e8 l'opposto dell'operazione di split), che consiste nell'unire due fratelli Heap \u00b6 Albero binario quasi completo e in cui ogni nodo interno ha un valore maggiore uguale o minore uguale rispetto ai suoi due figli (in caso di heap di massimo o di minimo). Le chiavi di ogni nodo devono chiaramente essere confrontabili. L'operazione di heapsort \u00e8 un'operazione ricorsiva che permette di ordinare in un heap un array non ordinato, partendo dall'assunzione che i sotto-alberi siano heap. Operazioni (ogni operazione aspira ad essere \\(log(n)\\) ): Deletion di una foglia: Si cancella la foglia di un nodo interno: si fa il replace dell'ultima foglia con il nodo, si elimina il nodo e si fa un reheap Insertion si aggiunge il valore come foglia e si sostituisce il padre con la foglia finch\u00e9 l'albero non \u00e8 bilanciato (swap-reheapification) Edit Si modifica il valore della foglia e si controlla che l'albero sia bilanciato Deletion ed insertion insieme Implementabile come array: Le celle sono ordinate a partire dal primo livello, da sinistra verso destra Il genitore di un nodo i si trova attraverso la formula \\(\\lower {\\frac {i-1}{2}}\\) I figli di un nodo i sono i nodi \\(2i+1\\) e \\(2i+2\\) Ecco un esempio di operazioni che \u00e8 possibile fare su un heap di massimo ed il loro costo Operazione Costo Max heapify O(log n) Build max heap O(n) Heapsort O(n log n) Max-heap insert O(log n) Heap extract max O(log n) Heap increase key O(log n) Heap maximum O(1) Max heapify \u00b6 La max-heapify \u00e8 un'operazione di ordinamento ricorsiva, che partendo dalle foglie risale l'albero ordinando l'array in un max heap (heap di massimo) Il costo \u00e8 \\(O(h)\\) (dove h \u00e8 l'altezza) Build max-heap \u00b6 L'algoritmo chiamato build max-heap ci permette di creare un heap a partire da da un array non ordinato Il costo dell'algoritmo \u00e8 pari al costo dell'heapify moltiplicato per il numero di nodi nel livello: Partendo da un array, tolgo la radice posizionandola come primo elemento nell'array, sposto l'ultima foglia alla radice e bilancio l'albero, quindi ripeto l'operazione. Al termine, avr\u00f2 un array che rappresenta un heap. L'algoritmo ha un costo \\(O(n)\\) Dizionario \u00b6 Un dizionario \u00e8 una struttura che permette di memorizzare un insieme dinamico nel tempo. Si basa sul concetto di \"mapping\" chiave-valore (visibile anche come una funzione che dato una certa chiave, che identifica in modo univoco e permette di accedere ad un certo elemento), in maniera simile ad un vocabolario. L'universo delle chiavi \u00e8 chiamato u Le operazioni che permette di effettuare normalmente sono ricerca, inserimento e cancellazione: \\[ \\displaylines{ Ricerca (\\underbrace{S}_{\\text{dizionario}}, \\underbrace{K}_{\\text{chiave}}) = \\begin{cases} x & \\text{t.c. } x.key=k \\\\ NIL & \\text{se S non contiene elementi di chiave k} \\end{cases} \\\\ Insert(S,x) \\qquad S \\from S \\cup\\{x\\} \\\\ Delete(S,x) \\qquad S \\from S \\backslash \\{x\\} } \\] (Nel caso di aggiunta ed eliminazione, x \u00e8 il riferimento da rimuovere) Grande punto di forza di questa struttura dati \u00e8 il tempo richiedo per effettuare le operazioni, che \u00e8 in media costante . La cardinalit\u00e0 di un dizionario ( \\(|S|\\) ) \u00e8 il numero di elementi che S contiene. Questo serve quindi ad individuare la complessit\u00e0 in funzione di n. Se universo di chiavi u \u00e8 totalmente ordinato, \u00e8 possibile effettuare query aggiuntive, come Min(S) (per trovare l'elemento di chiave minima in S), Max(S) (per trovare l'element do chiave massima in S) e Successore(S,x) (per trovare l'elemento con la pi\u00f9 piccola chiave maggiore di x.key) I dati in un dizionario sono disposti in un vettore (o una tabella), la cui dimensione cerca di essere proporzionale con il numero di elementi nell'insieme S (ad esempio avendo il vettore il doppio pi\u00f9 grande della cardinalit\u00e0 di elementi in S \\(2 \\cdot |S|\\) ). Per usare la struttura dati, calcoleremo quindi la posizione di ogni elemento di S nel vettore T. Questo calcolo \u00e8 chiamato hashing e ci permette di \"mappare\" l'universo delle chiavi ad una posizione del vettore. \\(dim ~ T = m \\qquad \\underbrace{T[0...m-1]}_{\\text{Vettore da 0 a m}}\\) \\(\\underbrace{h}_{\\text{funzione di hashing}}: U \\to [0,m-1]\\) Possiamo quindi dire che \\(h(k) \\in [0,m-1]\\) Dato un valore x, questo viene memorizzato in \\(T[h(x.key)]=x\\) Propriet\u00e0 della funzione di hashing: Non pu\u00f2 essere iniettiva ( \\(|U| >> m\\) ) Questo implica che pu\u00f2 accadere che si verifichino collisioni. Una collisione si verifica quando chiavi diverse risolvono alla stessa posizione. Deve essere suriettiva (tutto il codominio deve essere coperto) Deve essere facile da calcolare ( \\(O(1)\\) ) Deve avere una distribuzione uniforme: \\(\\forall k \\in U.h(k) \\in [0,m-1]\\) con probabilit\u00e0 \\(\\frac 1 m\\) Deve essere deterministica ( h(k) produce sempre lo stesso valore) Esempio di funzione di hashing Un esempio di funzione di hashing pu\u00f2 essere quello usato dal metodo della divisione. Questo metodo fa uso della funzione di modulo per calcolare la cella sulla quale posizionare un elemento. \\(\\forall k \\in U\\) \\(h(k) = k ~ mod ~ \\underbrace{n}_\\text{numero primo}\\) Usiamo un numero primo per distribuire in modo omogeneo le chiavi nelle celle Il fattore di carico \u00b6 Il fattore di carico rappresenta il rapporto tra gli elementi inseriti all'interno del dizionario e lo spazio della tabella. \\(\\alpha = \\frac n m = \\frac {|S|} {dim ~ T} = \\frac {\\text{Dimensione dizionario (record)}} {\\text{Dimensione tabella}}\\) In media si cerca di avere un fattore \\(\\alpha = \\frac 1 2\\) , che consente di avere una cella vuota per ogni cella occupata da una lista La funzione di hashing \u00b6 Ci sono due modi in cui la funzione di hashing (e quindi l'organizzazione dei dati) pu\u00f2 essere fatta (e i nomi con i quali possono essere conosciuti sono molti): Indirizzamento chiuso/hashing perfetto Indirizzamento aperto/open hash/liste di trabocco/concatenamento A seconda del tipo di indirizzamento che si sceglie, cambiano i dettagli della struttura. La differenza giace nel come le collisioni vengono gestite e risolte. Esistono diversi tipi di funzione di hashing, tra cui: Hash Uniforme Semplice (HUS): L'HUS (Hash Uniforme Semplice) \u00e8 la funzione di hashing pi\u00f9 semplice, e consiste nella formula che abbiamo visto prima: \\(\\forall k \\in U\\) \\(h(k) = k ~ mod ~ \\underbrace{n}_\\text{numero primo}\\) Open hash \u00b6 L'open hash \u00e8 la gestione delle collisioni con concatenamento: questo significa il vettore T \u00e8 un array di liste doppie. Il funzionamento si basa sul calcolare con una funzione di hash l'indice a cui posizionare l'elemento, per poi aggiungere ad una lista (eventualmente vuota) l'elemento in testa. Search \\[ T[j] = \\begin{cases} NIL & \\forall x \\in S . h(x.key) \\ne j \\\\ \\text{indice alla lista doppia contenente tutti gli elementi } x \\in S.h(x.key) = j \\end{cases} \\] \\[ T(n) = \\begin{cases} O(1) & \\text{caso ottimo} \\\\ O(1) & \\text{caso medio} \\\\ O(n) & \\text{caso pessimo} \\\\ \\end{cases} \\] Il caso pessimo fa riferimento al caso in cui tutte le chiavi producono lo stesso hash Insert Inserisce l'elemento x in testa alla lista T[h(x.key)] \\(T(n) = O(1)\\) Delete Rimuove l'elemento x dalla lista T[h(x.key)] -- Dato che in genere (per via del fattore di carico \\(\\alpha = \\frac 1 2\\) ) \\(|T| \\cong 2 \\cdot |S|\\) , che permetterebbe di avere una cella vuota per ogni cella occupata Analisi del tempo del dizionario usando HUS (Hash Uniforme Semplice): Ricerca senza successo In un dizionario con HUS e concatenamento, la ricerca senza successo impiega \\(\\Theta(1+\\alpha)\\) al caso medio: \\(T_{\\text{medio}}(n,m) = \\Theta(1+\\frac n m) = \\Theta(1+\\alpha)\\) Dimostrazione Data la chiave k, accedere alla cella costa O(1). \u00c8 quindi poi necessario effettuare una scansione della lista per cercare l'elemento. La scansione costa quindi O(m) (con m il numero di elementi della lista). Dato HUS, possiamo assumere che gli elementi sono distribuiti uniformemente, quindi ci saranno \\(\\alpha\\) elementi Il numero di ispezioni alla lista \u00e8 \\(\\alpha\\) Ricerca con successo La ricerca richiede al caso medio \\(1+\\frac \\alpha 2 - \\frac {\\alpha} {2n}\\) ispezioni, ovvero \\(T_{\\text{medio}}(n,m) = \\Theta(1+\\alpha)\\) Dimostrazione Calcolata la cella (costante), il numero di ispezioni dipende dal numero di elementi che precedono quello che sto cercando. Dato che ispeziono \\(\\frac {n-i}{m}\\) elementi, ho n elementi su m celle. Il numero di ispezioni al caso medio \u00e8 quindi: \\(\\frac 1 n \\sum^n_{i=1}(1+\\frac{n-i}{m})\\) \\(\\frac 1 n \\sum^n_{i=1}(1)+\\sum^n_{i=1}(+\\frac{n-i}{m})\\) (dividiamo la sommatoria) \\(\\frac 1 n \\cdot n+\\sum^n_{i=1}(+\\frac{n-i}{m})\\) (semplifichiamo la prima sommatoria) \\(1+\\frac{1}{m\\cdot n}\\sum^n_{i=1}(n-i)\\) (semplifichiamo la sommatoria) \\(1+\\frac{1}{m\\cdot n}\\frac{n(n-1)}{2}\\) (semplifichiamo la sommatoria ai primi n-1 naturali) \\(1+\\frac{1}{m}\\frac{n-1}{2}\\) (semplifichiamo le n) \\(1+\\frac{n-1}{2m}\\) (ricordiamo che \\(m=\\frac n \\alpha\\) ) \\(1+\\frac{n}{2m} - \\frac{1}{2m}\\) (dividiamo la frazione) \\(1+\\frac{\\alpha}{2} - \\frac{1}{2\\cdot \\frac n \\alpha}\\) (Sostituiamo m ed \\(\\alpha\\) , \\((m=\\frac n \\alpha)\\) ) \\(1+\\frac{\\alpha}{2} - \\frac{1}{2\\cdot \\frac n \\alpha}\\) Pro e Contro dell'hashing con indirizzamento aperto Pro: Preferibile in strutture che ricevono molte writes Contro: Spazio non costante Ricerca degli elementi (che diventa \\(O(m)\\) , con m gli elementi nella lista) Closed hashing \u00b6 Il closed hashing si preoccupa di memorizzare il valore non su una lista ma direttamente nella cella del vettore. Le collisioni sono gestite modificando la sequenza di ispezione, che quando una cella \u00e8 occupata, permette di scegliere una posizione \"successiva\". In questo caso il fattore di carico \\(\\frac {\\text{elementi}}{\\text{celle}} = \\frac n m = \\alpha \\le 1\\) , che significa che ci sono sempre pi\u00f9 celle disponibili che elementi memorizzati. La funzione di hashing sar\u00e0 quindi diversa: \\(h:\\mathcal U \\times [0,m-1] \\to [0, m-1]\\) Come vediamo, c'\u00e8 il prodotto cartesiano tra l'universo delle chiavi e un intero minore uguale al numero di celle nell'array (che \u00e8 possibile vedere come tutti i possibili tentativi di mettere una chiave nell'universo nell'array). Notare come la funzione non ritorna un numero, ma una sequenza . h associa una sequenza di ispezione, ovvero un ordine che deve essere seguito nell'esaminare le celle per una certa chiave k. La sequenza avr\u00e0 quindi un aspetto del genere per una stessa chiave k: \\(\\anglebr{h(k,0), h(k,1), ..., h(k, m-1)}\\) La sequenza di ispezione deve essere una permutazione dei primi n interi Insert \\(T_{\\text{ottimo}}=\\Theta(1)\\) \\(T_{\\text{pessimo}}=\\Theta(n)=\\Theta(m)\\) \\(T_{\\text{medio}}=O(\\frac{1}{1-\\alpha}\\) (con \\(\\alpha \\le 1\\) ) Lo pseudocodice per un inserimento pu\u00f2 assomigliare a qualcosa del genere: i = tentativi = 0 for j = h ( k , i ) if ( T [ j ] == nil ) T [ j ] = k return j if ( ++ i + 1 > n ) : return \"Overflow\" Search Segue la stessa sequenza per l'inserimento Se una cella \u00e8 vuota, k non \u00e8 presente \\(T_{\\text{ottimo}}=\\Theta(1)\\) \\(T_{\\text{pessimo}}=\\Theta(n)\\) \\(T_{\\text{medio}}=\\begin{cases} O(\\frac{1}{1-n}) \\\\ O(\\frac 1 \\alpha \\ln(\\frac{1}{1-\\alpha})) \\end{cases}\\) i = 0 for j = h ( k , i ) if ( T [ j ] == nil ) return nil if ( T [ j ] == k ) return k if ( ++ i + 1 >= n ) : return \"Overflow\" Delete L'eliminazione deve essere logica o virtuale, perch\u00e9 altrimenti la ricerca, trovando una cella vuota, andrebbe in halt La deletion rende quindi la cella libera per l'inserimento ma occupata per la ricerca. Questo rende necessaria una modifica all'algoritmo di inserimento, che deve controllare se la cella \u00e8 stata eliminata ed eventualmente sovrascrivere il valore. Analisi del tempo del dizionario : Assunzioni: \\(\\alpha = \\frac n m < 1\\) (esiste almeno una cella libera) Non ci sono state cancellazioni Facciamo uso di hashing uniforme (la sequenza di ispezione di ogni chiave \u00e8 una permutazione delle celle di pari probabilit\u00e0) Conteremo inoltre il numero di ispezioni, non il tempo Ricerca senza successo Il numero di accessi in una ricerca senza successo \u00e8 \\(\\le \\frac {1}{1-\\alpha}\\) Dimostrazione Prendendo x come il numero di accessi alla tabella, il valore medio (o atteso) di x \u00e8 la somma dei valori che x pu\u00f2 assumere, moltiplicato per la probabilit\u00e0 di assumere quel valore. Probabilit\u00e0 di fare esattamente gli accessi: \\(\\sum^{\\pin}_{i=1} (i \\cdot Prob[x=1])\\) Probabilit\u00e0 di fare almeno gli accessi: \\(\\sum_i(Prob[x \\ge 1])\\) Possiamo quindi esaminare la probabilit\u00e0 di avere le prime i-1 celle occupate: \\(i=1 \\qquad Pr[x \\ge 1] = 1\\) (\u00e8 sicuro che almeno un accesso lo facciamo) \\(i=2 \\qquad Pr[x \\ge 2] = \\alpha\\) (cIl secondo accesso viene effettuato solo se la prima cella \u00e8 occupata da un'altra chiave) \\(i=3 \\qquad Pr[x \\ge 3] = \\underbrace{\\frac n m}_{\\text{prima cella occupata}} \\cdot \\underbrace {\\frac {n-1}{m-1}}_{\\text{seconda cella occupata}} < \\alpha^2\\) (Che diventa maggiorabile con \\(\\alpha^{i-1}\\) ) Il valore medio del numero di accessi \u00e8 quindi: \\(\\sum^m_{i=1}Pr[x \\ge 1]\\) \\(\\sum^m_{i=1}2^{i-1}\\) \\(\\sum^{m-1}_{i=0}\\alpha^i \\le \\sum_{i=0}\\alpha^i = \\frac {1}{1-\\alpha}\\) Inserimento al caso medio Il numero di accessi in caso di inserimento al caso medio \u00e8 \\(\\le \\frac{1}{1-\\alpha}\\) Si controllano le stesse cella della ricerca senza successo, fermandosi alla prima vuota. | \\(\\alpha\\) |Occupazione array| numero accessi ricerca senza successo| | \\(\\frac{1}{2}\\) |50%| \\(\\frac{1}{1-\\frac 1 2} \\to 2\\) | | \\(\\frac{1}{10}\\) |10%| \\(\\frac{1}{1-\\frac{1}{10}} \\to 1.11\\) | | \\(\\frac{9}{10}\\) |90%| \\(\\frac{1}{1-\\frac{9}{10}} \\to 10\\) | Ricerca con successo Il numero di accessi al caso medio \u00e8 \\(\\le \\frac {1}{\\alpha} ln \\frac{1}{1-\\alpha}\\) Generazione sequenza di ispezione \u00b6 Ci sono tre tecniche che vediamo per la generazione di una sequenza di ispezione Scansione lineare Descrizione La scansione lineare dopo aver individuato una cella, basa la permutazione delle celle andando alla cella contigua successiva. \\(h': \\mathcal U \\to [0,1,...,m-1]\\) (idealmente con m numero primo) \\(h(k,i)=(h'(k)+i) mod ~ m\\) con \\(0 \\le i \\le m\\) Pro: Cicliamo la tabella da un punto casuale Contro: Il passo \u00e8 costante (1) Il passo non dipende n\u00e9 da i, n\u00e9 dalla chiave Questo significa che dopo un certo numero di inserimenti, saranno prodotti agglomerati o (cluster primari). Questi cluster sono lunghi tratti di celle adiacenti occupate Quando si colpisce uno di questi cluster, in primo luogo \u00e8 necessario scansionare l'intero cluster. In aggiunta, si \"appende\" l'elemento al cluster, facendolo crescere Una collisione genera cluster secondari Un cluster secondario si verifica quando chiavi diverse producono sequenze di ispezioni identiche Esistono \\(n\\) possibili sequenze, contro \\(n!\\) permutazioni ideali Scansione quadratica Descrizione La scansione quadratica vuole risolvere il problema del cluster primario che presenta la scansione lineare. Questo problema viene risolto avendo un passo diverso da uno ogni volta. Continuiamo ad usare la funzione vista per la scansione lineare. Con m numero primo, \\(C_1, C_2\\) \\(C_2 \\ne 0\\) \\(h(k,i)=(h'(k)+C_1 \\cdot i + C_2 \\cdot i^2) mod ~ m\\) Abbiamo quindi che il punto di partenza \u00e8 casuale ed il passo dipende da i. Il numero di sequenza \u00e8 n (il passo rimane lo stesso per tutte le sequenze), e non abbiamo ancora risolto il problema dei cluster secondari, dato che la sequenza dipende ancora solamente dal punto iniziale Doppio hashing Descrizione Il doppio hash mira a risolvere anche il problema del cluster secondario. Il problema viene risolto adottando due funzioni hash: \\(h_1(k) = k ~ mod ~ m\\) \\(h_2(k) = k ~ mod ~ n < m\\) \\(h(k,i) = (h_1(k) + i \\cdot h_2(k)) ~ mod ~ m\\) Abbiamo quindi che il punto di partenza dipende solo dalla chiave, ed anche il passo di scansione dipende dalla chiave. m \u00e8 un numero primo, \\(h_2(k)\\) \u00e8 un coprimo, quindi il massimo comune mulitplo tra i due, essendo \\(h_2(k) < m\\) \u00e8 uno, quindi si effettua una permutazione di tutti gli elementi Pro: Non abbiamo cluster primari Non abbiamo cluster secondari (i passi hanno distanza \\(h_2(k)\\) ) Prestazioni simili alla teoria (quasi ideali) Contro: Le permutazioni non sono \\(n!\\) ma \\(n^2\\) , che \u00e8 comunque meglio delle opzioni viste fin'ora. Dizionari su alberi di ricerca (ABR) \u00b6 \u00c8 possibile implementare i dizionari anche su un albero binario. Le chiavi sono disposte per rispettare la propriet\u00e0 di ricerca. Tutti i nodi minori chiave k sono a sx e tutti i maggiori a destra. Questa propriet\u00e0 permette di avere una sequenza ordinata delle chiavi attraverso una visita simmetrica dell'albero. Comparazione delle applicazioni \u00b6 Operazione/Struttura Ricerca senza successo Inserimento cancellazione Minimo Build Spazio Hash con concatenamento \\(O(n)\\) \\(\\Theta(1+\\alpha)\\) O(1) \\(\\Theta(1)\\) \\(\\Theta(max(n,m))\\) \\(\\Theta(n)\\) \\(\\Theta(max(n,m))\\) Hash aperto \\(O(n)\\) \\(O(\\frac{1}{1-\\alpha})\\) \\(O(n)\\) \\(O(\\frac{1}{1-\\alpha})\\) \\(\\Theta(1)\\) \\(\\Theta(m)\\) \\(\\Theta(n^2)\\) \\(\\Theta(\\frac{n}{1-\\alpha^2})\\) \\(\\Theta(m)\\) ABR O(h) O(h) O(h) O(h) O(n log(n)) \\(\\Theta(n)\\) ABR Bilanciato O(h) O(h) O(h) O(h) O(n log(n)) \\(\\Theta(n)\\) Heap O(h) O(log(n))=O(h) O(log n) \\(\\Theta(1)\\) \\(\\Theta(n)\\) \\(\\Theta(n)\\) \\(\\Theta(n)\\) Looking at you, javascript \u21a9","title":"Strutture di algoritmi"},{"location":"ProAlgo/strutture/#le-strutture-dati","text":"Le strutture dati sono costrutti usati per organizzare dati o valori da manipolare. L'organizzazione dei dati \u00e8 divisa in due: Struttura fisica La struttura fisica dei dati si occupa di rappresentare il modo in cui i dati sono fisicamente immagazzinati all'interno della memoria centrale del computer. Un esempio pu\u00f2 essere un array, che rappresenta Organizzazione logica Come i dati sono organizzati in maniera logica, ad esempio un grafo. Una struttura dati (ADS, Abstract Data Type) permette di legare la struttura fisica di un computer con un'organizzazione logica Le operazioni che un'ADS deve essere in grado di fare sono: Lettura Scrittura/modifica Eliminazione/aggiunta Alcune strutture di dati possono essere: Array Stack (pila) Coda Lista collegata Alberi e grafi","title":"Le strutture dati"},{"location":"ProAlgo/strutture/#array","text":"Un array ha un'organizzazione logica che corrisponde a quella fisica: i valori sono in posizioni logicamente contigue e (spesso) in indirizzi contigui di memoria (a seconda del linguaggio e della sua implementazione 1 ). Permette quindi un accesso diretto ai valori, che permette di avere operazioni di accesso e modifica facili e veloci. Rende tuttavia complicate le operazioni di cancellazione ed inserimento, che dipendono poi dall'implementazioni Si pu\u00f2 quindi riassumere come una collezione ordinata in cui esiste un ordine posizionale","title":"Array"},{"location":"ProAlgo/strutture/#stack-pila","text":"Logicamente i valori sono posizionati in celle logicamente contigue, in una struttura LIFO (Last In First Out), permettendo 3 metodi: Push (aggiunta di un elemento nella pila) Pop (rimozione di un elemento dalla pila ed ispezione del suo valore) Top (ispezione del prossimo valore senza rimuoverlo dalla struttura)","title":"Stack (pila)"},{"location":"ProAlgo/strutture/#code","text":"Anche nelle code gli elementi sono logicamente contigui, mentre la struttura in questo caso \u00e8 FIFO (First In First Out). Permette operazioni di enqueue (messa in coda) e dequeue (rimozione dalla coda)","title":"Code"},{"location":"ProAlgo/strutture/#lista-collegata","text":"La lista \u00e8 una struttura in cui gli elementi non sono contigui, quindi \u00e8 richiesto un modo per accedere al successivo (ed in caso al precedente). Lettura, inserimento, modifica e cancellazioni sono quasi banali e possono essere resi circolari (struttura ad anello. )","title":"Lista collegata"},{"location":"ProAlgo/strutture/#grafi","text":"Un grafo \u00e8 una struttura dati visibile come una coppia di nodi ed archi.","title":"Grafi"},{"location":"ProAlgo/strutture/#algoritmi-di-ricerca","text":"In un grafo, per effettuare una ricerca, esistono numerose soluzioni. Lo scopo pu\u00f2 voler essere quello di mappare il grafo o cercare un nodo con un valore specifico.","title":"Algoritmi di ricerca"},{"location":"ProAlgo/strutture/#bfs","text":"L'algoritmo di Breadth First Search si occupa di ricercare prima i figli","title":"BFS"},{"location":"ProAlgo/strutture/#dfs","text":"La DFS (Depth First Search) esamina ogni figlio in profondit\u00e0 ed in maniera ricorsiva, per poi procedere con gli altri. Nel farlo, permette di costruire un \"albero\" (ovvero un DAG) ed eventuali archi che creano pi\u00f9 path per giungere ad un nodo. Questi archi sono: Tree Un arco di tipo tree \u00e8 visto come un \"normale\" nodo dell'albero. Back Un Back edge \u00e8 un arco che permette di arrivare ad un antenato del nodo, rispetto agli archi di tipo tree Forward Un Forward edge \u00e8 un arco che permette di arrivare ad un discendente attraversando meno archi rispetto a quanto si farebbe utilizzando un tree edge Cross Un Cross edge \u00e8 un arco che permette di attraversare l'albero per arrivare ad un fratello o ai suoi antenati/discendenti","title":"DFS"},{"location":"ProAlgo/strutture/#topological-sort-dag-dfs","text":"Il topological sort \u00e8 un algoritmo basato su DFS che permette di stabilire un ordine delle dipendenze (ed \u00e8 infatti usato anche da software come package managers). Permette di fare un'ordinamento secondo la tipologia, seguendo l'ordine di scoperta dei nodi fatto dalla DFS","title":"Topological sort (DAG) DFS"},{"location":"ProAlgo/strutture/#albero","text":"Un albero \u00e8 una struttura dati che si pu\u00f2 immaginare come un albero al contrario: in alto abbiamo la radice e sotto troviamo i figli Ogni nodo (o pallino) pu\u00f2 far parte o meno di un albero foresta Relazione gerarchica (padre, figlio, fratello, progenitore) foglie propriet\u00e0 strutturali","title":"Albero"},{"location":"ProAlgo/strutture/#albero-binario","text":"Un albero binario \u00e8 una struttura definita su un insieme di nodi Pu\u00f2 non contenere alcun nodo (albero vuoto), pu\u00f2 contenere un solo nodo detto radice, e pu\u00f2 contenere un sotto albero sinistro o destro della radice. In memoria \u00e8 rappresentato con nodo padre, il payload (quindi ad esempio chiave e valore), e puntatori al sotto albero sinistro e destro. Pu\u00f2 essere visitato in 3 diversi modi: Visita anticipata Prima viene visitato il nodo, e poi i suoi sotto alberi Visita simmetrica Prima viene visitato il figlio sinistro, a seguire il nodo, ed infine il figlio desto Visita posticipata Prima viene visitato il figlio sinistro, poi il figlio destro e solo infine il nodo Per quanto riguarda le propriet\u00e0 strutturali, possiamo facilmente individuare questi: Al pi\u00f9 \\(2^l\\) nodi al livello l Profondit\u00e0 la pi\u00f9 di \\(2^{d+1}-1\\) nodi Un albero con n nodi ha profondit\u00e0 almeno \\(\\log_2(n+1)-1\\) Ci sono diversi tipi di forme che possono assumere: Completo Tutte le foglie sono allo stesso livello e tutti i nodi interni hanno grado 2 Completamente bilanciato: \u00c8 un albero completo con tutte le foglie alla stessa profondit\u00e0 Bilanciato \u00c8 un albero di dimensione n ed altezza h, se \\(h=O(log(n))\\) Completo a sinistra/Quasi completo \u00c8 un albero completo tranne per l'ultimo, dove le foglie vanno da sinistra a destra. La prima non-foglia in un array si trova a \\(\\lower {\\frac n 2}\\) 1-bilanciato (bilanciato in altezza): L'altezza dei sotto-alberi destro e sinistro differiscono al pi\u00f9 di un'unit\u00e0 Il costo di una ricerca \u00e8 O(h) (in quanto per farlo tracciamo un percorso dalla radice alla nodo scendendo esclusivamente a sinistra o destra). Attenzione sul fatto che non essendoci un vincolo che mantiene l'albero bilanciato, h pu\u00f2 diventare lineare. \\(\\forall \\text{nodo x nell'albero T}\\) \\(\\forall \\text{nodo y nel sottoalbero sinistro}\\) \\(y.key < x.key\\) \\(\\forall \\text{nodo z nel sottoalbero destro}\\) \\(z.key > x.key\\) L'operazione di ricerca \\(T(n) = O(h)\\) , dove \\(h=O(log(n))\\) al caso medio/ottimo e \\(h=(O(n))\\) al caso pessimo. Anche le operazioni per trovare il valore minimo e massimo hanno tempo O(h): Minimo: Si ricerca il nodo pi\u00f9 profondo a sinistra senza figlio sinistro Massimo: Si ricerca il nodo pi\u00f9 profondo a destra senza figlio destro L'operazione successore (trovare il nodo y con la pi\u00f9 piccola chiave maggiore di x) invece \u00e8 un po' pi\u00f9 complicato: Se il nodo ha un sotto albero destro, si trova il minimo tra i nipoti destri Altrimenti, si trova l'antenato pi\u00f9 vicino ad x, ovvero che contiene x nel suo sottoalbero sinistro Anche questo ha come complessit\u00e0 \\(T(n)=O(h)\\) Notare che non ci serve comparare le chiavi, in quanto facciamo uso della propriet\u00e0 strutturale","title":"Albero binario"},{"location":"ProAlgo/strutture/#inserimento","text":"I nuovi nodi sono aggiunti come foglie. La complessit\u00e0 \u00e8 quindi \\(T(n)=O(h)\\)","title":"Inserimento"},{"location":"ProAlgo/strutture/#cancellazione","text":"Se il nodo \u00e8 una foglia, \u00e8 sufficiente eliminare la foglia Se il nodo \u00e8 interno ed ha un figlio, si collegano padre e figlio del nodo Se il nodo ha due figli, si sostituisce il successore (la foglia dx) con il nodo, e si elimina il nodo","title":"Cancellazione"},{"location":"ProAlgo/strutture/#2-3-alberi","text":"Un albero binario pu\u00f2 essere complicato da mantenere bilanciato, e si pu\u00f2 formare facilmente una catena, che fa deteriorare le prestazioni. Le propriet\u00e0 strutturali di un 2-3 albero puntano a mantenere un albero bilanciato: Ogni nodo ha almeno due figli e massimo tre Tutti i cammini radice-foglia hanno la stessa lunghezza (quindi \\(\\log_2(n) \\le n \\le log_3(n)\\) ) I dati sono tutti quanti memorizzati nelle foglie (in ordine crescente da sinistra verso destra) I noti intermedi contengono il massimo valore raggiungibile andando a sinistra (ed al centro nel caso il nodo abbia tre figli) Si usano i 2-3 alberi in quanto hanno prestazioni superiori agli ABR, che risultano essere lineari su h","title":"2-3 alberi"},{"location":"ProAlgo/strutture/#ricerca","text":"La ricerca ha un tempo di \\(\\Theta(log(n))\\) , in quanto, grazie alle propriet\u00e0 strutturali, tutti i percorsi radice-foglia hanno uguale lunghezza.","title":"Ricerca"},{"location":"ProAlgo/strutture/#inserimento_1","text":"L'inserimento di un nuovo valore si basa su alcuni step: Provo a cercare il valore nell'albero, per trovare la posizione pi\u00f9 adatta Se il nodo andrebbe in un nodo con due figli, si crea un nuovo figlio e si inserisce il valore del secondo figlio nel padre. Se il nodo ha tre figli, si effettua l'operazione di split : Viene creato un nuovo nodo con i primi due figli e si aggiunge il valore al nodo appena trovato. Se il genitore ha 4 figli si effettua una chiamata ricorsiva all'operazione di split La complessit\u00e0 \u00e8 \\(O(log(n))\\)","title":"Inserimento"},{"location":"ProAlgo/strutture/#eliminazione","text":"Si riceraca il valore da eliminare nell'albero. Una volta trovato, se rimane un solo figlio, si deve ricorrere all'operazione di merge (che \u00e8 l'opposto dell'operazione di split), che consiste nell'unire due fratelli","title":"Eliminazione"},{"location":"ProAlgo/strutture/#heap","text":"Albero binario quasi completo e in cui ogni nodo interno ha un valore maggiore uguale o minore uguale rispetto ai suoi due figli (in caso di heap di massimo o di minimo). Le chiavi di ogni nodo devono chiaramente essere confrontabili. L'operazione di heapsort \u00e8 un'operazione ricorsiva che permette di ordinare in un heap un array non ordinato, partendo dall'assunzione che i sotto-alberi siano heap. Operazioni (ogni operazione aspira ad essere \\(log(n)\\) ): Deletion di una foglia: Si cancella la foglia di un nodo interno: si fa il replace dell'ultima foglia con il nodo, si elimina il nodo e si fa un reheap Insertion si aggiunge il valore come foglia e si sostituisce il padre con la foglia finch\u00e9 l'albero non \u00e8 bilanciato (swap-reheapification) Edit Si modifica il valore della foglia e si controlla che l'albero sia bilanciato Deletion ed insertion insieme Implementabile come array: Le celle sono ordinate a partire dal primo livello, da sinistra verso destra Il genitore di un nodo i si trova attraverso la formula \\(\\lower {\\frac {i-1}{2}}\\) I figli di un nodo i sono i nodi \\(2i+1\\) e \\(2i+2\\) Ecco un esempio di operazioni che \u00e8 possibile fare su un heap di massimo ed il loro costo Operazione Costo Max heapify O(log n) Build max heap O(n) Heapsort O(n log n) Max-heap insert O(log n) Heap extract max O(log n) Heap increase key O(log n) Heap maximum O(1)","title":"Heap"},{"location":"ProAlgo/strutture/#max-heapify","text":"La max-heapify \u00e8 un'operazione di ordinamento ricorsiva, che partendo dalle foglie risale l'albero ordinando l'array in un max heap (heap di massimo) Il costo \u00e8 \\(O(h)\\) (dove h \u00e8 l'altezza)","title":"Max heapify"},{"location":"ProAlgo/strutture/#build-max-heap","text":"L'algoritmo chiamato build max-heap ci permette di creare un heap a partire da da un array non ordinato Il costo dell'algoritmo \u00e8 pari al costo dell'heapify moltiplicato per il numero di nodi nel livello: Partendo da un array, tolgo la radice posizionandola come primo elemento nell'array, sposto l'ultima foglia alla radice e bilancio l'albero, quindi ripeto l'operazione. Al termine, avr\u00f2 un array che rappresenta un heap. L'algoritmo ha un costo \\(O(n)\\)","title":"Build max-heap"},{"location":"ProAlgo/strutture/#dizionario","text":"Un dizionario \u00e8 una struttura che permette di memorizzare un insieme dinamico nel tempo. Si basa sul concetto di \"mapping\" chiave-valore (visibile anche come una funzione che dato una certa chiave, che identifica in modo univoco e permette di accedere ad un certo elemento), in maniera simile ad un vocabolario. L'universo delle chiavi \u00e8 chiamato u Le operazioni che permette di effettuare normalmente sono ricerca, inserimento e cancellazione: \\[ \\displaylines{ Ricerca (\\underbrace{S}_{\\text{dizionario}}, \\underbrace{K}_{\\text{chiave}}) = \\begin{cases} x & \\text{t.c. } x.key=k \\\\ NIL & \\text{se S non contiene elementi di chiave k} \\end{cases} \\\\ Insert(S,x) \\qquad S \\from S \\cup\\{x\\} \\\\ Delete(S,x) \\qquad S \\from S \\backslash \\{x\\} } \\] (Nel caso di aggiunta ed eliminazione, x \u00e8 il riferimento da rimuovere) Grande punto di forza di questa struttura dati \u00e8 il tempo richiedo per effettuare le operazioni, che \u00e8 in media costante . La cardinalit\u00e0 di un dizionario ( \\(|S|\\) ) \u00e8 il numero di elementi che S contiene. Questo serve quindi ad individuare la complessit\u00e0 in funzione di n. Se universo di chiavi u \u00e8 totalmente ordinato, \u00e8 possibile effettuare query aggiuntive, come Min(S) (per trovare l'elemento di chiave minima in S), Max(S) (per trovare l'element do chiave massima in S) e Successore(S,x) (per trovare l'elemento con la pi\u00f9 piccola chiave maggiore di x.key) I dati in un dizionario sono disposti in un vettore (o una tabella), la cui dimensione cerca di essere proporzionale con il numero di elementi nell'insieme S (ad esempio avendo il vettore il doppio pi\u00f9 grande della cardinalit\u00e0 di elementi in S \\(2 \\cdot |S|\\) ). Per usare la struttura dati, calcoleremo quindi la posizione di ogni elemento di S nel vettore T. Questo calcolo \u00e8 chiamato hashing e ci permette di \"mappare\" l'universo delle chiavi ad una posizione del vettore. \\(dim ~ T = m \\qquad \\underbrace{T[0...m-1]}_{\\text{Vettore da 0 a m}}\\) \\(\\underbrace{h}_{\\text{funzione di hashing}}: U \\to [0,m-1]\\) Possiamo quindi dire che \\(h(k) \\in [0,m-1]\\) Dato un valore x, questo viene memorizzato in \\(T[h(x.key)]=x\\) Propriet\u00e0 della funzione di hashing: Non pu\u00f2 essere iniettiva ( \\(|U| >> m\\) ) Questo implica che pu\u00f2 accadere che si verifichino collisioni. Una collisione si verifica quando chiavi diverse risolvono alla stessa posizione. Deve essere suriettiva (tutto il codominio deve essere coperto) Deve essere facile da calcolare ( \\(O(1)\\) ) Deve avere una distribuzione uniforme: \\(\\forall k \\in U.h(k) \\in [0,m-1]\\) con probabilit\u00e0 \\(\\frac 1 m\\) Deve essere deterministica ( h(k) produce sempre lo stesso valore) Esempio di funzione di hashing Un esempio di funzione di hashing pu\u00f2 essere quello usato dal metodo della divisione. Questo metodo fa uso della funzione di modulo per calcolare la cella sulla quale posizionare un elemento. \\(\\forall k \\in U\\) \\(h(k) = k ~ mod ~ \\underbrace{n}_\\text{numero primo}\\) Usiamo un numero primo per distribuire in modo omogeneo le chiavi nelle celle","title":"Dizionario"},{"location":"ProAlgo/strutture/#il-fattore-di-carico","text":"Il fattore di carico rappresenta il rapporto tra gli elementi inseriti all'interno del dizionario e lo spazio della tabella. \\(\\alpha = \\frac n m = \\frac {|S|} {dim ~ T} = \\frac {\\text{Dimensione dizionario (record)}} {\\text{Dimensione tabella}}\\) In media si cerca di avere un fattore \\(\\alpha = \\frac 1 2\\) , che consente di avere una cella vuota per ogni cella occupata da una lista","title":"Il fattore di carico"},{"location":"ProAlgo/strutture/#la-funzione-di-hashing","text":"Ci sono due modi in cui la funzione di hashing (e quindi l'organizzazione dei dati) pu\u00f2 essere fatta (e i nomi con i quali possono essere conosciuti sono molti): Indirizzamento chiuso/hashing perfetto Indirizzamento aperto/open hash/liste di trabocco/concatenamento A seconda del tipo di indirizzamento che si sceglie, cambiano i dettagli della struttura. La differenza giace nel come le collisioni vengono gestite e risolte. Esistono diversi tipi di funzione di hashing, tra cui: Hash Uniforme Semplice (HUS): L'HUS (Hash Uniforme Semplice) \u00e8 la funzione di hashing pi\u00f9 semplice, e consiste nella formula che abbiamo visto prima: \\(\\forall k \\in U\\) \\(h(k) = k ~ mod ~ \\underbrace{n}_\\text{numero primo}\\)","title":"La funzione di hashing"},{"location":"ProAlgo/strutture/#open-hash","text":"L'open hash \u00e8 la gestione delle collisioni con concatenamento: questo significa il vettore T \u00e8 un array di liste doppie. Il funzionamento si basa sul calcolare con una funzione di hash l'indice a cui posizionare l'elemento, per poi aggiungere ad una lista (eventualmente vuota) l'elemento in testa. Search \\[ T[j] = \\begin{cases} NIL & \\forall x \\in S . h(x.key) \\ne j \\\\ \\text{indice alla lista doppia contenente tutti gli elementi } x \\in S.h(x.key) = j \\end{cases} \\] \\[ T(n) = \\begin{cases} O(1) & \\text{caso ottimo} \\\\ O(1) & \\text{caso medio} \\\\ O(n) & \\text{caso pessimo} \\\\ \\end{cases} \\] Il caso pessimo fa riferimento al caso in cui tutte le chiavi producono lo stesso hash Insert Inserisce l'elemento x in testa alla lista T[h(x.key)] \\(T(n) = O(1)\\) Delete Rimuove l'elemento x dalla lista T[h(x.key)] -- Dato che in genere (per via del fattore di carico \\(\\alpha = \\frac 1 2\\) ) \\(|T| \\cong 2 \\cdot |S|\\) , che permetterebbe di avere una cella vuota per ogni cella occupata Analisi del tempo del dizionario usando HUS (Hash Uniforme Semplice): Ricerca senza successo In un dizionario con HUS e concatenamento, la ricerca senza successo impiega \\(\\Theta(1+\\alpha)\\) al caso medio: \\(T_{\\text{medio}}(n,m) = \\Theta(1+\\frac n m) = \\Theta(1+\\alpha)\\) Dimostrazione Data la chiave k, accedere alla cella costa O(1). \u00c8 quindi poi necessario effettuare una scansione della lista per cercare l'elemento. La scansione costa quindi O(m) (con m il numero di elementi della lista). Dato HUS, possiamo assumere che gli elementi sono distribuiti uniformemente, quindi ci saranno \\(\\alpha\\) elementi Il numero di ispezioni alla lista \u00e8 \\(\\alpha\\) Ricerca con successo La ricerca richiede al caso medio \\(1+\\frac \\alpha 2 - \\frac {\\alpha} {2n}\\) ispezioni, ovvero \\(T_{\\text{medio}}(n,m) = \\Theta(1+\\alpha)\\) Dimostrazione Calcolata la cella (costante), il numero di ispezioni dipende dal numero di elementi che precedono quello che sto cercando. Dato che ispeziono \\(\\frac {n-i}{m}\\) elementi, ho n elementi su m celle. Il numero di ispezioni al caso medio \u00e8 quindi: \\(\\frac 1 n \\sum^n_{i=1}(1+\\frac{n-i}{m})\\) \\(\\frac 1 n \\sum^n_{i=1}(1)+\\sum^n_{i=1}(+\\frac{n-i}{m})\\) (dividiamo la sommatoria) \\(\\frac 1 n \\cdot n+\\sum^n_{i=1}(+\\frac{n-i}{m})\\) (semplifichiamo la prima sommatoria) \\(1+\\frac{1}{m\\cdot n}\\sum^n_{i=1}(n-i)\\) (semplifichiamo la sommatoria) \\(1+\\frac{1}{m\\cdot n}\\frac{n(n-1)}{2}\\) (semplifichiamo la sommatoria ai primi n-1 naturali) \\(1+\\frac{1}{m}\\frac{n-1}{2}\\) (semplifichiamo le n) \\(1+\\frac{n-1}{2m}\\) (ricordiamo che \\(m=\\frac n \\alpha\\) ) \\(1+\\frac{n}{2m} - \\frac{1}{2m}\\) (dividiamo la frazione) \\(1+\\frac{\\alpha}{2} - \\frac{1}{2\\cdot \\frac n \\alpha}\\) (Sostituiamo m ed \\(\\alpha\\) , \\((m=\\frac n \\alpha)\\) ) \\(1+\\frac{\\alpha}{2} - \\frac{1}{2\\cdot \\frac n \\alpha}\\) Pro e Contro dell'hashing con indirizzamento aperto Pro: Preferibile in strutture che ricevono molte writes Contro: Spazio non costante Ricerca degli elementi (che diventa \\(O(m)\\) , con m gli elementi nella lista)","title":"Open hash"},{"location":"ProAlgo/strutture/#closed-hashing","text":"Il closed hashing si preoccupa di memorizzare il valore non su una lista ma direttamente nella cella del vettore. Le collisioni sono gestite modificando la sequenza di ispezione, che quando una cella \u00e8 occupata, permette di scegliere una posizione \"successiva\". In questo caso il fattore di carico \\(\\frac {\\text{elementi}}{\\text{celle}} = \\frac n m = \\alpha \\le 1\\) , che significa che ci sono sempre pi\u00f9 celle disponibili che elementi memorizzati. La funzione di hashing sar\u00e0 quindi diversa: \\(h:\\mathcal U \\times [0,m-1] \\to [0, m-1]\\) Come vediamo, c'\u00e8 il prodotto cartesiano tra l'universo delle chiavi e un intero minore uguale al numero di celle nell'array (che \u00e8 possibile vedere come tutti i possibili tentativi di mettere una chiave nell'universo nell'array). Notare come la funzione non ritorna un numero, ma una sequenza . h associa una sequenza di ispezione, ovvero un ordine che deve essere seguito nell'esaminare le celle per una certa chiave k. La sequenza avr\u00e0 quindi un aspetto del genere per una stessa chiave k: \\(\\anglebr{h(k,0), h(k,1), ..., h(k, m-1)}\\) La sequenza di ispezione deve essere una permutazione dei primi n interi Insert \\(T_{\\text{ottimo}}=\\Theta(1)\\) \\(T_{\\text{pessimo}}=\\Theta(n)=\\Theta(m)\\) \\(T_{\\text{medio}}=O(\\frac{1}{1-\\alpha}\\) (con \\(\\alpha \\le 1\\) ) Lo pseudocodice per un inserimento pu\u00f2 assomigliare a qualcosa del genere: i = tentativi = 0 for j = h ( k , i ) if ( T [ j ] == nil ) T [ j ] = k return j if ( ++ i + 1 > n ) : return \"Overflow\" Search Segue la stessa sequenza per l'inserimento Se una cella \u00e8 vuota, k non \u00e8 presente \\(T_{\\text{ottimo}}=\\Theta(1)\\) \\(T_{\\text{pessimo}}=\\Theta(n)\\) \\(T_{\\text{medio}}=\\begin{cases} O(\\frac{1}{1-n}) \\\\ O(\\frac 1 \\alpha \\ln(\\frac{1}{1-\\alpha})) \\end{cases}\\) i = 0 for j = h ( k , i ) if ( T [ j ] == nil ) return nil if ( T [ j ] == k ) return k if ( ++ i + 1 >= n ) : return \"Overflow\" Delete L'eliminazione deve essere logica o virtuale, perch\u00e9 altrimenti la ricerca, trovando una cella vuota, andrebbe in halt La deletion rende quindi la cella libera per l'inserimento ma occupata per la ricerca. Questo rende necessaria una modifica all'algoritmo di inserimento, che deve controllare se la cella \u00e8 stata eliminata ed eventualmente sovrascrivere il valore. Analisi del tempo del dizionario : Assunzioni: \\(\\alpha = \\frac n m < 1\\) (esiste almeno una cella libera) Non ci sono state cancellazioni Facciamo uso di hashing uniforme (la sequenza di ispezione di ogni chiave \u00e8 una permutazione delle celle di pari probabilit\u00e0) Conteremo inoltre il numero di ispezioni, non il tempo Ricerca senza successo Il numero di accessi in una ricerca senza successo \u00e8 \\(\\le \\frac {1}{1-\\alpha}\\) Dimostrazione Prendendo x come il numero di accessi alla tabella, il valore medio (o atteso) di x \u00e8 la somma dei valori che x pu\u00f2 assumere, moltiplicato per la probabilit\u00e0 di assumere quel valore. Probabilit\u00e0 di fare esattamente gli accessi: \\(\\sum^{\\pin}_{i=1} (i \\cdot Prob[x=1])\\) Probabilit\u00e0 di fare almeno gli accessi: \\(\\sum_i(Prob[x \\ge 1])\\) Possiamo quindi esaminare la probabilit\u00e0 di avere le prime i-1 celle occupate: \\(i=1 \\qquad Pr[x \\ge 1] = 1\\) (\u00e8 sicuro che almeno un accesso lo facciamo) \\(i=2 \\qquad Pr[x \\ge 2] = \\alpha\\) (cIl secondo accesso viene effettuato solo se la prima cella \u00e8 occupata da un'altra chiave) \\(i=3 \\qquad Pr[x \\ge 3] = \\underbrace{\\frac n m}_{\\text{prima cella occupata}} \\cdot \\underbrace {\\frac {n-1}{m-1}}_{\\text{seconda cella occupata}} < \\alpha^2\\) (Che diventa maggiorabile con \\(\\alpha^{i-1}\\) ) Il valore medio del numero di accessi \u00e8 quindi: \\(\\sum^m_{i=1}Pr[x \\ge 1]\\) \\(\\sum^m_{i=1}2^{i-1}\\) \\(\\sum^{m-1}_{i=0}\\alpha^i \\le \\sum_{i=0}\\alpha^i = \\frac {1}{1-\\alpha}\\) Inserimento al caso medio Il numero di accessi in caso di inserimento al caso medio \u00e8 \\(\\le \\frac{1}{1-\\alpha}\\) Si controllano le stesse cella della ricerca senza successo, fermandosi alla prima vuota. | \\(\\alpha\\) |Occupazione array| numero accessi ricerca senza successo| | \\(\\frac{1}{2}\\) |50%| \\(\\frac{1}{1-\\frac 1 2} \\to 2\\) | | \\(\\frac{1}{10}\\) |10%| \\(\\frac{1}{1-\\frac{1}{10}} \\to 1.11\\) | | \\(\\frac{9}{10}\\) |90%| \\(\\frac{1}{1-\\frac{9}{10}} \\to 10\\) | Ricerca con successo Il numero di accessi al caso medio \u00e8 \\(\\le \\frac {1}{\\alpha} ln \\frac{1}{1-\\alpha}\\)","title":"Closed hashing"},{"location":"ProAlgo/strutture/#generazione-sequenza-di-ispezione","text":"Ci sono tre tecniche che vediamo per la generazione di una sequenza di ispezione Scansione lineare Descrizione La scansione lineare dopo aver individuato una cella, basa la permutazione delle celle andando alla cella contigua successiva. \\(h': \\mathcal U \\to [0,1,...,m-1]\\) (idealmente con m numero primo) \\(h(k,i)=(h'(k)+i) mod ~ m\\) con \\(0 \\le i \\le m\\) Pro: Cicliamo la tabella da un punto casuale Contro: Il passo \u00e8 costante (1) Il passo non dipende n\u00e9 da i, n\u00e9 dalla chiave Questo significa che dopo un certo numero di inserimenti, saranno prodotti agglomerati o (cluster primari). Questi cluster sono lunghi tratti di celle adiacenti occupate Quando si colpisce uno di questi cluster, in primo luogo \u00e8 necessario scansionare l'intero cluster. In aggiunta, si \"appende\" l'elemento al cluster, facendolo crescere Una collisione genera cluster secondari Un cluster secondario si verifica quando chiavi diverse producono sequenze di ispezioni identiche Esistono \\(n\\) possibili sequenze, contro \\(n!\\) permutazioni ideali Scansione quadratica Descrizione La scansione quadratica vuole risolvere il problema del cluster primario che presenta la scansione lineare. Questo problema viene risolto avendo un passo diverso da uno ogni volta. Continuiamo ad usare la funzione vista per la scansione lineare. Con m numero primo, \\(C_1, C_2\\) \\(C_2 \\ne 0\\) \\(h(k,i)=(h'(k)+C_1 \\cdot i + C_2 \\cdot i^2) mod ~ m\\) Abbiamo quindi che il punto di partenza \u00e8 casuale ed il passo dipende da i. Il numero di sequenza \u00e8 n (il passo rimane lo stesso per tutte le sequenze), e non abbiamo ancora risolto il problema dei cluster secondari, dato che la sequenza dipende ancora solamente dal punto iniziale Doppio hashing Descrizione Il doppio hash mira a risolvere anche il problema del cluster secondario. Il problema viene risolto adottando due funzioni hash: \\(h_1(k) = k ~ mod ~ m\\) \\(h_2(k) = k ~ mod ~ n < m\\) \\(h(k,i) = (h_1(k) + i \\cdot h_2(k)) ~ mod ~ m\\) Abbiamo quindi che il punto di partenza dipende solo dalla chiave, ed anche il passo di scansione dipende dalla chiave. m \u00e8 un numero primo, \\(h_2(k)\\) \u00e8 un coprimo, quindi il massimo comune mulitplo tra i due, essendo \\(h_2(k) < m\\) \u00e8 uno, quindi si effettua una permutazione di tutti gli elementi Pro: Non abbiamo cluster primari Non abbiamo cluster secondari (i passi hanno distanza \\(h_2(k)\\) ) Prestazioni simili alla teoria (quasi ideali) Contro: Le permutazioni non sono \\(n!\\) ma \\(n^2\\) , che \u00e8 comunque meglio delle opzioni viste fin'ora.","title":"Generazione sequenza di ispezione"},{"location":"ProAlgo/strutture/#dizionari-su-alberi-di-ricerca-abr","text":"\u00c8 possibile implementare i dizionari anche su un albero binario. Le chiavi sono disposte per rispettare la propriet\u00e0 di ricerca. Tutti i nodi minori chiave k sono a sx e tutti i maggiori a destra. Questa propriet\u00e0 permette di avere una sequenza ordinata delle chiavi attraverso una visita simmetrica dell'albero.","title":"Dizionari su alberi di ricerca (ABR)"},{"location":"ProAlgo/strutture/#comparazione-delle-applicazioni","text":"Operazione/Struttura Ricerca senza successo Inserimento cancellazione Minimo Build Spazio Hash con concatenamento \\(O(n)\\) \\(\\Theta(1+\\alpha)\\) O(1) \\(\\Theta(1)\\) \\(\\Theta(max(n,m))\\) \\(\\Theta(n)\\) \\(\\Theta(max(n,m))\\) Hash aperto \\(O(n)\\) \\(O(\\frac{1}{1-\\alpha})\\) \\(O(n)\\) \\(O(\\frac{1}{1-\\alpha})\\) \\(\\Theta(1)\\) \\(\\Theta(m)\\) \\(\\Theta(n^2)\\) \\(\\Theta(\\frac{n}{1-\\alpha^2})\\) \\(\\Theta(m)\\) ABR O(h) O(h) O(h) O(h) O(n log(n)) \\(\\Theta(n)\\) ABR Bilanciato O(h) O(h) O(h) O(h) O(n log(n)) \\(\\Theta(n)\\) Heap O(h) O(log(n))=O(h) O(log n) \\(\\Theta(1)\\) \\(\\Theta(n)\\) \\(\\Theta(n)\\) \\(\\Theta(n)\\) Looking at you, javascript \u21a9","title":"Comparazione delle applicazioni"},{"location":"ProAlgo/valutazione/","text":"Valutazione di un algoritmo \u00b6 Analizzare un algoritmo significa predire le risorse che l'algoritmo richieder\u00e0. Si possono predire risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza. Un algoritmo pu\u00f2 essere valutato sulla base di diversi fattori: Correttezza Dimostrazione formale (matematica) Ispezione informale Utilizzo delle risorse Tempo di esecuzione Utilizzo della memoria Altre risorse (e.g. banda) Semplicit\u00e0 Comprensibilit\u00e0 e mantenibilit\u00e0 Nello specifico, il tempo di esecuzione pu\u00f2 dipendere (e pu\u00f2 essere influenzato) da tanti fattori, e a noi interessa un algoritmo pi\u00f9 efficiente, in quanto ci permette di compiere un lavoro in meno tempo Per questo motivo, quando valutiamo un algoritmo dobbiamo definire un modello La correttezza \u00b6 Un algoritmo si dice corretto (rispetto ad una specifica) quando rispetta le specifiche date. Il tipo di specifica pi\u00f9 usata \u00e8 quella funzionale , che tratta l'algoritmo come una funzione e definisce la correttezza se, dati all'algoritmo i valori necessari (e facenti parte del dominio), i valori restituiti rispetteranno la specifica Invariante di ciclo \u00b6 Un modo in cui possiamo dimostrare la correttezza (di una porzione di un algoritmo) \u00e8 mediante l'invariante di ciclo (questo quando si ha a che fare con cicli). Si compone di 3 blocchi, rappresentati la pre-iterazione di un ciclo, l'esecuzione del ciclo e la post-esecuzione. L'invariante di ciclo \u00e8 composta da 3 passaggi: Inizializzazione \u00c8 uno statement che deve essere verificato prima di entrare in un ciclo Mantenimento La condizione di mantenimento si riferisce ad uno statement che deve essere vero alla fine di una singola iterazione del ciclo Terminazione La terminazione \u00e8 una condizione che deve essere vera alla fine del ciclo La macchina astratta \u00b6 La macchina astratta \u00e8 un modello di calcolo su cui \u00e8 possibile fare i conti per astrarre dei dettagli implementativi dell'hardware. Un esempio pu\u00f2 essere la macchina di Von-Neumann Modello RAM - Von-Neumann \u00b6 Il modello RAM si basa sul cercare di creare un modello che possa essere condiviso tra tutti i tipi di computer moderni, evitando tuttavia ogni tipo di ottimizzazione trasparente e non diffusa. Il computer \u00e8 suddiviso in due componenti astratti: memoria e processore. Memoria astratta \u00b6 La memoria astratta \u00e8 un insieme finito di celle contigue di memoria, ciascuna con un indirizzo (locazione) univoco ed un contenuto (valore della cella). Questa struttura permette operazioni di scrittura e lettura. Possiamo rappresentare quindi le operazioni matematicamente, prendendo ad esempio l'operazione di lettura: \\(\\text{memoria } \\sigma: \\underbrace{Loc}_{\\text{Locazione di memoria}} \\to \\underbrace{Val}_{\\text{Valore della cella}}\\) Una delle operazioni pi\u00f9 importante \u00e8 l'assegnamento, che consiste nell'assegnamento. L'assegnamento si preoccupa di scrivere valori all'interno della locazione di memoria Valuta l'espressione a destra dell'operatore (che spesso \u00e8 il simbolo di uguaglianza, = ) nella locazione di memoria rappresentata dalla variabile (o identificatore) a sinistra Processore astratto \u00b6 Il processore astratto permette di fare calcoli e si occupa (virtualmente) di eseguire le operazioni che andiamo a rappresentare poi con le regole di inferenza. Si assume che le operazioni di letture es esecuzione id una computazione o scrittura impieghino una stessa unit\u00e0 di tempo costante. Identificatori ed ambiente \u00b6 Abbiamo parlato poco fa di identificatori, cerchiamo quindi di dare una spiegazione pi\u00f9 formale: Definizione di Identificatore Un'identificatore \u00e8 una sequenza di caratteri (\u00e8 una stringa) e permette di dare nomi alle locazioni (~il loader traduce i nomi in indirizzi fisici~) all'interno di un ambiente. Definizione di Ambiente Un'ambiente \u00e8 una funzione che associa nomi mnemonici alle locazioni Come per la memoria, possiamo rappresentare l'ambiente con una funzione: \\(\\text{ambiente } \\rho: \\underbrace{Id}_{\\text{Identificatore}} \\to Loc\\) Variabili \u00b6 Identificano le locazioni di memoria, il cui contenuto pu\u00f2 essere variato durante l'esecuzione L'istruzione a=b si traduce in \\(\\sigma(\\underbrace{\\rho(a)}_{\\text{Indirizzo}}) = \\underbrace{\\sigma(\\rho(b))}_{\\text{Valore}}\\) Costanti \u00b6 Le costanti sono identificatori che individuano variabili che non cambiano durante l'esecuzione. Nell'ambiente quindi, invece di avere un mapping ad una locazione di memoria, abbiamo direttamente il valore contenuto: \\(\\rho: Id \\to Loc \\cup Var\\) (che significa che dall'ambiente possiamo ottenere sia un valore (nel caso di una variabile) che una locazione di memoria (nel caso di una costante)). Esempio Per valutare l'espressione a = b + pi dove b \u00e8 una variabile e pi \u00e8 una costante, l'espressione risultante sar\u00e0 \\(\\theta(\\rho(a)) = \\theta(\\rho(b)) + \\rho(pi)\\) Categorie sintattiche \u00b6 Dichiarazioni \u00b6 Definiscono gli identificatori quando sono introdotti per la prima volta. Associano gli identificatori ad uan locazione di memoria libera, scrivendo il valore iniziale. Si elaborano per costruire l'ambiente. var x = 4 ; Che si traduce in: \\(\\theta(\\text{new } \\rho(x)) = 4\\) Che viene dall'elaborazione della dichiarazione, che estende l'ambiente \\(\\Delta\\) in \\(\\Delta^I\\) : \\(\\Delta \\vdash_d D: \\Delta^I\\) (che significa che dato un ambiente statico \\(\\Delta\\) , elaborando la dichiarazione D, l'ambiente viene esteso, trasformando l'ambiente statico \\(\\Delta\\) in \\(\\Delta^I\\) ) Comandi \u00b6 I comandi descrivono il cambiamento di stato e modificano la memoria o lo stato delle periferiche. I comandi si ESEGUONO x = y + x ; Si traduce in \\(\\sigma(\\rho(x)) = \\sigma(\\rho(y)) + \\sigma(\\rho(x))\\) , elaborato dalla regola \\(C: \\Delta \\vdash_c C\\) Dato un ambiente \\(\\Delta\\) , eseguendo il comando con i tipi definiti in \\(\\Delta\\) \u00e8 tutto corretto Espressioni \u00b6 Le espressioni rappresentano i valori su cui si opera NON modificano la memoria. Le espressioni si valutano 2 * ( x + y ) Che si traduce in: \\(E: \\Delta \\vdash_e: \\tau\\) Dato un ambiente \\(\\Delta\\) , l'espressione \u00e8 ben formata ed \u00e8 di tipo \\(\\tau\\) Classi di complessit\u00e0 \u00b6 Le classi di complessit\u00e0 ci permettono di categorizzare gli algoritmi in funzione della grandezza dell'input. Il tipo di comparazione che viene fatta \u00e8 molto spannometrica , nel senso che spesso si tende a definire l'ordine di grandezza con cui l'algoritmo cresce, oppure il massimo (o minimo) tempo garantito che l'algoritmo impiegher\u00e0 a fornire una risposta in funzione della grandezza dell'input. Il tutto approssimando il risultato a monomi (quindi ad esempio \\(log(n)\\) , \\(n\\) , \\(n^2\\) , \\(n!\\) , \\(n^n\\) , etc...) Questo tipo di valutazione ci consente di categorizzare gli algoritmi e poterli comparare in semplicit\u00e0. I tipi di categorizzazione pi\u00f9 usati sono spesso limite superiore e limite inferiore. Come si pu\u00f2 intuire dal nome, questi limiti ci permettono di definire un tempo di esecuzione che sicuramente l'algoritmo (rispettivamente) non superer\u00e0 o non migliorer\u00e0. Per questo motivo il limite superiore (conosciuto come Big O notation, o semplicemente O) \u00e8 usato per individuare il costo delle soluzioni. Allo stesso modo, il limite inferiore (conosciuto come \\(\\Omega\\) , o big omega) ci permette di individuare la complessit\u00e0 del problema che stiamo risolvendo. Quindi, per riassumere: Simbolo Lettura Tipo di limite Significato O O-grande Limite superiore asintotico Peggior situazione possibile \\(\\Omega\\) Omega Grande Limite inferiore asintotico Migliore situazione possibile \\(\\Theta\\) Theta Limite asintotico stretto Complessit\u00e0 della soluzione (asintotico si pu\u00f2 leggere come \" per valori che tendono a \\(\\pin\\) \") Big-O \u00b6 Big Omega \u00b6 \\(\\Omega\\) il lower bound, la classe di complessit\u00e0 minima per risolvere il problema, che significa che non \u00e8 possibile risolvere un problema in meno passi. Ad esempio, nel caso di un ordinamento per confronti (ovvero quando si ordinano elementi confrontabili tra di loro), come minimo devo vedere tutti gli n elementi, ma ci\u00f2 non pu\u00f2 bastare, perch\u00e9 devo anche confrontarli tra di loro. Dimostrare che una soluzione \u00e8 \"ottima\" equivale a dimostrare un lower bound. Ci\u00f2 significa che qualunque soluzione S corretta non pu\u00f2 impiegare meno tempo del lower bound. Theta \u00b6 Relazioni di ricorrenza \u00b6 Complessit\u00e0 della ricorsione \u00b6 L'approccio Divide-and-conquer \u00b6 Il divide-et-impera \u00e8 un paradigma di programmazione ricorsiva. Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera ricorsiva fino a generare una soluzione per il problema originale La ricorsione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo ricorsivo Si dice algoritmo ricorsivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso ricorsivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato. Analisi degli algoritmi divide-and-conquer \u00b6 Quando un algoritmo effettua una chiamata ricorsiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Nell'esempio sotto riportato, abbiamo che T(n) \u00e8 il tempo di esecuzione del programma. La forma dell'equazione di un algoritmo dividi-et-impera \u00e8 la seguente: \\[ T(n) = \\begin{cases} C & \\text{ se } n \\le k \\\\ \\underbrace{D(n)}_{\\text{Dividi}} + \\underbrace{\\sum^{h}_{i = 1} T(n_i)}_{\\text{impera}} + \\underbrace{C(n)}_{\\text{combina}} & \\text{ se } n > k \\end{cases} \\] Ovvero, semplificando: \\[ T(n) = \\begin{cases} \\Theta(1) & \\text{ se } n \\le k \\\\ aT(\\frac n b) + D(n) + C(n) & \\text{ se } n > k \\end{cases} \\] In questo caso a \u00e8 il numero di sottoproblemi, b \u00e8 la dimensione dei sottoproblemi, D(n) \u00e8 il costo della divisione dei sottoproblemi e C(n) \u00e8 il costo della combinazione dei sottoproblemi. Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metodo di sostituzione Il metodo di sostituzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem Metodo di sostituzione \u00b6 Albero di ricorrenza \u00b6 Il master theorem \u00b6 Il master theorem \u00e8 un procedimento che permette di valutare attraverso una formula un'equazione di ricorrenza, risolvendola molto velocemente, senza necessit\u00e0 di alberi. L'equazione deve essere della forma \\(aT(\\frac{n}{b}) + f(n)\\) con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema (che \u00e8 maggiore di uno, altrimenti la complessit\u00e0 non diminuisce con le iterazioni) ed infine \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi L'idea base teorema si basa sul comparare due funzioni e scegliere quella che cresce pi\u00f9 velocemente (che tende a vincere): \\[ n^{log_b(a)} \\text { vs } f(n) \\] Dove a , b ed f(n) sono gli stessi parametri che troviamo nell'equazione di ricorrenza. Ci sono quindi 3 possibili casi, quando si comparano le due funzioni: \\(n^{log_b(a)} > f(n)\\) (vince \\(n^{log_b(a)}\\) ) In questo caso \\(f(n) = O(n^{log_b(a) - \\epsilon}) . \\epsilon > 0\\) ( f(n) ha come limite superiore (big O) la funzione \\(n^{log_b(a) - \\epsilon}\\) per un \\(\\epsilon\\) maggiore di 0). Questo significa che f(n) cresce polinomialmente 1 pi\u00f9 lentamente rispetto a \\(n^{log_b(a)}\\) (e quindi elevando f(n) a qualche termine sarebbe possibile \"equiparare le velocit\u00e0\") La soluzione all'equazione di ricorrenza \u00e8 quindi \\(T(n) = \\Theta(n^{log_b(a)})\\) \\(n^{log_b(a)} < f(n)\\) (vince \\(f(n)\\) ) Questo significa che \\(f(n) = \\Omega(n^{log_b (a) + \\epsilon}). \\epsilon > 0\\) (che significa che \\(f(n)\\) cresce pi\u00f9 velocemente di un fattore \\(n^\\epsilon\\) ). Questa condizione tuttavia richiede una seconda clausola: la condizione di continuit\u00e0 . \\(a\\cdot f(\\frac n b) \\le c \\cdot f(n)\\) e \\(c < 1 \\land n > n_0. T(n) = O(f(n))\\) Questa condizione serve per assicurarsi che la funzione cresca molto pi\u00f9 velocemente anche per una frazione del risultato, rispetto ad una frazione del dominio (il numero in input, per numeri abbastanza grandi). Ad esempio, prendendo \\(a=2\\) , \\(b=2\\) , \\(c=0.5\\) e \\(f(n) = n^3\\) , per \\(n=6\\) avremmo \\(2\\cdot f(\\frac 6 2) \\le \\frac {f(6)} {2}\\) e quindi \\(2\\cdot3^3 \\le \\frac {6^3} {2} = 54 \\le 108\\) In questo caso la soluzione \u00e8 \\(T(n) = O(f(n))\\) \\(n^{log_b(a)} = f(n)\\) (sono uguali) Infine, \\(f(n) = \\Theta(n^{log_b(a)} \\cdot log^k(n)\\) con \\(k \\ge 0\\) Questo significa che \\(f(n)\\) e \\(n^{log_b(a)}\\) crescono allo stesso modo. Il che significa \\(T(n) = \\Theta(n^{log_b(a)} log^{k+1} (n))\\) Dimostrazione del master theorem Da fare... Esempi \u00b6 Algoritmi \u00b6 Il quicksort \u00b6 Il quicksort \u00e8 un algoritmo ricorsivo di ordinamento di complessit\u00e0 \\(O(n \\log n)\\) che basa il suo funzionamento sul concetto di pivot. L'idea su cui si basa \u00e8 quella di dividere in due l'array, mettendo a sinistra tutti gli elementi pi\u00f9 piccoli del pivot e a destra quelli pi\u00f9 grandi Si sceglie il cos\u00ec detto \"pivot\" (ad esempio l'ultimo elemento dell'array) Si cicla l'array, tenendo in mente due puntatori, uno che rappresenta l'iteratore del ciclo e l'altro che serve per tenere a mente dove l'array si \"divide\" tra i valori pi\u00f9 piccoli e pi\u00f9 grandi del pivot Ad ogni iterazione, si controlla se l'elemento dell'array \u00e8 pi\u00f9 piccolo o pi\u00f9 grande del pivot. Se \u00e8 pi\u00f9 grande, non succede nulla. Se invece l'elemento \u00e8 pi\u00f9 piccolo, viene incrementato il puntatore che \"divide\" i valori dell'array, indicando che il che il nuovo elemento \u00e8 pi\u00f9 piccolo del pivot. Si scambiano poi i valori corrispondenti ai due puntatori (quello che dice a che valore punta il ciclo e quello che rappresenta la met\u00e0 dell'array inferiore). In questo modo, viene sostituito il valore pi\u00f9 piccolo del pivot, mantenendo la met\u00e0 dell'array pi\u00f9 piccola del pivot. A fine iterazione, si avr\u00e0 che una parte dell'array sar\u00e0 pi\u00f9 grande del pivot, e l'altra sar\u00e0 pi\u00f9 piccola. A questo punto si sostituisce la cella successiva all'ultimo valore pi\u00f9 piccolo dell'array con il pivot e si riesegue l'algoritmo sulle due met\u00e0 dell'array. Un \"avversario\" potrebbe \"rovinare\" l'algoritmo mettendo come ultimo elemento (che usiamo come pivot) l'elemento pi\u00f9 grande o pi\u00f9 piccolo dell'array. Possiamo sopperire a questo problema sostituendo una cella a caso dell'array con l'ultima, randomizzando il pivot. Il sorting lineare \u00b6 Come detto, dimostrare che una soluzione \u00e8 ottima equivale a dimostrare un lower bound. Nel caso del sorting lineare, abbiamo un lower bound pari a \\(O(n)\\) (con N il numero degli elementi nell'array). Questo perch\u00e9 se ci fossero meno di n elementi, sarebbe possibile inserire l'elemento che si sta ricercando per fare il sorting nella cella che non verrebbe controllata. In genere, quando si ha un'operazione di sorting, \u00e8 impossibile averla in tempo lineare. Questo perch\u00e9 l'albero dei confronti ha n! foglie, ed \u00e8 necessario confrontare gli elementi per poter ordinare, che ci fa scegliere le diverse branches dell' albero dei confronti . \u00c8 possibile tuttavia ordinare senza fare confronti , basandosi sulle propriet\u00e0 degli oggetti da ordinare. Esempio Dato un array di n interi senza ripetizioni ed il suo massimo, rende possibile ricreare l'array. Dato un array di n interi (ma con ripetizioni), \u00e8 possibile scansionare una volta l'array e poi inserire le ripetizioni in un secondo array (sempre dato il suo massimo). Questo algoritmo si chiama counting sort, che ha complessit\u00e0 O(n+k) (dove n \u00e8 il numero di elementi dell'array e k \u00e8 il valore massimo). Senza avere questi constraints, \u00e8 necessario ricorrere alle comparazioni Ordinamento stabile Un algoritmo di ordinamento \u00e8 detto stabile quando preserva l'ordine iniziale tra due elementi con la stessa chiave Ad esempio Heapsort e Quicksort non sono stabili in quanto \"mescolano\" l'ordine. Il radix sort \u00e8 un algoritmo di ordinamento basato su MSB (Most Significant Bit, bit con importanza maggiore) ed un algoritmo di ordinamento stabile Viene usato per ordinare e parte dal bit meno significativo, per poi salire (dal meno significativo al pi\u00f9 significativo). Si pu\u00f2 quindi assumere per induzione che ad ogni passo (diverso dal passo base) tutte le cifre di \"indice\" minore sono ordinate. Se due cifre sono uguali, si ignorano, altrimenti si calcola l'ordine attraverso un algoritmo stabile (con una performance di O(n)). Una funzione cresce in modo polinomialmente differentemente quando la \"velocit\u00e0 di crescita\" differisce di un polinomio (o un monomio). Un polinomio \u00e8 un'espressione della forma \\(a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0\\) . \u21a9","title":"Valutazione di un algoritmo"},{"location":"ProAlgo/valutazione/#valutazione-di-un-algoritmo","text":"Analizzare un algoritmo significa predire le risorse che l'algoritmo richieder\u00e0. Si possono predire risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza. Un algoritmo pu\u00f2 essere valutato sulla base di diversi fattori: Correttezza Dimostrazione formale (matematica) Ispezione informale Utilizzo delle risorse Tempo di esecuzione Utilizzo della memoria Altre risorse (e.g. banda) Semplicit\u00e0 Comprensibilit\u00e0 e mantenibilit\u00e0 Nello specifico, il tempo di esecuzione pu\u00f2 dipendere (e pu\u00f2 essere influenzato) da tanti fattori, e a noi interessa un algoritmo pi\u00f9 efficiente, in quanto ci permette di compiere un lavoro in meno tempo Per questo motivo, quando valutiamo un algoritmo dobbiamo definire un modello","title":"Valutazione di un algoritmo"},{"location":"ProAlgo/valutazione/#la-correttezza","text":"Un algoritmo si dice corretto (rispetto ad una specifica) quando rispetta le specifiche date. Il tipo di specifica pi\u00f9 usata \u00e8 quella funzionale , che tratta l'algoritmo come una funzione e definisce la correttezza se, dati all'algoritmo i valori necessari (e facenti parte del dominio), i valori restituiti rispetteranno la specifica","title":"La correttezza"},{"location":"ProAlgo/valutazione/#invariante-di-ciclo","text":"Un modo in cui possiamo dimostrare la correttezza (di una porzione di un algoritmo) \u00e8 mediante l'invariante di ciclo (questo quando si ha a che fare con cicli). Si compone di 3 blocchi, rappresentati la pre-iterazione di un ciclo, l'esecuzione del ciclo e la post-esecuzione. L'invariante di ciclo \u00e8 composta da 3 passaggi: Inizializzazione \u00c8 uno statement che deve essere verificato prima di entrare in un ciclo Mantenimento La condizione di mantenimento si riferisce ad uno statement che deve essere vero alla fine di una singola iterazione del ciclo Terminazione La terminazione \u00e8 una condizione che deve essere vera alla fine del ciclo","title":"Invariante di ciclo"},{"location":"ProAlgo/valutazione/#la-macchina-astratta","text":"La macchina astratta \u00e8 un modello di calcolo su cui \u00e8 possibile fare i conti per astrarre dei dettagli implementativi dell'hardware. Un esempio pu\u00f2 essere la macchina di Von-Neumann","title":"La macchina astratta"},{"location":"ProAlgo/valutazione/#modello-ram-von-neumann","text":"Il modello RAM si basa sul cercare di creare un modello che possa essere condiviso tra tutti i tipi di computer moderni, evitando tuttavia ogni tipo di ottimizzazione trasparente e non diffusa. Il computer \u00e8 suddiviso in due componenti astratti: memoria e processore.","title":"Modello RAM - Von-Neumann"},{"location":"ProAlgo/valutazione/#memoria-astratta","text":"La memoria astratta \u00e8 un insieme finito di celle contigue di memoria, ciascuna con un indirizzo (locazione) univoco ed un contenuto (valore della cella). Questa struttura permette operazioni di scrittura e lettura. Possiamo rappresentare quindi le operazioni matematicamente, prendendo ad esempio l'operazione di lettura: \\(\\text{memoria } \\sigma: \\underbrace{Loc}_{\\text{Locazione di memoria}} \\to \\underbrace{Val}_{\\text{Valore della cella}}\\) Una delle operazioni pi\u00f9 importante \u00e8 l'assegnamento, che consiste nell'assegnamento. L'assegnamento si preoccupa di scrivere valori all'interno della locazione di memoria Valuta l'espressione a destra dell'operatore (che spesso \u00e8 il simbolo di uguaglianza, = ) nella locazione di memoria rappresentata dalla variabile (o identificatore) a sinistra","title":"Memoria astratta"},{"location":"ProAlgo/valutazione/#processore-astratto","text":"Il processore astratto permette di fare calcoli e si occupa (virtualmente) di eseguire le operazioni che andiamo a rappresentare poi con le regole di inferenza. Si assume che le operazioni di letture es esecuzione id una computazione o scrittura impieghino una stessa unit\u00e0 di tempo costante.","title":"Processore astratto"},{"location":"ProAlgo/valutazione/#identificatori-ed-ambiente","text":"Abbiamo parlato poco fa di identificatori, cerchiamo quindi di dare una spiegazione pi\u00f9 formale: Definizione di Identificatore Un'identificatore \u00e8 una sequenza di caratteri (\u00e8 una stringa) e permette di dare nomi alle locazioni (~il loader traduce i nomi in indirizzi fisici~) all'interno di un ambiente. Definizione di Ambiente Un'ambiente \u00e8 una funzione che associa nomi mnemonici alle locazioni Come per la memoria, possiamo rappresentare l'ambiente con una funzione: \\(\\text{ambiente } \\rho: \\underbrace{Id}_{\\text{Identificatore}} \\to Loc\\)","title":"Identificatori ed ambiente"},{"location":"ProAlgo/valutazione/#variabili","text":"Identificano le locazioni di memoria, il cui contenuto pu\u00f2 essere variato durante l'esecuzione L'istruzione a=b si traduce in \\(\\sigma(\\underbrace{\\rho(a)}_{\\text{Indirizzo}}) = \\underbrace{\\sigma(\\rho(b))}_{\\text{Valore}}\\)","title":"Variabili"},{"location":"ProAlgo/valutazione/#costanti","text":"Le costanti sono identificatori che individuano variabili che non cambiano durante l'esecuzione. Nell'ambiente quindi, invece di avere un mapping ad una locazione di memoria, abbiamo direttamente il valore contenuto: \\(\\rho: Id \\to Loc \\cup Var\\) (che significa che dall'ambiente possiamo ottenere sia un valore (nel caso di una variabile) che una locazione di memoria (nel caso di una costante)). Esempio Per valutare l'espressione a = b + pi dove b \u00e8 una variabile e pi \u00e8 una costante, l'espressione risultante sar\u00e0 \\(\\theta(\\rho(a)) = \\theta(\\rho(b)) + \\rho(pi)\\)","title":"Costanti"},{"location":"ProAlgo/valutazione/#categorie-sintattiche","text":"","title":"Categorie sintattiche"},{"location":"ProAlgo/valutazione/#dichiarazioni","text":"Definiscono gli identificatori quando sono introdotti per la prima volta. Associano gli identificatori ad uan locazione di memoria libera, scrivendo il valore iniziale. Si elaborano per costruire l'ambiente. var x = 4 ; Che si traduce in: \\(\\theta(\\text{new } \\rho(x)) = 4\\) Che viene dall'elaborazione della dichiarazione, che estende l'ambiente \\(\\Delta\\) in \\(\\Delta^I\\) : \\(\\Delta \\vdash_d D: \\Delta^I\\) (che significa che dato un ambiente statico \\(\\Delta\\) , elaborando la dichiarazione D, l'ambiente viene esteso, trasformando l'ambiente statico \\(\\Delta\\) in \\(\\Delta^I\\) )","title":"Dichiarazioni"},{"location":"ProAlgo/valutazione/#comandi","text":"I comandi descrivono il cambiamento di stato e modificano la memoria o lo stato delle periferiche. I comandi si ESEGUONO x = y + x ; Si traduce in \\(\\sigma(\\rho(x)) = \\sigma(\\rho(y)) + \\sigma(\\rho(x))\\) , elaborato dalla regola \\(C: \\Delta \\vdash_c C\\) Dato un ambiente \\(\\Delta\\) , eseguendo il comando con i tipi definiti in \\(\\Delta\\) \u00e8 tutto corretto","title":"Comandi"},{"location":"ProAlgo/valutazione/#espressioni","text":"Le espressioni rappresentano i valori su cui si opera NON modificano la memoria. Le espressioni si valutano 2 * ( x + y ) Che si traduce in: \\(E: \\Delta \\vdash_e: \\tau\\) Dato un ambiente \\(\\Delta\\) , l'espressione \u00e8 ben formata ed \u00e8 di tipo \\(\\tau\\)","title":"Espressioni"},{"location":"ProAlgo/valutazione/#classi-di-complessita","text":"Le classi di complessit\u00e0 ci permettono di categorizzare gli algoritmi in funzione della grandezza dell'input. Il tipo di comparazione che viene fatta \u00e8 molto spannometrica , nel senso che spesso si tende a definire l'ordine di grandezza con cui l'algoritmo cresce, oppure il massimo (o minimo) tempo garantito che l'algoritmo impiegher\u00e0 a fornire una risposta in funzione della grandezza dell'input. Il tutto approssimando il risultato a monomi (quindi ad esempio \\(log(n)\\) , \\(n\\) , \\(n^2\\) , \\(n!\\) , \\(n^n\\) , etc...) Questo tipo di valutazione ci consente di categorizzare gli algoritmi e poterli comparare in semplicit\u00e0. I tipi di categorizzazione pi\u00f9 usati sono spesso limite superiore e limite inferiore. Come si pu\u00f2 intuire dal nome, questi limiti ci permettono di definire un tempo di esecuzione che sicuramente l'algoritmo (rispettivamente) non superer\u00e0 o non migliorer\u00e0. Per questo motivo il limite superiore (conosciuto come Big O notation, o semplicemente O) \u00e8 usato per individuare il costo delle soluzioni. Allo stesso modo, il limite inferiore (conosciuto come \\(\\Omega\\) , o big omega) ci permette di individuare la complessit\u00e0 del problema che stiamo risolvendo. Quindi, per riassumere: Simbolo Lettura Tipo di limite Significato O O-grande Limite superiore asintotico Peggior situazione possibile \\(\\Omega\\) Omega Grande Limite inferiore asintotico Migliore situazione possibile \\(\\Theta\\) Theta Limite asintotico stretto Complessit\u00e0 della soluzione (asintotico si pu\u00f2 leggere come \" per valori che tendono a \\(\\pin\\) \")","title":"Classi di complessit\u00e0"},{"location":"ProAlgo/valutazione/#big-o","text":"","title":"Big-O"},{"location":"ProAlgo/valutazione/#big-omega","text":"\\(\\Omega\\) il lower bound, la classe di complessit\u00e0 minima per risolvere il problema, che significa che non \u00e8 possibile risolvere un problema in meno passi. Ad esempio, nel caso di un ordinamento per confronti (ovvero quando si ordinano elementi confrontabili tra di loro), come minimo devo vedere tutti gli n elementi, ma ci\u00f2 non pu\u00f2 bastare, perch\u00e9 devo anche confrontarli tra di loro. Dimostrare che una soluzione \u00e8 \"ottima\" equivale a dimostrare un lower bound. Ci\u00f2 significa che qualunque soluzione S corretta non pu\u00f2 impiegare meno tempo del lower bound.","title":"Big Omega"},{"location":"ProAlgo/valutazione/#theta","text":"","title":"Theta"},{"location":"ProAlgo/valutazione/#relazioni-di-ricorrenza","text":"","title":"Relazioni di ricorrenza"},{"location":"ProAlgo/valutazione/#complessita-della-ricorsione","text":"","title":"Complessit\u00e0 della ricorsione"},{"location":"ProAlgo/valutazione/#lapproccio-divide-and-conquer","text":"Il divide-et-impera \u00e8 un paradigma di programmazione ricorsiva. Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera ricorsiva fino a generare una soluzione per il problema originale La ricorsione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo ricorsivo Si dice algoritmo ricorsivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso ricorsivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato.","title":"L'approccio Divide-and-conquer"},{"location":"ProAlgo/valutazione/#analisi-degli-algoritmi-divide-and-conquer","text":"Quando un algoritmo effettua una chiamata ricorsiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Nell'esempio sotto riportato, abbiamo che T(n) \u00e8 il tempo di esecuzione del programma. La forma dell'equazione di un algoritmo dividi-et-impera \u00e8 la seguente: \\[ T(n) = \\begin{cases} C & \\text{ se } n \\le k \\\\ \\underbrace{D(n)}_{\\text{Dividi}} + \\underbrace{\\sum^{h}_{i = 1} T(n_i)}_{\\text{impera}} + \\underbrace{C(n)}_{\\text{combina}} & \\text{ se } n > k \\end{cases} \\] Ovvero, semplificando: \\[ T(n) = \\begin{cases} \\Theta(1) & \\text{ se } n \\le k \\\\ aT(\\frac n b) + D(n) + C(n) & \\text{ se } n > k \\end{cases} \\] In questo caso a \u00e8 il numero di sottoproblemi, b \u00e8 la dimensione dei sottoproblemi, D(n) \u00e8 il costo della divisione dei sottoproblemi e C(n) \u00e8 il costo della combinazione dei sottoproblemi. Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metodo di sostituzione Il metodo di sostituzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem","title":"Analisi degli algoritmi divide-and-conquer"},{"location":"ProAlgo/valutazione/#metodo-di-sostituzione","text":"","title":"Metodo di sostituzione"},{"location":"ProAlgo/valutazione/#albero-di-ricorrenza","text":"","title":"Albero di ricorrenza"},{"location":"ProAlgo/valutazione/#il-master-theorem","text":"Il master theorem \u00e8 un procedimento che permette di valutare attraverso una formula un'equazione di ricorrenza, risolvendola molto velocemente, senza necessit\u00e0 di alberi. L'equazione deve essere della forma \\(aT(\\frac{n}{b}) + f(n)\\) con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema (che \u00e8 maggiore di uno, altrimenti la complessit\u00e0 non diminuisce con le iterazioni) ed infine \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi L'idea base teorema si basa sul comparare due funzioni e scegliere quella che cresce pi\u00f9 velocemente (che tende a vincere): \\[ n^{log_b(a)} \\text { vs } f(n) \\] Dove a , b ed f(n) sono gli stessi parametri che troviamo nell'equazione di ricorrenza. Ci sono quindi 3 possibili casi, quando si comparano le due funzioni: \\(n^{log_b(a)} > f(n)\\) (vince \\(n^{log_b(a)}\\) ) In questo caso \\(f(n) = O(n^{log_b(a) - \\epsilon}) . \\epsilon > 0\\) ( f(n) ha come limite superiore (big O) la funzione \\(n^{log_b(a) - \\epsilon}\\) per un \\(\\epsilon\\) maggiore di 0). Questo significa che f(n) cresce polinomialmente 1 pi\u00f9 lentamente rispetto a \\(n^{log_b(a)}\\) (e quindi elevando f(n) a qualche termine sarebbe possibile \"equiparare le velocit\u00e0\") La soluzione all'equazione di ricorrenza \u00e8 quindi \\(T(n) = \\Theta(n^{log_b(a)})\\) \\(n^{log_b(a)} < f(n)\\) (vince \\(f(n)\\) ) Questo significa che \\(f(n) = \\Omega(n^{log_b (a) + \\epsilon}). \\epsilon > 0\\) (che significa che \\(f(n)\\) cresce pi\u00f9 velocemente di un fattore \\(n^\\epsilon\\) ). Questa condizione tuttavia richiede una seconda clausola: la condizione di continuit\u00e0 . \\(a\\cdot f(\\frac n b) \\le c \\cdot f(n)\\) e \\(c < 1 \\land n > n_0. T(n) = O(f(n))\\) Questa condizione serve per assicurarsi che la funzione cresca molto pi\u00f9 velocemente anche per una frazione del risultato, rispetto ad una frazione del dominio (il numero in input, per numeri abbastanza grandi). Ad esempio, prendendo \\(a=2\\) , \\(b=2\\) , \\(c=0.5\\) e \\(f(n) = n^3\\) , per \\(n=6\\) avremmo \\(2\\cdot f(\\frac 6 2) \\le \\frac {f(6)} {2}\\) e quindi \\(2\\cdot3^3 \\le \\frac {6^3} {2} = 54 \\le 108\\) In questo caso la soluzione \u00e8 \\(T(n) = O(f(n))\\) \\(n^{log_b(a)} = f(n)\\) (sono uguali) Infine, \\(f(n) = \\Theta(n^{log_b(a)} \\cdot log^k(n)\\) con \\(k \\ge 0\\) Questo significa che \\(f(n)\\) e \\(n^{log_b(a)}\\) crescono allo stesso modo. Il che significa \\(T(n) = \\Theta(n^{log_b(a)} log^{k+1} (n))\\) Dimostrazione del master theorem Da fare...","title":"Il master theorem"},{"location":"ProAlgo/valutazione/#esempi","text":"","title":"Esempi"},{"location":"ProAlgo/valutazione/#algoritmi","text":"","title":"Algoritmi"},{"location":"ProAlgo/valutazione/#il-quicksort","text":"Il quicksort \u00e8 un algoritmo ricorsivo di ordinamento di complessit\u00e0 \\(O(n \\log n)\\) che basa il suo funzionamento sul concetto di pivot. L'idea su cui si basa \u00e8 quella di dividere in due l'array, mettendo a sinistra tutti gli elementi pi\u00f9 piccoli del pivot e a destra quelli pi\u00f9 grandi Si sceglie il cos\u00ec detto \"pivot\" (ad esempio l'ultimo elemento dell'array) Si cicla l'array, tenendo in mente due puntatori, uno che rappresenta l'iteratore del ciclo e l'altro che serve per tenere a mente dove l'array si \"divide\" tra i valori pi\u00f9 piccoli e pi\u00f9 grandi del pivot Ad ogni iterazione, si controlla se l'elemento dell'array \u00e8 pi\u00f9 piccolo o pi\u00f9 grande del pivot. Se \u00e8 pi\u00f9 grande, non succede nulla. Se invece l'elemento \u00e8 pi\u00f9 piccolo, viene incrementato il puntatore che \"divide\" i valori dell'array, indicando che il che il nuovo elemento \u00e8 pi\u00f9 piccolo del pivot. Si scambiano poi i valori corrispondenti ai due puntatori (quello che dice a che valore punta il ciclo e quello che rappresenta la met\u00e0 dell'array inferiore). In questo modo, viene sostituito il valore pi\u00f9 piccolo del pivot, mantenendo la met\u00e0 dell'array pi\u00f9 piccola del pivot. A fine iterazione, si avr\u00e0 che una parte dell'array sar\u00e0 pi\u00f9 grande del pivot, e l'altra sar\u00e0 pi\u00f9 piccola. A questo punto si sostituisce la cella successiva all'ultimo valore pi\u00f9 piccolo dell'array con il pivot e si riesegue l'algoritmo sulle due met\u00e0 dell'array. Un \"avversario\" potrebbe \"rovinare\" l'algoritmo mettendo come ultimo elemento (che usiamo come pivot) l'elemento pi\u00f9 grande o pi\u00f9 piccolo dell'array. Possiamo sopperire a questo problema sostituendo una cella a caso dell'array con l'ultima, randomizzando il pivot.","title":"Il quicksort"},{"location":"ProAlgo/valutazione/#il-sorting-lineare","text":"Come detto, dimostrare che una soluzione \u00e8 ottima equivale a dimostrare un lower bound. Nel caso del sorting lineare, abbiamo un lower bound pari a \\(O(n)\\) (con N il numero degli elementi nell'array). Questo perch\u00e9 se ci fossero meno di n elementi, sarebbe possibile inserire l'elemento che si sta ricercando per fare il sorting nella cella che non verrebbe controllata. In genere, quando si ha un'operazione di sorting, \u00e8 impossibile averla in tempo lineare. Questo perch\u00e9 l'albero dei confronti ha n! foglie, ed \u00e8 necessario confrontare gli elementi per poter ordinare, che ci fa scegliere le diverse branches dell' albero dei confronti . \u00c8 possibile tuttavia ordinare senza fare confronti , basandosi sulle propriet\u00e0 degli oggetti da ordinare. Esempio Dato un array di n interi senza ripetizioni ed il suo massimo, rende possibile ricreare l'array. Dato un array di n interi (ma con ripetizioni), \u00e8 possibile scansionare una volta l'array e poi inserire le ripetizioni in un secondo array (sempre dato il suo massimo). Questo algoritmo si chiama counting sort, che ha complessit\u00e0 O(n+k) (dove n \u00e8 il numero di elementi dell'array e k \u00e8 il valore massimo). Senza avere questi constraints, \u00e8 necessario ricorrere alle comparazioni Ordinamento stabile Un algoritmo di ordinamento \u00e8 detto stabile quando preserva l'ordine iniziale tra due elementi con la stessa chiave Ad esempio Heapsort e Quicksort non sono stabili in quanto \"mescolano\" l'ordine. Il radix sort \u00e8 un algoritmo di ordinamento basato su MSB (Most Significant Bit, bit con importanza maggiore) ed un algoritmo di ordinamento stabile Viene usato per ordinare e parte dal bit meno significativo, per poi salire (dal meno significativo al pi\u00f9 significativo). Si pu\u00f2 quindi assumere per induzione che ad ogni passo (diverso dal passo base) tutte le cifre di \"indice\" minore sono ordinate. Se due cifre sono uguali, si ignorano, altrimenti si calcola l'ordine attraverso un algoritmo stabile (con una performance di O(n)). Una funzione cresce in modo polinomialmente differentemente quando la \"velocit\u00e0 di crescita\" differisce di un polinomio (o un monomio). Un polinomio \u00e8 un'espressione della forma \\(a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0\\) . \u21a9","title":"Il sorting lineare"},{"location":"ProAlgo/IntroToAlgorithms/intro/","text":"Quando scriviamo gli algoritmi in pseudocodice, lo facciamo per garantire una maggiore espressivit\u00e0 e concisione. Se necessario possiamo anche scrivere in linguaggio naturale. Di conseguenza, uno pseudocodice non si preoccupa di indirizzare problemi tipici dell'ingegnerizzazione del codice, ma solo di esprimere un algoritmo e quindi garantirne o renderne esplicita la correttezza. Dato che la performance della risoluzione di un certo problema dipende in equal modo sia dall'hardware di un calcolatore che dall'algoritmo, dovremmo considerare gli algoritmi come tecnologia. Cosa che gi\u00e0 facciamo per l'hardware. Loop invariants \u00b6 Quando abbiamo un ciclo in una algoritmo, possiamo parlare di alcune propriet\u00e0 che il ciclo deve soddisfare per aiutarci capire come mai un algoritmo \u00e8 corretto. Queste propriet\u00e0 sono dette invarianti di ciclo (loop invariants)e ci richiedono di dimostrare tre cose: Inizializzazione: Mostriamo che una certa propriet\u00e0 \u00e8 vera prima di effettuare la prima iterazione del ciclo Manutenzione: Una certa propriet\u00e0 \u00e8 vera prima di un'iterazione e rimane vera prima dell'iterazione successiva Terminazione: La propriet\u00e0 ottenuta alla fine del ciclo, che ci permette di dimostrare che un algoritmo \u00e8 corretto \u00c8 possibile tracciare un parallelismo con l' induzione matematica , dove per provare una certa propriet\u00e0, possiamo provare un caso base ed un passo induttivo. Analisi di un algoritmo \u00b6 Analizzare un algoritmo \u00e8 diventato sinonimo di predire le risorse che l'algoritmo richieder\u00e0. Alcune tra queste risorse possono essere memoria, larghezza di banda o risorse fisiche, ma la pi\u00f9 calcolata e di maggiore interesse \u00e8 il tempo computazionale. Grazie ad un'analisi, siamo in grado di confrontare delle soluzioni tra di loro, scegliendo la pi\u00f9 efficiente tra le due. Modello di implementazione \u00b6 Prima di analizzare un algoritmo, dobbiamo avere un modello della tecnologia che andremo ad usare, includendo le tecnologie a disposizione ed il costo per l'accesso. Durante l'uso del libro, si far\u00e0 uso del modello RAM (Random-Access Machine), dove ogni istruzione \u00e8 eseguita ona dopo l'altra senza operazioni concorrenti. \u00c8 tuttavia necessario non abusare del sistema preso come riferimento: da un punto di vista formale sarebbe necessario definire ogni istruzione del modello ed il rispettivo costo, ma un tipo di analisi simile andrebbe ben oltre il dominio dell'analisi degli algoritmi. Un abuso potrebbe corrispondere a fare uso di un'istruzione in grado di ordinare un array in tempo costante. Un modello simile non risulterebbe realistico dato che i computer non hanno questo genere di istruzione. Possiamo limitarci quindi a dire che il modello RAM contiene istruzioni comunemente trovate nei computer reali (come aritmetica base (addizione, sottrazione, divisione, moltiplicazione, modulo, arrotondamento e troncamento), gestione dei dati (caricamento, salvataggio e copia), controllo (salti condizionati e non, chiamate a sottoprogrammi e return)). I computer reali tuttavia hanno anche loro zone \"grigie\", ad esempio un computer pu\u00f2 calcolare un numero \\(2^k\\) in tempo costante, effettuando un'operazione di shifting verso sinistra. I computer fanno inoltre uso di cache e memoria virtuale; Anche queste tecnologie non vengono incluse. La funzione di costo \u00b6 In genere, il tempo richiesto da un algoritmo per calcolare una risposta dipende dalla grandezza dei parametri in ingresso. \u00c8 quindi pratica comune descrivere il tempo di esecuzione di un programma in funzione della grandezza dei parametri dati in ingresso. La nozione di \"grandezza\" dell'input dipende dal tipo di problema preso in considerazione: per molti problemi, il modo pi\u00f9 naturale di misurare l'input \u00e8 il numero di oggetti dati in inputer, mentre per altri problemi pu\u00f2 essere il numero totale di bit richiesti per rappresentare l'input. Un'altra assunzione importante \u00e8 che ogni istruzione in ogni riga ( \\(n\\) ) di un programma impiega un tempo costante ( \\(c_n\\) ) per essere eseguita. Il tempo di esecuzione di un algoritmo \u00e8 quindi la somma dei tempi di esecuzioni di ogni istruzione eseguita. Analisi del caso medio e peggiore \u00b6 Durante l'analisi di un algoritmo, ci si tende a concentrare sull'analisi del caso peggiore, che fornisce il limite superiore (il massimo tempo che l'algoritmo pu\u00f2 impiegare) per ogni input. Ci viene quindi garantito che l'algoritmo non impiegher\u00e0 mai, pi\u00f9 tempo del limite superiore, senza doverci far compiere stime. Per alcuni algoritmi il caso peggiore si verifica quasi sempre (ad esempio nel caso di una ricerca). Il tempo medio invece \u00e8 spesso pessimo quanto il caso peggiore; Inoltre definire il caso medio \u00e8 complicato in quanto richiede tecniche di analisi probabilistica. Potrebbe inoltre non sempre essere ovvio cosa costituisce un caso medio per un dato problema. Potrebbe essere possibile fare delle assunzioni, come che tutte le possibili grandezze siano equamente probabili, ma spesso questa assunzione \u00e8 violata. Ordine di grandezza \u00b6 Quando si analizza un algoritmo, si tende a considerare ogni istruzione dello stesso tipo come costante, ma spesso questo approccio ci fornisce pi\u00f9 dettagli di quanti veramente richiesti. Un'astrazione di livello ancora pi\u00f9 alto pu\u00f2 essere quella basata sul tasso di crescita o ordine di grandezza : Questo ci permette di considerare solo il termine di grado maggiore in un'equazione (ad esempio solo il termine \\(an^2\\) nell'equazione \\(an^2+bn+c\\) ). Questa considerazione viene dal fatto che per valori molto grandi, i valori di grado inferiore sono spesso insignificanti. Diciamo quindi che un algoritmo ha un caso peggiore di \\(\\theta (n^2)\\) ( theta di n al quadrato). Consideriamo quindi un algoritmo pi\u00f9 efficiente di un altro quando questo ha un ordine di grandezza del caso peggiore inferiore. Design di un algoritmo \u00b6 Dividi et impera \u00b6 Molti algoritmi utili sono ricorsivi in natura: per risolvere un problema, chiamano s\u00e9 stessi pi\u00f9 volte in maniera ricorsiva, in modo da avere a che fare con problemi strettamente correlati. Tipicamente questi algoritmi seguono un approccio dividi et impera (o divide-and-conquer): Dividono un problema in sotto problemi simili al problema originale ma pi\u00f9 piccoli in grandezza L'approccio dividi et impera \u00e8 composto da 3 fasi: Divide: Divide il problema in un numero di sottoproblemi pi\u00f9 piccoli Conquer: ' Conquista ' il sottoproblema, risolvendolo ricorsivamente. Quando la grandezza del sottoproblema diventa abbastanza piccola, risolve banalmente il sottoproblema Combine: Combina le soluzioni di 2 sottoproblemi in una soluzione per il problema originale. Merging with the merge sort L'algoritmo merge sort \u00e8 un algoritmo ricorsivo che serve per ordinare dei numeri. L'operazione chiave dell'algoritmo \u00e8 l'unione (passo combine) di due sequenze ordinate in una unica. Nel caso del merge sort, effettuiamo l'unione (il merge) chiamando la procedura Merge(A,p,q,r) , dove A \u00e8 l'array di elementi che vogliamo ordinare, e p , q ed r sono indici che puntano all'array e tali che \\(p \\leq q < r\\) . Questi sono i tre step che l'algoritmo compie (per un array con numero pari di elementi, per semplicit\u00e0 di spiegazione): Dividi: L'array \u00e8 diviso a met\u00e0 e la funzione \u00e8 chiamata ricorsivamente. Al termine della chiamata si avranno 2 met\u00e0 dell'array che corrisponderanno a 2 elementi Conquista: Questo passo ordina i due elementi (quindi si tratta di comparare due numeri e determinare quale sia il pi\u00f9 grande) e ritorna la sequenza ordinata Combina: In quest'ultimo passo, che parte dalla penultima iterazione, l'algoritmo si trova due array da 2 elementi ognuno ordinato e deve unirli in un solo array. Per farlo inizia comparando i due elementi dei due array, con un indice per array. L'elemento pi\u00f9 piccolo verr\u00e0 quindi messo in un nuovo array ed il puntatore corrispettivo avanzer\u00e0 fino a giungere alla fine dell'array. In questo modo si otterr\u00e0 quindi un array ordinato composto dagli array pi\u00f9 piccoli. Il risultato sar\u00e0 quindi calcolato iterativamente fino a giungere al primo chiamante della funzione di sort, che si trover\u00e0 quindi un array ordinato in tempo \\(\\Theta(n)\\) . (Rivedere; Sono andato praticamente solo a memoria) Analisi di un algoritmo divide-and-conquer \u00b6 Quando un algoritmo contiene una chiamata ricorsiva a s\u00e9 stesso, possiamo spesso descrivere il suo tempo di esecuzione con un'equazione di ricorrenza. Possiamo quindi usare strumenti matematici per risolvere la ricorrenza e fornire dei limiti alle performances dell'algoritmo. L'analisi di un algoritmo segue i tre step base del divide and conquer: Partiamo definendo come \\(T(n)\\) il costo del problema in funzione di un input di grandezza n. Se la grandezza del problema \u00e8 sufficientemente piccola (ovvero \\(n < c\\) per qualche costante \\(c\\) , si pensi all'ultima iterazione della fase di dividi ), la soluzione richiede un tempo costante, che scriviamo come \\(\\Theta(1)\\) . Se invece la soluzione del problema richiede \\(a\\) sottoproblemi, ognuno di grandezza \\(\\frac{1}{b}\\) rispetto al problema originale, allora il sottoproblema richieder\u00e0 un tempo di \\(T(\\frac{1}{b})\\) per essere risolto. Di conseguenza il tempo per risolvere \\(a\\) sottoproblemi sar\u00e0 \\(a\\cdot T(\\frac{1}{b})\\) . Big O \u00b6 Floor ceiling & modul \u00b6 \\(a mod n = a - n \\lower{a/n}\\) \\(a \\le a mod n < n\\) \\((a mod n) = (b mod n)\\) , then \\(a \\eqiv b (mod n)\\) (a is equivalente to be modulo n). \\(a \\nequiv b\\) if that's not the case \\(ln^* n\\)","title":"Intro"},{"location":"ProAlgo/IntroToAlgorithms/intro/#loop-invariants","text":"Quando abbiamo un ciclo in una algoritmo, possiamo parlare di alcune propriet\u00e0 che il ciclo deve soddisfare per aiutarci capire come mai un algoritmo \u00e8 corretto. Queste propriet\u00e0 sono dette invarianti di ciclo (loop invariants)e ci richiedono di dimostrare tre cose: Inizializzazione: Mostriamo che una certa propriet\u00e0 \u00e8 vera prima di effettuare la prima iterazione del ciclo Manutenzione: Una certa propriet\u00e0 \u00e8 vera prima di un'iterazione e rimane vera prima dell'iterazione successiva Terminazione: La propriet\u00e0 ottenuta alla fine del ciclo, che ci permette di dimostrare che un algoritmo \u00e8 corretto \u00c8 possibile tracciare un parallelismo con l' induzione matematica , dove per provare una certa propriet\u00e0, possiamo provare un caso base ed un passo induttivo.","title":"Loop invariants"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-di-un-algoritmo","text":"Analizzare un algoritmo \u00e8 diventato sinonimo di predire le risorse che l'algoritmo richieder\u00e0. Alcune tra queste risorse possono essere memoria, larghezza di banda o risorse fisiche, ma la pi\u00f9 calcolata e di maggiore interesse \u00e8 il tempo computazionale. Grazie ad un'analisi, siamo in grado di confrontare delle soluzioni tra di loro, scegliendo la pi\u00f9 efficiente tra le due.","title":"Analisi di un algoritmo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#modello-di-implementazione","text":"Prima di analizzare un algoritmo, dobbiamo avere un modello della tecnologia che andremo ad usare, includendo le tecnologie a disposizione ed il costo per l'accesso. Durante l'uso del libro, si far\u00e0 uso del modello RAM (Random-Access Machine), dove ogni istruzione \u00e8 eseguita ona dopo l'altra senza operazioni concorrenti. \u00c8 tuttavia necessario non abusare del sistema preso come riferimento: da un punto di vista formale sarebbe necessario definire ogni istruzione del modello ed il rispettivo costo, ma un tipo di analisi simile andrebbe ben oltre il dominio dell'analisi degli algoritmi. Un abuso potrebbe corrispondere a fare uso di un'istruzione in grado di ordinare un array in tempo costante. Un modello simile non risulterebbe realistico dato che i computer non hanno questo genere di istruzione. Possiamo limitarci quindi a dire che il modello RAM contiene istruzioni comunemente trovate nei computer reali (come aritmetica base (addizione, sottrazione, divisione, moltiplicazione, modulo, arrotondamento e troncamento), gestione dei dati (caricamento, salvataggio e copia), controllo (salti condizionati e non, chiamate a sottoprogrammi e return)). I computer reali tuttavia hanno anche loro zone \"grigie\", ad esempio un computer pu\u00f2 calcolare un numero \\(2^k\\) in tempo costante, effettuando un'operazione di shifting verso sinistra. I computer fanno inoltre uso di cache e memoria virtuale; Anche queste tecnologie non vengono incluse.","title":"Modello di implementazione"},{"location":"ProAlgo/IntroToAlgorithms/intro/#la-funzione-di-costo","text":"In genere, il tempo richiesto da un algoritmo per calcolare una risposta dipende dalla grandezza dei parametri in ingresso. \u00c8 quindi pratica comune descrivere il tempo di esecuzione di un programma in funzione della grandezza dei parametri dati in ingresso. La nozione di \"grandezza\" dell'input dipende dal tipo di problema preso in considerazione: per molti problemi, il modo pi\u00f9 naturale di misurare l'input \u00e8 il numero di oggetti dati in inputer, mentre per altri problemi pu\u00f2 essere il numero totale di bit richiesti per rappresentare l'input. Un'altra assunzione importante \u00e8 che ogni istruzione in ogni riga ( \\(n\\) ) di un programma impiega un tempo costante ( \\(c_n\\) ) per essere eseguita. Il tempo di esecuzione di un algoritmo \u00e8 quindi la somma dei tempi di esecuzioni di ogni istruzione eseguita.","title":"La funzione di costo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-del-caso-medio-e-peggiore","text":"Durante l'analisi di un algoritmo, ci si tende a concentrare sull'analisi del caso peggiore, che fornisce il limite superiore (il massimo tempo che l'algoritmo pu\u00f2 impiegare) per ogni input. Ci viene quindi garantito che l'algoritmo non impiegher\u00e0 mai, pi\u00f9 tempo del limite superiore, senza doverci far compiere stime. Per alcuni algoritmi il caso peggiore si verifica quasi sempre (ad esempio nel caso di una ricerca). Il tempo medio invece \u00e8 spesso pessimo quanto il caso peggiore; Inoltre definire il caso medio \u00e8 complicato in quanto richiede tecniche di analisi probabilistica. Potrebbe inoltre non sempre essere ovvio cosa costituisce un caso medio per un dato problema. Potrebbe essere possibile fare delle assunzioni, come che tutte le possibili grandezze siano equamente probabili, ma spesso questa assunzione \u00e8 violata.","title":"Analisi del caso medio e peggiore"},{"location":"ProAlgo/IntroToAlgorithms/intro/#ordine-di-grandezza","text":"Quando si analizza un algoritmo, si tende a considerare ogni istruzione dello stesso tipo come costante, ma spesso questo approccio ci fornisce pi\u00f9 dettagli di quanti veramente richiesti. Un'astrazione di livello ancora pi\u00f9 alto pu\u00f2 essere quella basata sul tasso di crescita o ordine di grandezza : Questo ci permette di considerare solo il termine di grado maggiore in un'equazione (ad esempio solo il termine \\(an^2\\) nell'equazione \\(an^2+bn+c\\) ). Questa considerazione viene dal fatto che per valori molto grandi, i valori di grado inferiore sono spesso insignificanti. Diciamo quindi che un algoritmo ha un caso peggiore di \\(\\theta (n^2)\\) ( theta di n al quadrato). Consideriamo quindi un algoritmo pi\u00f9 efficiente di un altro quando questo ha un ordine di grandezza del caso peggiore inferiore.","title":"Ordine di grandezza"},{"location":"ProAlgo/IntroToAlgorithms/intro/#design-di-un-algoritmo","text":"","title":"Design di un algoritmo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#dividi-et-impera","text":"Molti algoritmi utili sono ricorsivi in natura: per risolvere un problema, chiamano s\u00e9 stessi pi\u00f9 volte in maniera ricorsiva, in modo da avere a che fare con problemi strettamente correlati. Tipicamente questi algoritmi seguono un approccio dividi et impera (o divide-and-conquer): Dividono un problema in sotto problemi simili al problema originale ma pi\u00f9 piccoli in grandezza L'approccio dividi et impera \u00e8 composto da 3 fasi: Divide: Divide il problema in un numero di sottoproblemi pi\u00f9 piccoli Conquer: ' Conquista ' il sottoproblema, risolvendolo ricorsivamente. Quando la grandezza del sottoproblema diventa abbastanza piccola, risolve banalmente il sottoproblema Combine: Combina le soluzioni di 2 sottoproblemi in una soluzione per il problema originale. Merging with the merge sort L'algoritmo merge sort \u00e8 un algoritmo ricorsivo che serve per ordinare dei numeri. L'operazione chiave dell'algoritmo \u00e8 l'unione (passo combine) di due sequenze ordinate in una unica. Nel caso del merge sort, effettuiamo l'unione (il merge) chiamando la procedura Merge(A,p,q,r) , dove A \u00e8 l'array di elementi che vogliamo ordinare, e p , q ed r sono indici che puntano all'array e tali che \\(p \\leq q < r\\) . Questi sono i tre step che l'algoritmo compie (per un array con numero pari di elementi, per semplicit\u00e0 di spiegazione): Dividi: L'array \u00e8 diviso a met\u00e0 e la funzione \u00e8 chiamata ricorsivamente. Al termine della chiamata si avranno 2 met\u00e0 dell'array che corrisponderanno a 2 elementi Conquista: Questo passo ordina i due elementi (quindi si tratta di comparare due numeri e determinare quale sia il pi\u00f9 grande) e ritorna la sequenza ordinata Combina: In quest'ultimo passo, che parte dalla penultima iterazione, l'algoritmo si trova due array da 2 elementi ognuno ordinato e deve unirli in un solo array. Per farlo inizia comparando i due elementi dei due array, con un indice per array. L'elemento pi\u00f9 piccolo verr\u00e0 quindi messo in un nuovo array ed il puntatore corrispettivo avanzer\u00e0 fino a giungere alla fine dell'array. In questo modo si otterr\u00e0 quindi un array ordinato composto dagli array pi\u00f9 piccoli. Il risultato sar\u00e0 quindi calcolato iterativamente fino a giungere al primo chiamante della funzione di sort, che si trover\u00e0 quindi un array ordinato in tempo \\(\\Theta(n)\\) . (Rivedere; Sono andato praticamente solo a memoria)","title":"Dividi et impera"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-di-un-algoritmo-divide-and-conquer","text":"Quando un algoritmo contiene una chiamata ricorsiva a s\u00e9 stesso, possiamo spesso descrivere il suo tempo di esecuzione con un'equazione di ricorrenza. Possiamo quindi usare strumenti matematici per risolvere la ricorrenza e fornire dei limiti alle performances dell'algoritmo. L'analisi di un algoritmo segue i tre step base del divide and conquer: Partiamo definendo come \\(T(n)\\) il costo del problema in funzione di un input di grandezza n. Se la grandezza del problema \u00e8 sufficientemente piccola (ovvero \\(n < c\\) per qualche costante \\(c\\) , si pensi all'ultima iterazione della fase di dividi ), la soluzione richiede un tempo costante, che scriviamo come \\(\\Theta(1)\\) . Se invece la soluzione del problema richiede \\(a\\) sottoproblemi, ognuno di grandezza \\(\\frac{1}{b}\\) rispetto al problema originale, allora il sottoproblema richieder\u00e0 un tempo di \\(T(\\frac{1}{b})\\) per essere risolto. Di conseguenza il tempo per risolvere \\(a\\) sottoproblemi sar\u00e0 \\(a\\cdot T(\\frac{1}{b})\\) .","title":"Analisi di un algoritmo divide-and-conquer"},{"location":"ProAlgo/IntroToAlgorithms/intro/#big-o","text":"","title":"Big O"},{"location":"ProAlgo/IntroToAlgorithms/intro/#floor-ceiling-modul","text":"\\(a mod n = a - n \\lower{a/n}\\) \\(a \\le a mod n < n\\) \\((a mod n) = (b mod n)\\) , then \\(a \\eqiv b (mod n)\\) (a is equivalente to be modulo n). \\(a \\nequiv b\\) if that's not the case \\(ln^* n\\)","title":"Floor ceiling &amp; modul"}]}