{"config":{"indexing":"full","lang":["it"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Appunti universitari \u00b6 Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"#appunti-universitari","text":"Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"AnalisiI/","text":"","title":"Analisi I"},{"location":"FdI/","text":"","title":"Fondamenti di Informatica"},{"location":"FdI/calcoloCombinatorio/","text":"","title":"Calcolo Combinatorio"},{"location":"FdI/cheatsheet/","text":"Relazione Descrizione Totale Per ogni elemento in A, c'\u00e8 una connessione con almeno un elemento in B Univalente Per ogni elemento in A, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in B Surgettiva Per ogni elemento in B, c'\u00e8 una connessione con almeno un elemento in A Iniettiva Per ogni elemento in B, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in A Biietiva Tutte le precedenti Riflessiva Ogni elemento \u00e8 in relazione con s\u00e9 stesso (ha un cappio) (l'identit\u00e0 \u00e8 contenuta nella relazione) Transitiva Se esiste una relazione (a,b), e (b,c), esiste anche una relazione (a,c) Include anche la relazione vuota Antisimmetrica Non c'\u00e8 mai una relazione che va da a a b e contemporaneamente da b ad a (Non ci sono mai frecce opposte) \u00c8 tollerato lo stesso elemento (cappio) Simmetrica Per ogni relazione (a,b) , esiste una relazione (b,a) Per ogni elemento, ci sono 2 archi, uno da ed uno verso un altro elemento Composizione 2 relazioni sono composte quando l'elemento di arrivo per la prima diventa l'elemento di partenza per la seconda Avendo (a,b) e (b,c) in R, R composto R ( R;R ) \u00e8 ((a,b),c) , ovvero (a,c) R*, chiusura di Kleene La composizione di una relazione con s\u00e9 stessa infinite volte (zero incluso) \u00c8 riflessiva e transitiva Contiene l'identit\u00e0 (R0) R+, chiusura positiva R* ma senza 0 incluso Chiusura riflessiva Data una relazione R ed un insieme A, \u00e8 l'unione dell'identit\u00e0 di A con la relazione R Chiusura simmetrica Data una relazione R, \u00e8 l'unione di R ed R opposto Chiusura transitiva Data una relazione R, si unisce a questa la chiusura positiva fino a far diventare la funzione transitiva Ordinamento parziale Una relazione Riflessiva, Transitiva ed Antisimmetrica Ordinamento totale Ordinamento parziale + ogni (a, b) appartenente al prodotto cartesiano; (a,b) o (b,a) appartiene ad R Ogni coppia di elementi appartiene alla relazione R: ogni elemento \u00e8 in relazione con ogni altro elemento; C'\u00e8 una freccia per ogni elemento su ogni elemento Se \u00e8 totale, non \u00e8 parziale Grafo Relazione Descrizione Walk/Cammino Un collegamento da un nodo di partenza ad uno di arrivo Trail Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso arco (o collegamento) Path Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso NODO (o pallino/elemento) Non si deve passare 2 volte per lo stesso elemento Walk chiuso Un walk che permette di partire da un nodo e ritornare allo stesso ed ha lunghezza maggiore di 0 Circuito \u00c8 un walk chiuso che \u00e8 anche un trail (non si passa per lo stesso arco 2 volte) Ciclo \u00c8 un circuito che \u00e8 anche un path (non si passa per lo stesso nodo 2 volte) Aciclico Quando il grafo NON presenta un ciclo Connesso Quando ogni nodo \u00e8 \"raggiunto\" da almeno un arco (se \u00e8 orientato: sia in uscita che in entrata) Fortemente connesso Da ogni nodo, esiste un walk verso ogni altro nodo Componenti fortemente connesse Sottografi fortemente connessi (notare che ogni nodo pu\u00f2 arrivare a s\u00e9 stesso, quindi ogni nodo preso singolarmente \u00e8 una componente fortemente connessa) Universale Quando un nodo \u00e8 vicino a tutti gli altri DAG Grafo Aciclico Orientato Induzione (pecch\u00e9 non bastava prima)","title":"Cheatsheet"},{"location":"FdI/grafi/","text":"I grafi e gli alberi \u00b6 I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme. Grafi orientati \u00b6 Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) . Le propriet\u00e0 TUSI \u00b6 Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\) Rappresentazione dei grafi orientati \u00b6 Esistono diversi modi per rappresentare i grafi orientati Matrice di adiacenza \u00b6 La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra. Liste di adiacenza \u00b6 Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\) Grafi etichettati e pesati \u00b6 Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche: Cammini, cicli e connettivit\u00e0 \u00b6 In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path. Cicli nei grafi orientati \u00b6 walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\) Connettivit\u00e0 \u00b6 Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y. Grafi orientati aciclici \u00b6 Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico. Grafi non orientati \u00b6 Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari. Cammini, cicli e connettivit\u00e0 sui grafi non orientati \u00b6 La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path. Cicli nei grafi non orientati \u00b6 \u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente. Connettivit\u00e0 \u00b6 Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa Alberi \u00b6 Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa. Cammini euleriani ed hamiltoniani \u00b6 Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi) Cammini euleriani (archi) \u00b6 Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\) Cammini hamiltoniani (nodi) \u00b6 Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G Il problema del commesso viaggiatore \u00b6 Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\] Distanza su grafi \u00b6 Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi. Isomorfismo \u00b6 L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi. Altri grafi noti \u00b6 Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Grafi"},{"location":"FdI/grafi/#i-grafi-e-gli-alberi","text":"I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme.","title":"I grafi e gli alberi"},{"location":"FdI/grafi/#grafi-orientati","text":"Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) .","title":"Grafi orientati"},{"location":"FdI/grafi/#le-proprieta-tusi","text":"Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\)","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/grafi/#rappresentazione-dei-grafi-orientati","text":"Esistono diversi modi per rappresentare i grafi orientati","title":"Rappresentazione dei grafi orientati"},{"location":"FdI/grafi/#matrice-di-adiacenza","text":"La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra.","title":"Matrice di adiacenza"},{"location":"FdI/grafi/#liste-di-adiacenza","text":"Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\)","title":"Liste di adiacenza"},{"location":"FdI/grafi/#grafi-etichettati-e-pesati","text":"Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche:","title":"Grafi etichettati e pesati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita","text":"In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path.","title":"Cammini, cicli e connettivit\u00e0"},{"location":"FdI/grafi/#cicli-nei-grafi-orientati","text":"walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\)","title":"Cicli nei grafi orientati"},{"location":"FdI/grafi/#connettivita","text":"Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y.","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#grafi-orientati-aciclici","text":"Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico.","title":"Grafi orientati aciclici"},{"location":"FdI/grafi/#grafi-non-orientati","text":"Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari.","title":"Grafi non orientati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita-sui-grafi-non-orientati","text":"La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path.","title":"Cammini, cicli e connettivit\u00e0 sui grafi non orientati"},{"location":"FdI/grafi/#cicli-nei-grafi-non-orientati","text":"\u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente.","title":"Cicli nei grafi non orientati"},{"location":"FdI/grafi/#connettivita_1","text":"Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#alberi","text":"Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa.","title":"Alberi"},{"location":"FdI/grafi/#cammini-euleriani-ed-hamiltoniani","text":"Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi)","title":"Cammini euleriani ed hamiltoniani"},{"location":"FdI/grafi/#cammini-euleriani-archi","text":"Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\)","title":"Cammini euleriani (archi)"},{"location":"FdI/grafi/#cammini-hamiltoniani-nodi","text":"Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G","title":"Cammini hamiltoniani (nodi)"},{"location":"FdI/grafi/#il-problema-del-commesso-viaggiatore","text":"Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\]","title":"Il problema del commesso viaggiatore"},{"location":"FdI/grafi/#distanza-su-grafi","text":"Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi.","title":"Distanza su grafi"},{"location":"FdI/grafi/#isomorfismo","text":"L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi.","title":"Isomorfismo"},{"location":"FdI/grafi/#altri-grafi-noti","text":"Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Altri grafi noti"},{"location":"FdI/induzione/","text":"Induzione matematica \u00b6 L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme. Definizione induttiva \u00b6 Definizione induttiva di un insieme \u00b6 Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via. Definizione induttiva di una funzione \u00b6 La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\) Principio di induzione sui naturali \u00b6 Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\] Principio di induzione forte sui naturali \u00b6 In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Induzione Matematica"},{"location":"FdI/induzione/#induzione-matematica","text":"L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme.","title":"Induzione matematica"},{"location":"FdI/induzione/#definizione-induttiva","text":"","title":"Definizione induttiva"},{"location":"FdI/induzione/#definizione-induttiva-di-un-insieme","text":"Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via.","title":"Definizione induttiva di un insieme"},{"location":"FdI/induzione/#definizione-induttiva-di-una-funzione","text":"La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\)","title":"Definizione induttiva di una funzione"},{"location":"FdI/induzione/#principio-di-induzione-sui-naturali","text":"Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\]","title":"Principio di induzione sui naturali"},{"location":"FdI/induzione/#principio-di-induzione-forte-sui-naturali","text":"In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Principio di induzione forte sui naturali"},{"location":"FdI/induzioneRicorsione/","text":"L'induzione strutturale \u00b6 L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\] Rappresentazione grafica dei termini \u00b6 \u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) . Alberi \u00b6 TODO Rappresentazione di alberi binari come termini \u00b6 Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Liste \u00b6 TODO Rappresentazione di liste come termini \u00b6 Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\) Naturali \u00b6 Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Funzioni su termini \u00b6 \u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm X \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base) Il principio di Induzione Strutturale \u00b6 Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene Funzioni ricorsive \u00b6 Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita. Tipologie di ricorsione \u00b6 Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta Ricorsione annidata \u00b6 Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata Ricorsione mutua \u00b6 Ricorsione procedurale \u00b6","title":"Induzione Strutturale e Ricorsione"},{"location":"FdI/induzioneRicorsione/#linduzione-strutturale","text":"L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\]","title":"L'induzione strutturale"},{"location":"FdI/induzioneRicorsione/#rappresentazione-grafica-dei-termini","text":"\u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) .","title":"Rappresentazione grafica dei termini"},{"location":"FdI/induzioneRicorsione/#alberi","text":"TODO","title":"Alberi"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-alberi-binari-come-termini","text":"Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\]","title":"Rappresentazione di alberi binari come termini"},{"location":"FdI/induzioneRicorsione/#liste","text":"TODO","title":"Liste"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-liste-come-termini","text":"Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\)","title":"Rappresentazione di liste come termini"},{"location":"FdI/induzioneRicorsione/#naturali","text":"Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\]","title":"Naturali"},{"location":"FdI/induzioneRicorsione/#funzioni-su-termini","text":"\u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm X \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base)","title":"Funzioni su termini"},{"location":"FdI/induzioneRicorsione/#il-principio-di-induzione-strutturale","text":"Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene","title":"Il principio di Induzione Strutturale"},{"location":"FdI/induzioneRicorsione/#funzioni-ricorsive","text":"Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita.","title":"Funzioni ricorsive"},{"location":"FdI/induzioneRicorsione/#tipologie-di-ricorsione","text":"Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta","title":"Tipologie di ricorsione"},{"location":"FdI/induzioneRicorsione/#ricorsione-annidata","text":"Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata","title":"Ricorsione annidata"},{"location":"FdI/induzioneRicorsione/#ricorsione-mutua","text":"","title":"Ricorsione mutua"},{"location":"FdI/induzioneRicorsione/#ricorsione-procedurale","text":"","title":"Ricorsione procedurale"},{"location":"FdI/insiemi/","text":"Gli insiemi \u00b6 Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti Definizione di insiemi \u00b6 Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole. Definzione per Enumerazione \u00b6 L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale ! L'insieme vuoto \u00b6 L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\) Definizione per Propriet\u00e0 \u00b6 \u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\) I paradossi \u00b6 In base alle definizioni date, si possono verificare dei paradossi. Il paradosso di Russel \u00b6 Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato Diagrammi di Eulero-Venn \u00b6 I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 I confronti tra insiemi \u00b6 Uguaglianza \u00b6 Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ). Inclusione \u00b6 Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) . Operazioni su insiemi \u00b6 Unione \u00b6 Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) . Intersezione \u00b6 Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\) Differenza \u00b6 Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\) Complemento \u00b6 Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\] Operatori booleani \u00b6 I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica . Le leggi \u00b6 Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali. Dimostrazioni \u00b6 Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive Dimostrazione grafica \u00b6 La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo. Dimostrazione per sostituzione \u00b6 Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0) Dimostrazione discorsive \u00b6 Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente Insiemi di insiemi \u00b6 Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\) Famiglie di insiemi \u00b6 Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\) Partizioni \u00b6 Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\") Numeri naturali come insiemi \u00b6 \u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\) Il prodotto cartesiano \u00b6 Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) ) La cardinalit\u00e0 \u00b6 La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\) Propriet\u00e0 \u00b6 Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Insiemi"},{"location":"FdI/insiemi/#gli-insiemi","text":"Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti","title":"Gli insiemi"},{"location":"FdI/insiemi/#definizione-di-insiemi","text":"Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole.","title":"Definizione di insiemi"},{"location":"FdI/insiemi/#definzione-per-enumerazione","text":"L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale !","title":"Definzione per Enumerazione"},{"location":"FdI/insiemi/#linsieme-vuoto","text":"L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\)","title":"L'insieme vuoto"},{"location":"FdI/insiemi/#definizione-per-proprieta","text":"\u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\)","title":"Definizione per Propriet\u00e0"},{"location":"FdI/insiemi/#i-paradossi","text":"In base alle definizioni date, si possono verificare dei paradossi.","title":"I paradossi"},{"location":"FdI/insiemi/#il-paradosso-di-russel","text":"Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato","title":"Il paradosso di Russel"},{"location":"FdI/insiemi/#diagrammi-di-eulero-venn","text":"I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Diagrammi di Eulero-Venn"},{"location":"FdI/insiemi/#i-confronti-tra-insiemi","text":"","title":"I confronti tra insiemi"},{"location":"FdI/insiemi/#uguaglianza","text":"Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ).","title":"Uguaglianza"},{"location":"FdI/insiemi/#inclusione","text":"Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) .","title":"Inclusione"},{"location":"FdI/insiemi/#operazioni-su-insiemi","text":"","title":"Operazioni su insiemi"},{"location":"FdI/insiemi/#unione","text":"Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) .","title":"Unione"},{"location":"FdI/insiemi/#intersezione","text":"Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\)","title":"Intersezione"},{"location":"FdI/insiemi/#differenza","text":"Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\)","title":"Differenza"},{"location":"FdI/insiemi/#complemento","text":"Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\]","title":"Complemento"},{"location":"FdI/insiemi/#operatori-booleani","text":"I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica .","title":"Operatori booleani"},{"location":"FdI/insiemi/#le-leggi","text":"Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali.","title":"Le leggi"},{"location":"FdI/insiemi/#dimostrazioni","text":"Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive","title":"Dimostrazioni"},{"location":"FdI/insiemi/#dimostrazione-grafica","text":"La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo.","title":"Dimostrazione grafica"},{"location":"FdI/insiemi/#dimostrazione-per-sostituzione","text":"Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0)","title":"Dimostrazione per sostituzione"},{"location":"FdI/insiemi/#dimostrazione-discorsive","text":"Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente","title":"Dimostrazione discorsive"},{"location":"FdI/insiemi/#insiemi-di-insiemi","text":"Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\)","title":"Insiemi di insiemi"},{"location":"FdI/insiemi/#famiglie-di-insiemi","text":"Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\)","title":"Famiglie di insiemi"},{"location":"FdI/insiemi/#partizioni","text":"Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\")","title":"Partizioni"},{"location":"FdI/insiemi/#numeri-naturali-come-insiemi","text":"\u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\)","title":"Numeri naturali come insiemi"},{"location":"FdI/insiemi/#il-prodotto-cartesiano","text":"Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) )","title":"Il prodotto cartesiano"},{"location":"FdI/insiemi/#la-cardinalita","text":"La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\)","title":"La cardinalit\u00e0"},{"location":"FdI/insiemi/#proprieta","text":"Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Propriet\u00e0"},{"location":"FdI/linguaggi/","text":"","title":"Linguaggi Formali"},{"location":"FdI/logica/","text":"La logica \u00b6 La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ). Il calcolo proposizionale \u00b6 Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali) Composizione di proposizioni \u00b6 Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici . Sintassi del calcolo proposizionale \u00b6 Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali I connettivi logici \u00b6 Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) . La formalizzazione di proposizioni \u00b6 Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\) La semantica \u00b6 La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\] Le tavole di verit\u00e0 \u00b6 \u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\) Il concetto di Tautologia \u00b6 Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso. Dimostrazioni nel calcolo proposizionale \u00b6 Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) . Formalizzazione di inferenze e tautologie \u00b6 \u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Magari scrivere dopo Dimostrazioni per sostituzione di tautologie \u00b6 Rimpiazzamento \u00b6 Principio di sostituzione \u00b6 \u00b6 Logica dei predicati \u00b6","title":"Logica Matematica"},{"location":"FdI/logica/#la-logica","text":"La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ).","title":"La logica"},{"location":"FdI/logica/#il-calcolo-proposizionale","text":"Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali)","title":"Il calcolo proposizionale"},{"location":"FdI/logica/#composizione-di-proposizioni","text":"Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici .","title":"Composizione di proposizioni"},{"location":"FdI/logica/#sintassi-del-calcolo-proposizionale","text":"Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali","title":"Sintassi del calcolo proposizionale"},{"location":"FdI/logica/#i-connettivi-logici","text":"Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) .","title":"I connettivi logici"},{"location":"FdI/logica/#la-formalizzazione-di-proposizioni","text":"Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\)","title":"La formalizzazione di proposizioni"},{"location":"FdI/logica/#la-semantica","text":"La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\]","title":"La semantica"},{"location":"FdI/logica/#le-tavole-di-verita","text":"\u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\)","title":"Le tavole di verit\u00e0"},{"location":"FdI/logica/#il-concetto-di-tautologia","text":"Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso.","title":"Il concetto di Tautologia"},{"location":"FdI/logica/#dimostrazioni-nel-calcolo-proposizionale","text":"Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) .","title":"Dimostrazioni nel calcolo proposizionale"},{"location":"FdI/logica/#formalizzazione-di-inferenze-e-tautologie","text":"\u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Magari scrivere dopo","title":"Formalizzazione di inferenze e tautologie"},{"location":"FdI/logica/#dimostrazioni-per-sostituzione-di-tautologie","text":"","title":"Dimostrazioni per sostituzione di tautologie"},{"location":"FdI/logica/#rimpiazzamento","text":"","title":"Rimpiazzamento"},{"location":"FdI/logica/#principio-di-sostituzione","text":"","title":"Principio di sostituzione"},{"location":"FdI/logica/#_1","text":"","title":""},{"location":"FdI/logica/#logica-dei-predicati","text":"","title":"Logica dei predicati"},{"location":"FdI/relazioni/","text":"Relazioni \u00b6 Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\) Operazioni su relazioni \u00b6 Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\) Composizione \u00b6 Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C Quantificatori \u00b6 Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica Relazione opposta \u00b6 La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\) Leggi \u00b6 Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\) Propriet\u00e0 di relazioni \u00b6 Le propriet\u00e0 TUSI \u00b6 In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva Risultati di dualit\u00e0 \u00b6 Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\) Teorema di caratterizzazione \u00b6 Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\) Chiusura per composizione \u00b6 \u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva Funzioni \u00b6 Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ). Propriet\u00e0 \u00b6 Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) . Composizione di funzioni \u00b6 Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\) Teorema di caratterizzazione \u00b6 Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\) Funzioni parziali \u00b6 Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale. Funzioni surgettive ed iniettive \u00b6 Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0. Biiezioni \u00b6 Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione. Caratterizzazione attraverso relazioni invertibili \u00b6 Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile Insiemi in biiezione \u00b6 Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0. n-uple e sequenze \u00b6 Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"Relazioni"},{"location":"FdI/relazioni/#relazioni","text":"Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\)","title":"Relazioni"},{"location":"FdI/relazioni/#operazioni-su-relazioni","text":"Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\)","title":"Operazioni su relazioni"},{"location":"FdI/relazioni/#composizione","text":"Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C","title":"Composizione"},{"location":"FdI/relazioni/#quantificatori","text":"Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica","title":"Quantificatori"},{"location":"FdI/relazioni/#relazione-opposta","text":"La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\)","title":"Relazione opposta"},{"location":"FdI/relazioni/#leggi","text":"Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\)","title":"Leggi"},{"location":"FdI/relazioni/#proprieta-di-relazioni","text":"","title":"Propriet\u00e0 di relazioni"},{"location":"FdI/relazioni/#le-proprieta-tusi","text":"In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/relazioni/#risultati-di-dualita","text":"Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\)","title":"Risultati di dualit\u00e0"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione","text":"Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#chiusura-per-composizione","text":"\u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva","title":"Chiusura per composizione"},{"location":"FdI/relazioni/#funzioni","text":"Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ).","title":"Funzioni"},{"location":"FdI/relazioni/#proprieta","text":"Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) .","title":"Propriet\u00e0"},{"location":"FdI/relazioni/#composizione-di-funzioni","text":"Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\)","title":"Composizione di funzioni"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione_1","text":"Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#funzioni-parziali","text":"Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale.","title":"Funzioni parziali"},{"location":"FdI/relazioni/#funzioni-surgettive-ed-iniettive","text":"Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0.","title":"Funzioni surgettive ed iniettive"},{"location":"FdI/relazioni/#biiezioni","text":"Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione.","title":"Biiezioni"},{"location":"FdI/relazioni/#caratterizzazione-attraverso-relazioni-invertibili","text":"Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile","title":"Caratterizzazione attraverso relazioni invertibili"},{"location":"FdI/relazioni/#insiemi-in-biiezione","text":"Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0.","title":"Insiemi in biiezione"},{"location":"FdI/relazioni/#n-uple-e-sequenze","text":"Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"n-uple e sequenze"},{"location":"FdI/relazioniInsiemi/","text":"Relazioni su insiemi \u00b6 Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi . Propriet\u00e0 di relazioni su un insieme \u00b6 Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ). Teorema di caratterizzazione \u00b6 Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\) Le chiusure \u00b6 Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta Chiusura riflessiva \u00b6 Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme. Chiusura simmetrica \u00b6 Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta Chiusura transitiva \u00b6 La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\) La stella di Kleene \u00b6 Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\) Relazioni di equivalenza \u00b6 Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza. Kernel di una funzione \u00b6 Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa. Relazioni di equivalenza e partizioni \u00b6 Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\] Relazioni di ordinamento \u00b6 Relazione di ordinamento parziale \u00b6 Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) . Relazione di ordinamento \u00b6 Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\) Ordinamento lessicografico \u00b6 Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#relazioni-su-insiemi","text":"Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi .","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#proprieta-di-relazioni-su-un-insieme","text":"Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ).","title":"Propriet\u00e0 di relazioni su un insieme"},{"location":"FdI/relazioniInsiemi/#teorema-di-caratterizzazione","text":"Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioniInsiemi/#le-chiusure","text":"Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta","title":"Le chiusure"},{"location":"FdI/relazioniInsiemi/#chiusura-riflessiva","text":"Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme.","title":"Chiusura riflessiva"},{"location":"FdI/relazioniInsiemi/#chiusura-simmetrica","text":"Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta","title":"Chiusura simmetrica"},{"location":"FdI/relazioniInsiemi/#chiusura-transitiva","text":"La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\)","title":"Chiusura transitiva"},{"location":"FdI/relazioniInsiemi/#la-stella-di-kleene","text":"Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\)","title":"La stella di Kleene"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza","text":"Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza.","title":"Relazioni di equivalenza"},{"location":"FdI/relazioniInsiemi/#kernel-di-una-funzione","text":"Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa.","title":"Kernel di una funzione"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza-e-partizioni","text":"Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\]","title":"Relazioni di equivalenza e partizioni"},{"location":"FdI/relazioniInsiemi/#relazioni-di-ordinamento","text":"","title":"Relazioni di ordinamento"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento-parziale","text":"Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) .","title":"Relazione di ordinamento parziale"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento","text":"Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\)","title":"Relazione di ordinamento"},{"location":"FdI/relazioniInsiemi/#ordinamento-lessicografico","text":"Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Ordinamento lessicografico"},{"location":"LabI/","text":"","title":"Laboratorio I"},{"location":"ProAlgo/","text":"Definizione di Algoritmo \u00b6 Definizione di Programma \u00b6 Composizione di un programma \u00b6 Sintassi \u00b6 Categorie sintattiche \u00b6 Dichiarazioni \u00b6 Comandi \u00b6 Espressioni \u00b6 Lessico \u00b6 Grammatica \u00b6 Semantica \u00b6 Scoping \u00b6 Questa roba non so dove vada Funzioni \u00b6 Parametri formali Passaggio per riferimento e per valore Record di attivazione \u00b6 Contiene: - Identit\u00e0 - Chiamante - A chi restituire - Corpo della funzione corrente Tipologia di linguaggi \u00b6 Linguaggio interpretato \u00b6 Linugaggio compilato \u00b6 Architettura di von-Neumann \u00b6 Ciclo fetch-execute \u00b6 valutazione di un algoritmo \u00b6 Analizzare un algoritmo significa predirre le risorse che l'algoritmo richieder\u00e0. Si opssono predirre risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza. La recurisione e l'approccio divide-and-conquer \u00b6 Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera recursiva fino a generare una soluzione per il problema originale La recursione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo recursivo Si dice algoritmo recursivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso recursivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato. Analisi degli algoritmi divide-and-conquer \u00b6 Quando un algoritmo effettua una chiamata recursiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metod[o di sostituzione Il metodo di sostisuzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem Il master theorem \u00e8 un teorema che ci permtte di risolvere velocemente equazioni della forma \\(aT(\\frac{n}{b}) + f(n)\\) , con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema e \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi RISCRIVERE SEGUENDO GLI APPUNTI DEL PROF Classi di complessit\u00e0 \u00b6 se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo","title":"Definizione di Algoritmo"},{"location":"ProAlgo/#definizione-di-algoritmo","text":"","title":"Definizione di Algoritmo"},{"location":"ProAlgo/#definizione-di-programma","text":"","title":"Definizione di Programma"},{"location":"ProAlgo/#composizione-di-un-programma","text":"","title":"Composizione di un programma"},{"location":"ProAlgo/#sintassi","text":"","title":"Sintassi"},{"location":"ProAlgo/#categorie-sintattiche","text":"","title":"Categorie sintattiche"},{"location":"ProAlgo/#dichiarazioni","text":"","title":"Dichiarazioni"},{"location":"ProAlgo/#comandi","text":"","title":"Comandi"},{"location":"ProAlgo/#espressioni","text":"","title":"Espressioni"},{"location":"ProAlgo/#lessico","text":"","title":"Lessico"},{"location":"ProAlgo/#grammatica","text":"","title":"Grammatica"},{"location":"ProAlgo/#semantica","text":"","title":"Semantica"},{"location":"ProAlgo/#scoping","text":"Questa roba non so dove vada","title":"Scoping"},{"location":"ProAlgo/#funzioni","text":"Parametri formali Passaggio per riferimento e per valore","title":"Funzioni"},{"location":"ProAlgo/#record-di-attivazione","text":"Contiene: - Identit\u00e0 - Chiamante - A chi restituire - Corpo della funzione corrente","title":"Record di attivazione"},{"location":"ProAlgo/#tipologia-di-linguaggi","text":"","title":"Tipologia di linguaggi"},{"location":"ProAlgo/#linguaggio-interpretato","text":"","title":"Linguaggio interpretato"},{"location":"ProAlgo/#linugaggio-compilato","text":"","title":"Linugaggio compilato"},{"location":"ProAlgo/#architettura-di-von-neumann","text":"","title":"Architettura di von-Neumann"},{"location":"ProAlgo/#ciclo-fetch-execute","text":"","title":"Ciclo fetch-execute"},{"location":"ProAlgo/#valutazione-di-un-algoritmo","text":"Analizzare un algoritmo significa predirre le risorse che l'algoritmo richieder\u00e0. Si opssono predirre risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza.","title":"valutazione di un algoritmo"},{"location":"ProAlgo/#la-recurisione-e-lapproccio-divide-and-conquer","text":"Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera recursiva fino a generare una soluzione per il problema originale La recursione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo recursivo Si dice algoritmo recursivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso recursivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato.","title":"La recurisione e l'approccio divide-and-conquer"},{"location":"ProAlgo/#analisi-degli-algoritmi-divide-and-conquer","text":"Quando un algoritmo effettua una chiamata recursiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metod[o di sostituzione Il metodo di sostisuzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem Il master theorem \u00e8 un teorema che ci permtte di risolvere velocemente equazioni della forma \\(aT(\\frac{n}{b}) + f(n)\\) , con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema e \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi RISCRIVERE SEGUENDO GLI APPUNTI DEL PROF","title":"Analisi degli algoritmi divide-and-conquer"},{"location":"ProAlgo/#classi-di-complessita","text":"se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo","title":"Classi di complessit\u00e0"},{"location":"ProAlgo/relazioniRicorrenza/","text":"Relazioni di ricorrenza \u00b6","title":"Relazioni di ricorrenza"},{"location":"ProAlgo/relazioniRicorrenza/#relazioni-di-ricorrenza","text":"","title":"Relazioni di ricorrenza"}]}