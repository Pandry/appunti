{"config":{"indexing":"full","lang":["it"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Appunti universitari \u00b6 Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"#appunti-universitari","text":"Questo sito/repo vuole essere un esperimento di studio, per capire se \u00e8 un'opzione fattibile prendere appunti in Markdown per i miei corsi di informatica. Al momento l'unica materia presente \u00e8 Fondamenti di Informatica , e appunto essendo un esperimento non vuole essere assolutamente una sorgente di materiali.","title":"Appunti universitari"},{"location":"AlgebraLineare/","text":"","title":"Algebra Lineare"},{"location":"AnalisiI/calcoloDifferenziale/","text":"Massimo, maggiorante ed insieme limitato \u00b6 Massimo di un insieme \u00b6 Massimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice massimo di A se } m \\ge a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Dato un subset A di R non vuoto, un numero m reale si dice massimo dell'insieme A se m >= di a e m \u00e8 in A Quindi ad esempio se A \u00e8 l'intervallo \\(A = [0,1] \\Rightarrow max(A) =1\\) Tuttavia non tutti gli insiemi hanno un massimo: \\(B = [0,1)\\) allora B non ha massimo La dimostrazione \u00e8 abbastanza semplice quando fatta per assurdo: Dimostrazione Preso come esempio l'intervallo B appena citato, possiamo prendere un numero nell'insieme B e chiamarlo m (ad esempio 0.9). Troviamo quindi un \\(\\epsilon=1-m > 0\\) (in questo caso \\(\\epsilon = 0.1\\) ) A questo punto possiamo definire \\(m_1 = m + \\frac \\epsilon 2\\) . Avremo quindi che \\(m < m_1\\) , con \\(m_1 \\in B\\) e quindi \\(m_1\\) dovrebbe essere il massimo. Quindi B non ha massimo. Maggiorante \u00b6 Maggiorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice maggiorante di A se \\(k \\ge a \\forall a \\in A\\) . L'insieme di tutti i maggioranti si indica con \\(\\mathcal M_A\\) Un maggiorante deve essere quindi pi\u00f9 grande di tutti gli elementi di A e non \u00e8 detto che appartenga ad A. Quindi, riprendendo l'esempio precedente \\(A=[0,1]\\) , \\(3 \\in \\mathcal M_A\\) , mentre \\(\\frac 1 4\\) non \u00e8 un maggiorante Possiamo quindi fare un paio di osservazioni: Se esiste un maggiorante di A allora ne esistono infiniti: se k \u00e8 un maggiorante di A allora m \u00e8 un maggiorante di A \\(\\forall m \\ge k\\) Alcuni insiemi non hanno maggioranti: \\(A = \\mathbb R\\) non ha maggioranti, cos\u00ec come la semiretta \\([4, +\\infty)\\) Insieme superiormente limitato \u00b6 Insieme limitato superiormente Se l'insieme dei maggioranti \u00e8 non vuoto \\(\\mathcal M_A \\ne \\varnothing\\) , l'insieme A si dice limitato superiormente Minimo, minorante ed insieme limitato inferiormente \u00b6 Minimo, minorante ed insieme inferiormente limitato Le stesse definizioni ma opposte si applicano per minimo, minorante e insieme inferiormente limitato Minimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice minimo di A se } m \\le a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Minorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice minorante di A se \\(k \\le a \\forall a \\in A\\) . Insieme limitato inferiormente Se l'insieme dei minoranti \u00e8 non vuoto \\(m_A \\ne \\varnothing\\) , l'insieme A si dice limitato inferiormente Insieme limitato \u00b6 Insieme limitato Dato un insieme \\(A \\subset \\mathbb R, a \\ne \\varnothing\\) se A \u00e8 sia superiormente che inferiormente limitato, allora A si dice limitato Un insieme A \u00e8 quindi limitato se e solo se \\(\\exists h,k \\in \\mathbb R\\) tale che \\(k \\le a \\le h \\quad \\forall a \\in A\\) Quindi i due valori sono estermi all'insieme, limitandolo. L'estremo di una funzione \u00b6 Teorema dell'estremo superiore Dato un sotto insieme di R \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) , superiormente limitato, allora esiste il minimo dell'insieme dei maggioranti. Tale minimo si dice estremo superiore di A e si indica con \\(sup(A)\\) L'estremo superiore \u00e8 quindi il minimo dei maggioranti, ed ogni insieme limitato superioremente ha un estremo superiroe. Possiamo quindi vedere che l'insieme dei maggioranti ha sempre minimo Quindi, ad esempio: \\(A = [0,1) \\Rightarrow \\mathcal M_A = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di A \u00e8 1. \\(B = [0,1] \\Rightarrow \\mathcal M_B = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di B \u00e8 1. Il massimo di un insieme \u00e8 il suo limite superiore Se esiste il massimo di un insime A, allora il massimo di A coincide con l'estremo superiore. un insieme limitato superiormente ha sempre un estremo superiore. Se questo elemento appartiene anche all'insieme \u00e8 anche un massimo: \\(\\exists \\; max(A) \\rightarrow max(A) = sup(A)\\) (Se esiste \\(max(A)\\) allora \\(max(A)=sup(A)\\) ) Insieme non limitato superiormente Se l'insieme A non \u00e8 superiormente limitato, scriviamo \\(sup(A) = + \\infty\\) Verificare che un oggetto \u00e8 un estremo superiore \\(A \\ne \\varnothing\\) superioremente limitato. Allora \\(m = sup(A)\\) se e solo se valgono: \\(a \\le m \\; \\forall a \\in A\\) (che significa che m \u00e8 un maggiorante) \\(\\forall \\epsilon > 0 \\; \\exists \\; \\bar a \\in A\\) tale che \\(\\bar a > m - \\epsilon\\) (spostarsi a sinistra di m c'\u00e8 un elemento a destra di m \\epsilon, non ci sono maggioranti pi\u00f9 piccoli di m; m \u00e8 il pi\u00f9 piccolo dei maggioranti) Un insieme superiormente limitato \u00e8 minore di infinito La scrittura \\(sup(A) < + \\infty\\) singifica che l'estremo superore di A \u00e8 un numero reale, quindi A \u00e8 superiormente limitato. La retta reale estesa \u00b6 Retta reale estesa \\(\\bar{ \\; \\mathbb{R} \\; } = \\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{+\\infty\\}\\) in modo che valga \\(-\\infty \\le m \\le + \\infty \\quad \\forall x \\in \\bar{\\;\\mathbb R\\;}\\) Ergo, se \\(x \\in \\mathbb R\\) (quindi \\(x \\ne +\\infty, x \\ne -\\infty\\) ), allora \\(-\\infty < x < + \\infty\\) Operazionu sulla retta reale estesa \u00b6 Operazioni in \\(\\bar {\\mathbb R}\\) Se \\(x \\ne +\\infty\\) , allora \\(x + (- \\infty) = - \\infty\\) Se \\(x \\ne -\\infty\\) , allora \\(x + (+ \\infty) = + \\infty\\) Se \\(x \\gt 0\\) allora \\(x \\cdot (+ \\infty) = + \\infty\\) e \\(x \\cdot (- \\infty) = - \\infty\\) Se \\(x \\lt 0\\) allora \\(x \\cdot (+ \\infty) = - \\infty\\) e \\(x \\cdot (- \\infty) = + \\infty\\) Operazioni vietate (forme indeterminate) \\((+ \\infty) + (- \\infty)\\) \\(0 \\cdot (+ \\infty)\\) \\(0 \\cdot (- \\infty)\\) Operazioni valide \\(+ \\infty \\cdot + \\infty = + \\infty\\) \\(+ \\infty \\cdot - \\infty = - \\infty\\) \\(- \\infty \\cdot - \\infty = + \\infty\\) Minimi e massimi di insiemi limitati \u00b6 Insiemi limitati hanno minimi o massimi Dato \\(A \\subset \\mathbb Z\\) (interi) se A \u00e8 superiormente limitato, A ha massimo. Se A \u00e8 inferiormente limitato, allora A ha minimo Parte intera Dato \\(x \\in \\mathbb R\\) si dice parte intera di x e si indica con \\([x]\\) il numero \\([x] = max \\{ m \\in \\mathbb Z : m \\le x \\}\\) . Ovvero: se abbiamo x (reale) tra due interi, la parte intera di x \u00e8 il primo intero che si ottiene spostandosi a sinistra. Ad esempio: \\([\\frac {25}{10}] = 2\\) \\([-\\frac {25}{10}] = -3\\) Funzioni limitate \u00b6 Funzione limitata f si dice limitata: superiormente se f(a) (la sua immagine) \u00e8 limitato superiormente inferiormente se f(a) (la sua immagine) \u00e8 limitato inferiormente se \\(f(a)\\) (la sua immagine) \u00e8 limitato Massimo e minimo di una funzione \u00b6 Funzione con massimo \\(f\\) ha massimo se \\(f(A)\\) (la sua immagine) ha massimo. Si dice che \\(M\\) \u00e8 il massimo di \\(f\\) e si scrive \\(M = max(f)\\) se \\(M = max(A)\\) Funzione con minimo \\(f\\) ha minimo se \\(f(A)\\) (la sua immagine) ha minimo. Si dice che m \u00e8 il minimo di \\(f\\) e si scrive \\(m = min(f)\\) se \\(m = min(A)\\) Limiti di una funzione \u00b6 Limiti di una funzione \\(sup(f) = sup(f(A))\\) Se \\(f\\) non \u00e8 limitata superiormente si scrive \\(sup(f) = + \\infty\\) . Lo stesso vale per inf (limite inferiore). Punti di massimo di una funzione \u00b6 Punti di massimo Se \\(f\\) ha massimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = max(f)\\) si dicono punti di massimo. Se \\(f\\) ha minimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = min(f)\\) si dicono punti di minimo. Massimo e punti di massimo Il massimo di \\(f\\) \u00e8 unico; i punti di massimo potrebbero essere molti. Lo stesso vale per il minimo. Nella funzione seno, il massimo \u00e8 \\(max(f) = 1\\) e 0 i punti di massimo sono \\(x_0 = \\frac \\pi 2 + k\\cdot 2 \\pi, k \\in \\mathbb Z\\) Una funzione come \\(f:(0, +\\infty) \\rightarrow \\mathbb R \\quad f(x) = \\frac 1 x\\) non ha n\u00e9 massimo n\u00e9 minimo. La funzione ad infinito tende a 0: Se avesse massimo \\(\\Rightarrow \\exists M\\) tale che \\(f(x) \\le M \\forall x \\in (0, + \\infty)\\) : \\(f(x) > 0 \\forall x \\Rightarrow 0\\) \u00e8 un minorante \\(0=inf(f)\\) (inf = estremo inferiore) 0 \u00e8 quindi l'estremo inferiore di f, ma 0 NON \u00e8 un minimo. Se la funzione avesse minimo, allora dovrebbe essere \\(min(f)=inf(f)=0\\) , quindi dovrebbe esistere un \\(x_0\\) tale che \\(f(x_0)=0\\) cio\u00e8 \\(\\frac 1 {x_0}\\) , che \u00e8 impossibile. \\(f: A \\rightarrow \\mathbb R\\) allora \\(m = sup(f)\\) se e solo se: \\(f(x) \\le m \\forall x \\in A\\) \\(\\forall \\epsilon > 0 \\exists \\bar x \\in S\\) tale che \\(f(\\bar x) > m - \\epsilon\\) Se si abbassa la quota di m si \"taglia\" la funzione Valore assoluto \u00b6 Valore assoluto Dato \\(x \\in \\mathbb R\\) si dice valore assoluto di x e si indica con |x| il numero \\(|x| = max(x,-x)\\) Quindi: \\(x \\le |x|\\) \\(|x| = x\\) se \\(x \\ge 0\\) , \\(|x| = -x\\) se \\(x \\le 0\\) \\(|x| \\ge 0 \\forall x \\in \\mathbb R\\) \\(|x| = 0 \\Leftrightarrow x = 0\\) \\(|x| = |-x|\\) \\(-|x| \\le x \\le |x|\\) \\(|x| \\le M \\Leftrightarrow -M \\le x \\le M\\) ( \\(M \\gt 0\\) ) \\(|x| \\gt M \\Leftrightarrow x \\gt M\\) oppure \\(x \\lt -M\\) Come altre propriet\u00e0 possiamo poi aggiungere: \\(|x| \\le x_0 \\Leftrightarrow -x_0 \\le m \\le x_0\\) \\(|x| \\ge x_0 \\Leftrightarrow x \\le -x_0\\) oppure \\(x \\ge x_0\\) Disuguaglianza triangolare \u00b6 Disuguaglianza triangolare Dati \\(a, b \\in \\mathbb R\\) , risulta che: \\(|a + b| \\le |a| + |b|\\) \\(||a| - |b| | \\le |a-b|\\) Questo discorso vale anche per pi\u00f9 valori: \\(|a + b + c| \\le |a + b + c|\\) \\(|a + b + c| = |(a + b) + c| \\le |a + b| + |c| \\le |a| + |b| + |c|\\) La continuit\u00e0 \u00b6 Funzione continua in un punto \\(A \\subset \\mathbb R, f: A \\rightarrow \\mathbb R, x_0 \\in A\\) . La funzione si dice continua in x_0 se \\(\\forall \\epsilon > 0 \\; \\exists \\; \\delta > 0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)| < \\epsilon\\) Spiegandola un po': \\(|x - x_0| < \\delta \\Leftrightarrow x_0 - \\delta < x < x_0 + \\delta\\) ( \\(x\\) \u00e8 compreso tra \\(x_0 \\pm \\delta\\) ) \\(|f(x) - f(x_0)| < \\epsilon \\Leftrightarrow f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) (la funzione oscilla intorno ad \\(f(x_0)\\) ad un ampiezza massima di \\(\\epsilon\\) ) Se esiste un \\(\\delta\\) nell' \\(epsilon\\) dato, la funzione \u00e8 continua Una funzione \u00e8 sempre continua nei punti isolati La continuit\u00e0 include un concetto di prossimit\u00e0 del punto (al punto dove si considera la continuit\u00e0): se il punto \u00e8 isolato non \u00e8 possibile avvicinarsi al punto, ci si pu\u00f2 solo \"trovare\" nel punto. Esempio di funzione non continua in un punto Data la funzione \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione non \u00e8 continua nel punto \\(x_0 = 0\\) (in cui scegliamo \\(\\epsilon = \\frac 1 2\\) ): In questa funzione, \\(\\forall \\delta > 0, x \\in (0, \\delta) \\rightarrow f(x) =1\\) La disuguaglianza \\(f(x) < f(0)+\\epsilon\\) \u00e8 falsa: \\(0-\\frac 1 2 < f(x) < 0 + \\frac 1 2\\) : \\(1 < \\frac 1 2 \\Rightarrow f\\) non \u00e8 continua in \\(x_0 = 0\\) Funzione continua in un insieme Dati \\(A \\in \\mathbb R, f: A \\rightarrow \\mathbb R, B \\subset A\\) , Si dice che la funzione \\(f\\) \u00e8 continua in B se \u00e8 continua in ogni punto \\(x_0 \\in B\\) . Se si dice che f \u00e8 continua (senza specificare il sottoinsieme B), significa che f \u00e8 continua in tutti i punti del suo dominio A. Esempio di funzione non continua in un insieme Riprendendo la funzione di prima \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione \u00e8 continua in \\((-\\infty, 0) \\cup (0, + \\infty)\\) Teoremi sulla continuit\u00e0 \u00b6 Teorema sulla permanenza del segno \\(A \\subset \\mathbb R, f:A \\rightarrow \\mathbb R, x_0 \\in A\\) Se f \u00e8 continua in \\(x_0\\) e \\(f(x_0) > 0\\) allora \\(\\exists \\delta > 0\\) tale che se \\(x \\in A\\) e \\(|x -x_0| < \\delta Rightarrow f(x) > 0\\) . Stesso risultato se \\(f(x) < 0\\) Quindi, se una funzione continua assume valore di segno positivo in un punto, allora mantiene lo stesso segno nei punti molto vicini al punto. Dimostrazione Sappiamo che \\(f(x_0) > 0\\) . Scelgo \\(\\epsilon = \\frac {f(x_0)} 2\\) e lo uso nella definizione di continuit\u00e0. Esiste quindi un \\(\\delta >0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)|< \\epsilon\\) Ovvero: \\(f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) Prendendo la prima parte della disuguaglianza, si ottiene che \\(f(x) > f(x_0) - \\epsilon = f(x_0) - \\frac {f(x_0)} 2 \\Rightarrow \\frac {f(x_0)} 2 > 0\\) Essendo il valore lontano da zero, se ci si sposta un po' vicino al punto; Il valore della fuzonone si sposta poco e quindi il segno rimane concorde. Questo discorso vale anche per un valore \\(m \\in \\mathbb R\\) tale che \\(f(x_0) > m\\) In tal caso \\(\\exists \\delta > 0\\) t.c. \\(x \\in A, |x - x_0| < \\delta \\Rightarrow f(x) > m\\) (Questo discorso vale anche con \\(f(x) < m \\Rightarrow f(x) < m\\) ) Teorema sulla combinazione di funzioni continue (somma e prodotto) Se \\(f\\) e \\(g\\) sono continue in \\(x_0\\) allora lo sono anche le funzioni \\(f+g\\) , \\(f \\cdot g\\) e \\(|f|\\) . Se inoltre \\(f(x_0) \\neq 0\\) , allora anche \\(\\frac 1 f\\) \u00e8 continua. \\(\\frac f g\\) \u00e8 continua (se \\(g(x_0) \\ne 0\\) ). \\(\\frac f g = f \\cdot \\frac 1 g\\) \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow B \\subset \\mathbb R\\) . Se \\(f\\) \u00e8 continua in \\(I\\) ed \u00e8 invertibile, allora \\(f^{-1}\\) \u00e8 continua. L'ipotesi che il dominios sia un'intervallo non pu\u00f2 essere omessa. Esempio \\(f:(-\\infty, 1] \\cup (2, +\\infty) \\rightarrow \\mathbb R\\) \\(f(x)= \\begin{cases} x \\quad \\;\\;\\; \\text{ se } x \\le 1 \\\\ x-1 \\text{ se } x > 1 \\end{cases}\\) Alla domanda se la funzione \u00e8 continua, la risposta \u00e8 s\u00ec. Tuttavia la sua inversa \\(f^{-1}: \\mathbb R \\rightarrow (-\\infty, 1] \\cup (2, + \\infty)\\) non \u00e8 continua in \\(x_0\\) . Non \u00e8 continua perch\u00e9 c'\u00e8 una specie di salto in \\(x=1\\) : Se f non \u00e8 definita su un intervallo, potrebbe accadere che la sua funzione inversa non sia continua, anche se la funzione \u00e8 continua. Continuit\u00e0 delle funzioni elementari \u00b6 Le funzioni costanti sono continue \\(f(x) = x\\) \u00e8 continua. Da ci\u00f2 segue che tutti i polinomi sono continui: Un polinomio ( \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_1 \\cdot x + a_0\\) ) ha i coefficienti come numeri reali ( \\(a_0, a_1, ..., a_n \\in \\mathbb R\\) ). Quindi dal teorema su somma e del prodotto so che la funzione \u00e8 continua: Una costante \u00e8 una funzione continua. Una costante (che \u00e8 una funzione continua) per x \u00e8 una funzione continua (perch\u00e9 x \u00e8 una funzione continua) Un monomio \u00e8 una funzione continua, in quanto \\(x^2 = x \\cdot x\\) , ovvero una funzione continua moltiplicata per una funzione continua - Le funzioni razionali sono continue nel loro insieme di definizione. Una funzione razionale \u00e8 un quoziente di polinomi ( \\(f(x) = \\frac {p(x)}{q(x)}\\) dove p e q sono funzioni polinomiali) Definita se \\(q(x) \\ne 0\\) - \\(e^x\\) , \\(sin(x)\\) e \\(cos(x)\\) sono funzioni continue. Quindi anche \\(log(x)\\) , \\(arcsin(x)\\) , \\(arccos(x)\\) saranno continue in quanto inverse. Ma anch e \\(tg(x)\\) (perch\u00e9 \u00e8 quoziente di seno e coseno) e anche \\(arctg(x)\\) Continuit\u00e0 di composizione di funzioni Date le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow \\mathbb R\\) , con \\(x_0 \\in A, y_0=f(x_0) \\in B\\) Se \\(f\\) \u00e8 continua in \\(x_0\\) e \\(g\\) \u00e8 continua in \\(y_0\\) , allora \\(g \\circ f\\) \u00e8 continua in \\(x_0\\) Esempio \\(e^{cos(x)}\\) \u00e8 una funzione continua in quanto composizione di \\(f(x) = cos(x)\\) e \\(g(y) = e^y\\) Il massimo di un insieme \u00e8 il suo limite superiore Se si ha una funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua in \\([a,b]\\) , L'estremo superiore \u00e8 uguale se l'intevallo \u00e8 aperto o chiuso: \\({\\sup _{x \\in (a,b)}} f(x) = \\sup _{x \\in [a,b]} f(x)\\) Vale poi lo stesso per l'estremo inferiore: \\({\\inf _{x \\in (a,b)}} f(x) = \\inf _{x \\in [a,b]} f(x)\\) Teorema degli zeri \u00b6 Teorema degli zeri Data la funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua Se \\(f(a) \\cdot f(b) < 0\\) allora \\(\\exists \\; c \\in (a,b)\\) tale che \\(f(c) =0\\) Fondamentalmente se la moltiplicazione tra i valori che la funzione assume agli estremi dell'intervallo \u00e8 minore di zero (quindi moltiplichiamo un positivo con un negativo), esiste almeno un punto \\(c\\) nell'intervallo \\((a,b)\\) tale \\(f(c) = 0\\) . L'ipotesi di continuit\u00e0 \u00e8 necessaria Teorema dei valori intermedi \u00b6 Teorema dei valori intermedi \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow \\mathbb R\\) continua. Allora \\(f(I)\\) (l'immagine di f) \u00e8 un intervallo. In questo caso, se f assume i valori y_1 e y_2, allora assume anche tutti i valori compresi tra y_1 e y_2. Notare che I deve obbligatoriamente essere un intervallo. Teorema di Weierstrass \u00b6 Teorema di Weierstrass Definita \\(f: [a,b] \\rightarrow \\mathbb R\\) continua, allora f ha massimo e minimo. Quindi dati \\(a,b \\in \\mathbb R\\) (quindi \\(a,b \\ne \\pm \\infty\\) ). L'intervallo [a,b] \u00e8 un intervallo definito limitato (gli estremi non sono pi\u00f9 e meno infinito) e chiuso (ha entrambi gli estremi). Perch\u00e9 \\([a,b]\\) deve essere limitato e chiuso? In una funzione come \\(f: (0,1] \\rightarrow \\mathbb R, f(x) = \\frac 1 x\\) , f \u00e8 continua ma non ha massimo (inoltre \\(\\sup (f) = + \\infty\\) ). Inoltre l'intervallo non \u00e8 chiuso. Prendendo \\(f: \\mathbb R \\rightarrrow \\mathbb R, f(x) = arctg(x)\\) La funzione \u00e8 continua ed \u00e8 sempre compresa tra \\(\\pm \\frac \\pi 2\\) , ma non ha n\u00e9 massimo n\u00e9 minimo. Quindi \\(sup(f) = \\frac \\pi 2\\) e \\(inf(f) = \\frac \\pi 2\\) , ma non sono n\u00e9 massimo n\u00e9 minimo Gli intorni \u00b6 Intorno Dato \\(x_0 \\in \\reals\\) , si dice intorno di \\(x_0\\) un insieme del tipo \\((x_0 - \\epsilon, x_0 + \\epsilon)\\) , dove \\(\\epsilon \\in \\reals, \\epsilon > 0\\) . \\(\\epsilon\\) si dice raggio dell'intorno. L'intorno sono quindi i punti che sono vicini ad x_0 (ovvero che distano da x_0 una quantit\u00e0 strettamente minore di \\(\\epsilon\\) ). Intorno destro e sinistro In insieme del tipo \\([x_0, x_0 + \\epsilon)\\) si dice intorno destro di \\(x_0\\) . In insieme del tipo \\((x_0 - \\epsilon, x_0]\\) si dice intorno sinistro di \\(x_0\\) . Intorni di infinito Se \\(x_0 = + \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((a, + \\infty)\\) dove \\(a \\in \\reals\\) (l'insieme \u00e8 quindi una semiretta). Se \\(x_0 = - \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((- \\infty, a)\\) dove \\(a \\in \\reals\\) . Questo significa che l'insieme vale da qualsiasi punto di \\(\\reals\\) a \\(\\pm \\infty\\) Punti di accumulazione \u00b6 Punto di accumulazione Dato \\(A \\subset \\bar \\reals\\) (ricordando che \\(\\bar \\reals = \\reals \\cup \\{ + \\infty, - \\infty \\}\\) ); \\(x_0\\) si dice punto di accumulazione per l'insieme A se \\(\\forall u\\) intorno di \\(x_0\\) , risulta \\(u \\cap A \\backslash \\{x_0\\} \\ne \\varnothing\\) Questo significa che vicino \\(x_0\\) ci sono altri punti di A oltre a \\(x_0\\) (x potrebbe non appartenere ad A). Sotto un certo punto di vista, i punti di accumulazione sono tutti quei punti che sono parte dell'insieme o gli sono \"appiccicati\" Esempio di punto di accumulazione \\(A = (2,3)\\) I punti di accumulazione di A \\(Acc(A)\\) sono tutti i punti nell'intervallo \\((2,3)\\) : \\((2,3) \\subset Acc(A)\\) , ma lo \u00e8 anche per i punti 2 e 3. Quindi \\(Acc(A) = [2, 3]\\) Ma anche \\(Acc([2,3]) = [2,3]\\) Tenendo a mente il fatto che dal set viene eliminato il punto preso come \"perno\", se andiamo a vedere i punti di accumulazione del set \\([2,3] \\cup \\{5\\}\\) , 5 NON \u00e8 un punto di accumulazione, in quanto, scegliendo un intorno \\(u\\) con \"centro\" 5, rimuovendo poi il punto centrale, abbiamo che \\(I \\cap \\{5\\} \\backslash 5\\) , che quindi \u00e8 uguale a \\(\\varnothing\\) . I punti di accumulazione rimangono quindi quelli nel set \\([2,3]\\) Notare che un punto di accumulazione pu\u00f2 esere anche \\(\\infty\\) : \\(D= (3, + \\infty)\\) \\((3, + \\infty) \\subset Acc(D)\\) Prendendo un intorno \\(u\\) , intorni di \\(+\\infty\\) , abbiamo \\(u = (a, + \\infty)\\) \\(+\\infty\\) rispetta la definizione di punto di accumulazione, ed \u00e8 quindi punto di accumulazione per l'insieme D. L'insieme dei punti di accumulazione per l'insieme D \u00e8 quindi \\([3, +\\infty]\\) (estremi inclusi quindi) Se dovessimo poi prendere un insieme come \\(\\naturals\\) , che \u00e8 composto di elementi discreti, tutti gli elementi risultano essere punti isolati, quindi non ci sono punti di accumulazione, tranne \\(+ \\infty\\) . Quindi \\(Acc(\\naturals ) = \\{+ \\infty \\}\\) Stesso discorso poi vale anche per \\(\\mathbb Z\\) , solo che si aggiunge anche \\(- \\infty\\) all'insieme: \\(Acc(\\mathbb Z) = \\{ + \\infty, - \\infty \\}\\) Punto isolato \u00b6 Punto isolato Un punto \\(x_0 \\in A\\) si dice punto isolato di A se esiste un \\(u\\) intorno di \\(x_0\\) tale che \\(u \\cap A = \\{x_0\\}\\) . Esempio di punto isolato Prendendo l'esempio di prima ( \\(A = [2,3] \\cup \\{5\\}\\) ), 5 \u00e8 punto isolato di A Punto intero \u00b6 Punto interno \\(A \\subset \\reals, x_0 \\in A\\) si dice punto interno ad A se esiste \\(u\\) intorno di \\(x_0\\) tale che \\(u \\subset A\\) L'intorno deve quindi essere totalmente contenuto nell'insieme A Esempio di punto interno In questo esempio, \\(x_0\\) risulta essere un punto interno. Prendendo invece il punto di bordo (quel punto tale che appena mi muovo appena di pi\u00f9 esco dall'insieme) \\(x_1\\) , il suo intorno \"esce\" dall'insieme A. Di conseguenza non \u00e8 un punto interno. Punti di massimo e minimo \u00b6 Punto di massimo e minimo locale \\(A \\subset \\reals, f: A \\rightarrow \\reals\\) Un punto \\(x_0 \\in A\\) si dice punto minimo locale (o relativo) se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(f(x) \\ge f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di minimo locale stretto se \\(f(x) > f(x_0) \\forall x \\in a \\cap A \\backslash \\{x_0\\}\\) . Si dice punto di massimo locale se \\(f(x) \\le f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di massimo locale stretto se \\(f(x) < f(x_0) \\forall x \\in u \\cap A \\backslash \\{x_0\\}\\) . Un punto si dice di massimo o minimo (senza \"locale\", e a volte detto anche \"stretto\") quando si estende l'intorno a tutto il domino. Punto di minimo \u00e8 anche locale Se \\(x_0\\) \u00e8 punto di minimo, allora \u00e8 anche un punto di minimo anche locale.","title":"Calcolo differenziale"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-maggiorante-ed-insieme-limitato","text":"","title":"Massimo, maggiorante ed insieme limitato"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-di-un-insieme","text":"Massimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice massimo di A se } m \\ge a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Dato un subset A di R non vuoto, un numero m reale si dice massimo dell'insieme A se m >= di a e m \u00e8 in A Quindi ad esempio se A \u00e8 l'intervallo \\(A = [0,1] \\Rightarrow max(A) =1\\) Tuttavia non tutti gli insiemi hanno un massimo: \\(B = [0,1)\\) allora B non ha massimo La dimostrazione \u00e8 abbastanza semplice quando fatta per assurdo: Dimostrazione Preso come esempio l'intervallo B appena citato, possiamo prendere un numero nell'insieme B e chiamarlo m (ad esempio 0.9). Troviamo quindi un \\(\\epsilon=1-m > 0\\) (in questo caso \\(\\epsilon = 0.1\\) ) A questo punto possiamo definire \\(m_1 = m + \\frac \\epsilon 2\\) . Avremo quindi che \\(m < m_1\\) , con \\(m_1 \\in B\\) e quindi \\(m_1\\) dovrebbe essere il massimo. Quindi B non ha massimo.","title":"Massimo di un insieme"},{"location":"AnalisiI/calcoloDifferenziale/#maggiorante","text":"Maggiorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice maggiorante di A se \\(k \\ge a \\forall a \\in A\\) . L'insieme di tutti i maggioranti si indica con \\(\\mathcal M_A\\) Un maggiorante deve essere quindi pi\u00f9 grande di tutti gli elementi di A e non \u00e8 detto che appartenga ad A. Quindi, riprendendo l'esempio precedente \\(A=[0,1]\\) , \\(3 \\in \\mathcal M_A\\) , mentre \\(\\frac 1 4\\) non \u00e8 un maggiorante Possiamo quindi fare un paio di osservazioni: Se esiste un maggiorante di A allora ne esistono infiniti: se k \u00e8 un maggiorante di A allora m \u00e8 un maggiorante di A \\(\\forall m \\ge k\\) Alcuni insiemi non hanno maggioranti: \\(A = \\mathbb R\\) non ha maggioranti, cos\u00ec come la semiretta \\([4, +\\infty)\\)","title":"Maggiorante"},{"location":"AnalisiI/calcoloDifferenziale/#insieme-superiormente-limitato","text":"Insieme limitato superiormente Se l'insieme dei maggioranti \u00e8 non vuoto \\(\\mathcal M_A \\ne \\varnothing\\) , l'insieme A si dice limitato superiormente","title":"Insieme superiormente limitato"},{"location":"AnalisiI/calcoloDifferenziale/#minimo-minorante-ed-insieme-limitato-inferiormente","text":"Minimo, minorante ed insieme inferiormente limitato Le stesse definizioni ma opposte si applicano per minimo, minorante e insieme inferiormente limitato Minimo dell'insieme \\(A \\in \\mathbb R, A \\ne 0, m \\in \\mathbb R \\text{ si dice minimo di A se } m \\le a \\quad \\forall a \\in A \\text{ e } m \\in A\\) Minorante Dato \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) un numero \\(k \\in \\mathbb R\\) si dice minorante di A se \\(k \\le a \\forall a \\in A\\) . Insieme limitato inferiormente Se l'insieme dei minoranti \u00e8 non vuoto \\(m_A \\ne \\varnothing\\) , l'insieme A si dice limitato inferiormente","title":"Minimo, minorante ed insieme limitato inferiormente"},{"location":"AnalisiI/calcoloDifferenziale/#insieme-limitato","text":"Insieme limitato Dato un insieme \\(A \\subset \\mathbb R, a \\ne \\varnothing\\) se A \u00e8 sia superiormente che inferiormente limitato, allora A si dice limitato Un insieme A \u00e8 quindi limitato se e solo se \\(\\exists h,k \\in \\mathbb R\\) tale che \\(k \\le a \\le h \\quad \\forall a \\in A\\) Quindi i due valori sono estermi all'insieme, limitandolo.","title":"Insieme limitato"},{"location":"AnalisiI/calcoloDifferenziale/#lestremo-di-una-funzione","text":"Teorema dell'estremo superiore Dato un sotto insieme di R \\(A \\subset \\mathbb R, A \\ne \\varnothing\\) , superiormente limitato, allora esiste il minimo dell'insieme dei maggioranti. Tale minimo si dice estremo superiore di A e si indica con \\(sup(A)\\) L'estremo superiore \u00e8 quindi il minimo dei maggioranti, ed ogni insieme limitato superioremente ha un estremo superiroe. Possiamo quindi vedere che l'insieme dei maggioranti ha sempre minimo Quindi, ad esempio: \\(A = [0,1) \\Rightarrow \\mathcal M_A = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di A \u00e8 1. \\(B = [0,1] \\Rightarrow \\mathcal M_B = [1,+\\infty)\\) . Il minimo dell'insieme dei maggioranti \u00e8 1, quindi l'estremo superiore di B \u00e8 1. Il massimo di un insieme \u00e8 il suo limite superiore Se esiste il massimo di un insime A, allora il massimo di A coincide con l'estremo superiore. un insieme limitato superiormente ha sempre un estremo superiore. Se questo elemento appartiene anche all'insieme \u00e8 anche un massimo: \\(\\exists \\; max(A) \\rightarrow max(A) = sup(A)\\) (Se esiste \\(max(A)\\) allora \\(max(A)=sup(A)\\) ) Insieme non limitato superiormente Se l'insieme A non \u00e8 superiormente limitato, scriviamo \\(sup(A) = + \\infty\\) Verificare che un oggetto \u00e8 un estremo superiore \\(A \\ne \\varnothing\\) superioremente limitato. Allora \\(m = sup(A)\\) se e solo se valgono: \\(a \\le m \\; \\forall a \\in A\\) (che significa che m \u00e8 un maggiorante) \\(\\forall \\epsilon > 0 \\; \\exists \\; \\bar a \\in A\\) tale che \\(\\bar a > m - \\epsilon\\) (spostarsi a sinistra di m c'\u00e8 un elemento a destra di m \\epsilon, non ci sono maggioranti pi\u00f9 piccoli di m; m \u00e8 il pi\u00f9 piccolo dei maggioranti) Un insieme superiormente limitato \u00e8 minore di infinito La scrittura \\(sup(A) < + \\infty\\) singifica che l'estremo superore di A \u00e8 un numero reale, quindi A \u00e8 superiormente limitato.","title":"L'estremo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#la-retta-reale-estesa","text":"Retta reale estesa \\(\\bar{ \\; \\mathbb{R} \\; } = \\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{+\\infty\\}\\) in modo che valga \\(-\\infty \\le m \\le + \\infty \\quad \\forall x \\in \\bar{\\;\\mathbb R\\;}\\) Ergo, se \\(x \\in \\mathbb R\\) (quindi \\(x \\ne +\\infty, x \\ne -\\infty\\) ), allora \\(-\\infty < x < + \\infty\\)","title":"La retta reale estesa"},{"location":"AnalisiI/calcoloDifferenziale/#operazionu-sulla-retta-reale-estesa","text":"Operazioni in \\(\\bar {\\mathbb R}\\) Se \\(x \\ne +\\infty\\) , allora \\(x + (- \\infty) = - \\infty\\) Se \\(x \\ne -\\infty\\) , allora \\(x + (+ \\infty) = + \\infty\\) Se \\(x \\gt 0\\) allora \\(x \\cdot (+ \\infty) = + \\infty\\) e \\(x \\cdot (- \\infty) = - \\infty\\) Se \\(x \\lt 0\\) allora \\(x \\cdot (+ \\infty) = - \\infty\\) e \\(x \\cdot (- \\infty) = + \\infty\\) Operazioni vietate (forme indeterminate) \\((+ \\infty) + (- \\infty)\\) \\(0 \\cdot (+ \\infty)\\) \\(0 \\cdot (- \\infty)\\) Operazioni valide \\(+ \\infty \\cdot + \\infty = + \\infty\\) \\(+ \\infty \\cdot - \\infty = - \\infty\\) \\(- \\infty \\cdot - \\infty = + \\infty\\)","title":"Operazionu sulla retta reale estesa"},{"location":"AnalisiI/calcoloDifferenziale/#minimi-e-massimi-di-insiemi-limitati","text":"Insiemi limitati hanno minimi o massimi Dato \\(A \\subset \\mathbb Z\\) (interi) se A \u00e8 superiormente limitato, A ha massimo. Se A \u00e8 inferiormente limitato, allora A ha minimo Parte intera Dato \\(x \\in \\mathbb R\\) si dice parte intera di x e si indica con \\([x]\\) il numero \\([x] = max \\{ m \\in \\mathbb Z : m \\le x \\}\\) . Ovvero: se abbiamo x (reale) tra due interi, la parte intera di x \u00e8 il primo intero che si ottiene spostandosi a sinistra. Ad esempio: \\([\\frac {25}{10}] = 2\\) \\([-\\frac {25}{10}] = -3\\)","title":"Minimi e massimi di insiemi limitati"},{"location":"AnalisiI/calcoloDifferenziale/#funzioni-limitate","text":"Funzione limitata f si dice limitata: superiormente se f(a) (la sua immagine) \u00e8 limitato superiormente inferiormente se f(a) (la sua immagine) \u00e8 limitato inferiormente se \\(f(a)\\) (la sua immagine) \u00e8 limitato","title":"Funzioni limitate"},{"location":"AnalisiI/calcoloDifferenziale/#massimo-e-minimo-di-una-funzione","text":"Funzione con massimo \\(f\\) ha massimo se \\(f(A)\\) (la sua immagine) ha massimo. Si dice che \\(M\\) \u00e8 il massimo di \\(f\\) e si scrive \\(M = max(f)\\) se \\(M = max(A)\\) Funzione con minimo \\(f\\) ha minimo se \\(f(A)\\) (la sua immagine) ha minimo. Si dice che m \u00e8 il minimo di \\(f\\) e si scrive \\(m = min(f)\\) se \\(m = min(A)\\)","title":"Massimo e minimo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#limiti-di-una-funzione","text":"Limiti di una funzione \\(sup(f) = sup(f(A))\\) Se \\(f\\) non \u00e8 limitata superiormente si scrive \\(sup(f) = + \\infty\\) . Lo stesso vale per inf (limite inferiore).","title":"Limiti di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-massimo-di-una-funzione","text":"Punti di massimo Se \\(f\\) ha massimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = max(f)\\) si dicono punti di massimo. Se \\(f\\) ha minimo allora i punti \\(\\forall x_0 \\in A | f(x_0) = min(f)\\) si dicono punti di minimo. Massimo e punti di massimo Il massimo di \\(f\\) \u00e8 unico; i punti di massimo potrebbero essere molti. Lo stesso vale per il minimo. Nella funzione seno, il massimo \u00e8 \\(max(f) = 1\\) e 0 i punti di massimo sono \\(x_0 = \\frac \\pi 2 + k\\cdot 2 \\pi, k \\in \\mathbb Z\\) Una funzione come \\(f:(0, +\\infty) \\rightarrow \\mathbb R \\quad f(x) = \\frac 1 x\\) non ha n\u00e9 massimo n\u00e9 minimo. La funzione ad infinito tende a 0: Se avesse massimo \\(\\Rightarrow \\exists M\\) tale che \\(f(x) \\le M \\forall x \\in (0, + \\infty)\\) : \\(f(x) > 0 \\forall x \\Rightarrow 0\\) \u00e8 un minorante \\(0=inf(f)\\) (inf = estremo inferiore) 0 \u00e8 quindi l'estremo inferiore di f, ma 0 NON \u00e8 un minimo. Se la funzione avesse minimo, allora dovrebbe essere \\(min(f)=inf(f)=0\\) , quindi dovrebbe esistere un \\(x_0\\) tale che \\(f(x_0)=0\\) cio\u00e8 \\(\\frac 1 {x_0}\\) , che \u00e8 impossibile. \\(f: A \\rightarrow \\mathbb R\\) allora \\(m = sup(f)\\) se e solo se: \\(f(x) \\le m \\forall x \\in A\\) \\(\\forall \\epsilon > 0 \\exists \\bar x \\in S\\) tale che \\(f(\\bar x) > m - \\epsilon\\) Se si abbassa la quota di m si \"taglia\" la funzione","title":"Punti di massimo di una funzione"},{"location":"AnalisiI/calcoloDifferenziale/#valore-assoluto","text":"Valore assoluto Dato \\(x \\in \\mathbb R\\) si dice valore assoluto di x e si indica con |x| il numero \\(|x| = max(x,-x)\\) Quindi: \\(x \\le |x|\\) \\(|x| = x\\) se \\(x \\ge 0\\) , \\(|x| = -x\\) se \\(x \\le 0\\) \\(|x| \\ge 0 \\forall x \\in \\mathbb R\\) \\(|x| = 0 \\Leftrightarrow x = 0\\) \\(|x| = |-x|\\) \\(-|x| \\le x \\le |x|\\) \\(|x| \\le M \\Leftrightarrow -M \\le x \\le M\\) ( \\(M \\gt 0\\) ) \\(|x| \\gt M \\Leftrightarrow x \\gt M\\) oppure \\(x \\lt -M\\) Come altre propriet\u00e0 possiamo poi aggiungere: \\(|x| \\le x_0 \\Leftrightarrow -x_0 \\le m \\le x_0\\) \\(|x| \\ge x_0 \\Leftrightarrow x \\le -x_0\\) oppure \\(x \\ge x_0\\)","title":"Valore assoluto"},{"location":"AnalisiI/calcoloDifferenziale/#disuguaglianza-triangolare","text":"Disuguaglianza triangolare Dati \\(a, b \\in \\mathbb R\\) , risulta che: \\(|a + b| \\le |a| + |b|\\) \\(||a| - |b| | \\le |a-b|\\) Questo discorso vale anche per pi\u00f9 valori: \\(|a + b + c| \\le |a + b + c|\\) \\(|a + b + c| = |(a + b) + c| \\le |a + b| + |c| \\le |a| + |b| + |c|\\)","title":"Disuguaglianza triangolare"},{"location":"AnalisiI/calcoloDifferenziale/#la-continuita","text":"Funzione continua in un punto \\(A \\subset \\mathbb R, f: A \\rightarrow \\mathbb R, x_0 \\in A\\) . La funzione si dice continua in x_0 se \\(\\forall \\epsilon > 0 \\; \\exists \\; \\delta > 0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)| < \\epsilon\\) Spiegandola un po': \\(|x - x_0| < \\delta \\Leftrightarrow x_0 - \\delta < x < x_0 + \\delta\\) ( \\(x\\) \u00e8 compreso tra \\(x_0 \\pm \\delta\\) ) \\(|f(x) - f(x_0)| < \\epsilon \\Leftrightarrow f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) (la funzione oscilla intorno ad \\(f(x_0)\\) ad un ampiezza massima di \\(\\epsilon\\) ) Se esiste un \\(\\delta\\) nell' \\(epsilon\\) dato, la funzione \u00e8 continua Una funzione \u00e8 sempre continua nei punti isolati La continuit\u00e0 include un concetto di prossimit\u00e0 del punto (al punto dove si considera la continuit\u00e0): se il punto \u00e8 isolato non \u00e8 possibile avvicinarsi al punto, ci si pu\u00f2 solo \"trovare\" nel punto. Esempio di funzione non continua in un punto Data la funzione \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione non \u00e8 continua nel punto \\(x_0 = 0\\) (in cui scegliamo \\(\\epsilon = \\frac 1 2\\) ): In questa funzione, \\(\\forall \\delta > 0, x \\in (0, \\delta) \\rightarrow f(x) =1\\) La disuguaglianza \\(f(x) < f(0)+\\epsilon\\) \u00e8 falsa: \\(0-\\frac 1 2 < f(x) < 0 + \\frac 1 2\\) : \\(1 < \\frac 1 2 \\Rightarrow f\\) non \u00e8 continua in \\(x_0 = 0\\) Funzione continua in un insieme Dati \\(A \\in \\mathbb R, f: A \\rightarrow \\mathbb R, B \\subset A\\) , Si dice che la funzione \\(f\\) \u00e8 continua in B se \u00e8 continua in ogni punto \\(x_0 \\in B\\) . Se si dice che f \u00e8 continua (senza specificare il sottoinsieme B), significa che f \u00e8 continua in tutti i punti del suo dominio A. Esempio di funzione non continua in un insieme Riprendendo la funzione di prima \\(f(x) = \\begin{cases} 0 \\text{ se } x \\le 0 \\\\ 1 \\text{ se } x > =0 \\end{cases}\\) Questa funzione \u00e8 continua in \\((-\\infty, 0) \\cup (0, + \\infty)\\)","title":"La continuit\u00e0"},{"location":"AnalisiI/calcoloDifferenziale/#teoremi-sulla-continuita","text":"Teorema sulla permanenza del segno \\(A \\subset \\mathbb R, f:A \\rightarrow \\mathbb R, x_0 \\in A\\) Se f \u00e8 continua in \\(x_0\\) e \\(f(x_0) > 0\\) allora \\(\\exists \\delta > 0\\) tale che se \\(x \\in A\\) e \\(|x -x_0| < \\delta Rightarrow f(x) > 0\\) . Stesso risultato se \\(f(x) < 0\\) Quindi, se una funzione continua assume valore di segno positivo in un punto, allora mantiene lo stesso segno nei punti molto vicini al punto. Dimostrazione Sappiamo che \\(f(x_0) > 0\\) . Scelgo \\(\\epsilon = \\frac {f(x_0)} 2\\) e lo uso nella definizione di continuit\u00e0. Esiste quindi un \\(\\delta >0\\) tale che \\(x \\in A, |x - x_0| < \\delta \\Rightarrow |f(x) - f(x_0)|< \\epsilon\\) Ovvero: \\(f(x_0) - \\epsilon < f(x) < f(x_0) + \\epsilon\\) Prendendo la prima parte della disuguaglianza, si ottiene che \\(f(x) > f(x_0) - \\epsilon = f(x_0) - \\frac {f(x_0)} 2 \\Rightarrow \\frac {f(x_0)} 2 > 0\\) Essendo il valore lontano da zero, se ci si sposta un po' vicino al punto; Il valore della fuzonone si sposta poco e quindi il segno rimane concorde. Questo discorso vale anche per un valore \\(m \\in \\mathbb R\\) tale che \\(f(x_0) > m\\) In tal caso \\(\\exists \\delta > 0\\) t.c. \\(x \\in A, |x - x_0| < \\delta \\Rightarrow f(x) > m\\) (Questo discorso vale anche con \\(f(x) < m \\Rightarrow f(x) < m\\) ) Teorema sulla combinazione di funzioni continue (somma e prodotto) Se \\(f\\) e \\(g\\) sono continue in \\(x_0\\) allora lo sono anche le funzioni \\(f+g\\) , \\(f \\cdot g\\) e \\(|f|\\) . Se inoltre \\(f(x_0) \\neq 0\\) , allora anche \\(\\frac 1 f\\) \u00e8 continua. \\(\\frac f g\\) \u00e8 continua (se \\(g(x_0) \\ne 0\\) ). \\(\\frac f g = f \\cdot \\frac 1 g\\) \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow B \\subset \\mathbb R\\) . Se \\(f\\) \u00e8 continua in \\(I\\) ed \u00e8 invertibile, allora \\(f^{-1}\\) \u00e8 continua. L'ipotesi che il dominios sia un'intervallo non pu\u00f2 essere omessa. Esempio \\(f:(-\\infty, 1] \\cup (2, +\\infty) \\rightarrow \\mathbb R\\) \\(f(x)= \\begin{cases} x \\quad \\;\\;\\; \\text{ se } x \\le 1 \\\\ x-1 \\text{ se } x > 1 \\end{cases}\\) Alla domanda se la funzione \u00e8 continua, la risposta \u00e8 s\u00ec. Tuttavia la sua inversa \\(f^{-1}: \\mathbb R \\rightarrow (-\\infty, 1] \\cup (2, + \\infty)\\) non \u00e8 continua in \\(x_0\\) . Non \u00e8 continua perch\u00e9 c'\u00e8 una specie di salto in \\(x=1\\) : Se f non \u00e8 definita su un intervallo, potrebbe accadere che la sua funzione inversa non sia continua, anche se la funzione \u00e8 continua.","title":"Teoremi sulla continuit\u00e0"},{"location":"AnalisiI/calcoloDifferenziale/#continuita-delle-funzioni-elementari","text":"Le funzioni costanti sono continue \\(f(x) = x\\) \u00e8 continua. Da ci\u00f2 segue che tutti i polinomi sono continui: Un polinomio ( \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_1 \\cdot x + a_0\\) ) ha i coefficienti come numeri reali ( \\(a_0, a_1, ..., a_n \\in \\mathbb R\\) ). Quindi dal teorema su somma e del prodotto so che la funzione \u00e8 continua: Una costante \u00e8 una funzione continua. Una costante (che \u00e8 una funzione continua) per x \u00e8 una funzione continua (perch\u00e9 x \u00e8 una funzione continua) Un monomio \u00e8 una funzione continua, in quanto \\(x^2 = x \\cdot x\\) , ovvero una funzione continua moltiplicata per una funzione continua - Le funzioni razionali sono continue nel loro insieme di definizione. Una funzione razionale \u00e8 un quoziente di polinomi ( \\(f(x) = \\frac {p(x)}{q(x)}\\) dove p e q sono funzioni polinomiali) Definita se \\(q(x) \\ne 0\\) - \\(e^x\\) , \\(sin(x)\\) e \\(cos(x)\\) sono funzioni continue. Quindi anche \\(log(x)\\) , \\(arcsin(x)\\) , \\(arccos(x)\\) saranno continue in quanto inverse. Ma anch e \\(tg(x)\\) (perch\u00e9 \u00e8 quoziente di seno e coseno) e anche \\(arctg(x)\\) Continuit\u00e0 di composizione di funzioni Date le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow \\mathbb R\\) , con \\(x_0 \\in A, y_0=f(x_0) \\in B\\) Se \\(f\\) \u00e8 continua in \\(x_0\\) e \\(g\\) \u00e8 continua in \\(y_0\\) , allora \\(g \\circ f\\) \u00e8 continua in \\(x_0\\) Esempio \\(e^{cos(x)}\\) \u00e8 una funzione continua in quanto composizione di \\(f(x) = cos(x)\\) e \\(g(y) = e^y\\) Il massimo di un insieme \u00e8 il suo limite superiore Se si ha una funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua in \\([a,b]\\) , L'estremo superiore \u00e8 uguale se l'intevallo \u00e8 aperto o chiuso: \\({\\sup _{x \\in (a,b)}} f(x) = \\sup _{x \\in [a,b]} f(x)\\) Vale poi lo stesso per l'estremo inferiore: \\({\\inf _{x \\in (a,b)}} f(x) = \\inf _{x \\in [a,b]} f(x)\\)","title":"Continuit\u00e0 delle funzioni elementari"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-degli-zeri","text":"Teorema degli zeri Data la funzione \\(f: [a,b] \\rightarrow \\mathbb R\\) continua Se \\(f(a) \\cdot f(b) < 0\\) allora \\(\\exists \\; c \\in (a,b)\\) tale che \\(f(c) =0\\) Fondamentalmente se la moltiplicazione tra i valori che la funzione assume agli estremi dell'intervallo \u00e8 minore di zero (quindi moltiplichiamo un positivo con un negativo), esiste almeno un punto \\(c\\) nell'intervallo \\((a,b)\\) tale \\(f(c) = 0\\) . L'ipotesi di continuit\u00e0 \u00e8 necessaria","title":"Teorema degli zeri"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-dei-valori-intermedi","text":"Teorema dei valori intermedi \\(I \\subset \\mathbb R\\) intervallo, \\(f: I \\rightarrow \\mathbb R\\) continua. Allora \\(f(I)\\) (l'immagine di f) \u00e8 un intervallo. In questo caso, se f assume i valori y_1 e y_2, allora assume anche tutti i valori compresi tra y_1 e y_2. Notare che I deve obbligatoriamente essere un intervallo.","title":"Teorema dei valori intermedi"},{"location":"AnalisiI/calcoloDifferenziale/#teorema-di-weierstrass","text":"Teorema di Weierstrass Definita \\(f: [a,b] \\rightarrow \\mathbb R\\) continua, allora f ha massimo e minimo. Quindi dati \\(a,b \\in \\mathbb R\\) (quindi \\(a,b \\ne \\pm \\infty\\) ). L'intervallo [a,b] \u00e8 un intervallo definito limitato (gli estremi non sono pi\u00f9 e meno infinito) e chiuso (ha entrambi gli estremi). Perch\u00e9 \\([a,b]\\) deve essere limitato e chiuso? In una funzione come \\(f: (0,1] \\rightarrow \\mathbb R, f(x) = \\frac 1 x\\) , f \u00e8 continua ma non ha massimo (inoltre \\(\\sup (f) = + \\infty\\) ). Inoltre l'intervallo non \u00e8 chiuso. Prendendo \\(f: \\mathbb R \\rightarrrow \\mathbb R, f(x) = arctg(x)\\) La funzione \u00e8 continua ed \u00e8 sempre compresa tra \\(\\pm \\frac \\pi 2\\) , ma non ha n\u00e9 massimo n\u00e9 minimo. Quindi \\(sup(f) = \\frac \\pi 2\\) e \\(inf(f) = \\frac \\pi 2\\) , ma non sono n\u00e9 massimo n\u00e9 minimo","title":"Teorema di Weierstrass"},{"location":"AnalisiI/calcoloDifferenziale/#gli-intorni","text":"Intorno Dato \\(x_0 \\in \\reals\\) , si dice intorno di \\(x_0\\) un insieme del tipo \\((x_0 - \\epsilon, x_0 + \\epsilon)\\) , dove \\(\\epsilon \\in \\reals, \\epsilon > 0\\) . \\(\\epsilon\\) si dice raggio dell'intorno. L'intorno sono quindi i punti che sono vicini ad x_0 (ovvero che distano da x_0 una quantit\u00e0 strettamente minore di \\(\\epsilon\\) ). Intorno destro e sinistro In insieme del tipo \\([x_0, x_0 + \\epsilon)\\) si dice intorno destro di \\(x_0\\) . In insieme del tipo \\((x_0 - \\epsilon, x_0]\\) si dice intorno sinistro di \\(x_0\\) . Intorni di infinito Se \\(x_0 = + \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((a, + \\infty)\\) dove \\(a \\in \\reals\\) (l'insieme \u00e8 quindi una semiretta). Se \\(x_0 = - \\infty\\) , un intorno di \\(x_0\\) \u00e8 un insieme del tipo \\((- \\infty, a)\\) dove \\(a \\in \\reals\\) . Questo significa che l'insieme vale da qualsiasi punto di \\(\\reals\\) a \\(\\pm \\infty\\)","title":"Gli intorni"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-accumulazione","text":"Punto di accumulazione Dato \\(A \\subset \\bar \\reals\\) (ricordando che \\(\\bar \\reals = \\reals \\cup \\{ + \\infty, - \\infty \\}\\) ); \\(x_0\\) si dice punto di accumulazione per l'insieme A se \\(\\forall u\\) intorno di \\(x_0\\) , risulta \\(u \\cap A \\backslash \\{x_0\\} \\ne \\varnothing\\) Questo significa che vicino \\(x_0\\) ci sono altri punti di A oltre a \\(x_0\\) (x potrebbe non appartenere ad A). Sotto un certo punto di vista, i punti di accumulazione sono tutti quei punti che sono parte dell'insieme o gli sono \"appiccicati\" Esempio di punto di accumulazione \\(A = (2,3)\\) I punti di accumulazione di A \\(Acc(A)\\) sono tutti i punti nell'intervallo \\((2,3)\\) : \\((2,3) \\subset Acc(A)\\) , ma lo \u00e8 anche per i punti 2 e 3. Quindi \\(Acc(A) = [2, 3]\\) Ma anche \\(Acc([2,3]) = [2,3]\\) Tenendo a mente il fatto che dal set viene eliminato il punto preso come \"perno\", se andiamo a vedere i punti di accumulazione del set \\([2,3] \\cup \\{5\\}\\) , 5 NON \u00e8 un punto di accumulazione, in quanto, scegliendo un intorno \\(u\\) con \"centro\" 5, rimuovendo poi il punto centrale, abbiamo che \\(I \\cap \\{5\\} \\backslash 5\\) , che quindi \u00e8 uguale a \\(\\varnothing\\) . I punti di accumulazione rimangono quindi quelli nel set \\([2,3]\\) Notare che un punto di accumulazione pu\u00f2 esere anche \\(\\infty\\) : \\(D= (3, + \\infty)\\) \\((3, + \\infty) \\subset Acc(D)\\) Prendendo un intorno \\(u\\) , intorni di \\(+\\infty\\) , abbiamo \\(u = (a, + \\infty)\\) \\(+\\infty\\) rispetta la definizione di punto di accumulazione, ed \u00e8 quindi punto di accumulazione per l'insieme D. L'insieme dei punti di accumulazione per l'insieme D \u00e8 quindi \\([3, +\\infty]\\) (estremi inclusi quindi) Se dovessimo poi prendere un insieme come \\(\\naturals\\) , che \u00e8 composto di elementi discreti, tutti gli elementi risultano essere punti isolati, quindi non ci sono punti di accumulazione, tranne \\(+ \\infty\\) . Quindi \\(Acc(\\naturals ) = \\{+ \\infty \\}\\) Stesso discorso poi vale anche per \\(\\mathbb Z\\) , solo che si aggiunge anche \\(- \\infty\\) all'insieme: \\(Acc(\\mathbb Z) = \\{ + \\infty, - \\infty \\}\\)","title":"Punti di accumulazione"},{"location":"AnalisiI/calcoloDifferenziale/#punto-isolato","text":"Punto isolato Un punto \\(x_0 \\in A\\) si dice punto isolato di A se esiste un \\(u\\) intorno di \\(x_0\\) tale che \\(u \\cap A = \\{x_0\\}\\) . Esempio di punto isolato Prendendo l'esempio di prima ( \\(A = [2,3] \\cup \\{5\\}\\) ), 5 \u00e8 punto isolato di A","title":"Punto isolato"},{"location":"AnalisiI/calcoloDifferenziale/#punto-intero","text":"Punto interno \\(A \\subset \\reals, x_0 \\in A\\) si dice punto interno ad A se esiste \\(u\\) intorno di \\(x_0\\) tale che \\(u \\subset A\\) L'intorno deve quindi essere totalmente contenuto nell'insieme A Esempio di punto interno In questo esempio, \\(x_0\\) risulta essere un punto interno. Prendendo invece il punto di bordo (quel punto tale che appena mi muovo appena di pi\u00f9 esco dall'insieme) \\(x_1\\) , il suo intorno \"esce\" dall'insieme A. Di conseguenza non \u00e8 un punto interno.","title":"Punto intero"},{"location":"AnalisiI/calcoloDifferenziale/#punti-di-massimo-e-minimo","text":"Punto di massimo e minimo locale \\(A \\subset \\reals, f: A \\rightarrow \\reals\\) Un punto \\(x_0 \\in A\\) si dice punto minimo locale (o relativo) se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(f(x) \\ge f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di minimo locale stretto se \\(f(x) > f(x_0) \\forall x \\in a \\cap A \\backslash \\{x_0\\}\\) . Si dice punto di massimo locale se \\(f(x) \\le f(x_0) \\forall x \\in u \\cap A\\) . Si dice punto di massimo locale stretto se \\(f(x) < f(x_0) \\forall x \\in u \\cap A \\backslash \\{x_0\\}\\) . Un punto si dice di massimo o minimo (senza \"locale\", e a volte detto anche \"stretto\") quando si estende l'intorno a tutto il domino. Punto di minimo \u00e8 anche locale Se \\(x_0\\) \u00e8 punto di minimo, allora \u00e8 anche un punto di minimo anche locale.","title":"Punti di massimo e minimo"},{"location":"AnalisiI/limiti/","text":"Limite Dato l'insieme \\(A \\subset \\reals\\) , la funzione \\(f: A \\rightarrow \\reals\\) ed \\(x_0\\) punto di accumulazione per A, \\(L \\in \\bar \\reals\\) \u00e8 il limite per x che tende a \\(x_0\\) di \\(f(x)\\) (scritto \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) ) se \\(\\forall V\\) intorno di \\(L\\) (ovvero sull'asse delle y) esiste \\(u\\) intorno di \\(x_0\\) (il punto sulle x) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\in V\\) Quindi un x nell'intorno di U (e nel dominio della funzione), ma diverso dal punto \\(x_0\\) , \"finisca\" nell'intorno V di L, sull'asse delle y) Questo significa che, dato un punto \\(x_0\\) ed \\(L=f(x_0)\\) , quando mi muovo intorno ad \\(x_0\\) vado a finire in un intorno di L. In tutto ci\u00f2 NON ci interessa quanto vale la funzione nel punto \\(x_0\\) ! Come per la continuit\u00e0, prendiamo un intorno V di L e mi domando se esiste un intorno di \\(x_0\\) tale che la funzione nell'intorno di \\(x_0\\) va a finire nell'intorno di L determinato prima. Detto in un altro modo: \\[ \\lim_{x \\rightarrow a} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists \\delta > 0 . (|x - a| < \\delta \\rightarrow |f(x) - L| < \\epsilon) \\] Il limite pu\u00f2 essere di un punto NON appartenente al dominio, basta sia di accumulazione Nella definizione di limite non serve che \\(x_0\\) sia nel dominio della funzione. Basta che sia un punto di accumulazione per il dominio (ovvero, un punto nel dominio o \" appiccicato \" al dominio). Questa definizione vale quando \\(x_0\\) e \\(L\\) sono nei reali, che quando sono \\(\\pm \\infty\\) Dimostrazione della definizione con \\(x_0\\) ed \\(L\\) \\(\\in \\reals \\cup {\\pm \\infty}\\) \\(x_0 \\in \\reals, \\; L \\in \\reals\\) \\(x_0 \\in \\reals, \\; L = + \\infty\\) \\(x_0 \\rightarrow + \\infty, \\; L \\in \\reals\\) \\(x_0 \\rightarrow + \\infty, \\; L \\in + \\infty\\) L'intorno \\(u\\) di \\(x_0\\) \u00e8 \\(V=(x_0 - \\delta, x_0 + \\delta)\\) come da definizione E, sempre da definzione, \\(V\\) intorno di \\(L\\) (sulle y) \u00e8 \\(V= (L - \\epsilon, L + \\epsilon)\\) Possiamo quindi dire \\(x \\in u\\) (con \\(|x-x_0| < \\delta\\) ) e \\(f(x) \\in V\\) (ovvero \\(f(x_0)-\\epsilon < f(x) < f(x_0) + \\epsilon\\) ) La definizione quindi \u00e8 questa: \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists \\delta > 0 \\; . \\; \\biggr(x \\in A, |x - x_0| < \\delta \\text{ e } x \\ne x_0 \\rightarrow |f(x) - f(x_0)| < \\epsilon \\biggr) \\] Stavolta, \\(V\\) intorno di \\(+ \\infty\\) (sulle y) \u00e8 una semiretta \\(V= (a, + \\infty)\\) Quindi \\(f(x) \\Leftrightarrow f(x) > a\\) (infinito \u00e8 pi\u00f9 grande di ogni numero reale a) \\[ \\lim_{x \\rightarrow x_0} f(x) = + \\infty \\Leftrightarrow \\forall a \\in \\reals \\; \\exists \\delta > 0 \\; . \\; \\biggr(x \\in A, |x - x_0| < \\delta \\text{ e } x \\ne x_0 \\rightarrow f(x) > a \\biggr) \\] Quando la funzione ad infinito ha un numero nei reali, stiamo semplicemente dicendo che c'\u00e8 un valore di x oltre il quale, anche se x assume un valore pi\u00f9 grande a numero reale, \\[ \\lim_{x \\rightarrow + \\infty} f(x) = L \\Leftrightarrow \\forall \\epsilon > 0 \\; \\exists a \\in \\reals \\; . \\; \\biggr(x > a \\rightarrow |f(x) - L | < \\epsilon \\biggr) \\] \\[ \\lim_{x \\rightarrow + \\infty} f(x) = + \\infty \\Leftrightarrow \\forall a \\in \\reals \\; \\exists b \\in \\reals \\; . \\; \\biggr(x > b \\rightarrow f(x) > a \\biggr) \\] Ovviamente le stesse cose valgono anche con \\(- \\infty\\) Parallelismo con la continuit\u00e0 \u00b6 Il concetto di limite \u00e8 molto simile a quello di continuit\u00e0. La differenza principale \u00e8 che: Nel limite non guardiamo il punto \\(x_0\\) ma il suo intorno. Inoltre consideriamo solo i punti di accumulazione (quindi anche punti esterni al dominio (come 0 con la funzione \\(\\frac 1 x\\) ). Inoltre non consideriamo i punti isolati in quanto non sono di accumulazione) Nella continuit\u00e0 guardiamo il valore \\(x_0\\) ed un suo intorno, considerando ogni punto nel domino (quindi anche i punti isolati) Inoltre nella continuit\u00e0 \\(x_0\\) pu\u00f2 essere uguale ad x, quindi \\(x_0 = x \\Rightarrow f(x) - f(x_0) = 0\\) La definizione di limite e continuit\u00e0 infine possono essere viste compatibili se (oltre al requisito \\(x \\ne x_0\\) ) si scambiano tra di loro L ed \\(x_0\\) Teorema dell'unicit\u00e0 del limite \u00b6 Teorema dell'unicit\u00e0 del limite Se il limite esiste, allora \u00e8 unico. Questo perch\u00e9 dire che una funzione tende ad un valore \\(L_1\\) per x che tende a \\(x_0\\) significa che si avvicina a quel valore quando x si avvicina a \\(x_0\\) , quindi non pu\u00f2 tendere contemporaneamente ad \\(L_2\\) perch\u00e9 non pu\u00f2 avvicinarsi a due valori distinti contemporaneamente. Limiti destri e sinistri \u00b6 Definzione di limite destro e sinistro \\(A \\subset \\reals, x_0 \\in Acc(A), x_0 in \\reals\\) \\(f: A \\rightarrow \\reals\\) , l in \\(\\bar \\reals\\) \u00e8 il limite di f(x) per x che tende a \\(x_0\\) da destra e si scrive \\[ \\lim_{x \\rightarrow x_0^+} f(x) =f \\] Se \\(\\forall V\\) intorno di l esiste \\(\\delta >0\\) tale che \\(x_0 < x < x_0 + \\delta, x \\in A \\Rightarrow f(x) \\in V\\) . Qui si possono notare due cose: Il fatto che x sia diverso da \\(x_0\\) si pu\u00f2 osservare dall'uso del minore stretto (quindi non mi interessa neanche in questo caso quanto vale la funzione del punto) Il motivo per il quale \\(x_0\\) \u00e8 finito (in \\(\\reals\\) ) \u00e8 perch\u00e9 non ha senso avvicinare \\(+\\infty\\) da destra Da sinistra, se \\(x_0 - \\delta < x < x_0, x \\in A \\Rightarrow f(x) \\in V\\) Questo significa che nella definizione di limite, si considerano solo i \" mezzi intorni \" a desta o a sinistra Esempio di limite da destra e da sinistra Prendendo la funone \\(f: (-\\infty, 0) \\cup (0, + \\infty) \\rightarrow \\reals\\) Definita come \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questo caso, il limite per x che tende a 0 da destra di f(x) vale 1 ( \\(\\lim_{x \\rightarrow 0^+} f(x) = 1\\) ) e quello che tende a 0 da sinistra -1 ( \\(\\lim_{x \\rightarrow 0^-} f(x) = -1\\) ). In questo caso non esiste il limite per f(x) che tende a 0, perch\u00e9 il limite che tende a 0 da destra \u00e8 diverso dal limite per x che tende a 0 da sinistra. Il limite esiste solo se i limiti da destra e da sinistra sono uguali \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\lim_{x \\rightarrow x_0^+} f(x) = \\lim_{x \\rightarrow x_0^-} f(x) = L \\] Nella definzione di limite destro si usa solo il \" mezzo intorno \" destro e stessa cosa con quello sinistro. Se vengono messi insieme si ottiene la definizione di limite. Funzione definitivamente positiva e negativa \u00b6 Funzione definitivamente positiva e negativa \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Si dice che \\(\\lim_{x \\rightarrow x_0} f(x) = L^+\\) (con \\(L \\in \\reals\\) ), se: \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) Esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\{x_0\\} \\Rightarrow f(x) > L\\) Ci\u00f2 significa che la funzione \"tende\" al valore ma da 'sopra': La stessa definizione vale per \\(L^-\\) Esempio di limite positivo \\[ f(x) = \\frac 1 x \\qquad \\lim_{x \\rightarrow + \\infty} f(x) = 0^+ \\] Questo perch\u00e9 considerare la funzione vicino \\(+ \\infty\\) , la funzione tende a 0. Scegliendo una semiretta (e quindi un intervallo \\((a, + \\infty)\\) ) come intorno u \\(a > 0 \\Rightarrow f(x) > 0\\) (in questo caso 0=l), e quindi possiamo dire che la funzione \u00e8 definitivamente positiva In questo caso a noi interessa che la funzione sia positiva in un intorno del punto di cui calcoliamo il limite Teorema della permanenza del segno \u00b6 Teorema della permanenza del segno \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Se esisiste \\(\\lim_{x \\rightarrow x_0} f(x) = L \\in \\bar \\reals\\) e \\(L \\ne 0\\) allora esiste un intorno u di \\(x_0\\) tale che se \\(x \\in A \\cap u \\{x_0\\}\\) allora f ha lo stesso segno di L. [44:00] Continuit\u00e0 di una funzione a destra o sinistra \u00b6 Funzione continua a destra o sinistra Dato \\(A \\subset \\reals, x+0 in A, x_0 \\in Acc(A)\\) Se \\(\\lim_{x \\rightarrow x_{0^+}} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a destra in \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_{0^0-} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a sinistra in \\(x_0\\) . Funzione continua a destra o sinistra Riprendendo l'esempio della funzione vista prima e modificandola appena, di d\u00e0 la seguente funzione: \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questa funzione, il limite per x che tende a \\(0^+\\) vale quanto la funzione a 0. Quando la funzine presenta questo comportamento, viene detta funzione continua a destra. Ovviamente lo stesso discorso vale anche per il discorso \"a sinistra\" Teorema di confronto \u00b6 Teorema di confronto \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) Se esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x)\\) , allora \\(L_1 \\le L_2\\) . Ovvero, se si hanno due funzioni in cui nel grafico una delle due funzioni assume valori maggiori allo stesso punto, la disuguaglianza \" passa \" al limite. Nelle ipotesi corrette quindi: \\[ f(x) \\le g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x) \\] Il teorema non funziona con minore/maggiore stretto Se \\(f(x) > g(x)\\) potrei concludere che \\(\\lim_{x \\rightarrow x_0} f(x) < \\lim_{x \\rightarrow x_0} g(x)\\) ? No, perch\u00e9 prendendo ad esempio le funzioni \\(g(x) = \\frac 1 x\\) e \\(f(x) = - \\frac 1 x\\) su \\(x > 0\\) , entrame le funzioni tendono a 0; ed ecco che una disuguaglianza stretta diventa debole. Quindi \\(f(x) < g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x)\\) Le disuguaglianze passano quindi al limite ma diventano deboli. Teorema dei carabinieri \u00b6 Teorema di dei carabinieri \\(A \\subset \\reals, x_0 \\in Acc(A), f,g, h: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x)= L\\) e \\(\\lim_{x \\rightarrow x_0} h(x)= L\\) (L in questo caso ha lo stesso valore). Se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(x \\in A \\cap u \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x) \\le h(x)\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} g(x) = L\\) Ovvero, se abbiamo tre funzioni, dall'esistenza dei limiti di f ed h (uguali tra loro) deduco che esiste il limite di g. Rispetto al teorema di confronto, dove si sa che i limiti delle funzioni g ed h esistono, in questo caso non so se esiste il limite di G ma sapendo che la funzione \u00e8 compresa tra due funzioni ed il limite delle due funzioni \u00e8 L, deduco che il limite di g sia L. Uso di \"met\u00e0\" del teorema Se la funzione di sinistra va a \\(\\pin\\) , spinge a \\(\\pin\\) tutto quanto (quindi ogni funzione alla destra della disequazione non pu\u00f2 che essere qualcosa che va a pi\u00f9 infinito). Lo stesso concetto lo ho quando la parte della disequazione pi\u00f9 a sinistra va a \\(\\min\\) Ho bisogno di entrambe le met\u00e0 quando il limite \u00e8 un numero finito ed ho bisogno delle altre funzioni per \"schiaccia\" sia da sopra che da sotto la funzione in mezzo. Teorema di somma e prodotto di limiti \u00b6 Teorema di somma e prodotto di limiti \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Supponiamo esistano i limiti \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) con \\(L_1, L_2 \\in \\bar \\reals\\) Allora: Se ha senso \\(L_1 + L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = L_1+L_2\\) Se ha senso \\(L_1 \\cdot L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = L_1 \\cdot L_2\\) Casi di indeterminazione \u00b6 Il \"Se ha senso\" nella definizione precedente serve per escludere i casi di indeterminazione : \\(+ \\infty \\cdot - \\infty\\) e viceversa \\(\\pm \\infty \\cdot 0\\) Esempi di casi di indeterminazione \u00b6 Somma di \\(+ \\infty\\) con \\(- \\infty\\) Ponendo \\(f(x) = 2x\\) e \\(g(x) = -x\\) Le due funzioni hanno i limiti che a \\(+ \\infty\\) valgono rispettivamente \\(+ \\infty\\) e \\(- \\infty\\) . La loro somma \u00e8 quindi questa: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (2x - x) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = + \\infty\\) Se invece prendo \\(f(x) = \\frac x 2\\) e \\(g(x) = -x\\) , allora i rispettivi termini per x che tende a \\(+ \\infty\\) varranno \\(+ \\infty\\) e \\(- \\infty\\) Ma se proviamo a fare il discorso che abbiamo appena fatto: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac x 2 - x) = \\lim_{x \\rightarrow + \\infty} - \\frac x 2 = - \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = - \\infty\\) Dato che il risultato di una somma deve essere costante, scegliamo di trattare le operazioni tra infiniti come casi particolari e quindi di non risolverle algebricamente. Non ha senso parlare di somma. Per questo motivo \\((+ \\infty) + (- \\infty)\\) non ha senso e si dice che il limite \u00e8 indeterminato. Il prodotto \\(0 * + \\infty\\) si considera allo stesso modo rispetto alla somma: Considerando la funzione \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x) = \\lim_{x \\rightarrow + \\infty} 1 = 1 \\] Ed in questo caso avremmo \\((0) \\cdot (+ \\infty) = 1\\) Prendendo invece \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x^2\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (f \\cdot g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x^2) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] Quindi avremmo \\(0 \\cdot (+ \\infty) = + \\infty\\) . Quindi \\(0 \\cdot (+ \\infty)\\) non ha senso. Risoluzione dei casi di indeterminazione \u00b6 Una funzione che tende ad un numero finito \u00e8 limitata \\(A \\subset \\reals, x_0 \\in Acc(A), f: A \\rightarrow \\reals\\) Se esiste \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) ( \\(L\\) non \u00e8 \\(\\pm \\infty\\) ), allora f \u00e8 limitata in un intorno di \\(x_0\\) . Ovvero esiste un intorno \\(u\\) di \\(x_0\\) ed \\(\\exists M \\in R, M > 0\\) tale che \\(x \\in u \\cap A \\Rightarrow |f(x)| \\le M\\) Quindi una funzione che tende ad un numero finito, vicino al punto deve essere finita (limitata). Esempio di funzione limitata che tende a 0 \\(f(x) = \\frac 1 x\\) \u00e8 limitata in un intorno di \\(+ \\infty\\) perch\u00e9 ( \\(\\lim_{x \\rightarrow + \\infty} f(x) = 0\\) E da un certo punto in poi la funzione sta tra \\(\\pm M\\) , dato che la funzione tende ad un numero finito (e quindi da un certo punto in poi \u00e8 finita, essendo la funzione limitata) Funzione infinitesima \u00b6 Funzione infinitesima, divergente e convergente Se \\(\\lim_{x \\rightarrow x_0} f(x) = 0\\) , allora si dice che f \u00e8 infinitesima per x che tende a \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = + \\infty\\) , si dice che f diverge positivamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = - \\infty\\) , si dice che f diverge negativamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) , f converge a L per x che tende ad \\(x_0\\) . Se f \u00e8 limitata inferiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = + \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = + \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = - \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = - \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = 0\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = 0\\) . Una funzione infinitestima per una limitata \u00e8 una funzione infinitesima La somma f + g \u00e8 indeterminata quando una funzione va a + infinito ed una a - infinito; quindi mi basta che la funzione sia limitata inferiormente (perch\u00e9 \u00e8 un caso in cui la funzione non va a - infinito) per dire che la somma va a pi\u00f9 infinito (e viceversa). Nel caso di prodotto di una funzione limitata per una infinitesima: per rimuovere l'indeterminazione mi \"basta dire\" che la seconda funzione \u00e8 limitata. Tutte queste cose appena evidenziate derivano dal teorema dei carabinieri Esempio: Applicazione del teorema sul limite della somma con funzioni senza limite Prendendo la funzione \\(\\limit {+ \\infty} x + sin(x)\\) , possiamo scomporla in due: \\(\\limit {+ \\infty} x = + \\infty\\) \\(\\limit {+ \\infty} sin(x)\\) che non esiste In questo caso non si pu\u00f2 applicare il teorema sul limite della somma (che richede che entrambi i limiti esistano). Tuttavia sin(x) \u00e8 una funzione limitata inferiormente; Quindi: \\[ \\limit \\pin x + sin(x) = \\pin \\] Questo perch\u00e9 \\(x-1 \\le x+sin(x)\\) (perch\u00e9 \\(sin(x)\\) \u00e8 limitat inferiormente): per il teorema dei carabinieri \\(x-1\\) tende a \\(\\pin\\) , quindi anche \\(x + sin(x)\\) tende a \\(\\pin\\) . Limite del reciproco \u00b6 Limiti dei reciproci Se \\(\\limit {x_0} f(x)= 0^+\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\pin\\) Se \\(\\limit {x_0} f(x) = 0^-\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\min\\) Se \\(\\limit {x_0} f(x) = \\pin\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^+\\) Se \\(\\limit {x_0} f(x) = \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^-\\) Se \\(\\limit {x_0} f(x) = L\\) con \\(L \\ne 0, \\pin, \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\frac 1 L\\) Questa proposizione ci dice che il limite del reciproco di una funzione (ammesso che sia definita), \u00e8 il reciproco del limite: Se f tende a L, \\(\\frac 1 f\\) tende a \\(\\frac 1 L\\) \\[ \\displaylines{ f \\rightarrow L \\Rightarrow \\frac 1 f \\rightarrow \\frac 1 L \\\\ \\frac 1 {0^+} = \\pin, \\quad \\frac 1 {0^-} = \\min, \\quad \\frac 1 \\pin = 0^+, \\quad \\frac 1 \\min = 0^- } \\] Esistenza dei limiti per funzioni monotone \u00b6 Esistenza dei limiti per funzioni monotone \\(a, b \\in \\bar \\reals, f: (a,b) \\rightarrow \\reals\\) con f debolmente crescente . In tal caso esistono: \\(\\limit {a^+} f(x) = \\inf_{x \\in (a,b)} f(x)\\) \\(\\limit {b^-} f(x) = \\sup_{x \\in (a,b)} f(x)\\) L'opposto vale quando la funzione \u00e8 debolmente decrescente (invertendo estremo superiore ed inferiore) Avevamo visto che le funzioni monotone assumono massimo e minimo in un intervallo a destra se il dominio ha massimo ed il minimo a sinistra se il dominio ha minimo Questo teorema ci dice che in una funzione monotona i limiti esistono sempre. Esempio \\[ \\displaylines{ f:(0,\\pin) \\rightarrow \\reals \\quad f(x) = - \\frac 1 x \\\\ \\limit {0^+} - \\frac 1 x = \\min = \\inf(f) \\\\ \\limit \\pin - \\frac 1 x = 0 = \\sup(f) } \\] Cambio di variabile \u00b6 Per risolvere alcuni limiti che si presenteranno, pu\u00f2 essere necessario effettuare un cambio di variabile. Un cambio di variabile \u00e8 fatto quando si sostituisce una funzione (ad esempio \\(e^x\\) con una variabile come \\(y\\) ) Quando questo accade, \u00e8 necessario cambiare anche il limite, per far s\u00ec che non perda di significato: \\[ \\lim \\pin e^x = \\lim_{y \\to \\pin} y \\] Limiti fondamentali \u00b6 Esistono alcuni limiti fondamentali: Somma e prodotto di limiti \u00b6 \\(\\limit \\pin x = \\pin\\) \\(\\limit \\pin x^n = (\\lim_{n \\rightarrow \\pin} x) \\cot (\\lim_{n \\rightarrow \\pin} x) \\cdot ...\\) (questo \u00e8 il teorema su prodotto di limiti) \\(=(\\pin)\\cdot (\\pin) \\cdot ... = \\pin\\) \\(\\limit \\pin \\frac 1 x = \\frac 1 \\pin = 0\\) \\(\\limit \\pin \\frac 1 {x^n} = 0\\) Limiti di poliniomi \u00b6 Un polinomio di grado n \u00e8 qualcosa del tipo \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0\\) Dove \\(a_0, a_1, ..., a_n\\) sono i coefficienti del polinomio e sono numeri reali ( \\(a_0, a_1, ..., a_n \\in \\reals\\) ). n \u00e8 invece il grado del polinomio ( \\(n \\in \\naturals\\) ). Esempio di risoluzione di una forma indeterminata Il limite ad infinito di un polinomio \u00e8 spesso una forma indeterminata: \\(\\lim \\pin 3x^2 - 7x + 1 = \\pin \\min + 1\\) Questa \u00e8 quindi una forma indeterminata. Per eliminarla: \\[ \\displaylines{ \\limit \\pin 3x^2(1 - \\frac 7x {3x^2} + \\frac 1 {3x^2}) = \\\\ = \\limit \\pin 3x^2(1- \\frac 7 {3x} + \\frac 1 {3x^2}) = \\\\ = \\pin(1- \\frac 7 \\pin + \\frac 1 \\pin) = \\\\ = \\pin (1 - 0 - 0) = \\pin } \\] Raccogliamo quindi il \\(3x^2\\) e poi dividiamo, facendo infine il limite. Dato un polinomio possiamo quindi sempre raccogliere il monomio di grado pi\u00f9 grande e poi dividere per lo stesso. \\[ \\displaylines{ p(x) = a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\\\ = a_nx^n (1 + \\frac {a_{n-1}} {a_n} \\cdot \\frac {x^{n-1}} {x^n} + ... + \\frac {a_1} {a_n} \\cdot \\frac x {x^n} + \\frac {a_0} {a_n} \\cdot \\frac 1 {x^n}) } \\] A questo punto ho tutti termini che tendono a 0 se x tende a \\(\\pin\\) (o anche se x tende a \\(\\min\\) ). Quello che ottendo quindi \u00e8 che \\(\\limit \\pin a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\limit \\pin a_nx^n\\) . Lo stesso discorso vale anche per quando x tende a \\(\\min\\) . Quindi quando la variabile x tende a \\(\\pm \\infty\\) , il polinomio si comporta come si comporterebbe il monomio di grado pi\u00f9 grande. Esempio di comportamento del poliniomio rispetto al suo grado maggiore \\[ \\limit \\min -2x^5+3x^2 = \\limit \\min -2x^5 = -2(\\min)^5 = (-2)(\\min) = \\pin \\] Funzioni razionali \u00b6 Una funzione razionale \u00e8 una funzione \\(\\frac {p(x)} {q(x)}\\) dove p e q sono polinomi: \\[ \\displaylines{ p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0 \\\\ q(x) = b_m \\cdot x^m + b_{m-1} \\cdot x^{m-1} + ... + b_{1} \\cdot x + b_0 } \\] Quindi il limite della funzione sar\u00e0 equivalemtne al conto che si fa con i polinomi: \\[ \\displaylines{ \\limit {\\pm \\infty} \\frac {p(x)} {q(x)} = \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0} {b_mx^m + b_{m-1}x^{m-1} + ... + b_1x + b_0} \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n} {b_mx^m} } \\] Esempio di funzioni razionali \\[ \\displaylines{ \\limit \\pin \\frac {7x^4 + 5x^2} {-2x^3 + x} = \\\\ = \\limit \\pin \\frac {7x^4} {-2x^3} = \\\\ = \\limit \\pin \\frac {7x} {-2} = \\min } \\] In questo caso abbiamo un eccesso di grado al numeratore (al numeratore abbiamo un grado 4, al denominatore abbiamo un grado 3), quindi il limite va a \\(\\pm \\infty\\) a seconda del sengno dei coefficienti. Se fosse successo l'opposto (il grado del denominatore suepriore al grado del numeratore), il limite sarebbe andato a 0 Se invece il grado fosse stato lo stesso, il limite sarebbe andato al rapporto dei coefficenti tra i termini di grado maggiore. Altri limiti fondamentali \u00b6 \\[ \\displaylines{ \\limit \\pin e^x = \\pin \\\\ \\limit \\min e^x = 0^+ \\\\ \\limit {0^+} log(x) = \\min \\\\ \\limit \\pin log(x) = \\pin \\\\ } \\] Limiti notevoli \u00b6 \\(\\limit 0 \\frac {sin(x)} x = 1\\) Questo limite \u00e8 una forma indeterminata, in quanto il \\(\\limit 0 sin(x) = 0\\) , mentre il \\(\\limit 0 x = 0\\) , tuttavi si pu\u00f2 dimostrare che il limite faccia uno. Dimostrazione - Da fare //TODO - work in progress Guadando una circonferenza, pu\u00f2 essere facile dire che la tangente \u00e8 sempre pi\u00f9 grande del seno per lo stesso valore di x (per il primo quadrante). \\[ \\displaylines{ |sin(x)| \\le x \\le |tan(x)| = \\\\ = |sin(x)| \\le x \\le |\\frac {sin(x)}{cos(x)}| = \\quad (\\cdot \\frac 1 {|sin(x)|})\\\\ = \\frac {|sin(x)|} {|sin(x)|} \\le \\frac x {sin(x)} \\le \\frac {|sin(x)|}{|cos(x)|} \\cdot \\frac 1 {|sin(x)|} = \\\\ = 1 \\le \\frac x {sin(x)} \\le \\frac 1 {cos(x)} = \\quad \\text{ (inversione delle frazioni) }\\\\ = 1 \\ge \\frac {sin(x)} x \\ge cos(x) \\\\ \\\\ \\limit 0 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge \\limit 0 cos(x) = \\\\ = 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge 1 \\Rightarrow \\limit 0 \\frac {sin(x)} x = 1 } \\] Da questo limite se ne possono poi dimostrare altri: \\(\\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2\\) Dimostrazione \\[ \\displaylines{ \\frac {1 - cos(x)}{x^2} = \\frac {(1 - cos(x)) (1 + cos(x))}{x^2 (1 + cos(x))} \\\\ = \\frac {1 - cos^2 (x)} {x^2 (1 + cos(x))} = \\frac {sin^2 (x)}{x^2 1 + cos(x)} = \\\\ = \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} \\\\ \\\\ \\limit 0 \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} = 1 \\cdot 1 \\cdot \\frac 1 {1+1} = \\\\ = \\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2 } \\] \\(\\limit 0 \\frac {e^x -1} x = 1\\) \\(\\limit 0 \\frac {log(1 + x)} x = 1\\) \\(\\limit {0^+} x \\cdot \\log(x) = 0 \\cdot (\\min)\\) (forma indeterminata) Per questa si effettua il cambio di variabile, quindi \\(y=log(x), x = e^y\\) Se \\(x \\to 0^+ \\Rightarrow y = log(x) \\to \\min\\) \\(\\lim_{y \\to \\min} e^y \\cdot y\\) (questa \u00e8 ancora una forma indeterminata, \\(e^\\min \\cdot (\\min) = 0^+ \\cdot (\\min)\\) ) Quindi \u00e8 necessario fare un ulteriore cambio di variabile: \\(z = -y\\) , quindi se \\(y \\to \\min \\Rightarrow z \\to \\pin\\) \\(\\lim_{y \\to \\min} e^y \\cdot y = \\lim_{z \\to \\pin} e^{-z} \\cdot -z = \\lim_{z \\to \\pin} \\frac {-z} {e^z} = 0\\) \\(\\lim_{x \\to 0^+} x\\cdot log(x) = 0\\) \\(\\limit {0^+} x^\\alpha log(x)\\) (con \\(\\alpha > 0\\) ); Anche in questo caso dobbiamo ricorrere alla sostituzione: \\(y = x^\\alpha\\) , quindi \\(x = y^{\\frac 1 \\alpha}\\) Se \\(x \\to 0 \\Rightarrow y = x ^ \\alpha \\rightarrow 0\\) \\(\\limit {0^+} x^\\alpha log(x) = \\lim_{y \\to 0^+} y \\cdot log(y^{\\frac 1 \\alpha})\\) \\(= \\lim_{y \\to 0^+} y \\cdot \\frac 1 \\alpha log(y)\\) \\(= \\frac 1 \\alpha \\lim_{y \\to 0^+} y \\cdot log(y) = 0\\) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Dimostrazione \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = (1 + 0)^{\\frac 1 0^+ } = 1^\\pin\\) Questa \u00e8 una forma indeterminata: \\((1 + x)^{\\frac 1 x} = e^{log(1 + x)^{\\frac 1 x}} = e^{\\frac 1 x log(1+x)}\\) Da qui sostituiamo \\(y = \\frac 1 x log(1 + x)\\) Se \\(x \\to 0^+\\) , a quanto deve tendere y? \\(\\limit {0^+} \\frac 1 x log(1 + x) = 1\\) (Limite notevole) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Nuovi casi di indeterminazione \u00b6 \\(f(x) > 0, \\limit {x_0} f(x)^{g(x)}\\) . Quando questa \u00e8 una forma indeterminata? Possiamo manipolare il limite per rendere la domanda pi\u00f9 semplice: \\(f(x)^{g(x)}=e^{log(f(x)^{g(x)})} = e^{g(x) \\cdot log(f(x))}\\) Abbiamo quindi spostato la domanda: quando \u00e8 indeterminato il limite \\(\\limit {x_0} g(x) \\cdot log(f(x))\\) ? Abbiamo 3 casi: \\(g \\to 0, f \\to \\pin \\So log(f) \\to \\pin\\) \\(0 \\cdot \\pin\\) quindi \\((\\pin)^0\\) \u00e8 indeterminata \\(g \\to 0, f\\to 0^+ \\So \\log f \\to \\min\\) \\(\\So g \\cdot \\log(f) = 0 \\cdot (\\min)\\) \\(g \\to \\pm \\infty, f \\to 1\\) , quindi \\(log(f) \\to 0\\) \\(g \\cdot log(f) = \\pm \\infty \\cdot 0\\) \\((1)^{\\pm \\infty}\\) \u00e8 indeterminata Abbiamo quindi 4 nuove forme indeterminate: \\[ (\\pin)^0, \\qquad (0^+)^0, \\qquad (1)^{\\pin}, \\qquad (1)^{\\min} \\] Tutti e quattro i casi si risolvono riscrivendoli nella forma esponenziale Esempio $\\limit {0^+} x^x = \\limit {0^+} e {log(x x)} = $ \\(=\\limit {0^+} e^{x \\cdot log(x)} = e^0 = 1\\) Qui \u00e8 stato \"nascosto\" il cambio di variabile, che sarebbe stato \\(y = x \\cdot log(x)\\) , se \\(x \\to 0^+ \\So y \\to 0\\) \\(\\So \\lim_{y \\to 0} e^y = e^0 = 1\\) Esponenziale \u00b6 Dato \\(\\limit \\pin a^x\\) , ci sono 3 possibili soluzioni: \\[\\limit \\pin a^x = \\begin{cases} \\pin & \\text{ se } a > 1 1 & \\text{ se } a = 1 0^+ & \\text{ se } 0 < a < 1 \\end{cases} \\] Ovviamente a deve essere maggiore di 0 Se invece vogliamo far tendere \\(x \\to \\min\\) , possiamo effettuare un cambio variabile: \\(y = -x\\) , quindi se \\(x \\to \\min \\Rightarrow y \\to \\pin\\) . Di conseguenza: \\(\\limit \\min a^x = \\lim_{y \\to 1} a^-y = \\lim_{y \\to \\pin} \\frac 1 {a^y}\\) Quindi abbiamo di nuovo 3 casi: \\[ \\lim_{y \\to \\pin} \\frac 1 {a^y} = \\begin{cases} 0^+ & \\text{ se } a > 1 1 & \\text{ se } a = 1 \\pin & \\text{ se } 0 < a < 1 \\end{cases} \\] I risultati sono anche facilmente visibili: \\(a >1\\) \\(0<a<1\\) Potenze \u00b6 Consideriamo \\(\\alpha \\in \\reals\\) e quindi \\(x^\\alpha\\) Observation Notare che se si consdiera \\(x^\\alpha\\) con \\(\\alpha\\) non razionale, si \u00e8 forzati a prendere \\(x>0\\) (\u00e8 pari o dispari \\(\\pi\\) ?) Quindi, \\(\\limit \\pin x^\\alpha\\) vale: \\[ \\limit \\pin x^\\alpha = \\begin{cases} \\pin & \\text{ se } \\alpha > 0 \\\\ 1 & \\text{ se } \\alpha = 0 \\\\ 0^+ & \\text{ se } \\alpha < 0 \\end{cases} \\] Limite della composizione di funzioni \u00b6 Teorema del Limite della composizione di funzioni \\(A, B \\subset \\reals, f: A \\rightarrow B, g: B \\rightarrow \\reals\\) \\(x_0 \\in Acc(A)\\) Se esiste \\(\\limit {x_0} f(x) = y_0\\) , e \\(y_0 \\in Acc(B)\\) e \\(\\exists \\lim_{y \\rightarrow y_0} g(y) = L \\in \\bar \\reals\\) E se \u00e8 verificata almeno una delle seguenti due ipotesi: \\(y_0 \\in B\\) e g \u00e8 continua in \\(y_0\\) \\(\\exists u\\) intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\ne y_0\\) Allora \\(\\limit {x_0} (g \\circ f)(x) = L\\) , dove L \u00e8 il limite di g Quindi \\(\\limit {x_0} (g \\circ f)(x) = \\lim_{y \\rightarrow y_0} g(y)\\) Esempio dell'uso del teorema Calcoliamo \\(\\limit \\min arctg(x^2)\\) Il limite \u00e8 una composizione: \\(f(x) = x^2\\) , \\(g(y) = arctg(y)\\) \\((g \\circ f)(x) = g(f(x)) = g(x^2) = arctg(x^2)\\) \\(x_0 = \\min\\) , \\(y_0 = \\limit {x_0} f(x) = \\limit \\min x^2 = \\pin\\) A questo punto dobbiamo rendeci conto del caso in cui ci troviamo: Il primo caso non \u00e8 verificato in quanto \\(y_0 = \\pin\\) e non appartiene al dominio di g Il secondo caso \u00e8 verificato, perch\u00e9 \\(f(x) \\ne y_0 \\Rightarrow f(x) \\ne \\pin\\) , che \u00e8 sempre vero. Procediamo quindi applicando il teorema: \\(\\lim_{y \\to y_0} g(y) = \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) Quindi \\(\\limit \\min arctg(x^2) = \\frac \\pi 2\\) Osservazione: la soluzione appena vista \u00e8 un teorema di cambiamento di variabile Riprendendo l'esempio appena visto, siamo partiti da \\(\\limit \\min arctg(x^2)\\) . Cambiamo poi variabile e poniamo \\(y=x^2\\) , tuttavia troviamo la x anche come argomento del limite (che tende a \\(\\min\\) ). Quindi se \\(x \\to \\min\\) a quanto tende y? Basta fare \\(\\limit \\min y = \\limit \\min x^2 = \\pin\\) Cambiando variabile otteniamo quindi: \\(\\limit \\min arctg(x^2) \\Rightarrow \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) La seconda ipotesi nel teorema necessaria perch\u00e9 se la composizione tra due funzioni va a toccare in modo insistente il punto limite, dato che il secondo limite non si interessa di quanto valga la funzione nel centro dell'intorno, e dato che la funzione f va solo nel centro dell'intorno \"non si pu\u00f2 accorgere di quel che sta succedendo(?)\" Uso dell'ipotesi due nel problema \\(f: \\reals \\to \\reals \\quad f(x) = 1 \\quad \\forall x \\in \\reals\\) \\(x_0 = 0\\) \\(g(x) = \\begin{cases} 3 \\text{ se } y=1 \\\\ 5 \\text{ se } y \\ne 1 \\\\ \\end{cases}\\) \\(g: \\reals \\to \\reals\\) \\((g \\circ f)(x) = g(f(x)) = g(1) = 3 \\forall x \\in \\reals\\) Quindi la funzione \\((g \\circ f)(x)\\) \u00e8 sempre 3. Il limite di una funzione costante \u00e8 quindi una costante: \\(\\limit 0 (g \\circ f)(x) = 3\\) Prendendo poi come \\(y_0 = \\limit {x_0} f(x) = \\limit 0 f(x) = 1\\) , e quindi: \\(\\limit {x_0} (g \\circ f)(x) \\ne \\lim_{y \\to y_0} g(y)\\) Per\u00f2 non vale nessuna delle due ipotesi Confronti tra infiniti \u00b6 Dato un limite del tipo \\(\\limit \\pin \\frac {a^x}{x^\\alpha}\\) , abbiamo: \\[\\limit \\pin \\frac {a^x}{x^\\alpha} = \\begin{cases} \\pin & \\text{ se } a > 1 0^+ & \\text{ se } 0< a < 1 \\end{cases} \\] Se \\(a=1 \\Rightarrow a^x = 1\\) , quindi \\(\\lim \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac 1 {x^\\alpha}\\) Quindi quello che domina i limite \u00e8 l'a al numeratore, ovvero l'esponenziale, che vince sulla potenza. L'unico caso in cui l'esponenziale non guida la funzione \u00e8 quando a \u00e8 pari ad 1. Esempio \\(a=\\frac 1 2 \\quad \\alpha = -3\\) \\[ \\limit \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac {(\\frac 1 2)^x} {x^{-3}} = \\limit \\pin \\frac {x^3}{2^x} = 0^+ \\] Anche in questo caso quello che domina il limite \u00e8 l'esponenziale (il \\(2^x\\) al denominatore), che \u00e8 molto pi\u00f9 veloce rispetto alla potenza Confronto tra logaritmo e potenza \u00b6 Quando abbiamo a che fare con un logaritmo, conviene usare il cambio di variabile e sostituirlo (come mostrato nell'esempio) Esempio: cambio di potenza del logaritmo \\(\\limit \\pin \\frac {log(x)} x\\) , quindi facciamo il cambio di variabile \\(y = log(x)\\) (e quindi \\(x = e^x\\) una volta effettuato il cambio variabile nel limite) Se \\(x \\to \\pin \\Rightarrow \\limit \\pin log(x) = \\pin\\) \\(( y = log(x) \\to \\pin)\\) \\(\\limit \\pin \\frac {log (x)} x = \\lim_{y \\to \\pin} \\frac y {e^y} = 0\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha}\\) , \\(\\alpha, \\beta \\in \\reals\\) , \\(\\alpha, \\beta > 0\\) Anche in questo caso iniziamo con il cambio di variabile \\(y = log(x) \\Rightarrow x=e^y\\) Quindi se \\(x \\to \\pin\\) (se x tende a \\(\\pin\\) ), \\(\\Rightarrow y \\to \\pin\\) (allora anche y tende a \\(\\pin\\) ) Risostituiamo inoltre x con \\(e^y\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^y)^\\alpha} =\\) \\(=\\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^{y \\cdot \\alpha}} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^\\alpha)^y} =\\) Assegnamo quindi ad \\(a = e^\\alpha\\) : \\(\\lim_{y \\to \\pin} \\frac {y^\\beta}{a^y}\\) Da qui sappiamo che \\(\\alpha > 0\\) e quindi \\(e^\\alpha > 1\\) Questo limite ha quindi come risultato 0, perch\u00e9 l'esponenziale al denominatore porta a 0 il denominatore","title":"Limiti"},{"location":"AnalisiI/limiti/#parallelismo-con-la-continuita","text":"Il concetto di limite \u00e8 molto simile a quello di continuit\u00e0. La differenza principale \u00e8 che: Nel limite non guardiamo il punto \\(x_0\\) ma il suo intorno. Inoltre consideriamo solo i punti di accumulazione (quindi anche punti esterni al dominio (come 0 con la funzione \\(\\frac 1 x\\) ). Inoltre non consideriamo i punti isolati in quanto non sono di accumulazione) Nella continuit\u00e0 guardiamo il valore \\(x_0\\) ed un suo intorno, considerando ogni punto nel domino (quindi anche i punti isolati) Inoltre nella continuit\u00e0 \\(x_0\\) pu\u00f2 essere uguale ad x, quindi \\(x_0 = x \\Rightarrow f(x) - f(x_0) = 0\\) La definizione di limite e continuit\u00e0 infine possono essere viste compatibili se (oltre al requisito \\(x \\ne x_0\\) ) si scambiano tra di loro L ed \\(x_0\\)","title":"Parallelismo con la continuit\u00e0"},{"location":"AnalisiI/limiti/#teorema-dellunicita-del-limite","text":"Teorema dell'unicit\u00e0 del limite Se il limite esiste, allora \u00e8 unico. Questo perch\u00e9 dire che una funzione tende ad un valore \\(L_1\\) per x che tende a \\(x_0\\) significa che si avvicina a quel valore quando x si avvicina a \\(x_0\\) , quindi non pu\u00f2 tendere contemporaneamente ad \\(L_2\\) perch\u00e9 non pu\u00f2 avvicinarsi a due valori distinti contemporaneamente.","title":"Teorema dell'unicit\u00e0 del limite"},{"location":"AnalisiI/limiti/#limiti-destri-e-sinistri","text":"Definzione di limite destro e sinistro \\(A \\subset \\reals, x_0 \\in Acc(A), x_0 in \\reals\\) \\(f: A \\rightarrow \\reals\\) , l in \\(\\bar \\reals\\) \u00e8 il limite di f(x) per x che tende a \\(x_0\\) da destra e si scrive \\[ \\lim_{x \\rightarrow x_0^+} f(x) =f \\] Se \\(\\forall V\\) intorno di l esiste \\(\\delta >0\\) tale che \\(x_0 < x < x_0 + \\delta, x \\in A \\Rightarrow f(x) \\in V\\) . Qui si possono notare due cose: Il fatto che x sia diverso da \\(x_0\\) si pu\u00f2 osservare dall'uso del minore stretto (quindi non mi interessa neanche in questo caso quanto vale la funzione del punto) Il motivo per il quale \\(x_0\\) \u00e8 finito (in \\(\\reals\\) ) \u00e8 perch\u00e9 non ha senso avvicinare \\(+\\infty\\) da destra Da sinistra, se \\(x_0 - \\delta < x < x_0, x \\in A \\Rightarrow f(x) \\in V\\) Questo significa che nella definizione di limite, si considerano solo i \" mezzi intorni \" a desta o a sinistra Esempio di limite da destra e da sinistra Prendendo la funone \\(f: (-\\infty, 0) \\cup (0, + \\infty) \\rightarrow \\reals\\) Definita come \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questo caso, il limite per x che tende a 0 da destra di f(x) vale 1 ( \\(\\lim_{x \\rightarrow 0^+} f(x) = 1\\) ) e quello che tende a 0 da sinistra -1 ( \\(\\lim_{x \\rightarrow 0^-} f(x) = -1\\) ). In questo caso non esiste il limite per f(x) che tende a 0, perch\u00e9 il limite che tende a 0 da destra \u00e8 diverso dal limite per x che tende a 0 da sinistra. Il limite esiste solo se i limiti da destra e da sinistra sono uguali \\[ \\lim_{x \\rightarrow x_0} f(x) = L \\Leftrightarrow \\lim_{x \\rightarrow x_0^+} f(x) = \\lim_{x \\rightarrow x_0^-} f(x) = L \\] Nella definzione di limite destro si usa solo il \" mezzo intorno \" destro e stessa cosa con quello sinistro. Se vengono messi insieme si ottiene la definizione di limite.","title":"Limiti destri e sinistri"},{"location":"AnalisiI/limiti/#funzione-definitivamente-positiva-e-negativa","text":"Funzione definitivamente positiva e negativa \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Si dice che \\(\\lim_{x \\rightarrow x_0} f(x) = L^+\\) (con \\(L \\in \\reals\\) ), se: \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) Esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\{x_0\\} \\Rightarrow f(x) > L\\) Ci\u00f2 significa che la funzione \"tende\" al valore ma da 'sopra': La stessa definizione vale per \\(L^-\\) Esempio di limite positivo \\[ f(x) = \\frac 1 x \\qquad \\lim_{x \\rightarrow + \\infty} f(x) = 0^+ \\] Questo perch\u00e9 considerare la funzione vicino \\(+ \\infty\\) , la funzione tende a 0. Scegliendo una semiretta (e quindi un intervallo \\((a, + \\infty)\\) ) come intorno u \\(a > 0 \\Rightarrow f(x) > 0\\) (in questo caso 0=l), e quindi possiamo dire che la funzione \u00e8 definitivamente positiva In questo caso a noi interessa che la funzione sia positiva in un intorno del punto di cui calcoliamo il limite","title":"Funzione definitivamente positiva e negativa"},{"location":"AnalisiI/limiti/#teorema-della-permanenza-del-segno","text":"Teorema della permanenza del segno \\(A \\subset \\reals, f: A \\rightarrow \\reals, x_0 \\in Acc(A)\\) Se esisiste \\(\\lim_{x \\rightarrow x_0} f(x) = L \\in \\bar \\reals\\) e \\(L \\ne 0\\) allora esiste un intorno u di \\(x_0\\) tale che se \\(x \\in A \\cap u \\{x_0\\}\\) allora f ha lo stesso segno di L. [44:00]","title":"Teorema della permanenza del segno"},{"location":"AnalisiI/limiti/#continuita-di-una-funzione-a-destra-o-sinistra","text":"Funzione continua a destra o sinistra Dato \\(A \\subset \\reals, x+0 in A, x_0 \\in Acc(A)\\) Se \\(\\lim_{x \\rightarrow x_{0^+}} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a destra in \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_{0^0-} f(x) = f(x_0)\\) , allora si dice che f \u00e8 continua a sinistra in \\(x_0\\) . Funzione continua a destra o sinistra Riprendendo l'esempio della funzione vista prima e modificandola appena, di d\u00e0 la seguente funzione: \\(f(x)= \\begin{cases} -1 \\text{ se } x < 0 \\\\ 1 \\text{ se } x > 0 \\end{cases}\\) In questa funzione, il limite per x che tende a \\(0^+\\) vale quanto la funzione a 0. Quando la funzine presenta questo comportamento, viene detta funzione continua a destra. Ovviamente lo stesso discorso vale anche per il discorso \"a sinistra\"","title":"Continuit\u00e0 di una funzione a destra o sinistra"},{"location":"AnalisiI/limiti/#teorema-di-confronto","text":"Teorema di confronto \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) Se esiste u intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x)\\) , allora \\(L_1 \\le L_2\\) . Ovvero, se si hanno due funzioni in cui nel grafico una delle due funzioni assume valori maggiori allo stesso punto, la disuguaglianza \" passa \" al limite. Nelle ipotesi corrette quindi: \\[ f(x) \\le g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x) \\] Il teorema non funziona con minore/maggiore stretto Se \\(f(x) > g(x)\\) potrei concludere che \\(\\lim_{x \\rightarrow x_0} f(x) < \\lim_{x \\rightarrow x_0} g(x)\\) ? No, perch\u00e9 prendendo ad esempio le funzioni \\(g(x) = \\frac 1 x\\) e \\(f(x) = - \\frac 1 x\\) su \\(x > 0\\) , entrame le funzioni tendono a 0; ed ecco che una disuguaglianza stretta diventa debole. Quindi \\(f(x) < g(x) \\Rightarrow \\lim_{x \\rightarrow x_0} \\lim_{x \\rightarrow x_0} f(x) \\le \\lim_{x \\rightarrow x_0} g(x)\\) Le disuguaglianze passano quindi al limite ma diventano deboli.","title":"Teorema di confronto"},{"location":"AnalisiI/limiti/#teorema-dei-carabinieri","text":"Teorema di dei carabinieri \\(A \\subset \\reals, x_0 \\in Acc(A), f,g, h: A \\rightarrow \\reals\\) Se esistono \\(\\lim_{x \\rightarrow x_0} f(x)= L\\) e \\(\\lim_{x \\rightarrow x_0} h(x)= L\\) (L in questo caso ha lo stesso valore). Se esiste un intorno \\(u\\) di \\(x_0\\) tale che \\(x \\in A \\cap u \\backslash \\{x_0\\} \\Rightarrow f(x) \\le g(x) \\le h(x)\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} g(x) = L\\) Ovvero, se abbiamo tre funzioni, dall'esistenza dei limiti di f ed h (uguali tra loro) deduco che esiste il limite di g. Rispetto al teorema di confronto, dove si sa che i limiti delle funzioni g ed h esistono, in questo caso non so se esiste il limite di G ma sapendo che la funzione \u00e8 compresa tra due funzioni ed il limite delle due funzioni \u00e8 L, deduco che il limite di g sia L. Uso di \"met\u00e0\" del teorema Se la funzione di sinistra va a \\(\\pin\\) , spinge a \\(\\pin\\) tutto quanto (quindi ogni funzione alla destra della disequazione non pu\u00f2 che essere qualcosa che va a pi\u00f9 infinito). Lo stesso concetto lo ho quando la parte della disequazione pi\u00f9 a sinistra va a \\(\\min\\) Ho bisogno di entrambe le met\u00e0 quando il limite \u00e8 un numero finito ed ho bisogno delle altre funzioni per \"schiaccia\" sia da sopra che da sotto la funzione in mezzo.","title":"Teorema dei carabinieri"},{"location":"AnalisiI/limiti/#teorema-di-somma-e-prodotto-di-limiti","text":"Teorema di somma e prodotto di limiti \\(A \\subset \\reals, x_0 \\in Acc(A), f,g: A \\rightarrow \\reals\\) Supponiamo esistano i limiti \\(\\lim_{x \\rightarrow x_0} f(x) = L_1\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = L_2\\) con \\(L_1, L_2 \\in \\bar \\reals\\) Allora: Se ha senso \\(L_1 + L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = L_1+L_2\\) Se ha senso \\(L_1 \\cdot L_2\\) , allora esiste \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = L_1 \\cdot L_2\\)","title":"Teorema di somma e prodotto di limiti"},{"location":"AnalisiI/limiti/#casi-di-indeterminazione","text":"Il \"Se ha senso\" nella definizione precedente serve per escludere i casi di indeterminazione : \\(+ \\infty \\cdot - \\infty\\) e viceversa \\(\\pm \\infty \\cdot 0\\)","title":"Casi di indeterminazione"},{"location":"AnalisiI/limiti/#esempi-di-casi-di-indeterminazione","text":"Somma di \\(+ \\infty\\) con \\(- \\infty\\) Ponendo \\(f(x) = 2x\\) e \\(g(x) = -x\\) Le due funzioni hanno i limiti che a \\(+ \\infty\\) valgono rispettivamente \\(+ \\infty\\) e \\(- \\infty\\) . La loro somma \u00e8 quindi questa: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (2x - x) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = + \\infty\\) Se invece prendo \\(f(x) = \\frac x 2\\) e \\(g(x) = -x\\) , allora i rispettivi termini per x che tende a \\(+ \\infty\\) varranno \\(+ \\infty\\) e \\(- \\infty\\) Ma se proviamo a fare il discorso che abbiamo appena fatto: \\[ \\lim_{x \\rightarrow + \\infty} (f + g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac x 2 - x) = \\lim_{x \\rightarrow + \\infty} - \\frac x 2 = - \\infty \\] In questo caso avremmo che \\((+ \\infty) + (- \\infty) = - \\infty\\) Dato che il risultato di una somma deve essere costante, scegliamo di trattare le operazioni tra infiniti come casi particolari e quindi di non risolverle algebricamente. Non ha senso parlare di somma. Per questo motivo \\((+ \\infty) + (- \\infty)\\) non ha senso e si dice che il limite \u00e8 indeterminato. Il prodotto \\(0 * + \\infty\\) si considera allo stesso modo rispetto alla somma: Considerando la funzione \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x) = \\lim_{x \\rightarrow + \\infty} 1 = 1 \\] Ed in questo caso avremmo \\((0) \\cdot (+ \\infty) = 1\\) Prendendo invece \\(f(x) = \\frac 1 x\\) (che tende a 0) e la funzione \\(g(x) =x^2\\) , che tende a \\(+ \\infty\\) \\[ \\lim_{x \\rightarrow + \\infty} (f \\cdot g)(x) = \\lim_{x \\rightarrow + \\infty} (\\frac 1 x \\cdot x^2) = \\lim_{x \\rightarrow + \\infty} x = + \\infty \\] Quindi avremmo \\(0 \\cdot (+ \\infty) = + \\infty\\) . Quindi \\(0 \\cdot (+ \\infty)\\) non ha senso.","title":"Esempi di casi di indeterminazione"},{"location":"AnalisiI/limiti/#risoluzione-dei-casi-di-indeterminazione","text":"Una funzione che tende ad un numero finito \u00e8 limitata \\(A \\subset \\reals, x_0 \\in Acc(A), f: A \\rightarrow \\reals\\) Se esiste \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) ( \\(L\\) non \u00e8 \\(\\pm \\infty\\) ), allora f \u00e8 limitata in un intorno di \\(x_0\\) . Ovvero esiste un intorno \\(u\\) di \\(x_0\\) ed \\(\\exists M \\in R, M > 0\\) tale che \\(x \\in u \\cap A \\Rightarrow |f(x)| \\le M\\) Quindi una funzione che tende ad un numero finito, vicino al punto deve essere finita (limitata). Esempio di funzione limitata che tende a 0 \\(f(x) = \\frac 1 x\\) \u00e8 limitata in un intorno di \\(+ \\infty\\) perch\u00e9 ( \\(\\lim_{x \\rightarrow + \\infty} f(x) = 0\\) E da un certo punto in poi la funzione sta tra \\(\\pm M\\) , dato che la funzione tende ad un numero finito (e quindi da un certo punto in poi \u00e8 finita, essendo la funzione limitata)","title":"Risoluzione dei casi di indeterminazione"},{"location":"AnalisiI/limiti/#funzione-infinitesima","text":"Funzione infinitesima, divergente e convergente Se \\(\\lim_{x \\rightarrow x_0} f(x) = 0\\) , allora si dice che f \u00e8 infinitesima per x che tende a \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = + \\infty\\) , si dice che f diverge positivamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = - \\infty\\) , si dice che f diverge negativamente per x che tende ad \\(x_0\\) . Se \\(\\lim_{x \\rightarrow x_0} f(x) = L\\) e \\(L \\in \\reals\\) , f converge a L per x che tende ad \\(x_0\\) . Se f \u00e8 limitata inferiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = + \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = + \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = - \\infty\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f+g)(x) = - \\infty\\) . Se f \u00e8 limitata superiormente in un intorno di \\(x_0\\) e \\(\\lim_{x \\rightarrow x_0} g(x) = 0\\) , allora il limite per \\(\\lim_{x \\rightarrow x_0} (f \\cdot g)(x) = 0\\) . Una funzione infinitestima per una limitata \u00e8 una funzione infinitesima La somma f + g \u00e8 indeterminata quando una funzione va a + infinito ed una a - infinito; quindi mi basta che la funzione sia limitata inferiormente (perch\u00e9 \u00e8 un caso in cui la funzione non va a - infinito) per dire che la somma va a pi\u00f9 infinito (e viceversa). Nel caso di prodotto di una funzione limitata per una infinitesima: per rimuovere l'indeterminazione mi \"basta dire\" che la seconda funzione \u00e8 limitata. Tutte queste cose appena evidenziate derivano dal teorema dei carabinieri Esempio: Applicazione del teorema sul limite della somma con funzioni senza limite Prendendo la funzione \\(\\limit {+ \\infty} x + sin(x)\\) , possiamo scomporla in due: \\(\\limit {+ \\infty} x = + \\infty\\) \\(\\limit {+ \\infty} sin(x)\\) che non esiste In questo caso non si pu\u00f2 applicare il teorema sul limite della somma (che richede che entrambi i limiti esistano). Tuttavia sin(x) \u00e8 una funzione limitata inferiormente; Quindi: \\[ \\limit \\pin x + sin(x) = \\pin \\] Questo perch\u00e9 \\(x-1 \\le x+sin(x)\\) (perch\u00e9 \\(sin(x)\\) \u00e8 limitat inferiormente): per il teorema dei carabinieri \\(x-1\\) tende a \\(\\pin\\) , quindi anche \\(x + sin(x)\\) tende a \\(\\pin\\) .","title":"Funzione infinitesima"},{"location":"AnalisiI/limiti/#limite-del-reciproco","text":"Limiti dei reciproci Se \\(\\limit {x_0} f(x)= 0^+\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\pin\\) Se \\(\\limit {x_0} f(x) = 0^-\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\min\\) Se \\(\\limit {x_0} f(x) = \\pin\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^+\\) Se \\(\\limit {x_0} f(x) = \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = 0^-\\) Se \\(\\limit {x_0} f(x) = L\\) con \\(L \\ne 0, \\pin, \\min\\) allora \\(\\limit {x_0} \\frac 1 {f(x)} = \\frac 1 L\\) Questa proposizione ci dice che il limite del reciproco di una funzione (ammesso che sia definita), \u00e8 il reciproco del limite: Se f tende a L, \\(\\frac 1 f\\) tende a \\(\\frac 1 L\\) \\[ \\displaylines{ f \\rightarrow L \\Rightarrow \\frac 1 f \\rightarrow \\frac 1 L \\\\ \\frac 1 {0^+} = \\pin, \\quad \\frac 1 {0^-} = \\min, \\quad \\frac 1 \\pin = 0^+, \\quad \\frac 1 \\min = 0^- } \\]","title":"Limite del reciproco"},{"location":"AnalisiI/limiti/#esistenza-dei-limiti-per-funzioni-monotone","text":"Esistenza dei limiti per funzioni monotone \\(a, b \\in \\bar \\reals, f: (a,b) \\rightarrow \\reals\\) con f debolmente crescente . In tal caso esistono: \\(\\limit {a^+} f(x) = \\inf_{x \\in (a,b)} f(x)\\) \\(\\limit {b^-} f(x) = \\sup_{x \\in (a,b)} f(x)\\) L'opposto vale quando la funzione \u00e8 debolmente decrescente (invertendo estremo superiore ed inferiore) Avevamo visto che le funzioni monotone assumono massimo e minimo in un intervallo a destra se il dominio ha massimo ed il minimo a sinistra se il dominio ha minimo Questo teorema ci dice che in una funzione monotona i limiti esistono sempre. Esempio \\[ \\displaylines{ f:(0,\\pin) \\rightarrow \\reals \\quad f(x) = - \\frac 1 x \\\\ \\limit {0^+} - \\frac 1 x = \\min = \\inf(f) \\\\ \\limit \\pin - \\frac 1 x = 0 = \\sup(f) } \\]","title":"Esistenza dei limiti per funzioni monotone"},{"location":"AnalisiI/limiti/#cambio-di-variabile","text":"Per risolvere alcuni limiti che si presenteranno, pu\u00f2 essere necessario effettuare un cambio di variabile. Un cambio di variabile \u00e8 fatto quando si sostituisce una funzione (ad esempio \\(e^x\\) con una variabile come \\(y\\) ) Quando questo accade, \u00e8 necessario cambiare anche il limite, per far s\u00ec che non perda di significato: \\[ \\lim \\pin e^x = \\lim_{y \\to \\pin} y \\]","title":"Cambio di variabile"},{"location":"AnalisiI/limiti/#limiti-fondamentali","text":"Esistono alcuni limiti fondamentali:","title":"Limiti fondamentali"},{"location":"AnalisiI/limiti/#somma-e-prodotto-di-limiti","text":"\\(\\limit \\pin x = \\pin\\) \\(\\limit \\pin x^n = (\\lim_{n \\rightarrow \\pin} x) \\cot (\\lim_{n \\rightarrow \\pin} x) \\cdot ...\\) (questo \u00e8 il teorema su prodotto di limiti) \\(=(\\pin)\\cdot (\\pin) \\cdot ... = \\pin\\) \\(\\limit \\pin \\frac 1 x = \\frac 1 \\pin = 0\\) \\(\\limit \\pin \\frac 1 {x^n} = 0\\)","title":"Somma e prodotto di limiti"},{"location":"AnalisiI/limiti/#limiti-di-poliniomi","text":"Un polinomio di grado n \u00e8 qualcosa del tipo \\(p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0\\) Dove \\(a_0, a_1, ..., a_n\\) sono i coefficienti del polinomio e sono numeri reali ( \\(a_0, a_1, ..., a_n \\in \\reals\\) ). n \u00e8 invece il grado del polinomio ( \\(n \\in \\naturals\\) ). Esempio di risoluzione di una forma indeterminata Il limite ad infinito di un polinomio \u00e8 spesso una forma indeterminata: \\(\\lim \\pin 3x^2 - 7x + 1 = \\pin \\min + 1\\) Questa \u00e8 quindi una forma indeterminata. Per eliminarla: \\[ \\displaylines{ \\limit \\pin 3x^2(1 - \\frac 7x {3x^2} + \\frac 1 {3x^2}) = \\\\ = \\limit \\pin 3x^2(1- \\frac 7 {3x} + \\frac 1 {3x^2}) = \\\\ = \\pin(1- \\frac 7 \\pin + \\frac 1 \\pin) = \\\\ = \\pin (1 - 0 - 0) = \\pin } \\] Raccogliamo quindi il \\(3x^2\\) e poi dividiamo, facendo infine il limite. Dato un polinomio possiamo quindi sempre raccogliere il monomio di grado pi\u00f9 grande e poi dividere per lo stesso. \\[ \\displaylines{ p(x) = a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\\\ = a_nx^n (1 + \\frac {a_{n-1}} {a_n} \\cdot \\frac {x^{n-1}} {x^n} + ... + \\frac {a_1} {a_n} \\cdot \\frac x {x^n} + \\frac {a_0} {a_n} \\cdot \\frac 1 {x^n}) } \\] A questo punto ho tutti termini che tendono a 0 se x tende a \\(\\pin\\) (o anche se x tende a \\(\\min\\) ). Quello che ottendo quindi \u00e8 che \\(\\limit \\pin a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0 = \\limit \\pin a_nx^n\\) . Lo stesso discorso vale anche per quando x tende a \\(\\min\\) . Quindi quando la variabile x tende a \\(\\pm \\infty\\) , il polinomio si comporta come si comporterebbe il monomio di grado pi\u00f9 grande. Esempio di comportamento del poliniomio rispetto al suo grado maggiore \\[ \\limit \\min -2x^5+3x^2 = \\limit \\min -2x^5 = -2(\\min)^5 = (-2)(\\min) = \\pin \\]","title":"Limiti di poliniomi"},{"location":"AnalisiI/limiti/#funzioni-razionali","text":"Una funzione razionale \u00e8 una funzione \\(\\frac {p(x)} {q(x)}\\) dove p e q sono polinomi: \\[ \\displaylines{ p(x) = a_n \\cdot x^n + a_{n-1} \\cdot x^{n-1} + ... + a_{1} \\cdot x + a_0 \\\\ q(x) = b_m \\cdot x^m + b_{m-1} \\cdot x^{m-1} + ... + b_{1} \\cdot x + b_0 } \\] Quindi il limite della funzione sar\u00e0 equivalemtne al conto che si fa con i polinomi: \\[ \\displaylines{ \\limit {\\pm \\infty} \\frac {p(x)} {q(x)} = \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0} {b_mx^m + b_{m-1}x^{m-1} + ... + b_1x + b_0} \\\\ = \\limit {\\pm \\infty} \\frac {a_nx^n} {b_mx^m} } \\] Esempio di funzioni razionali \\[ \\displaylines{ \\limit \\pin \\frac {7x^4 + 5x^2} {-2x^3 + x} = \\\\ = \\limit \\pin \\frac {7x^4} {-2x^3} = \\\\ = \\limit \\pin \\frac {7x} {-2} = \\min } \\] In questo caso abbiamo un eccesso di grado al numeratore (al numeratore abbiamo un grado 4, al denominatore abbiamo un grado 3), quindi il limite va a \\(\\pm \\infty\\) a seconda del sengno dei coefficienti. Se fosse successo l'opposto (il grado del denominatore suepriore al grado del numeratore), il limite sarebbe andato a 0 Se invece il grado fosse stato lo stesso, il limite sarebbe andato al rapporto dei coefficenti tra i termini di grado maggiore.","title":"Funzioni razionali"},{"location":"AnalisiI/limiti/#altri-limiti-fondamentali","text":"\\[ \\displaylines{ \\limit \\pin e^x = \\pin \\\\ \\limit \\min e^x = 0^+ \\\\ \\limit {0^+} log(x) = \\min \\\\ \\limit \\pin log(x) = \\pin \\\\ } \\]","title":"Altri limiti fondamentali"},{"location":"AnalisiI/limiti/#limiti-notevoli","text":"\\(\\limit 0 \\frac {sin(x)} x = 1\\) Questo limite \u00e8 una forma indeterminata, in quanto il \\(\\limit 0 sin(x) = 0\\) , mentre il \\(\\limit 0 x = 0\\) , tuttavi si pu\u00f2 dimostrare che il limite faccia uno. Dimostrazione - Da fare //TODO - work in progress Guadando una circonferenza, pu\u00f2 essere facile dire che la tangente \u00e8 sempre pi\u00f9 grande del seno per lo stesso valore di x (per il primo quadrante). \\[ \\displaylines{ |sin(x)| \\le x \\le |tan(x)| = \\\\ = |sin(x)| \\le x \\le |\\frac {sin(x)}{cos(x)}| = \\quad (\\cdot \\frac 1 {|sin(x)|})\\\\ = \\frac {|sin(x)|} {|sin(x)|} \\le \\frac x {sin(x)} \\le \\frac {|sin(x)|}{|cos(x)|} \\cdot \\frac 1 {|sin(x)|} = \\\\ = 1 \\le \\frac x {sin(x)} \\le \\frac 1 {cos(x)} = \\quad \\text{ (inversione delle frazioni) }\\\\ = 1 \\ge \\frac {sin(x)} x \\ge cos(x) \\\\ \\\\ \\limit 0 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge \\limit 0 cos(x) = \\\\ = 1 \\ge \\limit 0 \\frac {sin(x)} x \\ge 1 \\Rightarrow \\limit 0 \\frac {sin(x)} x = 1 } \\] Da questo limite se ne possono poi dimostrare altri: \\(\\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2\\) Dimostrazione \\[ \\displaylines{ \\frac {1 - cos(x)}{x^2} = \\frac {(1 - cos(x)) (1 + cos(x))}{x^2 (1 + cos(x))} \\\\ = \\frac {1 - cos^2 (x)} {x^2 (1 + cos(x))} = \\frac {sin^2 (x)}{x^2 1 + cos(x)} = \\\\ = \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} \\\\ \\\\ \\limit 0 \\frac {sin(x)} x \\cdot \\frac {sin(x)} x \\frac 1 {1 + cos(x)} = 1 \\cdot 1 \\cdot \\frac 1 {1+1} = \\\\ = \\limit 0 \\frac {1 - cos(x)}{x^2} = \\frac 1 2 } \\] \\(\\limit 0 \\frac {e^x -1} x = 1\\) \\(\\limit 0 \\frac {log(1 + x)} x = 1\\) \\(\\limit {0^+} x \\cdot \\log(x) = 0 \\cdot (\\min)\\) (forma indeterminata) Per questa si effettua il cambio di variabile, quindi \\(y=log(x), x = e^y\\) Se \\(x \\to 0^+ \\Rightarrow y = log(x) \\to \\min\\) \\(\\lim_{y \\to \\min} e^y \\cdot y\\) (questa \u00e8 ancora una forma indeterminata, \\(e^\\min \\cdot (\\min) = 0^+ \\cdot (\\min)\\) ) Quindi \u00e8 necessario fare un ulteriore cambio di variabile: \\(z = -y\\) , quindi se \\(y \\to \\min \\Rightarrow z \\to \\pin\\) \\(\\lim_{y \\to \\min} e^y \\cdot y = \\lim_{z \\to \\pin} e^{-z} \\cdot -z = \\lim_{z \\to \\pin} \\frac {-z} {e^z} = 0\\) \\(\\lim_{x \\to 0^+} x\\cdot log(x) = 0\\) \\(\\limit {0^+} x^\\alpha log(x)\\) (con \\(\\alpha > 0\\) ); Anche in questo caso dobbiamo ricorrere alla sostituzione: \\(y = x^\\alpha\\) , quindi \\(x = y^{\\frac 1 \\alpha}\\) Se \\(x \\to 0 \\Rightarrow y = x ^ \\alpha \\rightarrow 0\\) \\(\\limit {0^+} x^\\alpha log(x) = \\lim_{y \\to 0^+} y \\cdot log(y^{\\frac 1 \\alpha})\\) \\(= \\lim_{y \\to 0^+} y \\cdot \\frac 1 \\alpha log(y)\\) \\(= \\frac 1 \\alpha \\lim_{y \\to 0^+} y \\cdot log(y) = 0\\) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\) Dimostrazione \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = (1 + 0)^{\\frac 1 0^+ } = 1^\\pin\\) Questa \u00e8 una forma indeterminata: \\((1 + x)^{\\frac 1 x} = e^{log(1 + x)^{\\frac 1 x}} = e^{\\frac 1 x log(1+x)}\\) Da qui sostituiamo \\(y = \\frac 1 x log(1 + x)\\) Se \\(x \\to 0^+\\) , a quanto deve tendere y? \\(\\limit {0^+} \\frac 1 x log(1 + x) = 1\\) (Limite notevole) \\(\\limit {0^+} (1 + x)^{\\frac 1 x} = \\lim_{y \\to 1} e^y = e^1 = e\\)","title":"Limiti notevoli"},{"location":"AnalisiI/limiti/#nuovi-casi-di-indeterminazione","text":"\\(f(x) > 0, \\limit {x_0} f(x)^{g(x)}\\) . Quando questa \u00e8 una forma indeterminata? Possiamo manipolare il limite per rendere la domanda pi\u00f9 semplice: \\(f(x)^{g(x)}=e^{log(f(x)^{g(x)})} = e^{g(x) \\cdot log(f(x))}\\) Abbiamo quindi spostato la domanda: quando \u00e8 indeterminato il limite \\(\\limit {x_0} g(x) \\cdot log(f(x))\\) ? Abbiamo 3 casi: \\(g \\to 0, f \\to \\pin \\So log(f) \\to \\pin\\) \\(0 \\cdot \\pin\\) quindi \\((\\pin)^0\\) \u00e8 indeterminata \\(g \\to 0, f\\to 0^+ \\So \\log f \\to \\min\\) \\(\\So g \\cdot \\log(f) = 0 \\cdot (\\min)\\) \\(g \\to \\pm \\infty, f \\to 1\\) , quindi \\(log(f) \\to 0\\) \\(g \\cdot log(f) = \\pm \\infty \\cdot 0\\) \\((1)^{\\pm \\infty}\\) \u00e8 indeterminata Abbiamo quindi 4 nuove forme indeterminate: \\[ (\\pin)^0, \\qquad (0^+)^0, \\qquad (1)^{\\pin}, \\qquad (1)^{\\min} \\] Tutti e quattro i casi si risolvono riscrivendoli nella forma esponenziale Esempio $\\limit {0^+} x^x = \\limit {0^+} e {log(x x)} = $ \\(=\\limit {0^+} e^{x \\cdot log(x)} = e^0 = 1\\) Qui \u00e8 stato \"nascosto\" il cambio di variabile, che sarebbe stato \\(y = x \\cdot log(x)\\) , se \\(x \\to 0^+ \\So y \\to 0\\) \\(\\So \\lim_{y \\to 0} e^y = e^0 = 1\\)","title":"Nuovi casi di indeterminazione"},{"location":"AnalisiI/limiti/#esponenziale","text":"Dato \\(\\limit \\pin a^x\\) , ci sono 3 possibili soluzioni: \\[\\limit \\pin a^x = \\begin{cases} \\pin & \\text{ se } a > 1 1 & \\text{ se } a = 1 0^+ & \\text{ se } 0 < a < 1 \\end{cases} \\] Ovviamente a deve essere maggiore di 0 Se invece vogliamo far tendere \\(x \\to \\min\\) , possiamo effettuare un cambio variabile: \\(y = -x\\) , quindi se \\(x \\to \\min \\Rightarrow y \\to \\pin\\) . Di conseguenza: \\(\\limit \\min a^x = \\lim_{y \\to 1} a^-y = \\lim_{y \\to \\pin} \\frac 1 {a^y}\\) Quindi abbiamo di nuovo 3 casi: \\[ \\lim_{y \\to \\pin} \\frac 1 {a^y} = \\begin{cases} 0^+ & \\text{ se } a > 1 1 & \\text{ se } a = 1 \\pin & \\text{ se } 0 < a < 1 \\end{cases} \\] I risultati sono anche facilmente visibili: \\(a >1\\) \\(0<a<1\\)","title":"Esponenziale"},{"location":"AnalisiI/limiti/#potenze","text":"Consideriamo \\(\\alpha \\in \\reals\\) e quindi \\(x^\\alpha\\) Observation Notare che se si consdiera \\(x^\\alpha\\) con \\(\\alpha\\) non razionale, si \u00e8 forzati a prendere \\(x>0\\) (\u00e8 pari o dispari \\(\\pi\\) ?) Quindi, \\(\\limit \\pin x^\\alpha\\) vale: \\[ \\limit \\pin x^\\alpha = \\begin{cases} \\pin & \\text{ se } \\alpha > 0 \\\\ 1 & \\text{ se } \\alpha = 0 \\\\ 0^+ & \\text{ se } \\alpha < 0 \\end{cases} \\]","title":"Potenze"},{"location":"AnalisiI/limiti/#limite-della-composizione-di-funzioni","text":"Teorema del Limite della composizione di funzioni \\(A, B \\subset \\reals, f: A \\rightarrow B, g: B \\rightarrow \\reals\\) \\(x_0 \\in Acc(A)\\) Se esiste \\(\\limit {x_0} f(x) = y_0\\) , e \\(y_0 \\in Acc(B)\\) e \\(\\exists \\lim_{y \\rightarrow y_0} g(y) = L \\in \\bar \\reals\\) E se \u00e8 verificata almeno una delle seguenti due ipotesi: \\(y_0 \\in B\\) e g \u00e8 continua in \\(y_0\\) \\(\\exists u\\) intorno di \\(x_0\\) tale che \\(x \\in u \\cap A \\backslash \\{x_0\\} \\Rightarrow f(x) \\ne y_0\\) Allora \\(\\limit {x_0} (g \\circ f)(x) = L\\) , dove L \u00e8 il limite di g Quindi \\(\\limit {x_0} (g \\circ f)(x) = \\lim_{y \\rightarrow y_0} g(y)\\) Esempio dell'uso del teorema Calcoliamo \\(\\limit \\min arctg(x^2)\\) Il limite \u00e8 una composizione: \\(f(x) = x^2\\) , \\(g(y) = arctg(y)\\) \\((g \\circ f)(x) = g(f(x)) = g(x^2) = arctg(x^2)\\) \\(x_0 = \\min\\) , \\(y_0 = \\limit {x_0} f(x) = \\limit \\min x^2 = \\pin\\) A questo punto dobbiamo rendeci conto del caso in cui ci troviamo: Il primo caso non \u00e8 verificato in quanto \\(y_0 = \\pin\\) e non appartiene al dominio di g Il secondo caso \u00e8 verificato, perch\u00e9 \\(f(x) \\ne y_0 \\Rightarrow f(x) \\ne \\pin\\) , che \u00e8 sempre vero. Procediamo quindi applicando il teorema: \\(\\lim_{y \\to y_0} g(y) = \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) Quindi \\(\\limit \\min arctg(x^2) = \\frac \\pi 2\\) Osservazione: la soluzione appena vista \u00e8 un teorema di cambiamento di variabile Riprendendo l'esempio appena visto, siamo partiti da \\(\\limit \\min arctg(x^2)\\) . Cambiamo poi variabile e poniamo \\(y=x^2\\) , tuttavia troviamo la x anche come argomento del limite (che tende a \\(\\min\\) ). Quindi se \\(x \\to \\min\\) a quanto tende y? Basta fare \\(\\limit \\min y = \\limit \\min x^2 = \\pin\\) Cambiando variabile otteniamo quindi: \\(\\limit \\min arctg(x^2) \\Rightarrow \\lim_{y \\to \\pin} arctg(y) = \\frac \\pi 2\\) La seconda ipotesi nel teorema necessaria perch\u00e9 se la composizione tra due funzioni va a toccare in modo insistente il punto limite, dato che il secondo limite non si interessa di quanto valga la funzione nel centro dell'intorno, e dato che la funzione f va solo nel centro dell'intorno \"non si pu\u00f2 accorgere di quel che sta succedendo(?)\" Uso dell'ipotesi due nel problema \\(f: \\reals \\to \\reals \\quad f(x) = 1 \\quad \\forall x \\in \\reals\\) \\(x_0 = 0\\) \\(g(x) = \\begin{cases} 3 \\text{ se } y=1 \\\\ 5 \\text{ se } y \\ne 1 \\\\ \\end{cases}\\) \\(g: \\reals \\to \\reals\\) \\((g \\circ f)(x) = g(f(x)) = g(1) = 3 \\forall x \\in \\reals\\) Quindi la funzione \\((g \\circ f)(x)\\) \u00e8 sempre 3. Il limite di una funzione costante \u00e8 quindi una costante: \\(\\limit 0 (g \\circ f)(x) = 3\\) Prendendo poi come \\(y_0 = \\limit {x_0} f(x) = \\limit 0 f(x) = 1\\) , e quindi: \\(\\limit {x_0} (g \\circ f)(x) \\ne \\lim_{y \\to y_0} g(y)\\) Per\u00f2 non vale nessuna delle due ipotesi","title":"Limite della composizione di funzioni"},{"location":"AnalisiI/limiti/#confronti-tra-infiniti","text":"Dato un limite del tipo \\(\\limit \\pin \\frac {a^x}{x^\\alpha}\\) , abbiamo: \\[\\limit \\pin \\frac {a^x}{x^\\alpha} = \\begin{cases} \\pin & \\text{ se } a > 1 0^+ & \\text{ se } 0< a < 1 \\end{cases} \\] Se \\(a=1 \\Rightarrow a^x = 1\\) , quindi \\(\\lim \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac 1 {x^\\alpha}\\) Quindi quello che domina i limite \u00e8 l'a al numeratore, ovvero l'esponenziale, che vince sulla potenza. L'unico caso in cui l'esponenziale non guida la funzione \u00e8 quando a \u00e8 pari ad 1. Esempio \\(a=\\frac 1 2 \\quad \\alpha = -3\\) \\[ \\limit \\pin \\frac {a^x}{x^\\alpha} = \\limit \\pin \\frac {(\\frac 1 2)^x} {x^{-3}} = \\limit \\pin \\frac {x^3}{2^x} = 0^+ \\] Anche in questo caso quello che domina il limite \u00e8 l'esponenziale (il \\(2^x\\) al denominatore), che \u00e8 molto pi\u00f9 veloce rispetto alla potenza","title":"Confronti tra infiniti"},{"location":"AnalisiI/limiti/#confronto-tra-logaritmo-e-potenza","text":"Quando abbiamo a che fare con un logaritmo, conviene usare il cambio di variabile e sostituirlo (come mostrato nell'esempio) Esempio: cambio di potenza del logaritmo \\(\\limit \\pin \\frac {log(x)} x\\) , quindi facciamo il cambio di variabile \\(y = log(x)\\) (e quindi \\(x = e^x\\) una volta effettuato il cambio variabile nel limite) Se \\(x \\to \\pin \\Rightarrow \\limit \\pin log(x) = \\pin\\) \\(( y = log(x) \\to \\pin)\\) \\(\\limit \\pin \\frac {log (x)} x = \\lim_{y \\to \\pin} \\frac y {e^y} = 0\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha}\\) , \\(\\alpha, \\beta \\in \\reals\\) , \\(\\alpha, \\beta > 0\\) Anche in questo caso iniziamo con il cambio di variabile \\(y = log(x) \\Rightarrow x=e^y\\) Quindi se \\(x \\to \\pin\\) (se x tende a \\(\\pin\\) ), \\(\\Rightarrow y \\to \\pin\\) (allora anche y tende a \\(\\pin\\) ) Risostituiamo inoltre x con \\(e^y\\) \\(\\limit \\pin \\frac { (log(x))^\\beta }{x^\\alpha} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^y)^\\alpha} =\\) \\(=\\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^{y \\cdot \\alpha}} = \\lim_{y \\to \\pin} \\frac {y^\\beta}{(e^\\alpha)^y} =\\) Assegnamo quindi ad \\(a = e^\\alpha\\) : \\(\\lim_{y \\to \\pin} \\frac {y^\\beta}{a^y}\\) Da qui sappiamo che \\(\\alpha > 0\\) e quindi \\(e^\\alpha > 1\\) Questo limite ha quindi come risultato 0, perch\u00e9 l'esponenziale al denominatore porta a 0 il denominatore","title":"Confronto tra logaritmo e potenza"},{"location":"AnalisiI/prerequisiti/","text":"Calcolo differenziale - funzioni Insiemi numerici \u00b6 Introduciamo il concectto di insiemi numerici; In questo caso ci limitiamo a trattarne 4: \\(\\mathbb N\\) : Numeri interi non negativi (0, 1, 2, 3, ...) \\(\\mathbb Z\\) : Numeri interi positivi e negativi (-2, -1, 0, 1, 2, ...) \\(\\mathbb Q\\) : Numeri razionali (classi di equivalenza di frazioni \\(\\frac{p}{q}\\) con \\(p,q \\in \\mathbb Z, q \\ne 0\\) ) \\(\\mathbb R\\) : Numeri reali. Razionali e \"non\" (e.g. \\(\\sqrt 2, \\pi, e\\) ) Intervalli \u00b6 Intervalli di \\(\\mathbb R\\) \\(I \\in \\mathbb R\\) si dice intervallo se \\(\\forall x,y \\in I\\) con \\(x < y\\) , dato \\(z\\) tale che \\(x < z < y\\) risulta che \\(z \\in I\\) Ovvero dati due elementi, \u00e8 possibile trovare un elemento \"in mezzo\" ai due, che a sua volta far\u00e0 parte dell'intervallo. Tipi di intervallo \u00b6 Ci possono essere diversi tipi di intervallo Aperto \u00b6 In un intervallo aperto, scritto come (a,b) , gli estremi sono esclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a < x < b \\}\\) Chiuso \u00b6 In un intervallo chiuso, scritto come (a,b) , gli estremi sono inclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a \\le x \\le b \\}\\) Semiaperto/semichiuso \u00b6 Un intervallo semiaperto o semichiuso \u00e8 un mix dei due tipi appena descritti, in cui i due estremi sono discordi: \\([a,b) = \\{ x \\in \\mathbb R | a \\le x < b \\}\\) \\((a,b] = \\{ x \\in \\mathbb R | a < x \\le b \\}\\) Semiretta \u00b6 Esiste poi un ulteriore tipo di intervallo, chiamato semiretta, che include l'infinito come uno dei due estremi. Anche questo pu\u00f2 essere sia chiuso, che aperto, e possono essere sia a destra che a sinistra. Una semiretta \u00e8 aperta o chiusa si riferisce al termine razionale: Una semiretta chiusa a destra : \\([a, + \\infty ) = \\{ x \\in \\mathbb R | a \\le x \\}\\) Una semiretta aperta a sinistra : \\((- \\infty, a) = \\{ x \\in \\mathbb R | a > x \\}\\) Con il simbolo \\((- \\infty, + \\infty)\\) si intende tutta la retta reale. Funzioni \u00b6 Una funzione \u00e8 una terna di oggetti \\((A,B,f)\\) , dove: A e B sono insiemi e, A si dice dominio, B si dice codominio ed f \u00e8 una legge che lega gli elementi di A a quelli di B. Il simbolo matematico \u00e8 \\(f: A \\rightarrow B\\) F mette in corrispondenza ogni elemento di A con uno ed un solo elemento di B. Immagine attraverso f Data una funzione \\(f: A \\rightarrow B\\) e \\(D \\subset A\\) e \\(f(D) = \\{ f(x) : x \\in D \\}\\) \\(f(D)\\) si dice immagine di D attraverso f. \\(f(D) \\subset B\\) Immagine Quando si parla invece di immagine (di f), si intende immagine di tutto il dominio, quindi: \\(Imm(f) = f(A)\\) Funzioni surgettive ed iniettive \u00b6 Vediamo quindi i concetti di surgettivit\u00e0 ed iniettivit\u00e0: Surgettivit\u00e0 \u00b6 Surgettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice surgettiva se \\(\\forall y \\in \\exists \\text{ almeno un elemento } x \\in A\\) tale che (t.c.) \\(f(x) = y\\) . Che significa che ogni elemento nel codominio \"proviene\" da un elemento del dominio (nel codominio non ci sono elementi \"scoperti\") Cambiamento del dominio per rendere una funzione surgettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 surgettiva. Questo perch\u00e9 nessun numero razionale elevato al quadrato restituir\u00e0 un valore negativo. La funzione non \u00e8 quindi surgettiva La stessa funzione ma definita come \\(g: \\mathbb R \\rightarrow [0, + \\infty )\\) \u00e8 surgettiva. Possiamo quindi dire che una funzione \u00e8 surgettiva solo se la sua immagine coincide con il codominio. Per capire velocemente da un grafico se una funzione \u00e8 surgettiva, possiamo pensare di tracciare una linea orizzontale, se non intercetta almeno una volta la funzione, questa non \u00e8 surgettiva: La funzione NON \u00e8 surgettiva poich\u00e9 la retta orizzontale blu ( \\(y=2\\) ) non intercetta mai la funzione ( \\(y=|x|\\) ) Iniettivit\u00e0 \u00b6 Iniettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice iniettiva se \\(\\forall x_1,x_2 \\in A \\text{ con } x_1 \\ne x_2 \\text{ risulta che } f(x_1) \\ne f(x_2)\\) La funzione \u00e8 monotona (cresce o decresce e basta; Non si \"appiattisce) Se una funzione non \u00e8 iniettiva, ci possono comunque essere dei \"trucchi\" che ci consentono di farla diventare iniettiva, ad esempio scartando parte del dominio. Cambiamento del dominio per rendere una funzione iniettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 iniettiva. La stessa funzione ma definita come \\(g: [0, + \\infty ) \\rightarrow \\mathbb R\\) \u00e8 iniettiva. Per capire velocemente da un grafico se una funzione \u00e8 iniettiva, possiamo pensare di tracciare una linea orizzontale, se questa intercetta pi\u00f9 di una volta la funzione, questa non \u00e8 iniettiva: La funzione NON \u00e8 iniettiva poich\u00e9 la retta orizzontale blu ( \\(y=5\\) ) intercetta pi\u00f9 volte la funzione ( \\(y=x\\cdot |sin(x)|\\) ) Funzione bigettiva \u00b6 Funzione bigettiva una funzione \\(f\\) si dice bigettiva/biunivoca/invertibile se \u00e8 sia iniettiva che surgettiva Se una funzione \u00e8 bigettiva posso costruire la funzione inversa \\(f^{-1}: B \\rightarrow A\\) . Datp un elemento \\(b \\in B\\) esiste un elemento \\(a \\in A\\) tale che \\(f(a) = b\\) (perch\u00e9 f \u00e8 surgettiva). L'elemento a \u00e8 unico perch\u00e9 f \u00e8 iniettiva quindi \\(f^{-1}(b)=a \\Leftrightarrow f(a) = b\\) La radice quadrata \u00e8 la funzione inversa di f(x) = x^2 qunado dominio e codominio sono entrambi [0,+ \\infty) Che \u00e8 come mai \\sqrt 2 = 2 (che \u00e8 diverso da dire che x^2 =4, che ha due soluzioni) Per questo motivo \\sqrt {x^2} = |x| Propriet\u00e0 dai grafici \u00b6 Tralaslazione \u00b6 Possiamo traslare le funzioni sul grafico in ogni modo vogliamo: Prendendo una funzione come \\((\\frac{1}{2}x)^2\\) : Possiamo effettuare ogni traslazione desiderata: Traslazione verso l'alto : Abbiamo una traslazione verso l'alto quando al valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) + n \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x)^2+5\\) ) Traslazione verso il basso : Abbiamo una traslazione verso il basso quando al valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) - n \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x)^2-5\\) ) Traslazione verso sinistra : Abbiamo una traslazione verso sinistra quando all'argomento/valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x+n) \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x+5)^2\\) ) Traslazione verso destra : Abbiamo una traslazione verso destra quando all'argomento/valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x-n) \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x-5)^2\\) ) Valore assoluto \u00b6 Il valore assoluto coincide con la funzione \\(f\\) dove \\(f\\) \u00e8 positiva ed \u00e8 l'opposto dove \\(f\\) \u00e8 negativa: \\[ |f(x)| = \\begin{equation} \\begin{cases} f(x) \\text{ quando } x \\ge 0 \\\\ -f(x) \\text{ altrimenti} \\end{cases}\\,. \\end{equation} \\] Specchiamento \u00b6 \u00c8 possibile specchiare una funzione sia rispetto all'ascisse (sempre) che rispetto all'ordinata (quando il dominio \u00e8 simmetrico rispetto all'origine). Specchiamento Rispetto all'ascisse Rispetto all'ordinata Grafico Funzione \\(-f(x)\\) \\(f(-x)\\) Esempio nel grafico \\(y=-((0.5 \\cdot x+2)^2+2)\\) \\(y=(0.5 \\cdot -x+2)^2+2\\) Notare che nello specchiamento rispetto all'ordinata, il dominio deve essere simmetrico rispetto all'origine, e quindi permettere lo specchiamento. Funzioni invertibili \u00b6 Se f \u00e8 una funzione invertibile, i grafici di \\(f\\) e \\(f^{-1}\\) sono simmetrici rispetto alla retta \\(y=x\\) In questo esempio, possiamo vedere come la funzione blu ( \\(x^2\\) ) e la funzione verde ( \\(\\sqrt{2}\\) ) sono simmetriche rispetto alla retta gialla ( \\(y=x\\) ) Se il punto (2,4) appartiene al grafico di f, allora il punto (4,2) appartiene al grafico di g Funzioni m\u00f2n\u00f3t\u00f2ne \u00b6 La monotonia \u00e8 una propriet\u00e0 che riguarda strettamente la crescenza o la decrescenza delle funzioni Funzione monotona Dati \\(A, B \\subset \\mathbb R \\text{ e } x_1,x_2 \\in A \\text{ con } x_1 < x_2\\) Se \\(\\forall x_1,x_2\\) risulta che: \\(f(x_1) < f(f_2)\\) : f si dice strettamente crescente \\(f(x_1) \\le f(f_2)\\) : f si dice debolmente crescente \\(f(x_1) > f(f_2)\\) : f si dice strettamente decrescente \\(f(x_1) \\ge f(f_2)\\) : f si dice debolmente decrescente Se si verificano il caso 1 o 3, f si dice strettamente m\u00f2n\u00f3t\u00f2na Se si verificano il caso 2 o 4, f si dice debolmente m\u00f2n\u00f3t\u00f2na Una funzione (debolmente) crescente quindi, aumenter\u00e0 sempre di valore (o comunque non diminuir\u00e0) man mano che \\(x\\) cresce. Per essere strettamente crescente, la funzione non deve avere mai due soluzioni uguali in due punti diversi. Per una funzione decrescente, vale lo stesso discorso, ma \\(x\\) diminuir\u00e0 sempre di valore invece di crescere. Se una funzione ha un tratto \"orizzontale\", quella funzione non sar\u00e0 strettamente monotona. Se una funzione \u00e8 strettamente crescente/decrescente, lo sar\u00e0 anche debolmente. Rapporto incrementale \\(f\\) \u00e8 strettamente crescente se e solo se \\(\\frac{f(x_1) - f(x_2)}{x_1 - x_2} > 0\\) (questo \u00e8 il rapporto incrementale, \\(\\frac{\\Delta X}{\\Delta Y}\\) , che misura quanto \\(f\\) si \u00e8 spostata in rapporto a quanto \u00e8 stata spostata l'ascissa in orizzontale). Ovviamente con \\(x_1 \\neq x_2\\) . Dire che una funzione \u00e8 crescente significa dire che i rapporti incrementali sono positivi, e quindi che sia numeratore che denominatore sono concordi in segno. (Per lo \"strettamente\", occorre che il \\(\\Delta Y\\) sia diverso da 0). L'opposto vale per essere decrescente. Quando abbiamo una funzione come \\(\\frac 1 x\\) , come definiamo la funzione? Nel caso della funzione \\(\\frac 1 x\\) (un ramo di iperbole), in alcuni punti della funzione le coppie \\(x_1\\) , \\(x_2\\) mantengono l'ordinamento (ad esempio con \\(x_2 = 10\\) e \\(x_1 = 5\\) , \\(f(x_1)>f(x_2)\\) ), facendo risultare la funzione decrescente; in altre lo invertono (ad esempio per \\(x_2 = 20\\) e \\(x_1 = -20\\) , avendo quindi \\(f(x_1) < f(x_2)\\) ). Questo significa che questa funzione non \u00e8 globalmente monotona, ma \u00e8 decrescente su due intervalli: \\(f\\) \u00e8 decrescente \\((- \\infty, 0)\\) e in \\((0, \\infty)\\) , ma non in tutto il suo dominio ( \\(\\mathbb R \\backslash \\{0\\}\\) ). Composizione di funzioni monotone \u00b6 Proposizione Avendo: \\(A,B,C \\subset \\mathbb R\\) \\(f: A \\rightarrow B\\) \\(g: B \\rightarrow C\\) Allora: Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e \\(g\\) \u00e8 crescente \\(\\nearrow\\) , allora \\(g \\circ f\\) (g composto f) \u00e8 crescente \\(\\nearrow\\) Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e g \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 decrescente \\(\\searrow\\) (e viceversa) Se \\(f\\) \u00e8 decrescente \\(\\searrow\\) e \\(g\\) \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 crescente \\(\\nearrow\\) Quindi: \\(\\nearrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\nearrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) Insieme di definizione L'insieme di definizione (o dominio naturale) di una funzione \u00e8 il pi\u00f9 grande sottoinsieme di \\(\\mathbb R\\) dove ha senso scrivere la funzione Ad esempio nel caso di \\(\\frac 1 x\\) il dominio di definizione \u00e8 \\(\\mathbb \\backslash \\{0\\}\\) Funzione pari e dispari Se \\(f(x) = f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice pari. Se \\(f(x) = -f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice dispari. Questa definizione implica che il dominio di f sia tale che se x appartiene al dominio, allora anche -x appartiene al dominio (\u00e8 simmetrico rispetto allo 0). Funzione periodica \\(f\\) si dice periodica di periodo \\(p\\) con \\(p \\in \\mathbb R\\) se \\(\\forall x, f(x+p) = f(x)\\) Un esempio di una funzione periodica sono le funzioni trigonometriche (seno, coseno, tangente, etc...) Funzioni elementari \u00b6 Retta \u00b6 La retta \u00e8 scritta nella forma \\(f(x) = a \\cdot x + b \\text { con } a,b \\in \\mathbb R\\) a \u00e8 chiamato coefficiente angolare, b \u00e8 chiamato termine noto. Funzione potenza \u00b6 In N \u00b6 \\(f(x) = x^k, k \\in \\mathbb N\\) k pari, grafici sono una parabola (con la sola velocit\u00e0 di crescita che cambia). k dispari, grafici sono una \\(f\\) \u00e8 una funzine pari se \\(k\\) \u00e8 pari ed \u00e8 dispari se \\(k\\) \u00e8 dispari. (questo perch\u00e9 \\(-1^2 = 1\\) e \\(-1^3 = -1\\) ). In Z con k negativo \u00b6 \\(f(x) = x^k \\ k\\in \\mathbb Z; k < 0\\) k dispari iperbole equilatera (primo e terzo quadrante) k pari iperbole (primo e secondo quadrante) anche qui la funzione \u00e8 pari per k pari e dispari per k dispari In R \u00b6 \\(f(x) = x^\\frac p q ; p,q \\in \\mathbb N \\ q \\ne 0\\) La funzione f ha come dominio naturale Quando abbiamo \\(p = 1\\) (quindi \\(x^\\frac 1 q = sqrt[q]{x}\\) , inversa della funzione \\(x^q\\) ) Se q \u00e8 pari, il dominio \u00e8 \\(x \\ge 0\\) (possiamo fare la radice quadrata solo di un positivi), quindi \u00e8 invertibile solo come funzione da [0,+inf] -> [0, +inf] Se q \u00e8 dispari, il dominio \u00e8 \\(\\mathbb R\\) (possiamo fare la radice cubica di un negativo). x^3 \u00e8 una funzione invertibile su tutto R In R e non in Q (irrazionale) \u00b6 \\(f(x) = x^\\alpha, \\alpha \\in \\mathbb R \\ e \\ \\alpha \\notin \\mathbb Q\\) (quindi ad esempio \\(x^{\\sqrt 2}\\) oppure \\(x^\\pi\\) ) \\(x^\\alpha = e^{\\alpha \\cdot log(x)} \\ \\text{ definita per } x>0\\) Questo perch\u00e9: \\(e^{\\alpha log (x)} = (e^{log(x)})^\\alpha = x^\\alpha\\) Per definizione dobbiamo passare attraverso il logaritmo. Il dominio naturale \u00e8 \\((0, +\\infty)\\) Esponenziale \u00b6 con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione esponenziale \u00e8 \\(f(x) = a^x\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente In entrambi i casi la funzione intercetta il punto 1 delle ordinate e sono sempre positive: \\[ a^x > 0 \\forall x \\in \\mathbb R \\] Entrambi le funzioni sono invertibili, poich\u00e9 stettamente crescenti o decrescenti, quindi monotone, quindi iniettive e surgettive. Logaritmo in base a \u00b6 con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione logaritmica \u00e8 \\(f(x) = log_a(x)\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente Intercetta l'ascissa sempre ad 1 e presenta una simmetria (\u00e8 specchiata) rispetto alla bisettrice (y=x) del grafico dell'esponenziale Funzione esponenziale (in base e) \u00b6 Funzione esponenziale con \\(a = e \\cong 2,71\\) \u00e8 invertibile e la sua inversa si chiama logaritmo naturale. (Se la base non \u00e8 specificata, in matematica si intende in base e). Cambio di base del logaritmo \u00b6 Possiamo facilmente effettuare un cambio della base del logaritmo facendo uso di alcune regole matematiche: Il logaritmo \u00e8 la potenza che dobbiamo assegnare ad a per ottenere x: \\(log_a (x) = y \\Leftrightarrow a^y = x\\) Il logaritmo naturale dell'equazione dell'identit\u00e0 \u00e8: \\(log(a^y) = log(x) \\Leftrightarrow y \\cdot log(a) = log(x)\\) , ed abbiamo gi\u00e0 visto y: \\(y = log_a (x)\\) Quindi possiamo sostituire y, per poi semplificarla: \\(log_a (x) \\cdot log (a) = log(x) \\Rightarrow log_a (x) = \\frac{log(x)}{log(a)}\\) Funzioni trigonometriche \u00b6 Seno \u00b6 Il seno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) \\(f(x)=sin \\ x \\qquad f: \\mathbb R \\rightarrow [-1, 1]\\) perch\u00e9 \\(-1 \\le sin(x) \\le 1\\) . La funzione \u00e8 surgettiba se per codominio prendiamo \\([-1, 1]\\) Essendo periodica, \\(sin(x+2 \\pi) = sin(x) \\quad \\forall x \\in \\mathbb R\\) . Essendo il seno sull'asse delle orinate, il cerchio con angolo 0 ha valore 0 sulle ordinate, quindi \\(sin(0) = 0\\) . La funzione \u00e8 invertibile modificando dominio e codominio (quando la funzione \u00e8 definita come \\(f: [ -\\frac \\pi 2 , \\frac \\pi 2 ] \\rightarrow [-1, 1]\\) . f risulta quindi strettamente crescente (quindi monotona, quindi essendo continua, iniettiva) e surgettiva.) Dispari Arcoseno \u00b6 Funzione inversa del seno, definita come \\(f: [-1, 1] \\rightarrow [ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) La funzione arcsin \u00e8 quindi l'inversa del seno quando il dominio \u00e8 \\([ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) ed il codominio \u00e8 \\([-1, 1]\\) Se cos\u00ec non fosse la funzione seno non \u00e8 n\u00e9 iniettiva n\u00e9 surgettiva, e quindi non \u00e8 invertibile. Coseno \u00b6 Il coseno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) La funzione \u00e8 il seno, ma traslata di \\(\\frac \\pi 2\\) (quindi \\(cos(0) = 1\\) ) Pari Arcocoseno \u00b6 Se vogliamo invertire dobbiamo scegliere un intervallo dove la funzione \u00e8 monotona. Possiamo quindi definire il dominio naturle come \\(cos(x): [0, \\pi] \\rightarrow [-1, 1]\\) . Tangente \u00b6 \\(tg (x) = \\frac {sin(x)} {cos(x)}\\) , che quindi non \u00e8 definita se \\(cos(x) = 0\\) . Il dominio \u00e8 quindi \\(\\{ x \\in \\mathbb R: x \\ne \\frac \\pi 2 + k \\cdot \\pi, k \\in \\mathbb Z \\}\\) , composto da infiniti intervalli disgiunti. \u00c8 periodica di periodo \\(\\pi\\) \u00c8 invertibile quando \\(f: (-\\frac \\pi 2 , \\frac \\pi 2 ) \\rightarrow \\mathbb R\\) \u00c8 inoltre dispari Arcotangente \u00b6 \u00c8 l'inversa della tangente \\(arctan: \\mathbb \\rightarrow (-\\frac \\pi 2 , \\frac \\pi 2 )\\) Strettamente crescente nel suo dominio. (Da non invertire con la cotangente)","title":"Funzioni ed introduzione"},{"location":"AnalisiI/prerequisiti/#insiemi-numerici","text":"Introduciamo il concectto di insiemi numerici; In questo caso ci limitiamo a trattarne 4: \\(\\mathbb N\\) : Numeri interi non negativi (0, 1, 2, 3, ...) \\(\\mathbb Z\\) : Numeri interi positivi e negativi (-2, -1, 0, 1, 2, ...) \\(\\mathbb Q\\) : Numeri razionali (classi di equivalenza di frazioni \\(\\frac{p}{q}\\) con \\(p,q \\in \\mathbb Z, q \\ne 0\\) ) \\(\\mathbb R\\) : Numeri reali. Razionali e \"non\" (e.g. \\(\\sqrt 2, \\pi, e\\) )","title":"Insiemi numerici"},{"location":"AnalisiI/prerequisiti/#intervalli","text":"Intervalli di \\(\\mathbb R\\) \\(I \\in \\mathbb R\\) si dice intervallo se \\(\\forall x,y \\in I\\) con \\(x < y\\) , dato \\(z\\) tale che \\(x < z < y\\) risulta che \\(z \\in I\\) Ovvero dati due elementi, \u00e8 possibile trovare un elemento \"in mezzo\" ai due, che a sua volta far\u00e0 parte dell'intervallo.","title":"Intervalli"},{"location":"AnalisiI/prerequisiti/#tipi-di-intervallo","text":"Ci possono essere diversi tipi di intervallo","title":"Tipi di intervallo"},{"location":"AnalisiI/prerequisiti/#aperto","text":"In un intervallo aperto, scritto come (a,b) , gli estremi sono esclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a < x < b \\}\\)","title":"Aperto"},{"location":"AnalisiI/prerequisiti/#chiuso","text":"In un intervallo chiuso, scritto come (a,b) , gli estremi sono inclusi, quindi: \\(I = \\{ x \\in \\mathbb R | a \\le x \\le b \\}\\)","title":"Chiuso"},{"location":"AnalisiI/prerequisiti/#semiapertosemichiuso","text":"Un intervallo semiaperto o semichiuso \u00e8 un mix dei due tipi appena descritti, in cui i due estremi sono discordi: \\([a,b) = \\{ x \\in \\mathbb R | a \\le x < b \\}\\) \\((a,b] = \\{ x \\in \\mathbb R | a < x \\le b \\}\\)","title":"Semiaperto/semichiuso"},{"location":"AnalisiI/prerequisiti/#semiretta","text":"Esiste poi un ulteriore tipo di intervallo, chiamato semiretta, che include l'infinito come uno dei due estremi. Anche questo pu\u00f2 essere sia chiuso, che aperto, e possono essere sia a destra che a sinistra. Una semiretta \u00e8 aperta o chiusa si riferisce al termine razionale: Una semiretta chiusa a destra : \\([a, + \\infty ) = \\{ x \\in \\mathbb R | a \\le x \\}\\) Una semiretta aperta a sinistra : \\((- \\infty, a) = \\{ x \\in \\mathbb R | a > x \\}\\) Con il simbolo \\((- \\infty, + \\infty)\\) si intende tutta la retta reale.","title":"Semiretta"},{"location":"AnalisiI/prerequisiti/#funzioni","text":"Una funzione \u00e8 una terna di oggetti \\((A,B,f)\\) , dove: A e B sono insiemi e, A si dice dominio, B si dice codominio ed f \u00e8 una legge che lega gli elementi di A a quelli di B. Il simbolo matematico \u00e8 \\(f: A \\rightarrow B\\) F mette in corrispondenza ogni elemento di A con uno ed un solo elemento di B. Immagine attraverso f Data una funzione \\(f: A \\rightarrow B\\) e \\(D \\subset A\\) e \\(f(D) = \\{ f(x) : x \\in D \\}\\) \\(f(D)\\) si dice immagine di D attraverso f. \\(f(D) \\subset B\\) Immagine Quando si parla invece di immagine (di f), si intende immagine di tutto il dominio, quindi: \\(Imm(f) = f(A)\\)","title":"Funzioni"},{"location":"AnalisiI/prerequisiti/#funzioni-surgettive-ed-iniettive","text":"Vediamo quindi i concetti di surgettivit\u00e0 ed iniettivit\u00e0:","title":"Funzioni surgettive ed iniettive"},{"location":"AnalisiI/prerequisiti/#surgettivita","text":"Surgettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice surgettiva se \\(\\forall y \\in \\exists \\text{ almeno un elemento } x \\in A\\) tale che (t.c.) \\(f(x) = y\\) . Che significa che ogni elemento nel codominio \"proviene\" da un elemento del dominio (nel codominio non ci sono elementi \"scoperti\") Cambiamento del dominio per rendere una funzione surgettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 surgettiva. Questo perch\u00e9 nessun numero razionale elevato al quadrato restituir\u00e0 un valore negativo. La funzione non \u00e8 quindi surgettiva La stessa funzione ma definita come \\(g: \\mathbb R \\rightarrow [0, + \\infty )\\) \u00e8 surgettiva. Possiamo quindi dire che una funzione \u00e8 surgettiva solo se la sua immagine coincide con il codominio. Per capire velocemente da un grafico se una funzione \u00e8 surgettiva, possiamo pensare di tracciare una linea orizzontale, se non intercetta almeno una volta la funzione, questa non \u00e8 surgettiva: La funzione NON \u00e8 surgettiva poich\u00e9 la retta orizzontale blu ( \\(y=2\\) ) non intercetta mai la funzione ( \\(y=|x|\\) )","title":"Surgettivit\u00e0"},{"location":"AnalisiI/prerequisiti/#iniettivita","text":"Iniettivit\u00e0 Una funzione \\(f: A \\rightarrow B\\) si dice iniettiva se \\(\\forall x_1,x_2 \\in A \\text{ con } x_1 \\ne x_2 \\text{ risulta che } f(x_1) \\ne f(x_2)\\) La funzione \u00e8 monotona (cresce o decresce e basta; Non si \"appiattisce) Se una funzione non \u00e8 iniettiva, ci possono comunque essere dei \"trucchi\" che ci consentono di farla diventare iniettiva, ad esempio scartando parte del dominio. Cambiamento del dominio per rendere una funzione iniettiva La funzione \\(g: \\mathbb R \\rightarrow \\mathbb R\\) , \\(g(x) = x^2\\) non \u00e8 iniettiva. La stessa funzione ma definita come \\(g: [0, + \\infty ) \\rightarrow \\mathbb R\\) \u00e8 iniettiva. Per capire velocemente da un grafico se una funzione \u00e8 iniettiva, possiamo pensare di tracciare una linea orizzontale, se questa intercetta pi\u00f9 di una volta la funzione, questa non \u00e8 iniettiva: La funzione NON \u00e8 iniettiva poich\u00e9 la retta orizzontale blu ( \\(y=5\\) ) intercetta pi\u00f9 volte la funzione ( \\(y=x\\cdot |sin(x)|\\) )","title":"Iniettivit\u00e0"},{"location":"AnalisiI/prerequisiti/#funzione-bigettiva","text":"Funzione bigettiva una funzione \\(f\\) si dice bigettiva/biunivoca/invertibile se \u00e8 sia iniettiva che surgettiva Se una funzione \u00e8 bigettiva posso costruire la funzione inversa \\(f^{-1}: B \\rightarrow A\\) . Datp un elemento \\(b \\in B\\) esiste un elemento \\(a \\in A\\) tale che \\(f(a) = b\\) (perch\u00e9 f \u00e8 surgettiva). L'elemento a \u00e8 unico perch\u00e9 f \u00e8 iniettiva quindi \\(f^{-1}(b)=a \\Leftrightarrow f(a) = b\\) La radice quadrata \u00e8 la funzione inversa di f(x) = x^2 qunado dominio e codominio sono entrambi [0,+ \\infty) Che \u00e8 come mai \\sqrt 2 = 2 (che \u00e8 diverso da dire che x^2 =4, che ha due soluzioni) Per questo motivo \\sqrt {x^2} = |x|","title":"Funzione bigettiva"},{"location":"AnalisiI/prerequisiti/#proprieta-dai-grafici","text":"","title":"Propriet\u00e0 dai grafici"},{"location":"AnalisiI/prerequisiti/#tralaslazione","text":"Possiamo traslare le funzioni sul grafico in ogni modo vogliamo: Prendendo una funzione come \\((\\frac{1}{2}x)^2\\) : Possiamo effettuare ogni traslazione desiderata: Traslazione verso l'alto : Abbiamo una traslazione verso l'alto quando al valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) + n \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x)^2+5\\) ) Traslazione verso il basso : Abbiamo una traslazione verso il basso quando al valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x) - n \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x)^2-5\\) ) Traslazione verso sinistra : Abbiamo una traslazione verso sinistra quando all'argomento/valore della funzione aggiungiamo un valore \\(n\\) . Abbiamo quindi \\(f(x+n) \\text{ con } n > 0\\) (in questo caso \\((\\frac{1}{2}x+5)^2\\) ) Traslazione verso destra : Abbiamo una traslazione verso destra quando all'argomento/valore della funzione sottraiamo un valore \\(n\\) . Abbiamo quindi \\(f(x-n) \\text{ con } n < 0\\) (in questo caso \\((\\frac{1}{2}x-5)^2\\) )","title":"Tralaslazione"},{"location":"AnalisiI/prerequisiti/#valore-assoluto","text":"Il valore assoluto coincide con la funzione \\(f\\) dove \\(f\\) \u00e8 positiva ed \u00e8 l'opposto dove \\(f\\) \u00e8 negativa: \\[ |f(x)| = \\begin{equation} \\begin{cases} f(x) \\text{ quando } x \\ge 0 \\\\ -f(x) \\text{ altrimenti} \\end{cases}\\,. \\end{equation} \\]","title":"Valore assoluto"},{"location":"AnalisiI/prerequisiti/#specchiamento","text":"\u00c8 possibile specchiare una funzione sia rispetto all'ascisse (sempre) che rispetto all'ordinata (quando il dominio \u00e8 simmetrico rispetto all'origine). Specchiamento Rispetto all'ascisse Rispetto all'ordinata Grafico Funzione \\(-f(x)\\) \\(f(-x)\\) Esempio nel grafico \\(y=-((0.5 \\cdot x+2)^2+2)\\) \\(y=(0.5 \\cdot -x+2)^2+2\\) Notare che nello specchiamento rispetto all'ordinata, il dominio deve essere simmetrico rispetto all'origine, e quindi permettere lo specchiamento.","title":"Specchiamento"},{"location":"AnalisiI/prerequisiti/#funzioni-invertibili","text":"Se f \u00e8 una funzione invertibile, i grafici di \\(f\\) e \\(f^{-1}\\) sono simmetrici rispetto alla retta \\(y=x\\) In questo esempio, possiamo vedere come la funzione blu ( \\(x^2\\) ) e la funzione verde ( \\(\\sqrt{2}\\) ) sono simmetriche rispetto alla retta gialla ( \\(y=x\\) ) Se il punto (2,4) appartiene al grafico di f, allora il punto (4,2) appartiene al grafico di g","title":"Funzioni invertibili"},{"location":"AnalisiI/prerequisiti/#funzioni-monotone","text":"La monotonia \u00e8 una propriet\u00e0 che riguarda strettamente la crescenza o la decrescenza delle funzioni Funzione monotona Dati \\(A, B \\subset \\mathbb R \\text{ e } x_1,x_2 \\in A \\text{ con } x_1 < x_2\\) Se \\(\\forall x_1,x_2\\) risulta che: \\(f(x_1) < f(f_2)\\) : f si dice strettamente crescente \\(f(x_1) \\le f(f_2)\\) : f si dice debolmente crescente \\(f(x_1) > f(f_2)\\) : f si dice strettamente decrescente \\(f(x_1) \\ge f(f_2)\\) : f si dice debolmente decrescente Se si verificano il caso 1 o 3, f si dice strettamente m\u00f2n\u00f3t\u00f2na Se si verificano il caso 2 o 4, f si dice debolmente m\u00f2n\u00f3t\u00f2na Una funzione (debolmente) crescente quindi, aumenter\u00e0 sempre di valore (o comunque non diminuir\u00e0) man mano che \\(x\\) cresce. Per essere strettamente crescente, la funzione non deve avere mai due soluzioni uguali in due punti diversi. Per una funzione decrescente, vale lo stesso discorso, ma \\(x\\) diminuir\u00e0 sempre di valore invece di crescere. Se una funzione ha un tratto \"orizzontale\", quella funzione non sar\u00e0 strettamente monotona. Se una funzione \u00e8 strettamente crescente/decrescente, lo sar\u00e0 anche debolmente. Rapporto incrementale \\(f\\) \u00e8 strettamente crescente se e solo se \\(\\frac{f(x_1) - f(x_2)}{x_1 - x_2} > 0\\) (questo \u00e8 il rapporto incrementale, \\(\\frac{\\Delta X}{\\Delta Y}\\) , che misura quanto \\(f\\) si \u00e8 spostata in rapporto a quanto \u00e8 stata spostata l'ascissa in orizzontale). Ovviamente con \\(x_1 \\neq x_2\\) . Dire che una funzione \u00e8 crescente significa dire che i rapporti incrementali sono positivi, e quindi che sia numeratore che denominatore sono concordi in segno. (Per lo \"strettamente\", occorre che il \\(\\Delta Y\\) sia diverso da 0). L'opposto vale per essere decrescente. Quando abbiamo una funzione come \\(\\frac 1 x\\) , come definiamo la funzione? Nel caso della funzione \\(\\frac 1 x\\) (un ramo di iperbole), in alcuni punti della funzione le coppie \\(x_1\\) , \\(x_2\\) mantengono l'ordinamento (ad esempio con \\(x_2 = 10\\) e \\(x_1 = 5\\) , \\(f(x_1)>f(x_2)\\) ), facendo risultare la funzione decrescente; in altre lo invertono (ad esempio per \\(x_2 = 20\\) e \\(x_1 = -20\\) , avendo quindi \\(f(x_1) < f(x_2)\\) ). Questo significa che questa funzione non \u00e8 globalmente monotona, ma \u00e8 decrescente su due intervalli: \\(f\\) \u00e8 decrescente \\((- \\infty, 0)\\) e in \\((0, \\infty)\\) , ma non in tutto il suo dominio ( \\(\\mathbb R \\backslash \\{0\\}\\) ).","title":"Funzioni m\u00f2n\u00f3t\u00f2ne"},{"location":"AnalisiI/prerequisiti/#composizione-di-funzioni-monotone","text":"Proposizione Avendo: \\(A,B,C \\subset \\mathbb R\\) \\(f: A \\rightarrow B\\) \\(g: B \\rightarrow C\\) Allora: Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e \\(g\\) \u00e8 crescente \\(\\nearrow\\) , allora \\(g \\circ f\\) (g composto f) \u00e8 crescente \\(\\nearrow\\) Se \\(f\\) \u00e8 crescente \\(\\nearrow\\) e g \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 decrescente \\(\\searrow\\) (e viceversa) Se \\(f\\) \u00e8 decrescente \\(\\searrow\\) e \\(g\\) \u00e8 decrescente \\(\\searrow\\) , allora \\(g \\circ f\\) \u00e8 crescente \\(\\nearrow\\) Quindi: \\(\\nearrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\nearrow \\circ \\searrow \\ \\Rightarrow \\nearrow\\) \\(\\searrow \\circ \\nearrow \\ \\Rightarrow \\nearrow\\) Insieme di definizione L'insieme di definizione (o dominio naturale) di una funzione \u00e8 il pi\u00f9 grande sottoinsieme di \\(\\mathbb R\\) dove ha senso scrivere la funzione Ad esempio nel caso di \\(\\frac 1 x\\) il dominio di definizione \u00e8 \\(\\mathbb \\backslash \\{0\\}\\) Funzione pari e dispari Se \\(f(x) = f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice pari. Se \\(f(x) = -f(-x) \\forall x\\) nel dominio di \\(f\\) , allora f si dice dispari. Questa definizione implica che il dominio di f sia tale che se x appartiene al dominio, allora anche -x appartiene al dominio (\u00e8 simmetrico rispetto allo 0). Funzione periodica \\(f\\) si dice periodica di periodo \\(p\\) con \\(p \\in \\mathbb R\\) se \\(\\forall x, f(x+p) = f(x)\\) Un esempio di una funzione periodica sono le funzioni trigonometriche (seno, coseno, tangente, etc...)","title":"Composizione di funzioni monotone"},{"location":"AnalisiI/prerequisiti/#funzioni-elementari","text":"","title":"Funzioni elementari"},{"location":"AnalisiI/prerequisiti/#retta","text":"La retta \u00e8 scritta nella forma \\(f(x) = a \\cdot x + b \\text { con } a,b \\in \\mathbb R\\) a \u00e8 chiamato coefficiente angolare, b \u00e8 chiamato termine noto.","title":"Retta"},{"location":"AnalisiI/prerequisiti/#funzione-potenza","text":"","title":"Funzione potenza"},{"location":"AnalisiI/prerequisiti/#in-n","text":"\\(f(x) = x^k, k \\in \\mathbb N\\) k pari, grafici sono una parabola (con la sola velocit\u00e0 di crescita che cambia). k dispari, grafici sono una \\(f\\) \u00e8 una funzine pari se \\(k\\) \u00e8 pari ed \u00e8 dispari se \\(k\\) \u00e8 dispari. (questo perch\u00e9 \\(-1^2 = 1\\) e \\(-1^3 = -1\\) ).","title":"In N"},{"location":"AnalisiI/prerequisiti/#in-z-con-k-negativo","text":"\\(f(x) = x^k \\ k\\in \\mathbb Z; k < 0\\) k dispari iperbole equilatera (primo e terzo quadrante) k pari iperbole (primo e secondo quadrante) anche qui la funzione \u00e8 pari per k pari e dispari per k dispari","title":"In Z con k negativo"},{"location":"AnalisiI/prerequisiti/#in-r","text":"\\(f(x) = x^\\frac p q ; p,q \\in \\mathbb N \\ q \\ne 0\\) La funzione f ha come dominio naturale Quando abbiamo \\(p = 1\\) (quindi \\(x^\\frac 1 q = sqrt[q]{x}\\) , inversa della funzione \\(x^q\\) ) Se q \u00e8 pari, il dominio \u00e8 \\(x \\ge 0\\) (possiamo fare la radice quadrata solo di un positivi), quindi \u00e8 invertibile solo come funzione da [0,+inf] -> [0, +inf] Se q \u00e8 dispari, il dominio \u00e8 \\(\\mathbb R\\) (possiamo fare la radice cubica di un negativo). x^3 \u00e8 una funzione invertibile su tutto R","title":"In R"},{"location":"AnalisiI/prerequisiti/#in-r-e-non-in-q-irrazionale","text":"\\(f(x) = x^\\alpha, \\alpha \\in \\mathbb R \\ e \\ \\alpha \\notin \\mathbb Q\\) (quindi ad esempio \\(x^{\\sqrt 2}\\) oppure \\(x^\\pi\\) ) \\(x^\\alpha = e^{\\alpha \\cdot log(x)} \\ \\text{ definita per } x>0\\) Questo perch\u00e9: \\(e^{\\alpha log (x)} = (e^{log(x)})^\\alpha = x^\\alpha\\) Per definizione dobbiamo passare attraverso il logaritmo. Il dominio naturale \u00e8 \\((0, +\\infty)\\)","title":"In R e non in Q (irrazionale)"},{"location":"AnalisiI/prerequisiti/#esponenziale","text":"con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione esponenziale \u00e8 \\(f(x) = a^x\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente In entrambi i casi la funzione intercetta il punto 1 delle ordinate e sono sempre positive: \\[ a^x > 0 \\forall x \\in \\mathbb R \\] Entrambi le funzioni sono invertibili, poich\u00e9 stettamente crescenti o decrescenti, quindi monotone, quindi iniettive e surgettive.","title":"Esponenziale"},{"location":"AnalisiI/prerequisiti/#logaritmo-in-base-a","text":"con \\(a \\in \\mathbb R, a >0, a \\ne 1\\) la funzione logaritmica \u00e8 \\(f(x) = log_a(x)\\) a > 1 0 < a < 1 Strettamente crescente Strettamente decrescente Intercetta l'ascissa sempre ad 1 e presenta una simmetria (\u00e8 specchiata) rispetto alla bisettrice (y=x) del grafico dell'esponenziale","title":"Logaritmo in base a"},{"location":"AnalisiI/prerequisiti/#funzione-esponenziale-in-base-e","text":"Funzione esponenziale con \\(a = e \\cong 2,71\\) \u00e8 invertibile e la sua inversa si chiama logaritmo naturale. (Se la base non \u00e8 specificata, in matematica si intende in base e).","title":"Funzione esponenziale (in base e)"},{"location":"AnalisiI/prerequisiti/#cambio-di-base-del-logaritmo","text":"Possiamo facilmente effettuare un cambio della base del logaritmo facendo uso di alcune regole matematiche: Il logaritmo \u00e8 la potenza che dobbiamo assegnare ad a per ottenere x: \\(log_a (x) = y \\Leftrightarrow a^y = x\\) Il logaritmo naturale dell'equazione dell'identit\u00e0 \u00e8: \\(log(a^y) = log(x) \\Leftrightarrow y \\cdot log(a) = log(x)\\) , ed abbiamo gi\u00e0 visto y: \\(y = log_a (x)\\) Quindi possiamo sostituire y, per poi semplificarla: \\(log_a (x) \\cdot log (a) = log(x) \\Rightarrow log_a (x) = \\frac{log(x)}{log(a)}\\)","title":"Cambio di base del logaritmo"},{"location":"AnalisiI/prerequisiti/#funzioni-trigonometriche","text":"","title":"Funzioni trigonometriche"},{"location":"AnalisiI/prerequisiti/#seno","text":"Il seno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) \\(f(x)=sin \\ x \\qquad f: \\mathbb R \\rightarrow [-1, 1]\\) perch\u00e9 \\(-1 \\le sin(x) \\le 1\\) . La funzione \u00e8 surgettiba se per codominio prendiamo \\([-1, 1]\\) Essendo periodica, \\(sin(x+2 \\pi) = sin(x) \\quad \\forall x \\in \\mathbb R\\) . Essendo il seno sull'asse delle orinate, il cerchio con angolo 0 ha valore 0 sulle ordinate, quindi \\(sin(0) = 0\\) . La funzione \u00e8 invertibile modificando dominio e codominio (quando la funzione \u00e8 definita come \\(f: [ -\\frac \\pi 2 , \\frac \\pi 2 ] \\rightarrow [-1, 1]\\) . f risulta quindi strettamente crescente (quindi monotona, quindi essendo continua, iniettiva) e surgettiva.) Dispari","title":"Seno"},{"location":"AnalisiI/prerequisiti/#arcoseno","text":"Funzione inversa del seno, definita come \\(f: [-1, 1] \\rightarrow [ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) La funzione arcsin \u00e8 quindi l'inversa del seno quando il dominio \u00e8 \\([ -\\frac \\pi 2 , \\frac \\pi 2 ]\\) ed il codominio \u00e8 \\([-1, 1]\\) Se cos\u00ec non fosse la funzione seno non \u00e8 n\u00e9 iniettiva n\u00e9 surgettiva, e quindi non \u00e8 invertibile.","title":"Arcoseno"},{"location":"AnalisiI/prerequisiti/#coseno","text":"Il coseno \u00e8 una funzione trigonometrica periodica di periodo \\(2 \\pi\\) La funzione \u00e8 il seno, ma traslata di \\(\\frac \\pi 2\\) (quindi \\(cos(0) = 1\\) ) Pari","title":"Coseno"},{"location":"AnalisiI/prerequisiti/#arcocoseno","text":"Se vogliamo invertire dobbiamo scegliere un intervallo dove la funzione \u00e8 monotona. Possiamo quindi definire il dominio naturle come \\(cos(x): [0, \\pi] \\rightarrow [-1, 1]\\) .","title":"Arcocoseno"},{"location":"AnalisiI/prerequisiti/#tangente","text":"\\(tg (x) = \\frac {sin(x)} {cos(x)}\\) , che quindi non \u00e8 definita se \\(cos(x) = 0\\) . Il dominio \u00e8 quindi \\(\\{ x \\in \\mathbb R: x \\ne \\frac \\pi 2 + k \\cdot \\pi, k \\in \\mathbb Z \\}\\) , composto da infiniti intervalli disgiunti. \u00c8 periodica di periodo \\(\\pi\\) \u00c8 invertibile quando \\(f: (-\\frac \\pi 2 , \\frac \\pi 2 ) \\rightarrow \\mathbb R\\) \u00c8 inoltre dispari","title":"Tangente"},{"location":"AnalisiI/prerequisiti/#arcotangente","text":"\u00c8 l'inversa della tangente \\(arctan: \\mathbb \\rightarrow (-\\frac \\pi 2 , \\frac \\pi 2 )\\) Strettamente crescente nel suo dominio. (Da non invertire con la cotangente)","title":"Arcotangente"},{"location":"FdI/","text":"","title":"Fondamenti di Informatica"},{"location":"FdI/calcoloCombinatorio/","text":"Il calcolo combinatorio \u00b6 Il calcolo combinatorio \u00e8 quella branca della matematica che studia i modi per raggruppare o ordinare secondo delle regole date gli elementi di un insieme finito di oggetti. Possiamo vedere un esempio per quanto riguarda la cardinalit\u00e0 di alcune operazioni che abbiamo visto fin'ora: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\backslash B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A|+|B|-|A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|A \\times B \\times C| = |A| \\cdot |B| \\times |C|\\) \\(|\\mathcal P (A)| = 2^{|A|}\\) \\(|\\mathcal P_k (A)| = \\bigl({|A| \\atop k}\\bigr)\\) (prodotto binomiale) = \\(\\bigl({n \\atop k}\\bigr)\\) = Composizione(n,k) = \\(\\frac{n!}{n!(n-k)!}\\) \\(|Rel(A,B)| = 2^{|A| \\cdot |B|}\\) \\(|Fun(A,B)| = |B|^{|A|}\\) \\(|Bii(A,B)| = \\begin{cases} 0 & \\text{ se } |A| \\neq |B| \\\\ |A|! & \\text{ se } |A| = |B| \\end{cases}\\) \\(|A^n| = |A|^n\\) Operazioni su insiemi e cardinalit\u00e0 \u00b6 Una tecnica per contare gli elementi in un insieme consiste nel partizionamento di un insieme, e la successiva conta di ogni elemento nella partizione, che sommato per ogni sottoinsieme restituir\u00e0 la cardinalit\u00e0 di dell'insieme. Ad esempio, dato un insieme \\(A\\) , \\(\\mathcal F = \\{A_i | i \\in I\\}\\) sar\u00e0 una famiglia di sottoinsiemi cui: \\(\\cup_{i \\in I} A_i = A\\) (copertura di A) Per ogni coppia di indici \\((i,j) \\in I\\) con \\(i \\ne j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (gli insiemi sono disgiunti) Allora \\(|A| = \\sum_{i \\in I} |A_i|\\) Notare che \\(\\mathcal F\\) non \u00e8 una partizione, in quanto possono esistere insiemi vuoti, che non andrebbero ad intaccare il risultato della cardinalit\u00e0. Il principio di inclusione-esclusione Presi r insiemi \\(S_1,S_2,...S_r\\) abbiamo la seguente uguaglianza, dove \\((-1)^i\\) vale 1 se i \u00e8 un numero pari e vale -1 se \u00e8 dispari: \\[ \\bigg| \\bigcup^r_{j=1}S_j \\bigg | = \\sum_{I \\subseteq \\{1,2,...,r\\}, I \\ne \\varnothing} (-1)^{|I| +1} \\bigg | \\bigcap_{i \\in I} S_i \\bigg | \\] Ci\u00f2 significa che per trovare la cardinalit\u00e0 dell'unione di R insiemi, calcoliamo la cardinalit\u00e0 di ogni insieme e le sommiamo tutte. Procediamo poi con il sottrarre la cardinalit\u00e0 delle intersezioni con tra insiemi quando il numero di insiemi nell'operazione di intersezione \u00e8 pari, mentre aggiungiamo i valori se il numero di insiemi coinvolti \u00e8 dispari. Quindi, se ad esempio abbiamo \\(|S_1 \\cap S_2|\\) , abbiamo due insiemi, che significa che andremo a sottrarre , essendo 2 pari. Al contrario, se abbiamo \\(|S_1 \\cap S_2 \\cap S_3|\\) , andremo ad aggiungere il valore, essendo 3 dispari. \\[ \\displaylines{ A = \\{a, b\\} \\\\ B = \\{b,c\\} \\\\ C = \\{c,d\\} \\\\\\\\ R = \\{A,B\\} \\\\ S = \\{A,B,C\\} \\\\ \\bigg| \\bigcup^r_{j=1}R_j \\bigg| = |A| + |B| - |A \\cap B| \\\\ \\bigg| \\bigcup^r_{j=1}S_j \\bigg| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C| } \\] Da rivedere se sono stato chiaro Relazioni e cardinalit\u00e0 \u00b6 Dato che ogni relazione \u00e8 un insieme, possiamo parlare di cardinalit\u00e0 delle relazioni. Possiamo ad esempio intuire che \\(|R| \\leq |A \\times B|\\) . Ma possiamo fare anche altre affermazioni sulla base della natura della relazione: Se \\(R\\) \u00e8 totale, allora \\(|A| \\leq |R|\\) Se \\(R\\) \u00e8 univalente, allora \\(|R| \\leq |A|\\) Se \\(R\\) \u00e8 surgettiva, allora \\(|B| \\leq |R|\\) Se \\(R\\) \u00e8 iniettiva, allora \\(|R| \\leq |B|\\) Quindi, se \\(R: A \\rightarrow B\\) \u00e8 una funzione, allora \\(|R| = |A|\\) . Principio delle buche e dei piccioni / pidgen principle Dati due insiemi \\(P\\) e \\(C\\) , se \\(|P| > |C|\\) , non esiste nessuna relazione \\(R: P \\leftrightarrow C\\) che sia totale ed iniettiva: infatti abbiamo pi\u00f9 elementi nel dominio che nel codominio, ed almeno una eventuale relazione dovr\u00e0 per forza essere non essere univalente Regola di biiezione \u00b6 Regola di biiezione Per tutti gli insiemi \\(A,B\\) , vale che se esiste una biiezione allora \\(|A| = |B|\\) Questa regola si pu\u00f2 verificare assumendo 2 insiemi A e B con cardinalit\u00e0 n. Per simmetria e transitivit\u00e0 di \\(\\cong\\) , possiamo dire che \\(|A|=|B|=n \\Rightarrow |A| \\cong n \\ e\\ |B| \\cong n \\Rightarrow A \\cong B\\) Grazie a questa regola possiamo verificare le regole sulla cardinalit\u00e0 in modo semplice: Cardinalit\u00e0 di Fun(A,B) Per ogni coppia di insiemi A e B vale che \\(|Fun(A,B)| = |B|^{|A|}\\) . Per verificare questa regola, ci basta verificare la biiezione. Permutazioni, disposizioni e combinazioni \u00b6 Permutazioni \u00b6 Le permutazioni ci permttono di studiare i possibili modi in cui gli elementi di un certo insieme si possono ordinare Permutazione Dato un insieme finito A con \\(|A| = n\\) , una permutazione di A \u00e8 una sequenza ordinata \\(a_1,...,a_n\\) dove tutti gli elementi di A appaiono esattamente una volta L'insieme di tutte le permutazioni di un dato insieme A con cardinalit\u00e0 maggiore di 0 si calcola come: \\[ P(n) = n! \\] Anagrammi e permutazioni con ripetizioni \u00b6 Un esempio interessante di permutazione \u00e8 un anagramma, dato che spesso possono verificarsi delle ripetizioni di una lettera. Il motivo \u00e8 che le parole non sono un ineieme di lettere, ma una sequenza o tupla di lettere, in cui la stessa lettera pi\u00f9 comparire pi\u00f9 volte. In questo caso il numero di permutazioni distinte si ottiene considerando le occorrenze di ogni singola lettera Permutazioni con ripetizione Sia \\(S = s_1,s_2,...,s_k\\) una sequenza di elementi di un insieme A di cardinalit\u00e0 n, ogni elementi di A pu\u00f2 comparire una o pi\u00f9 volte in S. Per ogni \\(i \\in \\{1,2,...,n\\}\\) , \\(c_i\\) \u00e8 il numero di volte che l'elemento \\(a_i\\) compare nella sequenza S. Il numero di permutazioni con ripetizione \u00e8 dato quindi dalla formula \\[ \\frac{n!}{c_1! \\cdot c_2! \\cdot ... \\cdot c_n!} \\] Disposizioni \u00b6 Disposizioni Dato un insieme finito A con \\(|A| = n\\) ed un intero \\(k \\leq n\\) , una disposizione degli elementi di A in k posti \u00e8 una sequenza ordinata \\(a_1,...,a_k\\) Il suo valore \u00e8 calcolato con la formula: \\[ D(n,k) = \\frac{n!}{(n-k)!} \\] Combinazioni \u00b6 Combinazioni Sia \\(A\\) un insieme di cardinalit\u00e0 \\(n\\) e sia \\(k\\) un naturale tale che \\(k \\leq n\\) . Una combinazione di k elementi di A \u00e8 un k- insieme , ovvero un sottoinsieme di A con cardinalit\u00e0 K. L'insieme di tutte le combinazioni \u00e8 quindi denotato come \\(\\mathcal P_k(A)\\) . Il numero di combinazioni di k elementi in un insieme di cardinalit\u00e0 n \u00e8 chiamato coefficiente binomiale ed \u00e8 indicato come \\(({n \\atop k})\\) . La formula \u00e8 denominata anche formula dei tre fattoriali : \\[ \\bigg({n \\atop k}\\bigg) = \\frac{n!}{k!(n-k)!} \\] La formula delle combinazioni pu\u00f2 anche essere vista in funzione delle disposizioni, e quindi delle permutazioni: \\[ C(n,k) = \\bigg({n \\atop k}\\bigg) = \\frac{D(n,k)}{P(k)} = \\frac{\\frac{P(n)}{(n-k)!}}{k!} = \\frac{\\frac{n!}{(n-k)!}}{k!} = \\frac{n!}{k!(n-k)!} \\] Contare nei grafi \u00b6 Contare negli alberi \u00b6 Un albero pieno di altezza \\(h\\) ha \\(2^h\\) foglie e \\(2^h-1\\) nodi interni, per un totale di \\(2^{h+1}-1\\) nodi. Un nodo (radice compresa) si dice unario quando ha solo un figlio. Il numero di nodi non unari in T \u00e8 al massimo \\(f-1\\) (dove f \u00e8 il numero di foglie). Quanti grafi non orientati esistono? \u00b6 Contare il numero di grafi possibile corrisponde a prendere un sottoinsieme dei possibili archi \\(E = V \\times V\\) . Tuttavia essendo i grafi non orientati, si presentano delle restizioni nella scelta: Non possiamo scegliere dei cappi Un arco \\(\\{x,y\\}\\) \u00e8 del tutto equivalente ad un arco \\(\\{y,x\\}\\) Il numero di archi possibili \u00e8 quindi \\(m_{max} = \\frac{n(n-1)}{2}\\) Per ogni elemento \\(i =\\{0,...,m_{max}\\}\\) , il numero di grafi su n nodi con i archi corrisponde al numero di sottoinsiemi di i archi grandi. Ricordiamo che tutti i sottoinsiemi di cardinalit\u00e0 k \u00e8 uguale all'insieme delle parti \\(\\mathcal P(k)\\) . La cardinalit\u00e0 di \\(\\mathcal P(k)\\) , ovvero il numero di sottoinsiemi, corrisponde a tutti i modi di scegliere quali elementi includere: per ogni arco in \\(V \\times V\\) poissiamo scegliere se includerlo o no, ottenendo quindi \\(2^k\\) possibili combinazioni. \\[ \\mathcal P(m_{max}) = \\sum_{i \\in \\{0,...,m_{max}\\}} \\cb{m_{max}}{i} = 2^{m_{max}} = 2^{\\frac{n(n-1)}{2}} \\] \u00c8 importante tuttavia notare che alcuni di questi grafi risultano isomorfi . Non abbiamo modo di determinare quindi quanti grafi non isomorfi tra di loro abbiamo dato un certo insieme di grafi. Abbiamo inoltre potuto osservare un'importante conseguenza della sommatoria con il coefficiente binomiale: \\[ \\sum_{i\\in \\{0,...,k\\}} \\cb{k}{i} \\text { e quindi } \\forall k>0,i\\ge 0 . \\cb{k}{i} < 2^k \\] Quanti grafi orientati esistono? \u00b6 Rispondere a questa domanda diventa livemente pi\u00f9 semplice in quanto non abbiamo pi\u00f9 le restrizioni imposte dai grafi non orientati: Abbiamo quindi \\(|V \\times V| = n^2\\) possibili archi. Dato che come abbiamo detto, ogni arco pu\u00f2 far parte o meno del grafo, otteniamo che il numero di grafi possibili sar\u00e0 quindi \\(2^{n^2}\\) . Complemento di un grafo \u00b6 Dato un grafo, possiamo definire il suo complemento \\(H = (V,E^{'})\\) che ha come archi solo quelli che mancano in G. In formule quindi, il complemento di \\(G=(V,E)\\) \u00e8 \\(H = (V,E^{'})\\) , dove \\(E^{'}\\) \u00e8 definito come \\(E^{'} = \\{ xy \\in V\\times V | xy \\notin E\\}\\) . Notiamo che ogni grafo ha un complemento e la relazione complemento \\(C \\subseteq G_n \\times G_n\\) \u00e8 una biiezione. Osserviamo che \\(C^{-1} = C\\) Contare cammini in grafi notevoli \u00b6 Cammini in una cricca \u00b6 Definiznione di cricca Una cricca di n nodi \u00e8 un grafo dove ogni coppia di nodi \u00e8 connessa. La cricca biene anche denotata come \\(K_n\\) e grafo completo In una circca avremo quindi che il path pi\u00f9 corto tra due nodi \u00e8 di lunghezza 1. Inoltre ogni sequenza di nodi senza ripetizioni corrisponde ad un path. Qualunque permutazione \\(V!\\) dei nodi corrisponde quindi ad un path hamiltoniano . Ma dato che ogni nodo \u00e8 connesso a tutti gli altri, ne deriva che ogni path hamiltoniano \u00e8 anche un ciclo hamiltoniano. Tuttavia un ciclo come \\(1,2,3,4\\) , \u00e8 l'opposto del ciclo \\(4,3,2,1\\) , ma rappresentano lo stesso ciclo. Allo stesso modo, ripetendo due volte il cliclo \\(1,2,3,4,1,2,3,4\\) , iniziando da qualunque altro nodo che non sia il primo permetter\u00e0 di ottenere un nuovo ciclo hamiltoniano basato sugli stessi archi (chiameremo questo nuovo ciclo rotazione ). Per ottenere quindi il numero di cicli tra loro non equivalenti, dovremo dividere per i casi opposti (2) e per il numero di possibili rotazioni. Abbiamo quindi che \\(K_n\\) ha \\(\\frac{n!}{2n}\\) cicli hamiltoniani non equivalenti. Inoltre il numero di sequenze di lunghezza k sar\u00e0 pari al prodotto binomiale del numero dei nodi su k \\(\\cb{n}{k}\\) Cammini nel grafo bipartito completo \u00b6 Grafo bipartito Un grafo si dive bipartito se almeno una condizione \u00e8 vera (le condizioni sono equivalenti): G non contiene cicli di lunghezza dispari Esiste una patizione \\(V_1, V_2\\) di V tale che non esistono archi tra nodi nella stessa partizione. Per ogni arco \\(xy \\in E\\) vale che \\(x \\in v_1 \\Rightarrow y \\in V_2\\) Dati due colori, \u00e8 possibile colorare ogni nodo di G con un colore in modo che i due estremi di ongi acrvo abbiano sempre colori diversi (2-colorazione) Gli alberi non sono cicli, e quindi non possono avere cicli dispari. Di conseguenza ogni albero \u00e8 un grafo bipartito. Inoltre dato un grafo bipartito esiste una sola bipartizione \\(v_1, v_2\\)","title":"Calcolo Combinatorio"},{"location":"FdI/calcoloCombinatorio/#il-calcolo-combinatorio","text":"Il calcolo combinatorio \u00e8 quella branca della matematica che studia i modi per raggruppare o ordinare secondo delle regole date gli elementi di un insieme finito di oggetti. Possiamo vedere un esempio per quanto riguarda la cardinalit\u00e0 di alcune operazioni che abbiamo visto fin'ora: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\backslash B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A|+|B|-|A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|A \\times B \\times C| = |A| \\cdot |B| \\times |C|\\) \\(|\\mathcal P (A)| = 2^{|A|}\\) \\(|\\mathcal P_k (A)| = \\bigl({|A| \\atop k}\\bigr)\\) (prodotto binomiale) = \\(\\bigl({n \\atop k}\\bigr)\\) = Composizione(n,k) = \\(\\frac{n!}{n!(n-k)!}\\) \\(|Rel(A,B)| = 2^{|A| \\cdot |B|}\\) \\(|Fun(A,B)| = |B|^{|A|}\\) \\(|Bii(A,B)| = \\begin{cases} 0 & \\text{ se } |A| \\neq |B| \\\\ |A|! & \\text{ se } |A| = |B| \\end{cases}\\) \\(|A^n| = |A|^n\\)","title":"Il calcolo combinatorio"},{"location":"FdI/calcoloCombinatorio/#operazioni-su-insiemi-e-cardinalita","text":"Una tecnica per contare gli elementi in un insieme consiste nel partizionamento di un insieme, e la successiva conta di ogni elemento nella partizione, che sommato per ogni sottoinsieme restituir\u00e0 la cardinalit\u00e0 di dell'insieme. Ad esempio, dato un insieme \\(A\\) , \\(\\mathcal F = \\{A_i | i \\in I\\}\\) sar\u00e0 una famiglia di sottoinsiemi cui: \\(\\cup_{i \\in I} A_i = A\\) (copertura di A) Per ogni coppia di indici \\((i,j) \\in I\\) con \\(i \\ne j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (gli insiemi sono disgiunti) Allora \\(|A| = \\sum_{i \\in I} |A_i|\\) Notare che \\(\\mathcal F\\) non \u00e8 una partizione, in quanto possono esistere insiemi vuoti, che non andrebbero ad intaccare il risultato della cardinalit\u00e0. Il principio di inclusione-esclusione Presi r insiemi \\(S_1,S_2,...S_r\\) abbiamo la seguente uguaglianza, dove \\((-1)^i\\) vale 1 se i \u00e8 un numero pari e vale -1 se \u00e8 dispari: \\[ \\bigg| \\bigcup^r_{j=1}S_j \\bigg | = \\sum_{I \\subseteq \\{1,2,...,r\\}, I \\ne \\varnothing} (-1)^{|I| +1} \\bigg | \\bigcap_{i \\in I} S_i \\bigg | \\] Ci\u00f2 significa che per trovare la cardinalit\u00e0 dell'unione di R insiemi, calcoliamo la cardinalit\u00e0 di ogni insieme e le sommiamo tutte. Procediamo poi con il sottrarre la cardinalit\u00e0 delle intersezioni con tra insiemi quando il numero di insiemi nell'operazione di intersezione \u00e8 pari, mentre aggiungiamo i valori se il numero di insiemi coinvolti \u00e8 dispari. Quindi, se ad esempio abbiamo \\(|S_1 \\cap S_2|\\) , abbiamo due insiemi, che significa che andremo a sottrarre , essendo 2 pari. Al contrario, se abbiamo \\(|S_1 \\cap S_2 \\cap S_3|\\) , andremo ad aggiungere il valore, essendo 3 dispari. \\[ \\displaylines{ A = \\{a, b\\} \\\\ B = \\{b,c\\} \\\\ C = \\{c,d\\} \\\\\\\\ R = \\{A,B\\} \\\\ S = \\{A,B,C\\} \\\\ \\bigg| \\bigcup^r_{j=1}R_j \\bigg| = |A| + |B| - |A \\cap B| \\\\ \\bigg| \\bigcup^r_{j=1}S_j \\bigg| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C| } \\] Da rivedere se sono stato chiaro","title":"Operazioni su insiemi e cardinalit\u00e0"},{"location":"FdI/calcoloCombinatorio/#relazioni-e-cardinalita","text":"Dato che ogni relazione \u00e8 un insieme, possiamo parlare di cardinalit\u00e0 delle relazioni. Possiamo ad esempio intuire che \\(|R| \\leq |A \\times B|\\) . Ma possiamo fare anche altre affermazioni sulla base della natura della relazione: Se \\(R\\) \u00e8 totale, allora \\(|A| \\leq |R|\\) Se \\(R\\) \u00e8 univalente, allora \\(|R| \\leq |A|\\) Se \\(R\\) \u00e8 surgettiva, allora \\(|B| \\leq |R|\\) Se \\(R\\) \u00e8 iniettiva, allora \\(|R| \\leq |B|\\) Quindi, se \\(R: A \\rightarrow B\\) \u00e8 una funzione, allora \\(|R| = |A|\\) . Principio delle buche e dei piccioni / pidgen principle Dati due insiemi \\(P\\) e \\(C\\) , se \\(|P| > |C|\\) , non esiste nessuna relazione \\(R: P \\leftrightarrow C\\) che sia totale ed iniettiva: infatti abbiamo pi\u00f9 elementi nel dominio che nel codominio, ed almeno una eventuale relazione dovr\u00e0 per forza essere non essere univalente","title":"Relazioni e cardinalit\u00e0"},{"location":"FdI/calcoloCombinatorio/#regola-di-biiezione","text":"Regola di biiezione Per tutti gli insiemi \\(A,B\\) , vale che se esiste una biiezione allora \\(|A| = |B|\\) Questa regola si pu\u00f2 verificare assumendo 2 insiemi A e B con cardinalit\u00e0 n. Per simmetria e transitivit\u00e0 di \\(\\cong\\) , possiamo dire che \\(|A|=|B|=n \\Rightarrow |A| \\cong n \\ e\\ |B| \\cong n \\Rightarrow A \\cong B\\) Grazie a questa regola possiamo verificare le regole sulla cardinalit\u00e0 in modo semplice: Cardinalit\u00e0 di Fun(A,B) Per ogni coppia di insiemi A e B vale che \\(|Fun(A,B)| = |B|^{|A|}\\) . Per verificare questa regola, ci basta verificare la biiezione.","title":"Regola di biiezione"},{"location":"FdI/calcoloCombinatorio/#permutazioni-disposizioni-e-combinazioni","text":"","title":"Permutazioni, disposizioni e combinazioni"},{"location":"FdI/calcoloCombinatorio/#permutazioni","text":"Le permutazioni ci permttono di studiare i possibili modi in cui gli elementi di un certo insieme si possono ordinare Permutazione Dato un insieme finito A con \\(|A| = n\\) , una permutazione di A \u00e8 una sequenza ordinata \\(a_1,...,a_n\\) dove tutti gli elementi di A appaiono esattamente una volta L'insieme di tutte le permutazioni di un dato insieme A con cardinalit\u00e0 maggiore di 0 si calcola come: \\[ P(n) = n! \\]","title":"Permutazioni"},{"location":"FdI/calcoloCombinatorio/#anagrammi-e-permutazioni-con-ripetizioni","text":"Un esempio interessante di permutazione \u00e8 un anagramma, dato che spesso possono verificarsi delle ripetizioni di una lettera. Il motivo \u00e8 che le parole non sono un ineieme di lettere, ma una sequenza o tupla di lettere, in cui la stessa lettera pi\u00f9 comparire pi\u00f9 volte. In questo caso il numero di permutazioni distinte si ottiene considerando le occorrenze di ogni singola lettera Permutazioni con ripetizione Sia \\(S = s_1,s_2,...,s_k\\) una sequenza di elementi di un insieme A di cardinalit\u00e0 n, ogni elementi di A pu\u00f2 comparire una o pi\u00f9 volte in S. Per ogni \\(i \\in \\{1,2,...,n\\}\\) , \\(c_i\\) \u00e8 il numero di volte che l'elemento \\(a_i\\) compare nella sequenza S. Il numero di permutazioni con ripetizione \u00e8 dato quindi dalla formula \\[ \\frac{n!}{c_1! \\cdot c_2! \\cdot ... \\cdot c_n!} \\]","title":"Anagrammi e permutazioni con ripetizioni"},{"location":"FdI/calcoloCombinatorio/#disposizioni","text":"Disposizioni Dato un insieme finito A con \\(|A| = n\\) ed un intero \\(k \\leq n\\) , una disposizione degli elementi di A in k posti \u00e8 una sequenza ordinata \\(a_1,...,a_k\\) Il suo valore \u00e8 calcolato con la formula: \\[ D(n,k) = \\frac{n!}{(n-k)!} \\]","title":"Disposizioni"},{"location":"FdI/calcoloCombinatorio/#combinazioni","text":"Combinazioni Sia \\(A\\) un insieme di cardinalit\u00e0 \\(n\\) e sia \\(k\\) un naturale tale che \\(k \\leq n\\) . Una combinazione di k elementi di A \u00e8 un k- insieme , ovvero un sottoinsieme di A con cardinalit\u00e0 K. L'insieme di tutte le combinazioni \u00e8 quindi denotato come \\(\\mathcal P_k(A)\\) . Il numero di combinazioni di k elementi in un insieme di cardinalit\u00e0 n \u00e8 chiamato coefficiente binomiale ed \u00e8 indicato come \\(({n \\atop k})\\) . La formula \u00e8 denominata anche formula dei tre fattoriali : \\[ \\bigg({n \\atop k}\\bigg) = \\frac{n!}{k!(n-k)!} \\] La formula delle combinazioni pu\u00f2 anche essere vista in funzione delle disposizioni, e quindi delle permutazioni: \\[ C(n,k) = \\bigg({n \\atop k}\\bigg) = \\frac{D(n,k)}{P(k)} = \\frac{\\frac{P(n)}{(n-k)!}}{k!} = \\frac{\\frac{n!}{(n-k)!}}{k!} = \\frac{n!}{k!(n-k)!} \\]","title":"Combinazioni"},{"location":"FdI/calcoloCombinatorio/#contare-nei-grafi","text":"","title":"Contare nei grafi"},{"location":"FdI/calcoloCombinatorio/#contare-negli-alberi","text":"Un albero pieno di altezza \\(h\\) ha \\(2^h\\) foglie e \\(2^h-1\\) nodi interni, per un totale di \\(2^{h+1}-1\\) nodi. Un nodo (radice compresa) si dice unario quando ha solo un figlio. Il numero di nodi non unari in T \u00e8 al massimo \\(f-1\\) (dove f \u00e8 il numero di foglie).","title":"Contare negli alberi"},{"location":"FdI/calcoloCombinatorio/#quanti-grafi-non-orientati-esistono","text":"Contare il numero di grafi possibile corrisponde a prendere un sottoinsieme dei possibili archi \\(E = V \\times V\\) . Tuttavia essendo i grafi non orientati, si presentano delle restizioni nella scelta: Non possiamo scegliere dei cappi Un arco \\(\\{x,y\\}\\) \u00e8 del tutto equivalente ad un arco \\(\\{y,x\\}\\) Il numero di archi possibili \u00e8 quindi \\(m_{max} = \\frac{n(n-1)}{2}\\) Per ogni elemento \\(i =\\{0,...,m_{max}\\}\\) , il numero di grafi su n nodi con i archi corrisponde al numero di sottoinsiemi di i archi grandi. Ricordiamo che tutti i sottoinsiemi di cardinalit\u00e0 k \u00e8 uguale all'insieme delle parti \\(\\mathcal P(k)\\) . La cardinalit\u00e0 di \\(\\mathcal P(k)\\) , ovvero il numero di sottoinsiemi, corrisponde a tutti i modi di scegliere quali elementi includere: per ogni arco in \\(V \\times V\\) poissiamo scegliere se includerlo o no, ottenendo quindi \\(2^k\\) possibili combinazioni. \\[ \\mathcal P(m_{max}) = \\sum_{i \\in \\{0,...,m_{max}\\}} \\cb{m_{max}}{i} = 2^{m_{max}} = 2^{\\frac{n(n-1)}{2}} \\] \u00c8 importante tuttavia notare che alcuni di questi grafi risultano isomorfi . Non abbiamo modo di determinare quindi quanti grafi non isomorfi tra di loro abbiamo dato un certo insieme di grafi. Abbiamo inoltre potuto osservare un'importante conseguenza della sommatoria con il coefficiente binomiale: \\[ \\sum_{i\\in \\{0,...,k\\}} \\cb{k}{i} \\text { e quindi } \\forall k>0,i\\ge 0 . \\cb{k}{i} < 2^k \\]","title":"Quanti grafi non orientati esistono?"},{"location":"FdI/calcoloCombinatorio/#quanti-grafi-orientati-esistono","text":"Rispondere a questa domanda diventa livemente pi\u00f9 semplice in quanto non abbiamo pi\u00f9 le restrizioni imposte dai grafi non orientati: Abbiamo quindi \\(|V \\times V| = n^2\\) possibili archi. Dato che come abbiamo detto, ogni arco pu\u00f2 far parte o meno del grafo, otteniamo che il numero di grafi possibili sar\u00e0 quindi \\(2^{n^2}\\) .","title":"Quanti grafi orientati esistono?"},{"location":"FdI/calcoloCombinatorio/#complemento-di-un-grafo","text":"Dato un grafo, possiamo definire il suo complemento \\(H = (V,E^{'})\\) che ha come archi solo quelli che mancano in G. In formule quindi, il complemento di \\(G=(V,E)\\) \u00e8 \\(H = (V,E^{'})\\) , dove \\(E^{'}\\) \u00e8 definito come \\(E^{'} = \\{ xy \\in V\\times V | xy \\notin E\\}\\) . Notiamo che ogni grafo ha un complemento e la relazione complemento \\(C \\subseteq G_n \\times G_n\\) \u00e8 una biiezione. Osserviamo che \\(C^{-1} = C\\)","title":"Complemento di un grafo"},{"location":"FdI/calcoloCombinatorio/#contare-cammini-in-grafi-notevoli","text":"","title":"Contare cammini in grafi notevoli"},{"location":"FdI/calcoloCombinatorio/#cammini-in-una-cricca","text":"Definiznione di cricca Una cricca di n nodi \u00e8 un grafo dove ogni coppia di nodi \u00e8 connessa. La cricca biene anche denotata come \\(K_n\\) e grafo completo In una circca avremo quindi che il path pi\u00f9 corto tra due nodi \u00e8 di lunghezza 1. Inoltre ogni sequenza di nodi senza ripetizioni corrisponde ad un path. Qualunque permutazione \\(V!\\) dei nodi corrisponde quindi ad un path hamiltoniano . Ma dato che ogni nodo \u00e8 connesso a tutti gli altri, ne deriva che ogni path hamiltoniano \u00e8 anche un ciclo hamiltoniano. Tuttavia un ciclo come \\(1,2,3,4\\) , \u00e8 l'opposto del ciclo \\(4,3,2,1\\) , ma rappresentano lo stesso ciclo. Allo stesso modo, ripetendo due volte il cliclo \\(1,2,3,4,1,2,3,4\\) , iniziando da qualunque altro nodo che non sia il primo permetter\u00e0 di ottenere un nuovo ciclo hamiltoniano basato sugli stessi archi (chiameremo questo nuovo ciclo rotazione ). Per ottenere quindi il numero di cicli tra loro non equivalenti, dovremo dividere per i casi opposti (2) e per il numero di possibili rotazioni. Abbiamo quindi che \\(K_n\\) ha \\(\\frac{n!}{2n}\\) cicli hamiltoniani non equivalenti. Inoltre il numero di sequenze di lunghezza k sar\u00e0 pari al prodotto binomiale del numero dei nodi su k \\(\\cb{n}{k}\\)","title":"Cammini in una cricca"},{"location":"FdI/calcoloCombinatorio/#cammini-nel-grafo-bipartito-completo","text":"Grafo bipartito Un grafo si dive bipartito se almeno una condizione \u00e8 vera (le condizioni sono equivalenti): G non contiene cicli di lunghezza dispari Esiste una patizione \\(V_1, V_2\\) di V tale che non esistono archi tra nodi nella stessa partizione. Per ogni arco \\(xy \\in E\\) vale che \\(x \\in v_1 \\Rightarrow y \\in V_2\\) Dati due colori, \u00e8 possibile colorare ogni nodo di G con un colore in modo che i due estremi di ongi acrvo abbiano sempre colori diversi (2-colorazione) Gli alberi non sono cicli, e quindi non possono avere cicli dispari. Di conseguenza ogni albero \u00e8 un grafo bipartito. Inoltre dato un grafo bipartito esiste una sola bipartizione \\(v_1, v_2\\)","title":"Cammini nel grafo bipartito completo"},{"location":"FdI/cheatsheet/","text":"Relazione Descrizione Totale Per ogni elemento in A, c'\u00e8 una connessione con almeno un elemento in B Univalente Per ogni elemento in A, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in B Surgettiva Per ogni elemento in B, c'\u00e8 una connessione con almeno un elemento in A Iniettiva Per ogni elemento in B, c'\u00e8 al massimo una connessione (0 o 1) con un elemento in A Biietiva Tutte le precedenti Riflessiva Ogni elemento \u00e8 in relazione con s\u00e9 stesso (ha un cappio) (l'identit\u00e0 \u00e8 contenuta nella relazione) Transitiva Se esiste una relazione (a,b), e (b,c), esiste anche una relazione (a,c) Include anche la relazione vuota Antisimmetrica Non c'\u00e8 mai una relazione che va da a a b e contemporaneamente da b ad a (Non ci sono mai frecce opposte) \u00c8 tollerato lo stesso elemento (cappio) Simmetrica Per ogni relazione (a,b) , esiste una relazione (b,a) Per ogni elemento, ci sono 2 archi, uno da ed uno verso un altro elemento Composizione 2 relazioni sono composte quando l'elemento di arrivo per la prima diventa l'elemento di partenza per la seconda Avendo (a,b) e (b,c) in R, R composto R ( R;R ) \u00e8 ((a,b),c) , ovvero (a,c) R*, chiusura di Kleene La composizione di una relazione con s\u00e9 stessa infinite volte (zero incluso) \u00c8 riflessiva e transitiva Contiene l'identit\u00e0 (R0) R+, chiusura positiva R* ma senza 0 incluso Chiusura riflessiva Data una relazione R ed un insieme A, \u00e8 l'unione dell'identit\u00e0 di A con la relazione R Chiusura simmetrica Data una relazione R, \u00e8 l'unione di R ed R opposto Chiusura transitiva Data una relazione R, si unisce a questa la chiusura positiva fino a far diventare la funzione transitiva Ordinamento parziale Una relazione Riflessiva, Transitiva ed Antisimmetrica Ordinamento totale Ordinamento parziale + ogni (a, b) appartenente al prodotto cartesiano; (a,b) o (b,a) appartiene ad R Ogni coppia di elementi appartiene alla relazione R: ogni elemento \u00e8 in relazione con ogni altro elemento; C'\u00e8 una freccia per ogni elemento su ogni elemento Se \u00e8 totale, non \u00e8 parziale Grafo Relazione Descrizione Walk/Cammino Un collegamento da un nodo di partenza ad uno di arrivo Trail Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso arco (o collegamento) Path Un collegamento da un nodo di partenza ad uno di arrivo MA senza passare 2 volte per lo stesso NODO (o pallino/elemento) Non si deve passare 2 volte per lo stesso elemento Walk chiuso Un walk che permette di partire da un nodo e ritornare allo stesso ed ha lunghezza maggiore di 0 Circuito \u00c8 un walk chiuso che \u00e8 anche un trail (non si passa per lo stesso arco 2 volte) Ciclo \u00c8 un circuito che \u00e8 anche un path (non si passa per lo stesso nodo 2 volte) Aciclico Quando il grafo NON presenta un ciclo Connesso Quando ogni nodo \u00e8 \"raggiunto\" da almeno un arco (se \u00e8 orientato: sia in uscita che in entrata) Fortemente connesso Da ogni nodo, esiste un walk verso ogni altro nodo Componenti fortemente connesse Sottografi fortemente connessi (notare che ogni nodo pu\u00f2 arrivare a s\u00e9 stesso, quindi ogni nodo preso singolarmente \u00e8 una componente fortemente connessa) Universale Quando un nodo \u00e8 vicino a tutti gli altri DAG Grafo Aciclico Orientato Induzione (pecch\u00e9 non bastava prima)","title":"Cheatsheet"},{"location":"FdI/grafi/","text":"I grafi e gli alberi \u00b6 I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme. Grafi orientati \u00b6 Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) . Le propriet\u00e0 TUSI \u00b6 Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\) Rappresentazione dei grafi orientati \u00b6 Esistono diversi modi per rappresentare i grafi orientati Matrice di adiacenza \u00b6 La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra. Liste di adiacenza \u00b6 Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\) Grafi etichettati e pesati \u00b6 Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche: Cammini, cicli e connettivit\u00e0 \u00b6 In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path. Cicli nei grafi orientati \u00b6 walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\) Connettivit\u00e0 \u00b6 Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y. Grafi orientati aciclici \u00b6 Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico. Grafi non orientati \u00b6 Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari. Cammini, cicli e connettivit\u00e0 sui grafi non orientati \u00b6 La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path. Cicli nei grafi non orientati \u00b6 \u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente. Connettivit\u00e0 \u00b6 Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa Alberi \u00b6 Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa. Cammini euleriani ed hamiltoniani \u00b6 Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi) Cammini euleriani (archi) \u00b6 Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\) Cammini hamiltoniani (nodi) \u00b6 Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G Il problema del commesso viaggiatore \u00b6 Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\] Distanza su grafi \u00b6 Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi. Isomorfismo \u00b6 L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi. Altri grafi noti \u00b6 Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Grafi"},{"location":"FdI/grafi/#i-grafi-e-gli-alberi","text":"I grafi sono importanti perche ci permettono di modellare in modo preciso e visualmente intuitivo le relazioni tra elementi di un insieme.","title":"I grafi e gli alberi"},{"location":"FdI/grafi/#grafi-orientati","text":"Grafo orientato Un grafo orientato \u00e8 una relazione \\(E: V \\leftrightarrow V\\) su un insieme finito \\(V\\) . Gli elementi di \\(V\\) vengono detti nodi o vertici e gli elementi di \\(E\\) vengono detti archi o lati . Un grafo \u00e8 generalmente denotato con la lettera \\(G\\) o varianti ( \\(G^{'}, G_1, G_2,...\\) ). Per enfatizzare l'insieme dei nodi V e l'insieme degli archi, si tende a scrivere \\(G = (V, E)\\) I grafi definiti in questa maniere sono considerati orientati in quanto un arco \\((x,y) \\in E\\) (dove \\(x,y \\in V\\) , quindi x e y sono nodi), si dice che parte da x ed arriva ad y . Cappio o loop Un arco del tipo \\((x,x) \\in E\\) , parte ed arriva allo stesso nodo X ed \u00e8 denominato cappio o loop Il numero dei nodi in un grafo \u00e8 definito dalla cardinalit\u00e0 dell'insieme dei nodi ( \\(|V|\\) ). Il numero degli archi, dalla cardinalit\u00e0 dall'insieme degli archi \\(|E|\\) . La dimensione di \\(G\\) \u00e8 data dalla somma \\(|V|+|E|\\) . Vicinato Due nodi \\(x,y \\in V\\) si dicono adiacenti o vicini quando c'\u00e8 un arco che li collega ( \\((x,y) \\in E \\lor (y,x) \\in E\\) ). Il vicinato (di un nodo \\(x \\in V\\) ) si pu\u00f2 poi distinguere in vicinato in uscita ( \\(N^+(x) = \\{ y | (x,y) \\in E \\}\\) ), chiamato anche stella uscente in x e vicinato in ingresso ( \\(N^-(x) = \\{ x | (x, y) \\in E \\}\\) ), chiamato anche stella entrante in x Grado Il grado di uscita di x \u00e8 definito come la cardinalit\u00e0 del suo vicinato di uscita \\(d^+_x = |N^+ (x)|\\) . Il suo grado di ingresso \u00e8 \\(d^-_x = |N^- (x)|\\) .","title":"Grafi orientati"},{"location":"FdI/grafi/#le-proprieta-tusi","text":"Le propriet\u00e0 TUSI valgono anche per i grafi: \\(E: V \\leftrightarrow V\\) \u00e8 totale se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 univalente se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^+_x \\leq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 surgettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\geq 1\\) \\(E: V \\leftrightarrow V\\) \u00e8 iniettiva se e solo se per ogni nodo \\(x \\in V\\) vale \\(d^-_x \\leq 1\\)","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/grafi/#rappresentazione-dei-grafi-orientati","text":"Esistono diversi modi per rappresentare i grafi orientati","title":"Rappresentazione dei grafi orientati"},{"location":"FdI/grafi/#matrice-di-adiacenza","text":"La matrice di adienza rappresenta una rapresentazione tabellare Matrice di adiacenza Una matrice di adiacenza di \\(G\\) \u00e8 una matrice quadrata (tabella con lo stesso numero di righe e colonne), da 0 a n-1 righe e colonne, dove l'elemento \\(A_{ij}\\) (riga i e colonna j) assume un valore in \\({0,1}\\) con il significato \\[ A_{ij}=\\begin{cases} 1 & \\text{se l'arco } (i,j) \\in E \\\\ 0 & \\text{se l'arco } (i,j) \\notin E \\end{cases} \\] \u00c8 possibile osservare un esempio della matrice di adiacenza nell'esempio poco sopra.","title":"Matrice di adiacenza"},{"location":"FdI/grafi/#liste-di-adiacenza","text":"Grafo sparso Un grafo si dice sparso quando il numero di archi \u00e8 proporzionale al numero di nodi Le liste di adiacenza sono spesso usate per rappresentare grafi sparsi, che quindi spesso si ricollegano alla vita reale. Liste di adiacenza Una lista di adiacenza di un grafo orientato \\(G = (V,E)\\) \u00e8 un array \\(A\\) di \\(n = |V|\\) insiemi in cui l'elementi \\(i\\) -esimo rappresenta il vicinato in uscita del nodo \\(i \\in V\\) , ovvero \\(A[i] = N^+ (i)\\)","title":"Liste di adiacenza"},{"location":"FdI/grafi/#grafi-etichettati-e-pesati","text":"Possiamo arricchire la struttura base di un grafo \\(G = (V,E)\\) aggiungendo delle etichette sugli archi e/o sui nodi. Grafo etichettato e pesato Un grafo orientato etichettato \u00e8 una tripla \\(G = (V,E,L)\\) dove \\(L\\) \u00e8 una funzione \\(L: (V \\cup U) \\rightarrow D\\) , che associa ad ogni nodo ed arco un'etichetta presa da un dominio D. Se D \u00e8 un valore numerico, il grafo si dice pesato e ciascuna eticehtta diventa quindi un peso. \u00c8 possibile quindi adattare anche le rappresentazioni grafiche:","title":"Grafi etichettati e pesati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita","text":"In un grafo orientato, la relazione \\((i,j)\\) pu\u00f2 essere interpretata come il fatto che il nodo i raggiunge direttamente il nodo j (eventualmente con un certo costo, dato dall'etichetta). Introduciamo quindi il concetto di cammino, che ci permette di formulare problemi basati sulla raggiungibilit\u00e0. Un cammino \u00e8 una sequenza di nodi, ogniuno dei quali \u00e8 collegato al successivo con un arco. Un nodo \u00e8 raggiungibile da un altro se esiste un cammino che li collega. Un cammino chiuso, che inizia e termina con lo stesso nodo, si definisce ciclo . Walk Dato un grafo \\(G = (V,E)\\) un walk \\(P\\) in \\(G\\) \u00e8 una sequanza di nodi \\(P = v_0,...,v_k\\) con \\(k \\in \\mathbb N\\) tali che \\((v_{i-1}, v_i) \\in E\\) per \\(i \\in \\{1,...,k\\}\\) . In questo caso, \\(P\\) \u00e8 un walk di lunghezza \\(k\\) . Le coppie \\((v_{i-1}, v_i)\\) sono detti archi attraversati da \\(P\\) , mentre i nodi \\(v_0,...,v_k\\) sono detti i nodi attraversati da \\(P\\) . I nodi tra v_0 e v_k sono detti estremi di P. Se \\(k=0\\) il walk ha lunghezza 0 ed \u00e8 costituito dal solo nodo \\(v_0\\) Dato un grafo orientato \\(G = (V,E)\\) , con \\(x,y \\in V\\) : Esiste un walk di lunghezza \\(n \\in \\mathbb N\\) se e solo se \\((x,y)in E^n\\) Trail, Path Un walk P \u00e8 detto un trail se attraversa un arco al pi\u00f9 una volta. Un trail \u00e8 detto path se attraversa un nodo al pi\u00f9 una volta. Notare che il walk \\((0,0)\\) non \u00e8 un path ma un trail: il nodo 0 viene attraversato 2 volte, mentre l'arco una sola. Se esiste un walk tra 2 nodi, allora esiste anche un trail. Se il walk ha lunghezza \\(>0\\) , allora anche il trail ha lunghezza \\(> 0\\) . Se esiste un trail tra 2 nodi, allora esiste anche un path.","title":"Cammini, cicli e connettivit\u00e0"},{"location":"FdI/grafi/#cicli-nei-grafi-orientati","text":"walk chiuso, circuito, ciclo Un walk \u00e8 detto chiuso se i suoi estremi sono uguali ( \\(v_0 = v_k\\) ) e se ha lunghezza > 0. Un walk chiuso che \u00e8 un trail \u00e8 detto circuito . Un circuito che \u00e8 anche un path \u00e8 detto ciclo . Grafo ciclico e aciclico Un grafo G si dice ciclico se esiste almeno un ciclo in G, altrimenti si dice aciclico . Le seguenti affermazioni sono quindi equivalenti: Esiste un walk chiuso che inizia e termina in x Esiste un circuito che inizia e termina in x Esiste un ciclo che inizia e temrina in x \\((x,x) \\in E^+\\)","title":"Cicli nei grafi orientati"},{"location":"FdI/grafi/#connettivita","text":"Grafo fortemente connesso Un grafo orientato \u00e8 fortemente connesso se per ogni coppia di nodi \\((u,v) \\in V \\times V\\) esiste un walk da \\(u\\) a \\(v\\) . Componente fortemente connessa Una componente fortemente connessa di un grafo orientato \u00e8 un sottinsieme non vuoto di nodi \\(U \\in V\\) tale che: 1. Per ogni coppiad i nodi \\((x,y) \\in U \\times U\\) , esiste un walk da x a y 2. Se \\(U^{'}\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) , allora \\(U=U^{'}\\) La seconda condizione serve a garantire che U sia massimale, ovvero che aggiungendo un nodo esterno, la condizione venga violata. Se un grafo \u00e8 fortemente connesso, allora ha una sola componente fortemente connessa (l'intero grafo). L'insieme delle componenti fortemente connesse di G ( \\(\\{ U \\subseteq V | U \\text{ componente fortemente connessa di } G \\}\\) ) forma una partizione di V. Notare che: Ogni componente fortemente connessa \u00e8 non vuota L'unione di tutte le componenti fortemente connesse \u00e8 uguale a V (Copertura) Se \\(U_1\\) e \\(U_2\\) sono due componenti fortemente connesse distinte, allora sono disgiunte (Disgiunzione) G \u00e8 fortemente connesso se e solo se \\(V \\times V \\subseteq E^*\\) Un grafo G \u00e8 fortemente connesso se e esolo se per ogni coppia di nodi \\(x,y \\in V\\) distinti ( \\(x \\neq y\\) ) esiste un walk chiuso che attraversa x e y.","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#grafi-orientati-aciclici","text":"Grafo orientato aciclico Un grafo orientato aciclico, detto DAG , \u00e8 un grafo in cui i nodi d'i Pozzi e sorgenti In un DAG, i nodi con grado d'ingresso 0 sono detti sorgenti, ed i nodi con gradi d'uscita 0 sono detti pozzi. Se un grafo \u00e8 un dag, allora \\(E^*\\) \u00e8 una relazione d'ordinamento parziale. Ordinamento topologico Dato un DAG \\(G = (V,E)\\) , un ordinamento topologico di G \u00e8 una biiezione \\(\\eta: V \\rightarrow n = \\{ 0,1,...,n-1 \\}\\) tali che per ogni arco \\((u,v) \\in E\\) vale \\(\\eta (u) < \\eta (v)\\) La numerazione \\(\\eta\\) ordina quindi i nodi sulla base del numero di archi in ingresso (? - verificare) Ogni DAG ha almeno un ordinamento topologico.","title":"Grafi orientati aciclici"},{"location":"FdI/grafi/#grafi-non-orientati","text":"Grafo non orientato Si definisce grafo non orientato un grafo \\(G = (V,E)\\) tale che \\(V\\) \u00e8 un insieme finito e \\(E \\subseteq \\mathcal P_2(V)\\) Si ricorda che \\(\\mathcal P_2(V)\\) rappresenta tutti i sottoinsiemi di V con cardinalit\u00e0 2. \u00c8 inoltre importante osservare che nei grafi non orientati non ci possono essere cappi: l'insieme \\({x,x}\\) \u00e8 esattamente l'insieme \\({x}\\) , che quindi non appartiene a \\(\\mathcal P_2(V)\\) avendo cardinalit\u00e0 1. Grafo orientato associato Un grafo orientato associato ha la relazione degli archi \\(E\\) definita come \\(E = \\{ (x,y) \\in V \\times V | \\{x,y\\} \\in E \\}: V \\leftrightarrow V\\) Tuttavia non \u00e8 corretto pensare ad un grafo non orientatato come al suo grafo associato. Incidenza ed estremi Dato un grafo non orientato, due nodi \\(x,y \\in V\\) sono vicini o adiacenti se c'\u00e8 un arco \\(\\{x,y\\} \\in E\\) . In questo caso si dice che l' arco \u00e8 incidente a x e y , i quasi sono gli estremi dell'arco. Il vicinato di un insieme \\(N(x) = \\{ y | x y \\in E\\}\\) Nodo universale ed isolato Un nodo x si dice universale se se \u00e8 vicino a tutti i nodi ( \\(E \\backslash x \\subseteq N(x)\\) ), mentre \u00e8 isolato se il vicinato N(x) \u00e8 vuoto. Con \\(\\Delta\\) si rappresenta il grado massimo in G handshaking lemma Per ogni grafo non orientato, la somma dei gradi dei nodi \u00e8 il doppio del numero degli archi. \\[ \\sum_{x \\in V} d_x = 2|E| \\] G contiene un numero pari di nodi che hanno gradi dispari.","title":"Grafi non orientati"},{"location":"FdI/grafi/#cammini-cicli-e-connettivita-sui-grafi-non-orientati","text":"La definizione di walk differisce solo per la sequenza di nodi come un insieme invece che una coppia. La lunghezza di un walk, gli estremi, i nodi attraversati e gli archi attraversati sono definiti come per i grafi orientati. Per tutti i grafi non orientati \\(G = (V,E)\\) e tutti i nodi \\(x,y \\in V\\) , esiste un walk di lunghezza \\(n \\in \\mathbb N\\) da x a y se e solo se \\((x,y) \\in \\tilde{E}^n\\) In un grafo non orientato, se esiste un walk tra due nodi, allora esiste anche un trail, e quindi anche un path.","title":"Cammini, cicli e connettivit\u00e0 sui grafi non orientati"},{"location":"FdI/grafi/#cicli-nei-grafi-non-orientati","text":"\u00c8 importante notare che l'esistenza di un walk chiuso non implica l'esistenza di un circuito. Questo perch\u00e9 il trail corrispondente a tale walk potrebbe essere di lunghezza 0, e quindi non essere un circuito. Vale invece che l'esistenza di un circuito implica un ciclo. Se esiste un circuito che inizia e termina in x, allora esiste anche un ciclo corrispondente.","title":"Cicli nei grafi non orientati"},{"location":"FdI/grafi/#connettivita_1","text":"Un grafo non orientato si dice fortemente connesso quando il grafo corrispondente \u00e8 fortemente connesso. Una componente fortemente connesssa \u00e8 la stessa presente anche nel grafo connesso corrispondente. Grafo connesso Un grafo non orientato \\(G=(V,E)\\) si dice connesso se per ogni coppia di nodi \\(u, v \\in V \\times V\\) esiste un walk da u a v. Componente connessa Sia \\(G=(V,E)\\) un grafo non orientato, un sottoinsieme non vuoto dei nodi \\(U \\subseteq V\\) si dice componente connessa se: Per ogni coppia di nodi \\(x,y \\in U \\times U\\) esiste un walk da x a y Se \\(U^{'} \\subseteq V\\) soddisfa la propriet\u00e0 1 e \\(U \\subseteq U^{'}\\) allora \\(U = U ^{'}\\) \\((x,y) \\in \\tilde E^*\\) se e solo se esiste un walk da x a y. Dato che \\(\\tilde E\\) \u00e8 una relazione simmetrica, \\(\\tilde E^*\\) \u00e8 una relazione di equivalenza. Quindi x e y appartengono alla stessa copmonente connessa solo se appartengono a \\(\\tilde E^*\\) . Quindi le classi di equivalenza di \\(\\tilde E^*\\) sono esattamente le componenti connesse di G. Un grafo \\(G=(V,E)\\) con \\(x,y \\in V\\) : \u00c8 connesso solo se \\(V \\times V = \\tilde E^*\\) \\((x,y) \\in \\tilde E^*\\) se e solo se x ed y appartengono alla stessa componente connessa","title":"Connettivit\u00e0"},{"location":"FdI/grafi/#alberi","text":"Definizione di Albero Un albero \u00e8 un grafo non orientato connesso aciclico e non vuoto. I nodi alle estremit\u00e0, ovvero di grado 1, sono detti foglie , mentre gli altri nodi sono chiamati interni . Definizione di foresta Una foresta \u00e8 un grafo non orientato e aciclico (ed eventualmente non connesso), tale che ogni componente connesssa di una foresta \u00e8 un albero. Dato un albero \\(G=(V,E)\\) , con \\(n = |V|\\) , valgono le seguenti propriet\u00e0: Se \\(n \\geq 2\\) , allora G ha almeno una foglia, ovvero un nodo di grado 1 G ha esattamente \\(n-1\\) archi, overo \\(|E| = n-1\\) Per ogni coppia di nodi distinti \\(x,y \\in V\\) , esiste un unico path da x a y Per ogni arco \\(x y \\in E\\) , la rimozione di \\(x y\\) rende il grafo non connesso Per ogni coppia di nodi distinti \\(x, y \\in V\\) , tale che \\(x y \\notin E\\) , l'aggiunta dell'arco \\(x y\\) crea un ciclo Albero radicato Un albero radicato \\(G = (V,E,r)\\) \u00e8 un albero in cui un suo nodo \\(r \\in V\\) viene chiamato radice. Dato un nodo \\(y \\neq r\\) , i nodi lungi l'unco cammino che va da y ad r vengono chiamati antenati (come in un albero genealogico). Il primo \u00e8 chiamato padre di y. Simmetricamente, y viene detto discendente dei suoi antenati e figlio del suo nodo padre. Sottoalbero Un sottoalbero di \\(G=(V,E,r)\\) con radice \\(r^{'} \\in V\\) \u00e8 l'albero radicato in \\(G^{'} = (V^{'}, E^{'},r^{'})\\) in cui \\(V^{'} \\subseteq V\\) contiene \\(r^{'}\\) e tutti i suoi discendenti in G. \\(E^{'} \\subseteq E\\) contiene tutti gli archi di G tra i nodi \\(V^{'}\\) (quindi \\(E^{'} = E \\cap \\mathcal P_2(V^{'})\\) ) Albero cardinale ed ordinale Un albero radicato si dice ordinale se per ciscuno nodo interno \u00e8 definito un ordinamento totale tra i suoi figli. Si dice cardinale o k-ario se ogni nodo interno ha esattamente k figli, alcuni dei quali possono essere nulli (indicati con null). I figli sono enumerati e sono chiamati figlio0, figlio1, ..., figliok-1. L'albero \u00e8 completo se ogni nodo interno ha tutti e k i figli non vuoti. Un esempio particolare \u00e8 quando \\(k=2\\) , chiamato albero binario , dove il primo figlio viene chiamato figlio destro ed il secondo figlio sinistro . Attenzione: gli alberi cardinali ed ordinali sono strutture diverse: quello che pu\u00f2 essere un albero cardinale non necessariamente \u00e8 ordinale e viceversa.","title":"Alberi"},{"location":"FdI/grafi/#cammini-euleriani-ed-hamiltoniani","text":"Personalmente io ricordo a cosa sono assiciati ricordando che un arco \"viene prima\" di un nodo in termini di requisiti, e quindi mi baso sull'ordine lessicografico (alfabetico) per ricordare che la E di eulero (e la A di archi) vengono prima della h di Hamilton (e la N di nodi)","title":"Cammini euleriani ed hamiltoniani"},{"location":"FdI/grafi/#cammini-euleriani-archi","text":"Circuito e trail euleriano Un circuito eurleriano per un grafo non orientato connesso G \u00e8 un circuito che attraversa tutti gli archi in E una sola volta. Un trail (o percorso) euleriano \u00e8 un trail che attraversa tutti gli archi una e una sola volta. Un grafo contiene un percorso euleriano con estremi diversi se e solo se esattamente due nodi hanno grado dispari . Dato un grafo non orientato connesso \\(G\\) , esiste un circuito euleriano se e solo se ogni nodo ha grado pari. Esiste un percorso euleriano tra due nodi distinti \\(d_x\\) e \\(d_y\\) se e solo se \\(x \\neq y\\)","title":"Cammini euleriani (archi)"},{"location":"FdI/grafi/#cammini-hamiltoniani-nodi","text":"Ciclo e path hamiltoniano Un ciclo hamiltoniano in un grafo orientato connesso \u00e8 un ciclo che attraverssa tutti i nodi in V una ed una sola volta. Un path (o cammino) hamiltoniano \u00e8 un path che attraversa tutti i nodi in V una ed una sola volta. In un grafo possono esistere pi\u00f9 cicli hamiltoniani. Trovare un path hamiltoniano si basa sul trovare una permutazione dei nodi in V che diano luogo ad un path. Non esiste una caratterizzazione che ci permetta di garantire l'esistenza o meno di un ciclo hamiltoniano in G","title":"Cammini hamiltoniani (nodi)"},{"location":"FdI/grafi/#il-problema-del-commesso-viaggiatore","text":"Il problema si basa sul cercare di individuare su una mappa un cammino che permetta ad una persona di attraverare tutto il grafo e tornare indietro percorrendo il minior numero possibile di chilometri. La soluzione pu\u00f2 essere identificata in un ciclo hamiltonianto di un grafo pesato che abbia il costo inferiore Peso di un ciclo hamiltoniano Dato un grafo pesato \\(G=(V,E,L)\\) , il peso di un ciclo hamiltoniano \\(H = v_0,v_1,...,v_k\\) \u00e8 la somma dei pesi degli archi attraversati da H: \\[ peso(H) = \\sum^j_{i = 1} L=(v_{i-1}, v_i) \\]","title":"Il problema del commesso viaggiatore"},{"location":"FdI/grafi/#distanza-su-grafi","text":"Il concetto di distanza a cui ci riferiamo \u00e8 quella euclidea: la distanza che unisce 2 oggetti intesa come distanza di un segmento di retta che li unisce. Distnaza La distanza metica su un insieme A \u00e8 una funzione \\(d: A \\leftrightarrow \\mathbb R\\) che soddisfa le seguenti propriet\u00e0 per ogni \\(x,y,z \\in A\\) : \\(d(x,y) \\geq 0\\) \\(d(x,y) =0\\) se e solo se \\(x = y\\) \\(d(x,y) = d(y, x)\\) (simmetria) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) (distanza triangolare) Una funzione che soddisfa tutte queste propriet\u00e0 tranne la simmetria \u00e8 chiamata distanza quasi-metrica . Distanza su grafo La distanza tra due nodi di un grafo non orientato connesso \u00e8 la lunghezza del walk pi\u00f9 breve tra x e y, chiamato walk minimo Possiamo definire la distanza anche in maniera induttiva: 1. \\(d(x,y) = 0\\) se \\(x=y\\) (caso base) 2. \\(d(x,y) = 1 + min\\{ d(z,y) | z \\in N(x) \\}\\) (passo induttivo) La distanza sui grafi \u00e8 una distanza metrica per i grafi non orientati, mentre \u00e8 quasi-metrica per i grafi orientati, soddisfando il concetto di distanza. Diametro di un grafo Il diametro di un grafo \u00e8 la massima distanza tra coppie di nodi: \\[ diam(G) = \\underset{x,y \\ \\in V}{max } \\ d(x,y) \\] Gli alberi essendo grafi non orientati ereditano il concetto di distanza da questi ultimi. Profondit\u00e0 e altezza di nodi negli alberi In un albero radicato la profondit\u00e0 di un nodo x \u00e8 la sua distanza dalla radice r \\(d(x,r)\\) . L'altezza \u00e8 massima distanza tra x e le sue foglie discentendi. L'altezza di un albero radicato \u00e8 la sua altezza dalla radice. Un albero cardinale si dice pieno se \u00e8 completo e se foglie sono tutte alla stessa distanza dalla radice. La radice r ha sempre profondit\u00e0 0, mentre quella degli altri \u00e8 sempre pari a 1 + la profondit\u00e0 del genitore. Ogni foglia ha altezza 0 ed ogni nodo interno ha altezza pari ad 1 pi\u00f9 il peso massimo tra le altezze dei figli. Per i grafi pensati con pesi non negativi, si considera la somma dei pesi lungo il ammino piuttsoto che la loro lunghezza. Per cammino minimo si intende il cammino pesato avente somma minima. Inoltre in un albero il diametro \u00e8 naturalmente definito, essendo la distanza massima tra coppie di nodi.","title":"Distanza su grafi"},{"location":"FdI/grafi/#isomorfismo","text":"L'isomorfismo \u00e8 una relazione che possiamo stabilire tra due grafi che hanno lo stesso numero di archi e nodi per realizzare che in realt\u00e0 sono lo stesso grafo ma con etichette differenti. Questa relazione pu\u00f2 essere stabilita solo se possiamo trovare una corrispondenza tra i nodi Isomorfismo Dati due qualunque grafi \\(G_1\\) e \\(G_2\\) , con stessa cardinalit\u00e0 di nodi \\(|V_1| = |V_2|\\) ed archi \\(|E_1| = |E_2|\\) , un isomorfismo tra i due grafi \u00e8 una biiezione \\(f: G_1 \\mapsto G_2\\) tale che per ogni coppia di nodi \\(u,v \\in V_1\\) , vale che \\(uv \\in E_1\\) se e solo se \\(f(v)f(v) \\in E_2\\) (esiste il corrispondente arco in entrambi i grafi, oppure non esiste in entrambi). In tal caso \\(G_1\\) e \\(G_2\\) sono detti isomorfi.","title":"Isomorfismo"},{"location":"FdI/grafi/#altri-grafi-noti","text":"Una clique \u00e8 un grafo in cui ogni coppia di nodi \u00e8 collegata da un arco. Un ciclo \u00e8 un grafo ciclico composto da un solo ciclo. Un grafo lineare \u00e8 un grafo aciclico composto da un solo cammino semplice. Una stessa ha un nodo universale con tutti gli altri nodi come foglie.","title":"Altri grafi noti"},{"location":"FdI/induzione/","text":"Induzione matematica \u00b6 L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme. Definizione induttiva \u00b6 Definizione induttiva di un insieme \u00b6 Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via. Definizione induttiva di una funzione \u00b6 La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\) Principio di induzione sui naturali \u00b6 Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\] Principio di induzione forte sui naturali \u00b6 In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Induzione Matematica"},{"location":"FdI/induzione/#induzione-matematica","text":"L'induzione \u00e8 un metodo formale usato effettuare dimostrazioni in modo rigoroso o definiire funzioni o propriet\u00e0 che valgono per ogni insieme.","title":"Induzione matematica"},{"location":"FdI/induzione/#definizione-induttiva","text":"","title":"Definizione induttiva"},{"location":"FdI/induzione/#definizione-induttiva-di-un-insieme","text":"Una definizione induttiva di un insieme ci permette di definire un insieme e si basa su 3 componenti: Passi per una dimostrazione induttiva di un insieme La clausola base Questa clausola serve per stabilire alcuni oggetti che appartengono all'insieme e sono alla base degli altri oggetti che saranno presenti nell'insieme. La clausola induttiva Questa clausola descrive in chhe modo gli elementi dell'insieme possono essere usati per produrre altri elementi delll'insieme La clausola Questa clausola viene usata quando l'insieme che si sta definendo non contiene ulteriori elementi dopo quelli appena descritti. Questo fa s\u00ec che l'insieme definito sia il pi\u00f9 piccolo insieme in grado di soddisfare le due condizioni precedenti. Esempio di definizione induttiva di \\(\\mathbb N\\) \\(0 \\in \\mathbb N\\) Se \\(n \\in \\mathbb N\\) allora \\((n+1) \\in \\mathbb N\\) Nessun altro elemento appartiene ad N In questo insieme diamo come sottointeso il concetto di numero e di addizione. Inoltre stiamo definendo N, ma in funzione di un insieme di numeri pi\u00f9 grande. Con la formula appena descritta possiamo definire tutti i naturali, come 1 ( \\(0 + 1 \\in \\mathbb N\\) ), 3 ( \\(2+1 \\in \\mathbb N\\) ) e cos\u00ec via.","title":"Definizione induttiva di un insieme"},{"location":"FdI/induzione/#definizione-induttiva-di-una-funzione","text":"La definizione di una funzione \u00e8 molto simile a quella insiemistica. Infatti la definzione di una funzione richiede: Il valore della funzione su elementi che riconducono alla clausola base Una regola per calcolare il valore degli elementi che riconduca alla definizione data nella clausola base Notiamo che non \u00e8 presente una clausola terminale. Questo perch\u00e9 siamo certi che i primi due punti siano sufficienti a definire la funzione. Dimostrazione induttiva dei numeri triangolari Un numero triangolare \\(T_n\\) \u00e8 un numero uguale alla solla di tutti i numeri precedenti: \\[ T_n = \\sum_{i=0}^n i \\] Possiamo definire induttivamente con queste due clausole: \\(T_n = 0\\) \\(T_{n+1} = T_n + (n+1)\\)","title":"Definizione induttiva di una funzione"},{"location":"FdI/induzione/#principio-di-induzione-sui-naturali","text":"Il principio di induzione sui naturali \u00e8 un'asserzione che pu\u00f2 essere vera o falsa al variare di \\(n \\in \\mathbb N\\) . Principio di induzione sui naturali Se (Caso base) \\(P(0)\\) \u00e8 vera, e se (Passo induttivo) per ogni \\(n \\in \\mathbb N\\) vale che \\(P(n)\\) \u00e8 vera, allora anche \\(P(n+1)\\) lo \u00e8. Ma se lo \u00e8 , allora \\(P(m)\\) \u00e8 vera per ogni \\(m \\in \\mathbb N\\) Possiamo quindi espimere in modo pi\u00f9 compatto il principio di induzione come una formula di inferenza: \\[ \\frac{P(0) ~ \\forall n \\in \\mathbb N .(P(n) \\Rightarrow P(n+1))}{\\forall m \\in \\mathbb N.P(m)} \\quad \\text{ Principio di induzione} \\]","title":"Principio di induzione sui naturali"},{"location":"FdI/induzione/#principio-di-induzione-forte-sui-naturali","text":"In alcuni casi il principio di induzione non basta in quanto Il princpio dei naturali forte permtte di rafforzare le ipotesi del passo induttivo per effettuare la dimostrazione in maniera pi\u00f9 semplice. Questo viene fatto (formalmente) inglobando il passo base nell'unica premessa: \\[ \\frac{\\forall n . (P(0) \\land P(1) \\land ... \\land P(n-1) \\Rightarrow P(n))}{\\forall m .P(M)} \\quad \\text{ Induzione forte} \\] Da controllare ed eventualmente migliorare","title":"Principio di induzione forte sui naturali"},{"location":"FdI/induzioneRicorsione/","text":"Induzione strutturale e ricorsione \u00b6 La maggior pparte degli oggetti nell'informatica sono definiti induttivamente, ovvero su istanze pi\u00f9 piccole di loro stessi. Le definizione induttive garantiscono la correttezza di una tecnica di dimostrazione chiamata principio di induzione strutturale. Le definizione induttive sono un caso specifico di definizioni ricorsive, che permettono di di definire una funzione in termini del suo valore su oggetti arbitrari (non necessariamente pi\u00f9 piccoli). Liste \u00b6 Le liste sono sequenze di dati di lunghezza variabile, tipicamente di valore omogeneo. Gli oggetti sono in genere denotati tra parentesi quadre [ e ] . La lista buona \u00e8 denotata dal simbolo [] e rappresenta una sequenza senza elementi. Una cosa importante \u00e8 che le liste sono sempre sequenze finite . Cos\u00ec come tutti i numeri naturali possono essere formati partendo da 0 e facendo uso dell'operazione _ + 1 , possiamo fare lo stesso partendo dalla lista vuota [] usando l'operazione a:_ , che aggiunge un elemento \\(a \\in A\\) in testa alla lista. Lista [1,1,2,3] La lista [1,1,2,3] \u00e8 ottenibile come \\(1:(1:(2:(3:[])))\\) . Definizione di lista (induttiva) L'insieme \\(L_A\\) delle liste degli elementi di A \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Clausola base: \\([] \\in L_A\\) (la lista vuota) Passo induttivo: Per ogni \\(a \\in A\\) se \\(lst \\in L_A\\) , allora \\(a:lst \\in L_A\\) (se la lista appartiene a \\(L_A\\) , continuer\u00e0 ad appartenere aggiungendo un nuovo elemento in A) Funzioni su liste \u00b6 \u00c8 possibile sfruttare la definizione induttiva di lista per definire induttivamente funzioni su \\(L_A\\) . Definizione di lunghezza La funzione \\(les: |L_A \\rightarrow \\mathbb N\\) \u00e8 definita per induzione come: Clausola base: \\(len([]) =0\\) Clausola induttiva: \\(len(a:lst) = len(lst) + 1\\) per ogni \\(a \\in A\\) Definizione di somma su lista La funzione \\(sunList(lst): L_{\\mathbb N} \\rightarrow \\mathbb N\\) \u00e8 definita induttivamente come: Clausola base: \\(sumList([]) = 0\\) Clausola induttiva: \\(sumList(n:lst) = sumList(lst) + n\\) per ogni \\(n \\in \\mathbb N\\) Definizione di appartenenza ad una lista Le funzione \\(belList: L_A \\times A \\rightarrow Bool\\) \u00e8 definita (induttivamente) come: Caso base: \\(belList([],b) = f\\) per ogni \\(b \\in A\\) \\(belList(a:lst, b) = t\\) per ogni \\(a,b \\in A\\) tali che \\(a=b\\) \\(belList(a:lst, b) = belList(lst,b)\\) per ogni \\(a,b \\in A\\) tali che \\(a \\ne b\\) Questo algoritmo appena descritto si pu\u00f2 pensare come ad un algoritmo che controlla la lista da sinistra a destra e restituisce t appena trova l'elemento, altrimenti continua fino ad esaurire gli elementi della lista. Concatenazione La funzione \\(app: L_A \\times L_A \\rightarrow L_A\\) si pu\u00f2 definire come: \\(app([], lst_2) = lst_2\\) \\(app(a:lst_1, lst_2) = a:app(lst_1, lst_2)\\) Inversione di liste La funzione \\(rev: L_A \\rightarrow L_A\\) si definisce come: \\(rev([]) = []\\) $rev(a:lst) = app(rev(lst), a:[]) Il principio di induzione sulle liste \u00b6 Il principio di induzione sulle liste Il principio di induzione sulle liste stabilisce che: Caso base: se \\(P([])\\) \u00e8 vera, e Passo induttivo: per ogni \\(a \\in A\\) , per ogni lista \\(lst^{'} \\in L_A\\) se \\(P(lst^{'})\\) \u00e8 vera, allora anche \\(P(a:lst^{'})\\) \u00e8 vera. Allora \\(P(lst)\\) \u00e8 vera per ogni lista in A. Possiamo scrivere questo principio anche come formula di inferenza: \\[ \\frac{P([]) \\quad \\forall a \\in A.\\forall lst^{'} \\in L_A.P(lst^{'}) \\Rightarrow P(a:lst^{'})}{\\forall lst \\in L_A.P(lst)} \\quad \\text{ P.I. su }L_A \\] Alberi binari \u00b6 Alberi binari L'insieme BT degli alberi binari \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda in BT\\) l'albero vuoto se \\(t_1,t_2 \\in BT\\) allora \\(N(t_1,t_2) \\in BT\\) , un nodo con due sottoalberi I due sottoalberi \\(t_1\\) e \\(t_2\\) sono chiami sottoalbero sinistro e sottoalbero destro. Un nodo \u00e8 una foglia se entrambi i suoi sottoalberi sono vuoti, altrimeni \u00e8 un nodo interno. Un esempio di albero binario \u00e8 il seguente: \\[ t = \\underbrace{N}_\\text{radice}(N(\\lambda,N(\\lambda,\\lambda)),N(N(\\lambda,N(\\lambda,\\lambda)), N(\\lambda,\\lambda))) \\] Funzioni su alberi binari \u00b6 Come per le liste, possiamo sfruttare la definizione induttiva degli alberi binari per generare le funzioni. Dimensione La funzione \\(size: BT \\rightarrow \\mathbb N\\) \u00e8 definita come: \\(size(0) = 0\\) $size(N(t_1, t_2)) = size(t_1) + size(t_2) + 1 La funzione size associa ad ogni albero la sua dimensione (ovvero il numero di nodi) Altezza La funzione \\(height: BT \\rightarrow \\mathbb N \\cup \\{-1\\}\\) \u00e8 definita come: \\(height(\\lambda) = -1\\) $height(N(t_1, t_2)) = max(height(t_1), height(t_2)) + 1 La funzione height associa ad ogni albero la sua altezza, ovvero la lunghezza massima di un tral che vada dall radice al nodo pi\u00f9 distante Principio di induzione sugli alberi binari \u00b6 Principio di induzione sugli alberi binari Il principio di induzione sugli alberi binari stabilisce che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(t_1, t_2 \\in BT\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall t_1,t_2 \\in BT.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,t_2)))}{\\forall t \\in BT. P(t)} \\text{ P.I. su BT} \\] Per tutti gli alberi, height(t) <= size(t) Caso base: t = \\(\\lambda\\) \\(height(\\lambda) = -1\\) (clausola base height) \\(-1 \\leq 0\\) \\(= size(\\lambda)\\) Passo induttivo: \\(height(N(t_1, t_2)) = max(height(t_1), height(t_2)) +1\\) (Clausola induttiva height) \\(\\leq max(size(t_1), size(t_2)) +1\\) (Ipotesi induttiva) \\(\\leq size(t_1) + size(t_2) + 1\\) \\(= size(N(t_1, t_2))\\) (Clausola induttiva size) Alberi binari etichettati \u00b6 Definizione strutturale di alberi binari etichettati L'insieme \\(BT_A\\) degli alberi binari etichettati con elementi di un dato insieme A, \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda \\in BT_A\\) (L'albero vuoto) se \\(t_1,t_2 \\in BT_A\\) allora \\(N(t_1, a, t_2) \\in BT_A\\) per ogni \\(a \\in A\\) Funzioni su alberi binari etichettati \u00b6 Appartenenza ad un albero La funzione \\(belBT: BT_A \\times A \\rightarrow Bool\\) \u00e8 definita come: $belBT(\\lambda,b) =f $ \\(belBT(N(t_1,a, t_2),b) = t\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) \\(belBT(N(t_1,a,t_2),b) = belBT(t_1,b) \\lor belBT(t_2,b)\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) Somma su albero La funzione \\(sumBT: BT_N \\rightarrow \\mathcal N\\) \u00e8 definita come induzione come \\(sumBT(\\lambda) = 0\\) \\(sumBT(N(t_1,n,T_2)) = sumBT(t_1) + sumBT(t_2) + n\\) Questa funzione prende l'etichetta \\(n\\) in ogni nodo e la somma con tutti gli altri nodi Visita di un albero in ordine simmetrico La funzione \\(visit: BT_A \\rightarrow L_A\\) \u00e8 definita come: \\(visit(\\lambda)=[\\ ]\\) visit(N(t_1,n,t_2)) = app(visit(t_1),a,visit(t_2)) Questa funzione visita l'albero in ordine simmetrico da sinistra a destra, dato ch eper ogni nodo viene prima visitato il figlio sinistro, poi il nodo stesso e poi il nodo destro. L'ordine della visione pu\u00f2 essere modificato attraverso l'ordine dei parametri della seconda funzione. Principio di induzione sugli alberi binari etichettati \u00b6 Principio di induzione sugli alberi binari etichettati Il principio di induzione sugli alberi binari stabilisce un concetto simile a quello che vale per gli alberi binari, con l'unica accortezza di ferificare P su che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(a \\in A\\) , per ogni \\(t_1, t_2 \\in BT_A\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,a,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT_A\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall a \\in A, \\forall t_1,t_2 \\in BT_A.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,a,t_2)))}{\\forall t \\in BT_A. P(t)} \\text{ P.I. su } BT_A \\] L'induzione strutturale \u00b6 L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\] Rappresentazione grafica dei termini \u00b6 \u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) . Alberi \u00b6 TODO Rappresentazione di alberi binari come termini \u00b6 Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Liste \u00b6 TODO Rappresentazione di liste come termini \u00b6 Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\) Naturali \u00b6 Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Funzioni su termini \u00b6 \u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm \\times \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base) Il principio di Induzione Strutturale \u00b6 Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene Funzioni ricorsive \u00b6 Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita. Relazione di precedenza indotta da una funzione ricorsiva Data una definizione ricordiva di \\(rec: A \\rightarrow B\\) , la lreazione di precedenza indotta \u00e8 la relazione \\(\\prec_{rec} \\in Rel(A,A)\\) definita come: Per ogni \\(x,y \\in A, x \\prec_{rec} y\\) se e solo se \\(rec(y)\\) \u00e8 definita direttamente in termini di \\(rec(x)\\) Questa definizione non \u00e8 necessariamente aciclica Quindi, data la definizione di precedenza, possiamo presentare alcune relazioni di precedenza: \\(\\prec_{due} \\in Rel(\\mathbb N,\\mathbb N)\\) , definita come \\(n+1 \\prec_{due}n\\) se \\(n \\leq 100\\) \\(\\prec_g \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(n+1\\prec_g n\\) se \\(n > 0\\) \\(\\prec_f \\in Rel(\\mathbb Z,\\mathbb Z)\\) definita come \\(n-1 \\prec_f n\\) se \\(n \\in \\mathbb Z\\) \\(\\prec_h \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(\\prec_h = \\{ (n-2,n) | n \\geq 2 \\} \\cup \\{(3,1)\\}\\) Quindi, se \\(b \\prec_{rec} a\\) , devo valutare \\(rec(b)\\) per poter valutare \\(rec(a)\\) . Ma se una funzione \u00e8 definita solamente in termin di s\u00e9 stessa, la valutazione non termina mai. Relazione ben fondata Una relazione \\(\\sqsubset\\) su un insieme A, definita come \\(\\sqsubset \\in Rel(A,A)\\) , si dice ben fondata se non esiste una catena infinita decrescente \\[ a_1 \\sqsupset a_2 \\sqsupset a_3 \\sqsupset ... \\] di elementi \\(a_i\\) su A Possiamo quindi dire che una funzione non \u00e8 ben fondata quando \u00e8 definita infinite volte su se stessa. Al contrario, una definizione ricorsiva di \\(rec: A \\rightarrow B\\) \u00e8 ben data (ovvero \u00e8 totale ed univalente) quando: Per ogni elemento \\(a \\in A\\) c'\u00e8 esattamente una clausola della definizione applicabile per valutare \\(rec(a)\\) La relazione \\(\\prec_{rec}\\) \u00e8 ben fondata Le definizioni induttive sono sempre ben date: relazioni di precedenza indotta da definizione induttiva Data una definizione induttiva di un insieme A, la relazione di precedenza indotta \u00e8 \\(\\prec_A \\in Rel(A,A)\\) . Questo \u00e8 dato dal fatto che, se per la clausola induttiva l'elemento a appartiene all'insieme ci appartengono \\(a_1,...,a_n\\) : \\(a_1 \\prec_A a,a_2 \\prec_A a,...,a_k \\prec_A a\\) Questa definizione pu\u00f2 essere applicata a qualunque definizione induttiva, mantenuta cos\u00ec generale grazie al concetto di f-termine : Per ogni \\(n \\geq 1\\) , per ogni \\(f \\in \\mathbb F\\) , \\(t_1 \\prec f(t_1, ...,t_2), \\quad t_2 \\prec f(t_1,...,t_2),..., t_n \\prec f(t_1,...,t_n)\\) Quindi una relazione definita tramite induttiva \u00e8 ben data poihc\u00e9 l'insieme caratterizzato \u00e8 il pi\u00f9 piccolo che soddisfa clausola base e passo induttivo: ogni elemento dell'insieme appartiene ad una sequenza finita di di applicazioni della clausola induttiva, che garantisce che la relazione \\(\\prec\\) \u00e8 ben fondata. Possiamo quindi determinare delle propriet\u00e0: Se \\(\\sqsubset\\) \u00e8 ben fondata, e \\(\\sqsubset_1 \\subseteq \\sqsubset\\) , allora anche \\(\\sqsubset_1\\) \u00e8 ben fondata. Una relazione \\(\\sqsubset\\) \u00e8 ben fondata solo se lo \u00e8 la sua chiusura transitiva \\(\\sqsubset^+\\) La congettura di Collatz \u00b6 La congettura di Collatz afferma che una funzione come questa: \\[ f(n) = \\begin{cases} 1 & \\text{ se } n \\leq 1 \\\\ f(n/2) & \\text{ se } n >1 \\text { ed \u00e8 pari} \\\\ f(3 \\cdot n+1) & \\text{ se } n>1 \\text { ed \u00e8 dispari} \\end{cases} \\] \u00e8 totale, tuttavia non \u00e8 stato determinato se \u00e8 cos\u00ec per ogni valore \\(k \\in \\mathbb N\\) Tipologie di ricorsione \u00b6 Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta Ricorsione annidata \u00b6 Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata Un esempio di ricorsione annidata \u00e8 data dall'equazione di McCarthy: \\[ f(n) = \\begin{cases} n-10 & \\text{ se } n>100 \\\\ f(f(n+11)) & \\text{ se } n \\leq 100 \\end{cases} \\] Ricorsione mutua \u00b6 La recusione si dice mutua quando la chiamata avviene indirettamente, ovvero da parte di una seconda funzione chiamata a suoa volta direttamente o indirettamente dalla prima. Esempio di ricosione mutua $$ ping(n) = \\begin{cases} 0 & \\text{ se } n=0 \\ pong(n-1) & \\text{ altrimenti } \\end{cases} pong(n) = \\begin{cases} 0 & \\text{ se } n=100 \\ ping(n-1) & \\text{ altrimenti } \\end{cases} $$ Ricorsione procedurale \u00b6 Le ricorsioni procedurali sono funzioni scritte attraverso linguaggi di programmazione, che possono avere collaterali come input, output, stampa a schermo ecc... void stampa_array ( int a [], int i , int n ){ if ( i < n ){ // Clausola ricorsiva: c'\u00e8 andora qulcosa da stampare printf ( \"%d\" , a [ i ]); stampa_array ( a , i + 1 , n ); } //Clausola base: i == n; l'array a[i..n-1] \u00e8 vuoto, la procedura termina }","title":"Induzione Strutturale e Ricorsione"},{"location":"FdI/induzioneRicorsione/#induzione-strutturale-e-ricorsione","text":"La maggior pparte degli oggetti nell'informatica sono definiti induttivamente, ovvero su istanze pi\u00f9 piccole di loro stessi. Le definizione induttive garantiscono la correttezza di una tecnica di dimostrazione chiamata principio di induzione strutturale. Le definizione induttive sono un caso specifico di definizioni ricorsive, che permettono di di definire una funzione in termini del suo valore su oggetti arbitrari (non necessariamente pi\u00f9 piccoli).","title":"Induzione strutturale e ricorsione"},{"location":"FdI/induzioneRicorsione/#liste","text":"Le liste sono sequenze di dati di lunghezza variabile, tipicamente di valore omogeneo. Gli oggetti sono in genere denotati tra parentesi quadre [ e ] . La lista buona \u00e8 denotata dal simbolo [] e rappresenta una sequenza senza elementi. Una cosa importante \u00e8 che le liste sono sempre sequenze finite . Cos\u00ec come tutti i numeri naturali possono essere formati partendo da 0 e facendo uso dell'operazione _ + 1 , possiamo fare lo stesso partendo dalla lista vuota [] usando l'operazione a:_ , che aggiunge un elemento \\(a \\in A\\) in testa alla lista. Lista [1,1,2,3] La lista [1,1,2,3] \u00e8 ottenibile come \\(1:(1:(2:(3:[])))\\) . Definizione di lista (induttiva) L'insieme \\(L_A\\) delle liste degli elementi di A \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Clausola base: \\([] \\in L_A\\) (la lista vuota) Passo induttivo: Per ogni \\(a \\in A\\) se \\(lst \\in L_A\\) , allora \\(a:lst \\in L_A\\) (se la lista appartiene a \\(L_A\\) , continuer\u00e0 ad appartenere aggiungendo un nuovo elemento in A)","title":"Liste"},{"location":"FdI/induzioneRicorsione/#funzioni-su-liste","text":"\u00c8 possibile sfruttare la definizione induttiva di lista per definire induttivamente funzioni su \\(L_A\\) . Definizione di lunghezza La funzione \\(les: |L_A \\rightarrow \\mathbb N\\) \u00e8 definita per induzione come: Clausola base: \\(len([]) =0\\) Clausola induttiva: \\(len(a:lst) = len(lst) + 1\\) per ogni \\(a \\in A\\) Definizione di somma su lista La funzione \\(sunList(lst): L_{\\mathbb N} \\rightarrow \\mathbb N\\) \u00e8 definita induttivamente come: Clausola base: \\(sumList([]) = 0\\) Clausola induttiva: \\(sumList(n:lst) = sumList(lst) + n\\) per ogni \\(n \\in \\mathbb N\\) Definizione di appartenenza ad una lista Le funzione \\(belList: L_A \\times A \\rightarrow Bool\\) \u00e8 definita (induttivamente) come: Caso base: \\(belList([],b) = f\\) per ogni \\(b \\in A\\) \\(belList(a:lst, b) = t\\) per ogni \\(a,b \\in A\\) tali che \\(a=b\\) \\(belList(a:lst, b) = belList(lst,b)\\) per ogni \\(a,b \\in A\\) tali che \\(a \\ne b\\) Questo algoritmo appena descritto si pu\u00f2 pensare come ad un algoritmo che controlla la lista da sinistra a destra e restituisce t appena trova l'elemento, altrimenti continua fino ad esaurire gli elementi della lista. Concatenazione La funzione \\(app: L_A \\times L_A \\rightarrow L_A\\) si pu\u00f2 definire come: \\(app([], lst_2) = lst_2\\) \\(app(a:lst_1, lst_2) = a:app(lst_1, lst_2)\\) Inversione di liste La funzione \\(rev: L_A \\rightarrow L_A\\) si definisce come: \\(rev([]) = []\\) $rev(a:lst) = app(rev(lst), a:[])","title":"Funzioni su liste"},{"location":"FdI/induzioneRicorsione/#il-principio-di-induzione-sulle-liste","text":"Il principio di induzione sulle liste Il principio di induzione sulle liste stabilisce che: Caso base: se \\(P([])\\) \u00e8 vera, e Passo induttivo: per ogni \\(a \\in A\\) , per ogni lista \\(lst^{'} \\in L_A\\) se \\(P(lst^{'})\\) \u00e8 vera, allora anche \\(P(a:lst^{'})\\) \u00e8 vera. Allora \\(P(lst)\\) \u00e8 vera per ogni lista in A. Possiamo scrivere questo principio anche come formula di inferenza: \\[ \\frac{P([]) \\quad \\forall a \\in A.\\forall lst^{'} \\in L_A.P(lst^{'}) \\Rightarrow P(a:lst^{'})}{\\forall lst \\in L_A.P(lst)} \\quad \\text{ P.I. su }L_A \\]","title":"Il principio di induzione sulle liste"},{"location":"FdI/induzioneRicorsione/#alberi-binari","text":"Alberi binari L'insieme BT degli alberi binari \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda in BT\\) l'albero vuoto se \\(t_1,t_2 \\in BT\\) allora \\(N(t_1,t_2) \\in BT\\) , un nodo con due sottoalberi I due sottoalberi \\(t_1\\) e \\(t_2\\) sono chiami sottoalbero sinistro e sottoalbero destro. Un nodo \u00e8 una foglia se entrambi i suoi sottoalberi sono vuoti, altrimeni \u00e8 un nodo interno. Un esempio di albero binario \u00e8 il seguente: \\[ t = \\underbrace{N}_\\text{radice}(N(\\lambda,N(\\lambda,\\lambda)),N(N(\\lambda,N(\\lambda,\\lambda)), N(\\lambda,\\lambda))) \\]","title":"Alberi binari"},{"location":"FdI/induzioneRicorsione/#funzioni-su-alberi-binari","text":"Come per le liste, possiamo sfruttare la definizione induttiva degli alberi binari per generare le funzioni. Dimensione La funzione \\(size: BT \\rightarrow \\mathbb N\\) \u00e8 definita come: \\(size(0) = 0\\) $size(N(t_1, t_2)) = size(t_1) + size(t_2) + 1 La funzione size associa ad ogni albero la sua dimensione (ovvero il numero di nodi) Altezza La funzione \\(height: BT \\rightarrow \\mathbb N \\cup \\{-1\\}\\) \u00e8 definita come: \\(height(\\lambda) = -1\\) $height(N(t_1, t_2)) = max(height(t_1), height(t_2)) + 1 La funzione height associa ad ogni albero la sua altezza, ovvero la lunghezza massima di un tral che vada dall radice al nodo pi\u00f9 distante","title":"Funzioni su alberi binari"},{"location":"FdI/induzioneRicorsione/#principio-di-induzione-sugli-alberi-binari","text":"Principio di induzione sugli alberi binari Il principio di induzione sugli alberi binari stabilisce che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(t_1, t_2 \\in BT\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall t_1,t_2 \\in BT.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,t_2)))}{\\forall t \\in BT. P(t)} \\text{ P.I. su BT} \\] Per tutti gli alberi, height(t) <= size(t) Caso base: t = \\(\\lambda\\) \\(height(\\lambda) = -1\\) (clausola base height) \\(-1 \\leq 0\\) \\(= size(\\lambda)\\) Passo induttivo: \\(height(N(t_1, t_2)) = max(height(t_1), height(t_2)) +1\\) (Clausola induttiva height) \\(\\leq max(size(t_1), size(t_2)) +1\\) (Ipotesi induttiva) \\(\\leq size(t_1) + size(t_2) + 1\\) \\(= size(N(t_1, t_2))\\) (Clausola induttiva size)","title":"Principio di induzione sugli alberi binari"},{"location":"FdI/induzioneRicorsione/#alberi-binari-etichettati","text":"Definizione strutturale di alberi binari etichettati L'insieme \\(BT_A\\) degli alberi binari etichettati con elementi di un dato insieme A, \u00e8 il pi\u00f9 piccolo insieme che soddisfa: \\(\\lambda \\in BT_A\\) (L'albero vuoto) se \\(t_1,t_2 \\in BT_A\\) allora \\(N(t_1, a, t_2) \\in BT_A\\) per ogni \\(a \\in A\\)","title":"Alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#funzioni-su-alberi-binari-etichettati","text":"Appartenenza ad un albero La funzione \\(belBT: BT_A \\times A \\rightarrow Bool\\) \u00e8 definita come: $belBT(\\lambda,b) =f $ \\(belBT(N(t_1,a, t_2),b) = t\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) \\(belBT(N(t_1,a,t_2),b) = belBT(t_1,b) \\lor belBT(t_2,b)\\) per ogni \\(a,b \\in A\\) tale che \\(a \\neq b\\) Somma su albero La funzione \\(sumBT: BT_N \\rightarrow \\mathcal N\\) \u00e8 definita come induzione come \\(sumBT(\\lambda) = 0\\) \\(sumBT(N(t_1,n,T_2)) = sumBT(t_1) + sumBT(t_2) + n\\) Questa funzione prende l'etichetta \\(n\\) in ogni nodo e la somma con tutti gli altri nodi Visita di un albero in ordine simmetrico La funzione \\(visit: BT_A \\rightarrow L_A\\) \u00e8 definita come: \\(visit(\\lambda)=[\\ ]\\) visit(N(t_1,n,t_2)) = app(visit(t_1),a,visit(t_2)) Questa funzione visita l'albero in ordine simmetrico da sinistra a destra, dato ch eper ogni nodo viene prima visitato il figlio sinistro, poi il nodo stesso e poi il nodo destro. L'ordine della visione pu\u00f2 essere modificato attraverso l'ordine dei parametri della seconda funzione.","title":"Funzioni su alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#principio-di-induzione-sugli-alberi-binari-etichettati","text":"Principio di induzione sugli alberi binari etichettati Il principio di induzione sugli alberi binari stabilisce un concetto simile a quello che vale per gli alberi binari, con l'unica accortezza di ferificare P su che: Caso base: \\(P(\\lambda)\\) \u00e8 vera Passo induttivo: Per ogni \\(a \\in A\\) , per ogni \\(t_1, t_2 \\in BT_A\\) , vale che se \\(P(t_1)\\) \u00e8 vera e \\(P(t_2)\\) \u00e8 vera, allora anchr \\(P(N(t_1,a,t_2))\\) \u00e8 vera. Allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in BT_A\\) . Possiamo esprimere questo concetto anche attraverso una regola di inferenza: \\[ \\frac{P(\\lambda) \\quad \\forall a \\in A, \\forall t_1,t_2 \\in BT_A.(P(t_1) \\land P(t_2) \\Rightarrow P(N(t_1,a,t_2)))}{\\forall t \\in BT_A. P(t)} \\text{ P.I. su } BT_A \\]","title":"Principio di induzione sugli alberi binari etichettati"},{"location":"FdI/induzioneRicorsione/#linduzione-strutturale","text":"L'induzione strutturale ci permette di: Definire in maniera induttiva delle strutture (dati) Definire induttivamente delle funzioni sulle strutture Dimostrare delle propriet\u00e0 sulle strutture dati usando il principio di Induzione Il tutto in maniera generale ed usando una struttura chiamata termini , definiti parametricamente su una segnatura . Definizione di Segnatura Una segnatura \u00e8 una famiglia di insiemi indicizzata da \\(\\mathbb{N}\\) ( \\(\\mathcal{F} = \\{\\mathcal{F}_n\\}_{n \\in \\mathbb{N} }\\) ) i cui elementi di ogni famiglia sono detti simboli . Questi elementi ci permettono di elencare e descrivere i simboli di un linguaggio formale. \\(\\mathcal{F}_n\\) \u00e8 l insieme dei simboli di ariet\u00e0 n (o con n argomenti). I simboli di ariet\u00e0 0 sono detti simboli di costante . Si pu\u00f2 pensare ai simboli \\(\\mathcal{F}\\) come funzioni, la cui arit\u00e0 definisce il numero di argomenti che le funzioni in quella famiglia prenderanno in input. In base al numero di argomenti, le funzioni possono assumere diversi nomi: Ariet\u00e0 Simboli 0 Constanti 1 Unari 2 Binari k k-arai Esempio di segnatura Prendiamo in considerazione la segnatura \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Quindi \\(a\\) e \\(b\\) sono termini costanti, \\(f\\) \u00e8 un termine unario e \\(g\\) \u00e8 un termine binario. Definizione di Termine Data una segnatura \\(\\mathcal{F}\\) , l'insieme \\(\\mathcal{F}Term\\) degli \\(\\mathcal{F}\\) -termini \u00e8 il pi\u00f9 piccolo insieme che soddisfa: Per ogni simbolo \\(c \\in \\mathcal{F}_0, c \\in \\mathcal{F}Term\\) (Ogni simbolo costante \u00e8 un (F-)termine) Per ogni \\(n \\geq 1\\) ed ogni simbolo \\(f \\in \\mathcal{F}_n\\) se \\(t_1,...,t_n \\in \\mathcal{F}Term\\) allora \\(f(t_1,...,t_n) \\in \\mathcal{F}Term\\) (Per ogni segnatura in ogni famiglia, se la segnatura \u00e8 chiamata con un numero di argomenti pari alla sua arit\u00e0, la segnatura \u00e8 un (F-)termine) Esempio di termini Continuando con l'esempio riportato sopra, \\(\\mathcal{F}\\) : \\[ \\mathcal{F}_0 = \\\\{ a, b \\\\} \\qquad \\mathcal{F}_1 = \\\\{ f \\\\} \\qquad \\mathcal{F}_2 = \\\\{ g \\\\} \\qquad \\mathcal{F}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\] Essendo \\(a\\) e \\(b\\) termini costanti, sono termini di F. Essendo \\(f\\) un termine unario, scritture come \\[ f(a)\\qquad f(b)\\qquad f(f(a))\\qquad f(f(b))\\qquad f(f(f(f(b))))\\qquad \\] sono termini di F. Essendo \\(g\\) un termine binario, scritture come \\[ g(a,b)\\qquad g(b,a)\\qquad g(f(a), b)\\qquad g(f(f(b)),a)\\qquad \\] sono termini di F. Non sono invece termini scritture come le seguenti: \\[ f(a,b)\\qquad g(a) \\qquad g(a,a,b) \\qquad g \\qquad f \\qquad f(b,b,b,b,b) \\]","title":"L'induzione strutturale"},{"location":"FdI/induzioneRicorsione/#rappresentazione-grafica-dei-termini","text":"\u00c8 inoltre possibile rappresentare i termini in maniera grafica sottoforma di alberi radicati. Ogni nodo dell'albero avr\u00e0 un'etichetta con un simbolo in \\(\\mathcal{F}\\) .","title":"Rappresentazione grafica dei termini"},{"location":"FdI/induzioneRicorsione/#alberi","text":"TODO","title":"Alberi"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-alberi-binari-come-termini","text":"Gli alberi binari possono essere rappresentati la seguente segnatura \\(\\mathcal{BT}\\) : \\[ \\mathcal{BT}_0 = \\\\{\\lambda\\\\} \\qquad \\mathcal{BT}_1 = \\varnothing \\qquad \\mathcal{BT}_2 = \\\\{N\\\\} \\qquad \\mathcal{BT}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 3 \\]","title":"Rappresentazione di alberi binari come termini"},{"location":"FdI/induzioneRicorsione/#liste_1","text":"TODO","title":"Liste"},{"location":"FdI/induzioneRicorsione/#rappresentazione-di-liste-come-termini","text":"Le liste possono essere rappresentate utilizzando la seguente segnatura \\(\\mathcal{L}^A\\) : \\[ \\mathcal{L}^A_0 = \\\\{[ ~ ]\\\\} \\qquad \\mathcal{L}^A_1 = \\\\{a: ~ | ~ a \\in A\\\\} \\qquad \\mathcal{L}^A_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\] Che avr\u00e0 quindi come unica costante la segnatura \\([ ~ ]\\) ed un operatore unario \\(a :\\) per ogni \\(a \\in A\\)","title":"Rappresentazione di liste come termini"},{"location":"FdI/induzioneRicorsione/#naturali","text":"Anche i Naturali possono essere rappresentati come termini, con la seguente segnatura: \\[ \\mathcal{N}_0 = \\\\{Z\\\\} \\qquad \\mathcal{N}_1 = \\\\{S\\\\} \\qquad \\mathcal{N}_n = \\varnothing ~ per ~ ogni ~ n ~ \\geq 2 \\]","title":"Naturali"},{"location":"FdI/induzioneRicorsione/#funzioni-su-termini","text":"\u00c8 possibile definire delle funzioni (fin'ora definite induttivamente) in maniera pi\u00f9 generale facendo uso dei termini. Definire una funzione su \\(\\mathcal FTerm\\) (insieme dei termini per una segnatura \\(\\mathcal F\\) ) \u00e8 possibile in 2 passi: Definire il valore della funzione per i simboli di ariet\u00e0 0 (le costanti). Definire il valore della funzione per ogni simbolo di ariet\u00e0 \\(n \\geq 1\\) . Ricordare \u00e8 che possibile usare il valore appena calcolato per ogniuno degli altri n-valori. Valutazione di \\(\\mathcal N\\) -Termini La funzione \\(val: \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(val(Z) = 0\\) \\(val(S(x)) = val(x) + 1\\) Che con l'esempio \\(val(S(S(S(Z))))\\) pu\u00f2 essere sviluppata in questo modo: \\(val(S(S(S(Z))))=\\) \\(val(S(S(Z))) + 1=\\) (clausola induttiva) \\(val(S(Z)) + 1 + 1=\\) (clausola induttiva) \\(val(Z) + 1 + 1 + 1=\\) (clausola induttiva) \\(0 + 1 + 1 + 1=\\) (clausola base) \\(3\\) Somma di \\(\\mathcal N\\) -Termini La funzione \\(add: \\mathcal NTerm \\times \\mathcal NTerm \\rightarrow \\mathbb N\\) pu\u00f2 essere definita induttivamente seguendo le propriet\u00e0 appena descritte: \\(add(x, Z) = x\\) \\(add(x, S(y)) = S(add(x,y))\\) Che con l'esempio \\(add(S(S(S(Z))), S(S(Z)))\\) pu\u00f2 essere sviluppata in questo modo: \\(add(S(S(S(Z))), S(S(Z)))=\\) \\(S(add(S(S(S(Z))), S(Z))=\\) (clausola induttiva) \\(S(S(add(S(S(S(Z))), Z)))=\\) (clausola induttiva) \\(S(S(S(S(S(Z)))))=\\) (clausola base)","title":"Funzioni su termini"},{"location":"FdI/induzioneRicorsione/#il-principio-di-induzione-strutturale","text":"Il Principio di Induzione Strutturale viene anche chiamato Principio di Induzione sui termini e stabilisce che: Principio di Induzione Strutturale (Caso base) Se per ogni simbolo \\(c \\in \\mathcal F_0, P(c)\\) \u00e8 vera (la propriet\u00e0 \\(P\\) \u00e8 vera per ogni simbolo costante) (Passo induttivo) Se per ogni \\(n \\geq 1\\) , per ogni simbolo \\(f \\in \\mathcal F_n\\) , per tutti i termini \\(t_1,...,t_n \\in \\mathcal FTerm\\) , vale che se \\(P(t_1),...,P(t_n)\\) sono vere, allora anche \\(P(f(t_1,...,t_n))\\) \u00e8 vera (per ogni simbolo non costante di arit\u00e0 N, se \\(P\\) vale per tutti gli N argomenti F-Termini, allora \\(P\\) vale anche per il simbolo) allora \\(P(t)\\) \u00e8 vera per ogni \\(t \\in \\mathcal FTerm\\) Ma non l'ho gi\u00e0 detto? Trascrivere a p. 7-21 esempio di val(add(x,y)) = val(x) + val(y)?? Molto povera questa sezione, da capire bene","title":"Il principio di Induzione Strutturale"},{"location":"FdI/induzioneRicorsione/#funzioni-ricorsive","text":"Le funzioni definite induttivamente sono un caso particolare di funzioni ricorsive. Definizione ricorsiva Una funzione \u00e8 detta ricorsiva se il valore della funzione per un certo argomento \u00e8 espresso in termini del valore della stessa funzione applcata a uno o pi\u00f9 argomenti, non necessariamente pi\u00f9 piccoli Il numero di passi per la risoluzione di una funzione non sempre segue una regola precisa. Inoltre non sempre una funzione ricorsiva risulta calcolabile: Il Teorema di Rice (facente parte del Teorema della Calcolabilit\u00e0 ) afferma che ~non esiste un procedimento universale~ che permtta di determinare con esattezza se una funzione recursiva \u00e8 totale (e quindi \u00e8 una funzione; in caso contrario sarebbe una funzione parziale ) \u00c8 possibile per\u00f2 individuare delle condizioni sufficienti che ci permettano di garantire che una definizione ricorsiva sia ben data (o ben definita). Ci interessa che la funzione ricorsiva sia totale perch\u00e9 se cos\u00ec non fosse, implicherebbe che valutando tale funzione incorreremmo in una computazione infinita. Relazione di precedenza indotta da una funzione ricorsiva Data una definizione ricordiva di \\(rec: A \\rightarrow B\\) , la lreazione di precedenza indotta \u00e8 la relazione \\(\\prec_{rec} \\in Rel(A,A)\\) definita come: Per ogni \\(x,y \\in A, x \\prec_{rec} y\\) se e solo se \\(rec(y)\\) \u00e8 definita direttamente in termini di \\(rec(x)\\) Questa definizione non \u00e8 necessariamente aciclica Quindi, data la definizione di precedenza, possiamo presentare alcune relazioni di precedenza: \\(\\prec_{due} \\in Rel(\\mathbb N,\\mathbb N)\\) , definita come \\(n+1 \\prec_{due}n\\) se \\(n \\leq 100\\) \\(\\prec_g \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(n+1\\prec_g n\\) se \\(n > 0\\) \\(\\prec_f \\in Rel(\\mathbb Z,\\mathbb Z)\\) definita come \\(n-1 \\prec_f n\\) se \\(n \\in \\mathbb Z\\) \\(\\prec_h \\in Rel(\\mathbb N,\\mathbb N)\\) definita come \\(\\prec_h = \\{ (n-2,n) | n \\geq 2 \\} \\cup \\{(3,1)\\}\\) Quindi, se \\(b \\prec_{rec} a\\) , devo valutare \\(rec(b)\\) per poter valutare \\(rec(a)\\) . Ma se una funzione \u00e8 definita solamente in termin di s\u00e9 stessa, la valutazione non termina mai. Relazione ben fondata Una relazione \\(\\sqsubset\\) su un insieme A, definita come \\(\\sqsubset \\in Rel(A,A)\\) , si dice ben fondata se non esiste una catena infinita decrescente \\[ a_1 \\sqsupset a_2 \\sqsupset a_3 \\sqsupset ... \\] di elementi \\(a_i\\) su A Possiamo quindi dire che una funzione non \u00e8 ben fondata quando \u00e8 definita infinite volte su se stessa. Al contrario, una definizione ricorsiva di \\(rec: A \\rightarrow B\\) \u00e8 ben data (ovvero \u00e8 totale ed univalente) quando: Per ogni elemento \\(a \\in A\\) c'\u00e8 esattamente una clausola della definizione applicabile per valutare \\(rec(a)\\) La relazione \\(\\prec_{rec}\\) \u00e8 ben fondata Le definizioni induttive sono sempre ben date: relazioni di precedenza indotta da definizione induttiva Data una definizione induttiva di un insieme A, la relazione di precedenza indotta \u00e8 \\(\\prec_A \\in Rel(A,A)\\) . Questo \u00e8 dato dal fatto che, se per la clausola induttiva l'elemento a appartiene all'insieme ci appartengono \\(a_1,...,a_n\\) : \\(a_1 \\prec_A a,a_2 \\prec_A a,...,a_k \\prec_A a\\) Questa definizione pu\u00f2 essere applicata a qualunque definizione induttiva, mantenuta cos\u00ec generale grazie al concetto di f-termine : Per ogni \\(n \\geq 1\\) , per ogni \\(f \\in \\mathbb F\\) , \\(t_1 \\prec f(t_1, ...,t_2), \\quad t_2 \\prec f(t_1,...,t_2),..., t_n \\prec f(t_1,...,t_n)\\) Quindi una relazione definita tramite induttiva \u00e8 ben data poihc\u00e9 l'insieme caratterizzato \u00e8 il pi\u00f9 piccolo che soddisfa clausola base e passo induttivo: ogni elemento dell'insieme appartiene ad una sequenza finita di di applicazioni della clausola induttiva, che garantisce che la relazione \\(\\prec\\) \u00e8 ben fondata. Possiamo quindi determinare delle propriet\u00e0: Se \\(\\sqsubset\\) \u00e8 ben fondata, e \\(\\sqsubset_1 \\subseteq \\sqsubset\\) , allora anche \\(\\sqsubset_1\\) \u00e8 ben fondata. Una relazione \\(\\sqsubset\\) \u00e8 ben fondata solo se lo \u00e8 la sua chiusura transitiva \\(\\sqsubset^+\\)","title":"Funzioni ricorsive"},{"location":"FdI/induzioneRicorsione/#la-congettura-di-collatz","text":"La congettura di Collatz afferma che una funzione come questa: \\[ f(n) = \\begin{cases} 1 & \\text{ se } n \\leq 1 \\\\ f(n/2) & \\text{ se } n >1 \\text { ed \u00e8 pari} \\\\ f(3 \\cdot n+1) & \\text{ se } n>1 \\text { ed \u00e8 dispari} \\end{cases} \\] \u00e8 totale, tuttavia non \u00e8 stato determinato se \u00e8 cos\u00ec per ogni valore \\(k \\in \\mathbb N\\)","title":"La congettura di Collatz"},{"location":"FdI/induzioneRicorsione/#tipologie-di-ricorsione","text":"Esistono vari tipi di ricorsione, oltre alla tipologia vista fin'ora, chiamata Ricorsione diretta","title":"Tipologie di ricorsione"},{"location":"FdI/induzioneRicorsione/#ricorsione-annidata","text":"Questo tipo di ricorsione si ha quando una funzione ricorsiva richiama, nel proprio corpo, s\u00e9 stessa E s\u00e9 stessa come parametro, chiamando la funzione 2 volte Esempio di ricosione annidata Un esempio di ricorsione annidata \u00e8 data dall'equazione di McCarthy: \\[ f(n) = \\begin{cases} n-10 & \\text{ se } n>100 \\\\ f(f(n+11)) & \\text{ se } n \\leq 100 \\end{cases} \\]","title":"Ricorsione annidata"},{"location":"FdI/induzioneRicorsione/#ricorsione-mutua","text":"La recusione si dice mutua quando la chiamata avviene indirettamente, ovvero da parte di una seconda funzione chiamata a suoa volta direttamente o indirettamente dalla prima. Esempio di ricosione mutua $$ ping(n) = \\begin{cases} 0 & \\text{ se } n=0 \\ pong(n-1) & \\text{ altrimenti } \\end{cases} pong(n) = \\begin{cases} 0 & \\text{ se } n=100 \\ ping(n-1) & \\text{ altrimenti } \\end{cases} $$","title":"Ricorsione mutua"},{"location":"FdI/induzioneRicorsione/#ricorsione-procedurale","text":"Le ricorsioni procedurali sono funzioni scritte attraverso linguaggi di programmazione, che possono avere collaterali come input, output, stampa a schermo ecc... void stampa_array ( int a [], int i , int n ){ if ( i < n ){ // Clausola ricorsiva: c'\u00e8 andora qulcosa da stampare printf ( \"%d\" , a [ i ]); stampa_array ( a , i + 1 , n ); } //Clausola base: i == n; l'array a[i..n-1] \u00e8 vuoto, la procedura termina }","title":"Ricorsione procedurale"},{"location":"FdI/insiemi/","text":"Gli insiemi \u00b6 Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti Definizione di insiemi \u00b6 Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole. Definzione per Enumerazione \u00b6 L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale ! L'insieme vuoto \u00b6 L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\) Definizione per Propriet\u00e0 \u00b6 \u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\) I paradossi \u00b6 In base alle definizioni date, si possono verificare dei paradossi. Il paradosso di Russel \u00b6 Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato Diagrammi di Eulero-Venn \u00b6 I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 I confronti tra insiemi \u00b6 Uguaglianza \u00b6 Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ). Inclusione \u00b6 Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) . Operazioni su insiemi \u00b6 Unione \u00b6 Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) . Intersezione \u00b6 Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\) Differenza \u00b6 Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\) Complemento \u00b6 Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\] Operatori booleani \u00b6 I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica . Le leggi \u00b6 Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali. Dimostrazioni \u00b6 Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive Dimostrazione grafica \u00b6 La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo. Dimostrazione per sostituzione \u00b6 Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0) Dimostrazione discorsive \u00b6 Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente Insiemi di insiemi \u00b6 Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\) Famiglie di insiemi \u00b6 Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\) Partizioni \u00b6 Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\") Numeri naturali come insiemi \u00b6 \u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\) Il prodotto cartesiano \u00b6 Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) ) La cardinalit\u00e0 \u00b6 La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\) Propriet\u00e0 \u00b6 Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Insiemi"},{"location":"FdI/insiemi/#gli-insiemi","text":"Definizione di insieme Un insieme \u00e8 una collezione di oggetti, chiamati elementi . Dato un oggetto a ed un insieme A, scriviamo \\(a \\in A\\) per dire che \\(a\\) \u00e8 un elemento di \\(A\\) . Ugualmente, scriviamo \\(a \\notin A\\) per dire che \\(a\\) non \u00e8 un elemento di \\(A\\) . Il simbolo \\(\\in\\) \u00e8 il simbolo di appartenenza Per gli insiemi valgono questi concetti: L'ordine in cui sono presentati gli elementi non \u00e8 rilevante Il numero di ripetizioni con cui sono presentati gli oggetti non \u00e8 rilevante Gli insiemi sono usati per raggruppare oggetti","title":"Gli insiemi"},{"location":"FdI/insiemi/#definizione-di-insiemi","text":"Gli insiemi possono definire in diversi modi. Vale la pena specificare che spesso gli insiemi sono spesso definiti con lettere maiuscole, mentre gli elementi con lettere minuscole.","title":"Definizione di insiemi"},{"location":"FdI/insiemi/#definzione-per-enumerazione","text":"L'enumerazione (o modo estensionale ) consiste nell'elencare tutti gli elementi dell'insieme, separati da virgole. Esempio \\(Bool = {t,f}\\) Puntini Per quanto riguarda insiemi molto grandi, si possono usare i puntini ( \\(...\\) ) per sottointendere una regola di enumerazione. Notare che questa notazione \u00e8 informale !","title":"Definzione per Enumerazione"},{"location":"FdI/insiemi/#linsieme-vuoto","text":"L'insieme vuoto \u00e8 l'insieme che non contiene nessun elemento ed \u00e8 rappresentato con il simbolo \\(\\varnothing\\) . L'insieme vuoto \\(\\varnothing = \\{\\}\\)","title":"L'insieme vuoto"},{"location":"FdI/insiemi/#definizione-per-proprieta","text":"\u00c8 possibile descrivere un insieme anche mediante una propriet\u00e0 che tutti i suoi elementi soddisfano (anche conosciuto come modo intensionale ). Per farne uso indichiamo con \\(P\\) una generica propriet\u00e0 e con \\(P(a)\\) indichiamo che l'elemento \\(a\\) soddisfa la propriet\u00e0 \\(P\\) . In questo caso stiamo assumento che per ogni elemento \\(a\\) , questo o soddisfa la propriet\u00e0, o no. Definizione per propriet\u00e0 \\(X = \\{ x | x \\in A \\land P(x) \\}\\) In questo caso l'operatore \\(\\land\\) indica un \"e\", mentre il simbolo \\(|\\) si legge \"tale che\" e serve a specificare una condizione. L'equazione descritta si pu\u00f2 poi semplificare: \\(X = \\{ x \\in A | P(x) \\}\\) E se \\(A\\) \u00e8 implicito nel contesto: \\(X = \\{ x | P(x)\\}\\)","title":"Definizione per Propriet\u00e0"},{"location":"FdI/insiemi/#i-paradossi","text":"In base alle definizioni date, si possono verificare dei paradossi.","title":"I paradossi"},{"location":"FdI/insiemi/#il-paradosso-di-russel","text":"Il paradosso di Russel \u00e8 un' antinomia (ovvero proposizione che risulta autocontraddittoria sia nel caso che sia vera, sia nel caso che sia falsa). Il segue questo tipo di ragionamento: Esistono insiemi che possono contenere loro stessi (ad esempio il numero di insiemi non vuoti \u00e8 contenuto: \\(X = \\{ x | x \\in x \\}\\) ) Esistono insiemi in cui essi stessi non risultano (ad esempio insiemi che contengono un solo elemento: \\(X = \\{ x \\space | \\space |x| = 1 \\}\\) ) Se definiamo \\(R\\) come l'insieme che non appartengono a s\u00e9 stessi, otteniamo \\(R = \\{ x | x \\notin x\\}\\) . A questo punto: Se l'affermazione \u00e8 vera : \\(R\\) appartiene a s\u00e9 stesso \\(R\\) soddisfa la definizione \\(R\\) \u00e8 un insieme che appartiene a s\u00e9 stesso \\(R\\) non pu\u00f2 appartenere a s\u00e9 stesso, che va contro il primo enunciato Se invece la consideriamo falsa: \\(R\\) non appartiene a s\u00e9 stesso \\(R\\) non soddisfa la definizione \\(R\\) non appartenendo a s\u00e9 stesso dovrebbe essere incluso nell'insieme \\(R\\) appartiene a s\u00e9 stesso, che va contro il primo enunciato","title":"Il paradosso di Russel"},{"location":"FdI/insiemi/#diagrammi-di-eulero-venn","text":"I diagrammi di Eulero-Venn sono uno strumento per facilitare il ragionamento facneod uso di una notazione grafica intuitiva. In questa notazione, l'universo \\(\\mathcal U\\) viene rappresentato come un rettangolo, che conterr\u00e0 tutti gli elementi. Gli elementi sono poi identificati da punti. Infine, possiamo fare uso di forme come ellissi e circonfenreze per rappresentare gli insiemi. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 u \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 \u2022 \u2022 \u2502 \u2502 /\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\ \u2502 \u2502 / \u2022 \\ \u2022 \u2022 \u2022 \u2502 \u2502 / | \u2502 \u2502 | \u2022 | \u2502 \u2502 / \u2022 \u2500\u2500\u2500\u2500\u2500 \u2022 \u2022 \u2502 \u2502 | | \u2022 \u2502 \u2502 |\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2502 \u2022 \u2502 \u2502 \u2022 \u2022 \u2022 \u2022 \u2502 \u2502 \u2022 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Diagrammi di Eulero-Venn"},{"location":"FdI/insiemi/#i-confronti-tra-insiemi","text":"","title":"I confronti tra insiemi"},{"location":"FdI/insiemi/#uguaglianza","text":"Uguaglianza tra insiemi Due insiemi sono uguali \\(A = B\\) , se hanno gli stessi elementi. Due insiemi sono diversi \\(A \\neq B\\) se hanno elementi diversi (uno dei 2 contiene almeno un elemento che non appartiene all'altro). Ricordando quindi la definizione, se due insiemi differiscono solo nella ripetizione e l'ordine degli elementi ( \\(A = \\{1,2\\}\\) , \\(B = \\{2, 1, 2, 2\\}\\) ), sono lo stesso insieme ( \\(A = B\\) ).","title":"Uguaglianza"},{"location":"FdI/insiemi/#inclusione","text":"Inclusione tra insiemi \\(A\\) \u00e8 sottoinsime di \\(B\\) ( \\(A \\subseteq B\\) ) se ogni elemento di \\(A\\) \u00e8 anche elemento di \\(B\\) . \\(A\\) \u00e8 sottinsieme proprio di \\(B\\) ( \\(A \\subset B\\) ) se \\(A \\subseteq B \\land A \\neq B\\) . Due insiemi sono disgiunti se non hanno elementi in comune. Quindi: Per mostrare che \\(A \\subseteq B\\) , basta mostrare che ogni elemento di \\(A\\) appartiene a \\(B\\) . Per mostrare che \\(A = B\\) , basta mostrare che ogni elemento dell'uno appartiene all'altro, quindi \\(A \\subseteq B \\land B \\subseteq A\\) . Per mostrare che \\(A \\neq B\\) , basta esibire un elemento di un elemento che non appartiene all'altro. Per dismotrare che \\(A \\subset B\\) , con \\(A \\subseteq B\\) basta mostrare che un elemento di \\(B\\) che non appartiene ad \\(A\\) . Per dimostrare che i due insiemi sono disgiunti basta mostare che per ogni elemento di \\(A\\) non c'\u00e8 un elemento contenuto in \\(B\\) .","title":"Inclusione"},{"location":"FdI/insiemi/#operazioni-su-insiemi","text":"","title":"Operazioni su insiemi"},{"location":"FdI/insiemi/#unione","text":"Definizione di unione L'operazione di unione tra due insiemi A e B, denotata dalla formula \\(A \\cup B\\) , \u00e8 l'insime che contiene tutti gli elementi di A e di B. In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ oppure } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\lor x \\in B \\} \\] Quindi, avendo \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{ 3, 4, 5\\}\\) , \\(A \\cup B = \\{1, 2, 3, 4, 5\\}\\) .","title":"Unione"},{"location":"FdI/insiemi/#intersezione","text":"Intersezione L'operazione di intersezione tra A e B, denotata dalla formula \\(A \\cap B\\) , \u00e8 l'insieme degli elementi contenuti contemporaneamente sia da \\(A\\) che da \\(B\\) . In formule: \\[ A \\cup B = \\{x | x \\in A \\text{ e } x \\in B\\} \\qquad A \\cup B = \\{ x | x \\in A \\land x \\in B \\} \\] Quindi, riproponendo l'esempio precedente, \\(A \\cap B = \\{3\\}\\)","title":"Intersezione"},{"location":"FdI/insiemi/#differenza","text":"Differenza L'operazione di differenza tra A e B, denotata dalla formula \\(A \\ B\\) , \u00e8 l'insieme degli elementi contenuti solo e soltanto da \\(A\\) e non \\(B\\) . Se un elemento appartiene sia ad \\(A\\) che a \\(B\\) , non apparterr\u00e0 all'insieme \\(A \\ B\\) . In formule: \\[ A \\text{ \\ } B = \\{x | x \\in A \\land x \\notin B\\} \\] Quindi, continuando con l'esempio precedente, \\(A \\ B = \\{1, 2\\}\\)","title":"Differenza"},{"location":"FdI/insiemi/#complemento","text":"Complemento L'operazione di complemento si basa su un solo insieme, ma rispetto ad un altro: se \\(B \\in A\\) , allora \\(A \\ B\\) \u00e8 il complemento di B rispetto ad A . Se dal costesto \u00e8 evidente l'insieme di riferimento (ad esempio \\(A = \\cal U\\) ), allora si pu\u00f2 scrivere: \\[ \\overline B = \\{x | x \\notin B\\} \\]","title":"Complemento"},{"location":"FdI/insiemi/#operatori-booleani","text":"I principali operatori booleani che vediamo sono disgiunzione ( \\(\\lor\\) ), congiunzione( \\(\\land\\) ) e negazione (\\neg). I significati che possiamo attribuire, aiutandoci con il linguaggio naturale, sono i seguenti: Operazione Operatore Significato in linguaggio naturale Disgiunzione \\(\\lor\\) \"O\", intesa come NON mutualmente esclusivo: se si propone A o B, anche entrambe le opzioni possono essere vere. Congiunzione \\(\\land\\) \"E\", che richiede che entrambi i parametri siano veri Negazione \\(\\neg\\) Opposto del valore Questi operatori sono trattati in maniera pi\u00f9 approfondita nel capitolo sulla logica , e per quanto riguarda il loro significato, questo \u00e8 spiegato nella sezione sulla semantica .","title":"Operatori booleani"},{"location":"FdI/insiemi/#le-leggi","text":"Alcune formule valgono per tutti gli insiemi (ad esempio \\((A \\cup B) \\cup C \\equiv (A \\cup C) \\cup B\\) ), ma questo non vale per tutte le formule. Dato che non \u00e8 possibile verificare le eguaglianze per ogni insieme (in quanto esistono infiniti insiemi), si fornisce una prova o dimostrazione . Mentre per smentire un'eguaglianza, \u00e8 sufficiente fornire un controesempio , dimostrando quindi che non \u00e8 universale. Possiamo trovare qui alcune leggi che valgono per tutti gli insiemi A, B e C in qualunque universo \\(\\cal U\\) Legge Formula associativit\u00e0 \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) unit\u00e0 \\(A \\cup \\varnothing = A\\) \\(A \\cap \\mathcal U = A\\) commutativit\u00e0 \\(A \\cup B = B \\cup A\\) \\(A \\cap B = B \\cap A\\) idempotenza \\(A \\cup A = A\\) \\(A \\cap A = A\\) assorbimento \\(A \\cup \\mathcal U = \\mathcal U\\) \\(A \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) assorbimento \\(A \\cup (A \\cap B) = A\\) \\(A \\cap (A \\cup B) = A\\) complemento \\(A \\cup \\overline A = \\mathcal U\\) \\(A \\cap \\overline A = \\varnothing\\) \\(A \\cup (\\overline A \\cap B) = A \\cup B\\) \\(A \\cap (\\overline A \\cup B) = A \\cap B\\) \\(\\overline A \\cup (A \\cap B) = \\overline A \\cup B\\) \\(\\overline A \\cap (A \\cup B) = \\overline A \\cap B)\\) differenza \\(A \\text{ \\ } B = A \\cap \\overline B\\) convoluzione \\(\\overline {(\\overline A)} = A\\) De Morgan \\(\\overline {A \\cup B} = \\overline A \\cap \\overline B\\) \\(\\overline {A \\cap B} = \\overline A \\cup \\overline B\\) \\(\\mathcal U: \\varnothing\\) \\(\\overline \\varnothing = \\cal U\\) \\(\\overline {\\mathcal U} = \\varnothing\\) Si pu\u00f2 osservare l'uso delle parentesi tonde nelle formule. Le parentesi hanno lo scopo di specificare l'ordine delle operazioni all'interno della formula: le operazioni all'interno di una coppia di parentesi tonde viene eseguita prima di un'operazione all'esterno. Alcune leggi inotre ci permettono di semplificare alcune operazioni, come ad esempio quella della distribuitivit\u00e0, che ci permette di ridurre un calcolo di 3 operazioni in 2. Questo permette di aumentare l' efficienza della formula, che avendo un numero inferiore di formulepermette di eseguire l'operazione con meno tempo e risorse computazionali.","title":"Le leggi"},{"location":"FdI/insiemi/#dimostrazioni","text":"Le dimostrazioni ci servono per dimostrare la validit\u00e0 delle nostre formule. Ne esistono diversi tipi, dalle pi\u00f9 formali alle pi\u00f9 discorsive","title":"Dimostrazioni"},{"location":"FdI/insiemi/#dimostrazione-grafica","text":"La dimostrazione grafica si basa sulla notazione di Eulero-Venn, che ci permette di dimostrare una formula mediante un mezzo visivo.","title":"Dimostrazione grafica"},{"location":"FdI/insiemi/#dimostrazione-per-sostituzione","text":"Le dimostrazioni per sostituzione ci consentono di effettuare una dimostrazione basandoci su formule dimostrate precedentemente. Sono estremamente formali e convincenti, ma possono essere lunghe e difficili da completare. Esempio di dimostrazione per sostituzione Proviamo a dimostrare la legge di convoluzione ( \\(\\overline{(\\overline A)} = A\\) ) \\(A = A \\cup \\varnothing\\) (unit\u00e0) \\(= A \\cup (\\overline A \\cap \\overline{(\\overline A)})\\) (complemento) \\(= A \\cup \\overline{(\\overline A)}\\) (complemento, rimuovendo \\(\\overline A \\cap\\) ) \\(= \\overline{(\\overline A)} \\cup A\\) (commutativit\u00e0) \\(= \\overline{(\\overline A)} \\cup (\\overline A \\cap A)\\) (complemento, all'opposto) \\(= \\overline{(\\overline A)} \\cup \\varnothing\\) (complemento) \\(= \\overline{(\\overline A)}\\) (unit\u00e0)","title":"Dimostrazione per sostituzione"},{"location":"FdI/insiemi/#dimostrazione-discorsive","text":"Le dimostrazionio hanno lo scopo di rendere pi\u00f9 semplice effettuare una dimostrazione alternando linguaggio naturale e formule matematiche, rappresentando i vari passaggi talvolta anche oralmente","title":"Dimostrazione discorsive"},{"location":"FdI/insiemi/#insiemi-di-insiemi","text":"Come visto per il paradosso di Russel, alcuni insiemi possono racchiudere altri insiemi. Per questo \u00e8 importante notare che \\(\\{a\\}\\) ed \\(a\\) sono elementi diversi. Infatti \\(\\{a\\} \\in \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) , ma \\(a \\notin \\{ \\{ a \\}, \\{a, b\\}, \\{a, b,c\\} \\}\\) Allo stesso modo, \\(\\{a\\} \\ne \\{\\{a\\}\\}\\) Possiamo ora definire cosa si intende con insieme delle parti : Insieme delle parti Dato un insieme \\(A\\) , il suo Insieme delle parti \\(\\mathcal P(A)\\) \u00e8 quell'insieme contenente tutti i possibili sottoinsiemi di A: \\(\\mathcal P(A) = \\{ x | x \\subseteq A \\}\\) \u00c8 inoltre utile notare che il numero di elementi (cardinalit\u00e0) dell'insieme sar\u00e0 pari a \\(2^n\\) , dove \\(n\\) rappresenta il numero di elementi nell'insieme \\(A\\) . Possiamo inoltre affermare che \\(\\varnothing \\in \\cal P(A)\\) \\(A \\in \\mathcal P(A)\\)","title":"Insiemi di insiemi"},{"location":"FdI/insiemi/#famiglie-di-insiemi","text":"Una famiglia \\(\\cal F\\) di insiemi non \u00e8 altro che un insieme di insiemi. Per distinguere i sottoinsiemi, usiamo un pedice, che associamo al sottoinsieme. Pi\u00f9 formalmente: Famiglia di insiemi Sia \\(I\\) un insieme tale che per ogni \\(i \\in I\\) , esista e sia definito un certo insieme \\(A_i\\) . L'insieme \\(\\cal F\\) contiene tutti gli elementi \\(A_i\\) e viene detto famiglia indicizzata da \\(I\\) . In formule: \\(\\mathcal F = \\{ A_i | i \\in I\\} = \\{A_i\\}_{i \\in I}\\) Sulla base di questa definizione vengon poi generalizzati anche i concetti di unione ed intersezione: \\(\\cup \\mathcal F = \\cup _{i \\in I} \\ A_i\\) \\(\\cap \\mathcal F = \\cap _{i \\in I} \\ A_i\\) Inoltre quando \\(I = \\{1, 2, ..., n\\}\\) , \u00e8 possibile usare la notazione \\(\\cup^n_{i=1}\\) invece di \\(\\cup_{i \\in I}\\)","title":"Famiglie di insiemi"},{"location":"FdI/insiemi/#partizioni","text":"Una partizione \u00e8 un particolare tipo di famiglia. \u00c8 chiamato in questo modo in quanto partiziona gli elementi di un certo elemento \\(A\\) in elementi separati. Partizione Dato un insieme \\(A\\) , una partizione \u00e8 una famiglia di insiemi \\(\\mathcal F= \\{ A_i \\}_{i \\in I}\\) tali che: Ogni insieme \\(A_i\\) \u00e8 diverso da \\varnothing (il sottoinsieme non \u00e8 vuoto) \\(\\cup_{i \\in I} A_i = A\\) (Copertura di A: l'unione di ogni insieme della partizione rappresenta A) Presi 2 indici qualsiasi \\(i\\) e \\(j\\) con \\(i \\neq j\\) , si ha che \\(A_i \\cap A_j = \\varnothing\\) (tutti i sottoinsiemi sono disgiunti) Notare che la partizione rappresenta la famiglia, non l'elemento della famiglia (parliamo di partizione riferendosi a tutte le sotto-partizioni o \"sezioni\" dell'insieme, non ad una singola \"sezione\")","title":"Partizioni"},{"location":"FdI/insiemi/#numeri-naturali-come-insiemi","text":"\u00c8 possibile usare i numeri naturali \\(\\mathbb N\\) per denotare insiemi: Naturali come insiemi Per ogni \\(n \\in \\mathbb N\\) , denotiamo con \\(n\\) l'insieme \\(\\{m \\in \\mathbb N | m < n \\}\\) . In alternativa, possiamo definire per enumerazione \\(n = \\{0, 1, 2, ..., n-1\\}\\) Data questa definizione, avremo che: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\}\\) \\(2 = \\{0, 1\\}\\) \\(3 = \\{0, 1, 2\\}\\) \\(... = ...\\) In questo caso, l'insieme \\(n\\) avr\u00e0 proprio cardinalit\u00e0 \\(n\\) (cio\u00e8 \\(|n| = n\\) ). Possiamo inoltre espandere gli insiemi appena definiti: \\(0 = \\{\\}\\) (L'insieme vuoto \\(\\varnothing\\) ) \\(1 = \\{0\\} = \\text{ { {} } }\\) \\(2 = \\{0, 1\\} = \\text{ { {}, {{}} } }\\) \\(3 = \\{0, 1, 2\\} = \\text{ { {}, {{}}, {{{}}} } }\\) \\(... = ...\\)","title":"Numeri naturali come insiemi"},{"location":"FdI/insiemi/#il-prodotto-cartesiano","text":"Come detto, l'ordine e la rindondanza di un elemento in un insieme non \u00e8 imporante. Prima di procedere con il prodotto cartesiano, \u00e8 opportuno esprimere una notazione che invece ci permetta di rappresentare collezioni ordinate, come \\((a_1, a_2, a_3, ..., a_n )\\) , per rappresentare stringhe ordinate o vettori. (In alcuni casi \u00e8 possibile ossevare l'utilizzo delle parentesi angolari \\(\\langle a,b \\rangle\\) , ma non \u00e8 questo il caso). Possiamo quindi ora dire che le coppie \\((a,b)\\) e \\((b,a)\\) sono diverse, a differenza degli insiemi \\(\\{ a, b\\} = \\{b, a \\}\\) . Prodotto cartesiano Siano \\(A\\) e \\(B\\) due insiemi, il prodotto cartesiano di A per B \\(A \\times B\\) \u00e8 formato da tutte le coppie ordinate \\((a,b)\\) tali che \\(a \\in A\\) e \\(b \\in B\\) . In formule: \\(A \\times B = \\{ (a,b) \\ | \\ a \\in A, b \\in B \\}\\) \u00c8 importante notare che il prodotto cartesiano non \u00e8 associativo ( \\(A \\times (B \\times C) \\neq (A \\times B) \\times C\\) ) n\u00e9 commutativo( \\(A \\times B \\neq B \\times A\\) )","title":"Il prodotto cartesiano"},{"location":"FdI/insiemi/#la-cardinalita","text":"La cardinalit\u00e0 \u00e8 la quantit\u00e0 che rappresenta il numero di elementi in un insieme. Cardinalit\u00e0 Sia \\(A\\) un insieme contenente esattamente \\(n\\) elementi distinti tra loro (con \\(n \\in \\mathbb N\\) ). Diciamo che \\(A\\) \u00e8 un insieme finito e che \\(A\\) ha cardinalit\u00e0 \\(n\\) \\(|A| = n\\) Notiamo che l'insieme vuoto \\(\\varnothing = \\{\\}\\) ha cardinalit\u00e0 0: \\(|\\varnothing| = 0\\) . Esistono poi anche insiemi infiniti , come \\(\\mathbb R\\) o \\(\\mathbb N\\) . Terminiamo quindi con la cardinalit\u00e0 di alcuni insiemi notevoli: \\(|\\varnothing| = 0\\) \\(|n| = n\\) \\(|A \\text { \\ } B| = |A| - |A \\cap B|\\) \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\) \\(|A \\times B| = |A| \\cdot |B|\\) \\(|\\mathcal P(A)| = 2^{|A|}\\) \\(|\\mathcal P_k(A)| = ({|A| \\atop k})\\)","title":"La cardinalit\u00e0"},{"location":"FdI/insiemi/#proprieta","text":"Assicurarsi che questi vengano trattati pi\u00f9 avanti transitivit\u00e0 (se \\(A=B\\) e \\(B=C\\) allora \\(A=C\\) ) simmetria (se \\(A=B\\) allora \\(B=A\\) ) antisimmetria (se \\(A \\subseteq B\\) e \\(B \\subseteq A\\) allora \\(A=B\\) ) riflessivit\u00e0 ( \\(A = A\\) ) Albero dell'insieme delle parti","title":"Propriet\u00e0"},{"location":"FdI/linguaggi/","text":"Linguaggi formali \u00b6 Nei linugaggi dobbiamo distiguere due parti: Sintassi, che ha a che fare con la struttura Semantica, che ha a che fare con il significato delle frasi esprimibili Partiamo con la definizione di linguaggio: Definiamo linugaggio come sinonimo di insieme di frasi sintatticamente ammissibili. Fissato un alfabeto di elementi base, detti simboli, il linguaggio \u00e8 un sottoinsieme di tutte le stringhe, ovvero sequenze di lunghezza arbitraria di simboli. Descriere un linguaggio, significa quindi (i due punti sono alternativi): - decidere quali srienghe farann part e dell'insieme o quali no - costuire l'insieme di stringhe enumerando le stringhe che lo compongono Abbiamo due modi di risovere il come identificare l'insieme dellle stringhe ammissibili che caratterizano un linguaggio: Usare usare un automa, uno strumento in grado di riconoscere tutte e sole le stringhe che fanno parte di un linguaggio Usare una grammatica, che \u00e8 in grado di costruire o generare tutte le stringhe che fanno parte del linugaggio Alfabeti, Parole e Linguaggi \u00b6 Definizione di Alfabeto Un alfabeto \u00e8 un insieme finito. I suoi elementi sono detti simboli Definizione di stringhe Dato un alfabeto \\(A\\) , l'insieme \\(A^*\\) delle stringhe su \\(A\\) rappresenta il pi\u00f9 piccolo insieme che soddisfa: (Clausola base): \\(\\varepsilon \\in A^*\\) , dove \\(\\varepsilon\\) \u00e8 la stringa vuota (Clausola induttiva): Se \\(\\omega \\in A^*\\) e \\(a \\in A\\) , allora \\(a\\omega \\in A^*\\) Notare che l'insieme delle liste \\(L_A\\) e l'insieme \\(A*\\) sono in biiezione. Concatenazione di stringhe La concatenazione di stringhe \u00e8 una funzione \\(\\_ \\cdot \\_: A^* \\times A^* \\rightarrow A^*\\) , definita per tutte le stringhe \\(u,v \\in A^*\\) come \\(u \\times v = uv\\) Linugaggio Un linguaggio su A \u00e8 un insieme \\(L \\subseteq A^*\\) . L'insieme di tutti i linguaggi \u00e8 denotato come \\(\\mathcal P(A^*)\\) Operazioni su lunguaggi \u00b6 Per ogni alfabeto A, esistono sempre: Il linguaggio vuoto \\(\\varnothing = \\{\\}\\) Il linguaggio che contiene solo la stringa vuota \\({\\varepsilon}\\) Il linguaggio completo \\(A^*\\) I linguaggi possono essere combinate come con le operazioni insiemistiche. Concatenazione di linguaggi La funzione \\(\\_ \\cdot \\_: \\mathcal P(A^*) \\times \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) \u00e8 definita per tutti i linguaggi \\(L_1, L_2 \\in \\mathcal P(A^*)\\) come \\(L_1 \\cdot L_2 = \\{ \\omega \\in A^* | \\text{ esistono } \\omega_1 \\in L_1, \\omega_2 \\in L_2 \\text { tali che } \\omega = \\omega_1 \\cdot \\omega_2 \\}\\) Concatenazione n-aria di linguaggi Dato un insieme A ed un linguaggio \\(L \\in \\mathcal P(A)\\) , per ogni numero naturale \\(n \\in \\mathbb N\\) , definiamo \\(L^n\\) induttivamente: \\(L^0 = \\{ \\varepsilon \\}\\) \\(L^{n+1} = L \\cdot L^{n}\\) Stella di Kleene La stella di Kleene \u00e8 una funzione \\((_)^*: \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) per tutti i linguaggi \\(L \\in \\mathcal P(A^*)\\) definita come: \\[ \\bigcup _{n \\in \\mathbb N} L^n \\] Automi \u00b6 Gli automi sono chiamati anche macchine a stati, e vengono descritti attraverso transizioni di stato, letture in input e produzioni in output. Gli automi sono alberi i cui nodi rappresentano gli stati e gli archi i simboli la cui lettura \u00e8 necessarie per innescare la transizione. Automa Un automa sull'alfabeto A \u00e8 una tripla \\(A=(S,T,F)\\) , dove: S \u00e8 un insieme, detto insieme degli stati \\(T \\subseteq (A \\times S) \\times S\\) \u00e8 una relazione in \\(Rel(A \\times S,S)\\) detta relazione di transizione, che associa ad ogni lettera dell'alfabeto \\(a \\in A\\) ad ogni stato di partenza \\(x \\in S\\) zero o pi\u00f9 stati di destinazione \\(F \\subseteq S\\) \u00e8 l'insieme degli stati finali (o stati di accettazione) L'automa \\(\\mathcal A\\) si dice a stati finiti se l'insieme degli stati S \u00e8 finito Raggiungibilit\u00e0 negli automi Sia A = (S,T,F) un automa sull'alfabeto A, per ogni \\(a \\in A\\) si definisce la relazione \\(T_a \\in Rel(S,S)\\) come \\(T_a = \\{ (x,y) | ((a,x),y) \\in T \\}\\) Per ogni stringa in \\(\\omega \\in A^*\\) , defianio per induzione \\(T_w \\in Rel(S,S)\\) come: \\(T_\\omega = id_S\\) \\(T_{aw} = T_a;T_w\\) Lo stato y \\((x,y) \\in T_\\omega\\) si dice raggiungibile da x con la stringa \\(\\omega\\) Linguaggio accettato Sia A = (S,T,F) un automa a stati finiti, la funzione \\(\\langle \\langle \\cdot \\rangle \\rangle: S \\rightarrow \\mathcal P(A)\\) \u00e8 definita per ogni stato \\(x \\in S\\) come \\[ \\langle \\langle x \\rangle \\rangle = \\{ \\omega \\in A^* | \\text{ esiste } y \\in F \\text{ tale che } (x,y) \\in T_\\omega \\} \\] Il linguaggio \\(\\langle \\langle x \\rangle \\rangle\\) \u00e8 detto il linguaggio accettato da x. Se \\(\\omega \\in \\langle \\langle x \\rangle \\rangle\\) si dice che la stringa \\(\\omega\\) \u00e8 accettata dallo stato x Automi deterministici e non \u00b6 Automa deterministico Un automa \\(A=(S,T,F)\\) si dice deterministico se l'operazione di transizione \\(T \\in Rel(A \\times S, S)\\) \u00e8 una funzione Costruzione dei sottoinsiemi \u00b6 Grammatiche libere da contesto \u00b6","title":"Linguaggi Formali"},{"location":"FdI/linguaggi/#linguaggi-formali","text":"Nei linugaggi dobbiamo distiguere due parti: Sintassi, che ha a che fare con la struttura Semantica, che ha a che fare con il significato delle frasi esprimibili Partiamo con la definizione di linguaggio: Definiamo linugaggio come sinonimo di insieme di frasi sintatticamente ammissibili. Fissato un alfabeto di elementi base, detti simboli, il linguaggio \u00e8 un sottoinsieme di tutte le stringhe, ovvero sequenze di lunghezza arbitraria di simboli. Descriere un linguaggio, significa quindi (i due punti sono alternativi): - decidere quali srienghe farann part e dell'insieme o quali no - costuire l'insieme di stringhe enumerando le stringhe che lo compongono Abbiamo due modi di risovere il come identificare l'insieme dellle stringhe ammissibili che caratterizano un linguaggio: Usare usare un automa, uno strumento in grado di riconoscere tutte e sole le stringhe che fanno parte di un linguaggio Usare una grammatica, che \u00e8 in grado di costruire o generare tutte le stringhe che fanno parte del linugaggio","title":"Linguaggi formali"},{"location":"FdI/linguaggi/#alfabeti-parole-e-linguaggi","text":"Definizione di Alfabeto Un alfabeto \u00e8 un insieme finito. I suoi elementi sono detti simboli Definizione di stringhe Dato un alfabeto \\(A\\) , l'insieme \\(A^*\\) delle stringhe su \\(A\\) rappresenta il pi\u00f9 piccolo insieme che soddisfa: (Clausola base): \\(\\varepsilon \\in A^*\\) , dove \\(\\varepsilon\\) \u00e8 la stringa vuota (Clausola induttiva): Se \\(\\omega \\in A^*\\) e \\(a \\in A\\) , allora \\(a\\omega \\in A^*\\) Notare che l'insieme delle liste \\(L_A\\) e l'insieme \\(A*\\) sono in biiezione. Concatenazione di stringhe La concatenazione di stringhe \u00e8 una funzione \\(\\_ \\cdot \\_: A^* \\times A^* \\rightarrow A^*\\) , definita per tutte le stringhe \\(u,v \\in A^*\\) come \\(u \\times v = uv\\) Linugaggio Un linguaggio su A \u00e8 un insieme \\(L \\subseteq A^*\\) . L'insieme di tutti i linguaggi \u00e8 denotato come \\(\\mathcal P(A^*)\\)","title":"Alfabeti, Parole e Linguaggi"},{"location":"FdI/linguaggi/#operazioni-su-lunguaggi","text":"Per ogni alfabeto A, esistono sempre: Il linguaggio vuoto \\(\\varnothing = \\{\\}\\) Il linguaggio che contiene solo la stringa vuota \\({\\varepsilon}\\) Il linguaggio completo \\(A^*\\) I linguaggi possono essere combinate come con le operazioni insiemistiche. Concatenazione di linguaggi La funzione \\(\\_ \\cdot \\_: \\mathcal P(A^*) \\times \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) \u00e8 definita per tutti i linguaggi \\(L_1, L_2 \\in \\mathcal P(A^*)\\) come \\(L_1 \\cdot L_2 = \\{ \\omega \\in A^* | \\text{ esistono } \\omega_1 \\in L_1, \\omega_2 \\in L_2 \\text { tali che } \\omega = \\omega_1 \\cdot \\omega_2 \\}\\) Concatenazione n-aria di linguaggi Dato un insieme A ed un linguaggio \\(L \\in \\mathcal P(A)\\) , per ogni numero naturale \\(n \\in \\mathbb N\\) , definiamo \\(L^n\\) induttivamente: \\(L^0 = \\{ \\varepsilon \\}\\) \\(L^{n+1} = L \\cdot L^{n}\\) Stella di Kleene La stella di Kleene \u00e8 una funzione \\((_)^*: \\mathcal P(A^*) \\rightarrow \\mathcal P(A^*)\\) per tutti i linguaggi \\(L \\in \\mathcal P(A^*)\\) definita come: \\[ \\bigcup _{n \\in \\mathbb N} L^n \\]","title":"Operazioni su lunguaggi"},{"location":"FdI/linguaggi/#automi","text":"Gli automi sono chiamati anche macchine a stati, e vengono descritti attraverso transizioni di stato, letture in input e produzioni in output. Gli automi sono alberi i cui nodi rappresentano gli stati e gli archi i simboli la cui lettura \u00e8 necessarie per innescare la transizione. Automa Un automa sull'alfabeto A \u00e8 una tripla \\(A=(S,T,F)\\) , dove: S \u00e8 un insieme, detto insieme degli stati \\(T \\subseteq (A \\times S) \\times S\\) \u00e8 una relazione in \\(Rel(A \\times S,S)\\) detta relazione di transizione, che associa ad ogni lettera dell'alfabeto \\(a \\in A\\) ad ogni stato di partenza \\(x \\in S\\) zero o pi\u00f9 stati di destinazione \\(F \\subseteq S\\) \u00e8 l'insieme degli stati finali (o stati di accettazione) L'automa \\(\\mathcal A\\) si dice a stati finiti se l'insieme degli stati S \u00e8 finito Raggiungibilit\u00e0 negli automi Sia A = (S,T,F) un automa sull'alfabeto A, per ogni \\(a \\in A\\) si definisce la relazione \\(T_a \\in Rel(S,S)\\) come \\(T_a = \\{ (x,y) | ((a,x),y) \\in T \\}\\) Per ogni stringa in \\(\\omega \\in A^*\\) , defianio per induzione \\(T_w \\in Rel(S,S)\\) come: \\(T_\\omega = id_S\\) \\(T_{aw} = T_a;T_w\\) Lo stato y \\((x,y) \\in T_\\omega\\) si dice raggiungibile da x con la stringa \\(\\omega\\) Linguaggio accettato Sia A = (S,T,F) un automa a stati finiti, la funzione \\(\\langle \\langle \\cdot \\rangle \\rangle: S \\rightarrow \\mathcal P(A)\\) \u00e8 definita per ogni stato \\(x \\in S\\) come \\[ \\langle \\langle x \\rangle \\rangle = \\{ \\omega \\in A^* | \\text{ esiste } y \\in F \\text{ tale che } (x,y) \\in T_\\omega \\} \\] Il linguaggio \\(\\langle \\langle x \\rangle \\rangle\\) \u00e8 detto il linguaggio accettato da x. Se \\(\\omega \\in \\langle \\langle x \\rangle \\rangle\\) si dice che la stringa \\(\\omega\\) \u00e8 accettata dallo stato x","title":"Automi"},{"location":"FdI/linguaggi/#automi-deterministici-e-non","text":"Automa deterministico Un automa \\(A=(S,T,F)\\) si dice deterministico se l'operazione di transizione \\(T \\in Rel(A \\times S, S)\\) \u00e8 una funzione","title":"Automi deterministici e non"},{"location":"FdI/linguaggi/#costruzione-dei-sottoinsiemi","text":"","title":"Costruzione dei sottoinsiemi"},{"location":"FdI/linguaggi/#grammatiche-libere-da-contesto","text":"","title":"Grammatiche libere da contesto"},{"location":"FdI/logica/","text":"La logica \u00b6 La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ). Il calcolo proposizionale \u00b6 Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali) Composizione di proposizioni \u00b6 Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici . Sintassi del calcolo proposizionale \u00b6 Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali I connettivi logici \u00b6 Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) . La formalizzazione di proposizioni \u00b6 Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\) La semantica \u00b6 La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\] Le tavole di verit\u00e0 \u00b6 \u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\) Il concetto di Tautologia \u00b6 Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso. Dimostrazioni nel calcolo proposizionale \u00b6 Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) . Formalizzazione di inferenze e tautologie \u00b6 \u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Sistema di dimostrazioni Dato un insieme di formule \\(\\Delta\\) , un sistema di dimostrazioni (o proof system) per \\(\\Delta\\) \u00e8 un insieme di regole di interenza \\(\\cal R\\) . Una reola di inferenza \\(r \\in \\cal R\\) ha la struttura: \\[ \\frac{P_1 \\ \\cdots P_n}{P} [r] \\] Dove P \u00e8 la conseguenza e \\(P_1 \\ \\cdots P_n\\) sono le premesse. Se \\(n=0\\) la regola si chiama assioma. Dimostrazione Una dimostrazione in un proof system \\(\\cal R\\) di una formula \\(Q \\in \\Delta\\) in un insieme di premesse \\(\\Gamma \\in \\Delta\\) \u00e8 una sequenza di formule \\(Q_1,...,Q_n\\) , dove: Ogni formula \\(Q\\) \u00e8 un elemento di \\(\\Gamma\\) oppure \u00e8 ottenuta applicando una regola di inferenza di \\(\\cal R\\) a partire dalle formule in \\(\\Gamma\\) o in \\(Q_i,...,Q_{i-1}\\) \\(Q_n\\) \u00e8 proprio \\(Q\\) Se esiste una dimostrazione scriveremo: \\[ \\Gamma \\vdash _{\\cal R} Q \\quad \\text{Q \u00e8 dimostrabile da }\\Gamma \\] Correttezza e completezza \\[ \\Gamma \\vdash _{\\cal R} P \\ \\text{ implica } \\ \\Gamma \\vDash P \\text{ (correttezza)} \\] Dimostrazioni per sostituzione di tautologie \u00b6 Rimpiazzamento \u00b6 Principio di sostituzione \u00b6 \u00b6 Logica dei predicati \u00b6","title":"Logica Matematica"},{"location":"FdI/logica/#la-logica","text":"La logica serve per, date certe premesse, verificare la validit\u00e0 di un certo enunciato. Facciamo uso della logica per stabilire precisamente il significato degli enunciati matematici, e quindi determinare le argomentazioni valide. Questo tipo di distinzione ci permette di capire se una dimostrazione \u00e8 corretta oppure no. Questo signifiva che la logica non ci permette di determinare delle validit\u00e0 assolute, ma solo in funzione delle premesse. Possiamo inoltre dimostrare degli enunciati basandoci sulle dimostrazioni logiche effettuate in precedenza, creando una sorta di \"struttura di dimostrazioni\". Questo genere di dimostrazioni si dicono conseguenze logiche delle premesse. Logiche classiche Chiamiamo Logiche classiche quelle logiche che trattano enunciati che possono essere solo o veri o falsi. (Ovvero, formalmente, enunciati che possono assumere uno e solo uno dei valori parte dell'insieme \\(Bool = \\{ \\textbf t, \\textbf f\\}\\) .) Abbiamo parlato di proposizioni o enunciati, quindi cerchiamo di capire meglio di cosa si tratta: definiamo proposizione un'affermazione (possibilmente non ambigua e contraddittoria). Definizione di Proposizione Una proposizione \u00e8 un enunciato dichiarativo (nel senso che dichiara qualcosa, anche in un linguaggio naturale (come l'italiano) ). Questa poposizione deve soddisfare due principi: - Principio del terzo escluso: O la proposizione \u00e8 vera, o \u00e8 falsa, non ci sono altre possbilit\u00e0. - Principio di non contraddoriet\u00e0: La proposizioe non pu\u00f2 essere contemporaneamente vera e falsa. \u00c8 possibile rappresentare astrattamente una proposizione semplice (come ad esempio ora sta piovendo ). Notare inoltre che le proposizioni si possono rappresentare astrattamente con le lettere maiuscole ( \\(A = \\text{le biciclette possono volare.}\\) ).","title":"La logica"},{"location":"FdI/logica/#il-calcolo-proposizionale","text":"Il calcolo proposizionale (o logica proposizionale ) si trova alla base delle logiche classiche e fornisce un insieme di regole di sintassi e semantica (come scrivere e leggere le formule proposizionali)","title":"Il calcolo proposizionale"},{"location":"FdI/logica/#composizione-di-proposizioni","text":"Pi\u00f9 proposizioni sepmplici possono essere combinate insieme per formare proposizioni pi\u00f9 complesse. Queste composizioni sono rese possibili grazie ai connettivi logici (come and , or e not ), che vengono considerati operatori algebrici .","title":"Composizione di proposizioni"},{"location":"FdI/logica/#sintassi-del-calcolo-proposizionale","text":"Il calcolo proposizionale fa uso di una grammatica ben specifica, formata dai simboli proposizionali (i simboli in un insieme che contiene le nostre proposizioni) il cui risultato viene definito formula proposizionale . Sintassi del calcolo proposizionale Preso un insieme di simboli proposizionali (che rappresentano proposizioni) \\(X = \\{A,B,C,..\\}\\) , il linguaggio (generato dalla categoria sintattica \\(\\langle Prop \\rangle\\) ) \u00e8 l'insieme delle formule proposizionali . Si tende ad indicare con i simboli A, B, C, ... i simboli proposizionali, mentre invece le lettere P, Q, R sono pi\u00f9 utilizzate per indicare le formule proposizionali. Grammatica del calcolo proposizionale \\(\\: \\anglebr {Prop} \\leadsto \\anglebr {Atom} | \\neg \\anglebr {Atom} | \\anglebr {Prop} \\anglebr {OpB} \\anglebr {Prop}\\) \\(\\anglebr {Atom} \\leadsto \\textbf T | \\textbf F | \\anglebr X | ( \\anglebr {Prop})\\) - Questa regola ci permette di genere le formule atomiche \\(\\anglebr {OpB} \\leadsto \\land | \\lor | \\Rightarrow | \\Leftarrow | \\Leftrightarrow\\) - Questa regola ci permette di generare i connettivi logici \\(\\quad \\: \\anglebr X \\leadsto A | B | C | \\dots\\) - Questa regola indica i simboli proposizionali","title":"Sintassi del calcolo proposizionale"},{"location":"FdI/logica/#i-connettivi-logici","text":"Per quanto riguarda i connettivi logici sopra descritti, rappresentano i pi\u00f9 comuni e possiamo osservare il loro significato : Simbolo (Connettivo logico) Nome Utilizzo Lettura \\(\\neg\\) Negazione \\(\\neg P\\) \"Non P\" \"Not P\" \"Non \u00e8 vero che P vale\" \\(\\land\\) Congiunzione \\(P \\land Q\\) \"P e Q\" \"P and Q\" \"P e anche Q\" \\(\\lor\\) Discongiunzione \\(P \\lor Q\\) \"P o Q\" \"P or Q\" \"P oppure Q\" \\(\\Rightarrow\\) Implicazione \\(P \\Rightarrow Q\\) \"se P allora Q\" \"P implica Q\" \"P solo se Q\" \"P \u00e8 condizione sufficiente per Q\" \\(\\Leftarrow\\) Conseguenza \\(P \\Leftarrow Q\\) \"P \u00e8 conseguenza di Q\" \"P se Q\" \"P if Q\" \"P \u00e8 condizione necessaria per Q\" \\(\\Leftrightarrow\\) Doppia implicazione \\(P \\Leftrightarrow Q\\) \"P sse Q\" \"P se e solo se Q\" \"P iff Q\" \"P \u00e8 condizione necessaria e sufficiente per Q\" Nel caso dell'implicazione, \\(P\\) assume il nome di premessa , mentre \\(Q\\) quello di conseguenza o conclusione . Vale inoltre la pena notare che \\(P \\Leftarrow Q\\) \u00e8 logicamente equivalente a \\(Q \\Rightarrow P\\) .","title":"I connettivi logici"},{"location":"FdI/logica/#la-formalizzazione-di-proposizioni","text":"Per formalizzare si intende il processo di estrarre da una proposizione in linguaggio naturale (come italiano o inglese) una una formula di calcolo proposizionale che ha la stessa struttura logica Esempio di formalizzazione Avendo la frase \" Piove e fa freddo \", possiamo da questa proposizione estrarre due proposizioni elementari: \\(P=\\) \" Piove \" e \\(Fr=\\) \" fa freddo \". La proposizione risultante sar\u00e0 quindi \\(P \\land Fr\\)","title":"La formalizzazione di proposizioni"},{"location":"FdI/logica/#la-semantica","text":"La semantica di una proposizione (il suo valore) si pu\u00f2 calcolare per induzione sul suo albero di derivazione. Il risultato in genere per\u00f2 non \u00e8 assoluto ma dipende da un' interpretazione . Definizione di interpretazione Con interpretazione si intende una funzione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) che ci permetta di assegnare un valore di verit\u00e0 ad ogni simbolo proposizionale. Possiamo pensare ad un'interpretazione in una proposizione composta (che definiremo a breve) come ad funzione che mappa ogni simbolo proposizionale ad un valore. Ad esempio, avendo i simboli \\(A\\) , \\(B\\) e \\(C\\) , l'interpretazione ci permette di definire i corrispettivi valori: \\(A=t\\) , \\(B=f\\) e \\(C=t\\) . Per comporre le proposizioni semplici, come abbiamo detto prima, abbiamo bisogno dei connettivi logici, che abbiamo visto prima, ma senza vedere la loro semantica. I connettivi logici possono essere visti come funzioni \\(Bool \\times Bool \\rightarrow Bool\\) . Definizione dei connettivi logici Possiamo definire i connettivi logici attraverso le loro tabelle di verit\u00e0. Possiamo iniziare vedendo la tabella di verit\u00e0 della negazione ( \\(\\neg\\) ): \\(x\\) \\(\\neg x\\) f t t f E poi continuare con gli altri operatori: \\(x\\) \\(y\\) \\(x \\land y\\) \\(x \\lor y\\) \\(x \\Rightarrow y\\) \\(x \\Leftarrow y\\) \\(x \\Leftrightarrow y\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf t\\) \\(\\mathbf f\\) \\(\\mathbf t\\) \\(\\mathbf f\\) Vale la pena notare che nel caso dell'implicazione, se la premessa \u00e8 falsa, la proposizione composta sar\u00e0 vera in quanto la regola non si applicher\u00e0. Per quanto invece riguarda la doppia implicazione, questa richiede che entrambe le proposizioni (da entrambe le parti del segno) siano vere per poter essere vera. Ora che abbiano definito formalmente gli operatori, possiamo introdurre come calcolare formalmente la semantica di una proposizione complessa. Questo perch\u00e9 dobbiamo associare una proposizione con un'interpretazione, che ci possa permettere di stabilire se la pi\u00f9 piccola proposizione ha come valore (nel nostro caso) vero o falso. Semantica del calcolo proposizionale Data un'interpretazione \\(\\mathcal I : X \\rightarrow \\{t,f\\}\\) , il valore rispetto ad \\(\\mathcal I\\) di una formula proposizionale \u00e8 dato dalla funzione \\(\\llbracket \\_ \\rrbracket _\\mathcal I : \\mathbf{Prop} \\rightarrow \\{t,f\\}\\) . Questa funzione \u00e8 definita induttivamente in questo modo: \\(\\doublebr T_\\mathcal I = \\mathbf t\\) e \\(\\doublebr F_\\mathcal I = \\mathbf f\\) \\(\\doublebr A_\\mathcal I = \\mathcal I (A)\\) per ogni \\(A \\in X\\) \\(\\doublebr{(P)}_\\mathcal I = (\\doublebr P_\\mathcal I)\\) per ogni \\(P \\in \\bf Prop\\) \\(\\doublebr {\\neg Q}_\\mathcal I = \\neg \\doublebr Q _\\mathcal I\\) per ogni formula atomica Q \\(\\doublebr {P ~ op ~ Q}_\\mathcal I = \\doublebr P _\\mathcal I ~ ~ op ~ ~ \\doublebr Q_\\mathcal I\\) per ogni connettivo \\(op \\in \\{ \\land,\\lor,\\Rightarrow,\\Leftarrow,\\Leftrightarrow\\}\\) e per ogni \\(P,Q \\in \\mathbf {Prop}\\) \u00c8 possibile notare come le clausule appena descritte, corrispondano alle produzioni grammaticali (nella sezione dedicata alla Sintassi ). Definito il concetto di interpretazione e semantica, abbiamo abbastanza elementi per costruire il concetto di modello logico . Modello logico Data una formula proposizionale \\(P\\) ed un'interpretazione \\(\\cal I\\) , diciamo che \\(\\cal I\\) \u00e8 un modello di \\(P\\) , se \\(P\\) \u00e8 vera in \\(\\cal I\\) (ovvero, se \\(\\doublebr P _\\mathcal I = t\\) ) Per questo concetto, esiste una notazione apposita: \\[ \\mathcal I \\vDash P \\qquad \\qquad (\\mathcal I \\text { \u00e8 modello di P}) \\] Se invece l'interpretazione in \\(\\cal I\\) di \\(P\\) risulta falsa, scriveremo \\(\\mathcal I \\nvDash P\\) . Notare che \u00e8 l'interpretazione ad essere modello di una proposizione. \u00c8 poi possibile estendere ulteriormente questa definizione ad un insieme (di formule \\(\\Gamma\\) (Gamma)). Insieme di formule Gamma \\(\\Gamma\\) Scriviamo \\(\\mathcal I \\vDash \\Gamma\\) ( \\(\\mathcal I\\) \u00e8 modello di Gamma), se \\(\\mathcal I \\vDash P\\) per ogni \\(P\\) in \\(\\Gamma\\) . Se invece esiste almeno una forula in \\(\\Gamma\\) che non \u00e8 modello di \\(I\\) ( \\(\\mathcal I \\nvDash \\cal I\\) ), I non \u00e8 un modello dell'insieme \\(\\Gamma\\) : \\(\\mathcal I \\nvDash \\Gamma\\) Possiamo sottolineare come ogni interpretazione \\(\\cal I\\) valga se consideriamo il modello \\(\\mathcal I \\vDash \\varnothing\\) , dove \\(\\varnothing\\) \u00e8 l'insieme vuoto di formule. Possiamo verificarlo semplicemente seguendo qualche passaggio: Possiamo partire dalla definizione \\(\\mathcal I \\vDash \\Gamma\\) , dove \\(\\Gamma\\) vale \\(\\varnothing\\) Procediamo quindi prendendo ogni elemento di \\(\\Gamma\\) \\(P\\) e verificando se \\(\\cal I\\) vale in \\(P\\) Essendo tuttavia \\(\\Gamma\\) vuoto, non c'\u00e8 nulla da verificare, quindi \\(\\mathcal I \\vDash \\varnothing\\) vale vacuamente Una volta definiti i modelli, potremmo voler considerare quindi la possibilit\u00e0 di compararli. Definiamo quindi il concetto di equivalenza Equivalenza logica Quando due modelli hanno gli stessi modelli (ovvero assumo lo stesso valore di verit\u00e0 per ogni interpretazione), vengono detti logicamente equivalenti** : \\[ P \\equiv Q \\qquad \\qquad (\\text { P e Q sono logicamente equivalenti}) \\] Conseguenza logica Data una formula proposizionale \\(P\\) ed un insieme di formule \\(\\Gamma\\) , \\(P\\) \u00e8 una conseguenza logica di \\(\\Gamma\\) se: \\(P\\) \u00e8 vera in ogni interpretazione che rende vere tutte le formule di \\(\\Gamma\\) oppure (in modo equivalente) Se ogni modello di \\(\\Gamma\\) \u00e8 anche un modello di \\(P\\) Possiamo quindi formalizzare in questo modo: \\[ \\Gamma \\equiv P \\qquad \\qquad (\\text {P \u00e8 conseguenza logica di } \\Gamma) \\] Abbiamo quindi determinato come, date due formule proposizionali \\(P\\) e \\(Q\\) , vale che: \\[ P \\equiv Q \\qquad \\text {se e solo se} \\qquad \\{P\\} \\vDash Q \\;\\; e \\;\\; \\{Q\\} \\vDash P \\]","title":"La semantica"},{"location":"FdI/logica/#le-tavole-di-verita","text":"\u00c8 possibile valutare una formula proposizionale anche facendo uso delle tavole di verit\u00e0 , che ci permettono di raggiungere lo stesso scopo in maniera pi\u00f9 semplice. Possiamo assegnare una priorit\u00e0 agli operatori che vediamo (in questo caso la priorit\u00e0 \u00e8 in ordine decrescente): Connettivo Priorit\u00e0 \\(\\neg\\) 1 \\(\\land\\) , \\(\\lor\\) 2 \\(\\Rightarrow\\) , \\(\\Leftarrow\\) 3 \\(\\Leftrightarrow\\) 4 Possiamo quindi dire che, data questa priorit\u00e0, la formula \\(A \\land \\neg B \\Leftrightarrow C \\Leftarrow D\\) \u00e8 equivalente a \\((A \\land (\\neg (B))) \\Leftrightarrow (C \\Leftarrow D)\\) . Onde non essere (o non rischiare di essere) ambigui, \u00e8 comunque consigliato fare uso abbondante di parentesi. Facendo uso di una tavola di verit\u00e0, possiamo avere sul lato \"sinistro\" della tabella tutte le possibili interpretazioni di ogni proposizione semplice, o un sottoinsieme di queste. Sul lato destro, abbiamo invece il valore che la forumla proposizionale in questione avr\u00e0 con l'interpretazione \\(\\cal I\\) fornita dal \"lato sinistro\". Possiamo osservare un esempio di una tavola di verit\u00e0 con una sola interpretazione: \\(A\\) \\(B\\) \\(C\\) \\(((\\ A \\ \\land \\ B) \\ \\lor \\ \\neg \\ C)\\) \\(t\\) \\(f\\) \\(f\\) Valutiamo \\(A\\) , \\(B\\) e \\(C\\) \\(t \\qquad ~ f \\qquad \\quad f ~\\) Valutiamo \\(A \\land B\\) e \\(\\neg \\ C\\) \\(\\ f \\qquad \\quad ~ ~ t ~\\) Valutiamo l' \\(\\lor\\) \\(\\qquad ~ t\\)","title":"Le tavole di verit\u00e0"},{"location":"FdI/logica/#il-concetto-di-tautologia","text":"Definizione di Tautologia Una tautologia \u00e8 una formula proposizionale che risulta sempre vera per ogni interpretazione . Possiamo definirla sintatticamente come un modello senza interpretazione , che quindi varr\u00e0 a priori: \\[ \\varnothing \\vDash P \\qquad \\text {oppure} \\qquad \\vDash P \\] Oltre alle tautologie (che come detto sono vere indifferentemente dall'interpretazione), possiamo definire altre 2 categorie di forule proposizionali: Formule proposizionali Soddisfacibili : Hanno almeno un'interpretazione che le rende vere. Possiamo considerare una tautologia come appartenente anche a questa categoria Contraddizioni : Sono formule proposizionali che sono false in ogni interpretazione. Possiamo indicarle con \\(\\varnothing \\nvDash P\\) oppure \\(\\nvDash P\\) . Non tautologie ( \\(\\nvDash\\) ): L'insieme delle formule proposizionali, tranne le tautologie (che quindi compende anche le contraddizioni) \u250c\u2500 Formule proposizionali soddisfacibili \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tautologie \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500 Non-tautologie \u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u250c Contraddizioni \u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 TODO (tanto non lo far\u00f2 mai \ud83d\ude43): Sostituire con un grafico vero ed esempi Possiamo dimostrare che una formula non \u00e8 una tautologia trovando un'interpretazione per la quale la formula non risulta vera. Stesso discorso vale per le formule proposizionali soddisfacibili: \u00e8 sufficiente trovare una singola interpretazione che renda la formula vera per farla rientrare nella categoria. Esempio di Tautologia Prendiamo in considerazione il seguente esempio. Notare che le varie righe per ogni cella rappresentano il valore della sottoproposizione ad ogni step (quindi nella prima riga valutiamo le proposizioni semplici facendo uso dell'interpretazione a sinistra, nella seconda valutiamo l'and e nella terza l'implicazione) \\(A\\) \\(B\\) \\(A \\land B \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(f\\) \\(t\\) \\(f \\quad t \\qquad t\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(f\\) \\(t \\quad f \\qquad f\\) \\(\\;\\; f\\) \\(\\qquad \\quad t\\) \\(t\\) \\(t\\) \\(t \\quad t \\qquad t\\) \\(\\;\\; t\\) \\(\\qquad \\quad t\\) Esempio di Contraddizione \\(A\\) \\(B\\) \\(A \\land (B \\land \\neg A)\\) \\(f\\) \\(f\\) \\(f \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(f\\) \\(t\\) \\(f \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} t\\) \\(\\hspace{2.9em} t\\) \\(\\hspace{1em} f\\) \\(t\\) \\(f\\) \\(t \\hspace{1.5em} f \\hspace{2.2em} f\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.5em} t \\hspace{2.2em} t\\) \\(\\hspace{4em} f\\) \\(\\hspace{2.9em} f\\) \\(\\hspace{1em} f\\) Esempio di formula soddisfacibile \\(A\\) \\(B\\) \\(A \\Rightarrow B\\) \\(f\\) \\(f\\) \\(f \\hspace{1.8em} f\\) \\(\\hspace{1.2em} t\\) \\(f\\) \\(t\\) \\(f \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) \\(t\\) \\(f\\) \\(t \\hspace{1.8em} f\\) \\(\\hspace{1.2em} f\\) \\(t\\) \\(t\\) \\(t \\hspace{1.8em} t\\) \\(\\hspace{1.2em} t\\) Come abbiamo appena visto, non \u00e8 del tutto scontato identificare una tautologia quando ne vediamo una. Questo rappresenta un problema fondamentale del calcolo proposizionale: costruire una tabella di verit\u00e0 per una formula con 10 simboli, significherebbe avere \\(2^{10}\\) righe. Possiamo tuttavia dimostrare quando una formula \u00e8 una tatutologia ricorrendo a delle dimostrazioni per sostituzione. In alternativa, \u00e8 possibile trovare una soluzione partendo dall'ultimo connettivo logico (in termimi di valutazione) ed \"assegnandogli\" un valore falso, andando quindi a ritroso.","title":"Il concetto di Tautologia"},{"location":"FdI/logica/#dimostrazioni-nel-calcolo-proposizionale","text":"Come abbiamo visto, la proposizione \\(P\\) \u00e8 conseguenza logica di un insieme di formule \\(\\Gamma\\) se \\(P\\) \u00e8 vera in tutti i modelli di \\(\\Gamma\\) .","title":"Dimostrazioni nel calcolo proposizionale"},{"location":"FdI/logica/#formalizzazione-di-inferenze-e-tautologie","text":"\u00c8 possibile fare uso della formalizzazione per mostrare la correttezza di una certa inferenza o ragionamenti logici semplici espressi in linguaggio naturale. Sistema di dimostrazioni Dato un insieme di formule \\(\\Delta\\) , un sistema di dimostrazioni (o proof system) per \\(\\Delta\\) \u00e8 un insieme di regole di interenza \\(\\cal R\\) . Una reola di inferenza \\(r \\in \\cal R\\) ha la struttura: \\[ \\frac{P_1 \\ \\cdots P_n}{P} [r] \\] Dove P \u00e8 la conseguenza e \\(P_1 \\ \\cdots P_n\\) sono le premesse. Se \\(n=0\\) la regola si chiama assioma. Dimostrazione Una dimostrazione in un proof system \\(\\cal R\\) di una formula \\(Q \\in \\Delta\\) in un insieme di premesse \\(\\Gamma \\in \\Delta\\) \u00e8 una sequenza di formule \\(Q_1,...,Q_n\\) , dove: Ogni formula \\(Q\\) \u00e8 un elemento di \\(\\Gamma\\) oppure \u00e8 ottenuta applicando una regola di inferenza di \\(\\cal R\\) a partire dalle formule in \\(\\Gamma\\) o in \\(Q_i,...,Q_{i-1}\\) \\(Q_n\\) \u00e8 proprio \\(Q\\) Se esiste una dimostrazione scriveremo: \\[ \\Gamma \\vdash _{\\cal R} Q \\quad \\text{Q \u00e8 dimostrabile da }\\Gamma \\] Correttezza e completezza \\[ \\Gamma \\vdash _{\\cal R} P \\ \\text{ implica } \\ \\Gamma \\vDash P \\text{ (correttezza)} \\]","title":"Formalizzazione di inferenze e tautologie"},{"location":"FdI/logica/#dimostrazioni-per-sostituzione-di-tautologie","text":"","title":"Dimostrazioni per sostituzione di tautologie"},{"location":"FdI/logica/#rimpiazzamento","text":"","title":"Rimpiazzamento"},{"location":"FdI/logica/#principio-di-sostituzione","text":"","title":"Principio di sostituzione"},{"location":"FdI/logica/#_1","text":"","title":""},{"location":"FdI/logica/#logica-dei-predicati","text":"","title":"Logica dei predicati"},{"location":"FdI/relazioni/","text":"Relazioni \u00b6 Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\) Operazioni su relazioni \u00b6 Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\) Composizione \u00b6 Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C Quantificatori \u00b6 Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica Relazione opposta \u00b6 La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\) Leggi \u00b6 Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\) Propriet\u00e0 di relazioni \u00b6 Le propriet\u00e0 TUSI \u00b6 In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva Risultati di dualit\u00e0 \u00b6 Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\) Teorema di caratterizzazione \u00b6 Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\) Chiusura per composizione \u00b6 \u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva Funzioni \u00b6 Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ). Propriet\u00e0 \u00b6 Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) . Composizione di funzioni \u00b6 Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\) Teorema di caratterizzazione \u00b6 Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\) Funzioni parziali \u00b6 Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale. Funzioni surgettive ed iniettive \u00b6 Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0. Biiezioni \u00b6 Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione. Caratterizzazione attraverso relazioni invertibili \u00b6 Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile Insiemi in biiezione \u00b6 Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0. n-uple e sequenze \u00b6 Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"Relazioni"},{"location":"FdI/relazioni/#relazioni","text":"Esaminiamo qui la nozione di relazione. Ma cos'\u00e8 una relazione? Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Segue quindi che \\(Rel(A,B) = \\mathcal P(A \\times B)\\) . Data inoltre una relazione \\(R: A \\leftrightarrow B\\) , avendo \\(a \\in A\\) e \\(b \\in B\\) , se \\((a,b) \\in R\\) , allora possiamo dire che \\(a\\) \u00e8 in relazione \\(R\\) con \\(b\\) . Possiamo quindi vedere una relazione: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Possiamo ora definire quindi 3 occorrenze speciali Relazione completa Definiamo una relazione come completa quando il prodotto cartesiano \\(A \\times B\\) \u00e8 una relazione in \\(Rel(A,B)\\) . Ecco un esempio di relazione completa: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u25bc \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u25b2 \u2502 \u2514\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500y\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u252c\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u25bc \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Relazione vuota Chiamiamo relazione vuota quella relazione derivante dal fatto che \\(\\varnothing \\subseteq A \\times B\\) , che \u00e8 quindi una relazione in \\(Rel(A,B)\\) . La relazione vuota viene denotata con \\(\\varnothing _ {A,B}\\) Ecco una relazione che contiene solo la relazione vuota \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 a \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 x \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 y \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 c \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00c8 poi possibile osservare che l'insieme di partenza e di arrivo possono coincidere. Questo dettaglio ci torner\u00e0 utile per definire il concetto di relazione di identit\u00e0: Relazione di identit\u00e0 Per ogni insieme A, chiamiamo la relazione \\(\\{(x,x) | x \\in A \\} \\subseteq A \\times A\\) Relazione Identit\u00e0 e la richiamiamo con la notazione \\(Id_A : A \\leftrightarrow A\\) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 a \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba a \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 b \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba b \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 c \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25ba c \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Per quanto riguarda notazioni molto grandi, \u00e8 possibile fare uso dei punti per sottointendere la regola, come vediamo accadere per molte relazioni matematiche. Ad esempio la relazione \\(Succ = \\{ (x,y) \\in \\mathbb N \\times \\mathbb N | y = x + 1 \\} : \\mathbb N \\leftrightarrow \\mathbb N\\) si pu\u00f2 semplificare in questo modo: \\(Succ = \\{ (0,1), (1,2), (2,3), ...\\} : \\mathbb N \\leftrightarrow \\mathbb N\\)","title":"Relazioni"},{"location":"FdI/relazioni/#operazioni-su-relazioni","text":"Dal momento che ogni relazione \u00e8 essa stessa un insieme, possiamo combinare le relazioni con gli operatori insiemistici che abbiamo gi\u00e0 visto. Quando si combinano le relazioni \u00e8 sempre bene prestare attenzione agli operatori di partenza e di arrivo. Distinguiamo 4 operazioni insiemistiche sulle relazioni: unione, intersezione, differenza e complemento. Per gli esempi, consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: A \\leftrightarrow B\\) \\(R \\cup S: A \\leftrightarrow B\\) \u00e8 detta Unione di R ed S \\(R \\cap S : A \\leftrightarrow B\\) \u00e8 detta Intersezione di R ed S \\(R \\\\ S: A \\leftrightarrow B\\) \u00e8 detta Differenza di R con S \\((A \\times B) \\text{ \\ } R :A \\leftrightarrow B\\) \u00e8 detta Complemento di R Il complemento di una relazione \\(R: A \\leftrightarrow B\\) \u00e8 denotato da \\(\\overline R\\) Notiamo che quando si parla di relazione tra due insiemi A e B, si fissa sempre come universo \\(\\cal U\\) l'insieme \\(A \\times B\\)","title":"Operazioni su relazioni"},{"location":"FdI/relazioni/#composizione","text":"Definizione di Composizione Consideriamo due relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) , la composizione di R con S \u00e8 la relzione \\(R;S: A \\leftrightarrow C\\) . La definiamo cos\u00ec: \\[ R;S = \\{ (x,z) \\in A \\times C | \\text{ esiste almeno un } y \\in B \\text{ tale che } (x,y) \\in R \\text{ e } (y,z) \\in S \\} \\] Quindi possiamo vederla in questo modo: R;S \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 \u2502 R S \u25bc \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2022 A B C","title":"Composizione"},{"location":"FdI/relazioni/#quantificatori","text":"Alcune espressioni in matematica rivestono un ruolo particolare. Un esempio \u00e8 l'espressione \"esiste almeno\". Quantificatore esistenziale Prendiamo l'espressione \"esiste almeno\". Questa espressione viene denotata dal segno \\(\\exists\\) e viene chiamato quantificatore esistenziale . La formula \\((\\exists a \\in A.P(a))\\) si legge \"esiste almeno un elemento di A tale che la propriet\u00e0 P \u00e8 vera\". Quantificatore universale L'altra espressione \u00e8 \"Per ogni\", chiamata quantificatore universale e denotata dal simbolo \\(\\forall\\) . Avremo modo di riparlare dei quantificatori con maggior dettaglio quando tratteremo la logica","title":"Quantificatori"},{"location":"FdI/relazioni/#relazione-opposta","text":"La relazione opposta \u00e8 quella relazione che \"annulla\", una certa relazione. Se la relazione \u00e8 una funzione, la relazione opposta sar\u00e0 equivalente all'identit\u00e0. Relazione opposta La relazione opposta di \\(R: A \\leftrightarrow\\) \u00e8 la relazione \\(R^{op}: B \\leftrightarrow A\\) ed \u00e8 definita come: \\[ R^{op} = \\{ (y,x) \\in B \\times A \\ | \\ (x,y) \\in R \\} \\] Fondamentalmente si \"inverte\" l'ordine delle coppie nella relazione (da \\((a,b)\\) la relazione diventa \\((b,a)\\) ) Avendo due relazioni \\(R^{op}: B \\leftrightarrow A\\) e \\(S^{op}: C \\leftrightarrow B\\) , queste non possono essere composte ( \\(R^{op};S^{op}\\) ), perch\u00e9 l'insieme di arrivo di \\(R^{op}\\) e quello di partenza di \\(S^{op}\\) non coincidono. \u00c8 possibile per\u00f2 comporre la relazione \\(S^{op};R^{op}\\)","title":"Relazione opposta"},{"location":"FdI/relazioni/#leggi","text":"Come per gli insiemi, possiamo trovere delle leggi anche per gli insiemi Legge Formula associativit\u00e0 \\((R \\cup S) \\cup T = R \\cup (S \\cup T)\\) \\((R \\cap S) \\cap T = R \\cap (S \\cap T)\\) \\(R;(S;T) = (R;S);T\\) unit\u00e0 \\(R \\cup \\varnothing = R\\) \\(R \\cap (A \\times B) = R\\) \\(Id_A;R = R = R;Id_B\\) commutativit\u00e0 \\(R \\cup S = S \\cup R\\) \\(R \\cap S = S \\cap R\\) idempotenza \\(R \\cup R = R\\) \\(R \\cap R = R\\) assorbimento \\(R \\cup (A \\times B) = (A \\times B)\\) \\(R \\cap \\varnothing = \\varnothing\\) distributivit\u00e0 \\(R \\cup (S \\cap T) = (R \\cup S) \\cap (R \\cup T)\\) \\(R \\cap (S \\cup T) = (R \\cap S) \\cup (R \\cap T)\\) \\(R;(S \\cup T) = (R;S) \\cup (R;T)\\) \\((S \\cup T);U = (S;U) \\cup (T;U)\\) \\((R;S)^{op} = S^{op};R^{op}\\) \\((S \\cup T)^{op} = S^{op} \\cup R^{op}\\) \\((S \\cap T)^{op} = S^{op} \\cap T^{op}\\) \\((\\overline R)^{op} = \\overline {(R^{op})}\\) assorbimento \\(R \\cup (R \\cap S) = R\\) \\(R \\cap (R \\cup S) = R\\) \\(R;\\varnothing_{B,C} = \\varnothing_{A,C} = \\varnothing_{A,B};S\\) complemento \\(R \\cup \\overline R = (A \\times B)\\) \\(R \\cap \\overline R = \\varnothing\\) differenza \\(R \\text{ \\ } S = R \\cap \\overline S\\) convoluzione \\((R^{op})^{op} = R\\) opposto-id \\(Id_A^{op} = Id_A\\) opposto-complemento \\((A \\times B)^{op} = (B \\times A)\\) opposto-vuoto \\(\\varnothing^{op}_{A, B} = \\varnothing_{B,A}\\)","title":"Leggi"},{"location":"FdI/relazioni/#proprieta-di-relazioni","text":"","title":"Propriet\u00e0 di relazioni"},{"location":"FdI/relazioni/#le-proprieta-tusi","text":"In questa sezione vengono introdotte quattro tra le maggiori propriet\u00e0, sia nel campo della matematica che dell'informatica. Relazione Totale Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti gli \\(a \\in A\\) esiste almeno un \\(b \\in B\\) tale che \\((a,b) \\in R\\) Detto in maniera un po' pi\u00f9 grezza, ogni elemento di A \u00e8 in relazione R con almeno un elemento di B. Vista graficamente, da ogni elemento di A \"parte una freccia\" verso B . Relazione Univalente Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(a \\in A\\) se esiste al pi\u00f9 un elemento \\(b \\in B\\) tale che \\((a,b) \\in R\\) Questa se vogliamo \u00e8 un po' il complementare della relazione totale, dove si dice che un elemento di A \u00e8 al massimo in relazione con un elemento in B. Graficamente, possiamo immaginare come da ogni elemento in A parta al massimo una freccia. Notare che le 2 relazioni appena definite non sono mutualmente esclusive, tutt'altro: Per una relazione, essere Totale e Univalente significa che per ogni elemento di A esiste una ed una sola relazione con un elemento in B. Questa \u00e8 l'anticipazione alla definizione di funzione, che vedremo in seguito. Relazione Surgettiva Data \\(R: A \\leftrightarrow B\\) si dice totale se per tutti i \\(b \\in B\\) esiste almeno un \\(a \\in A\\) tale che \\((a,b) \\in R\\) Questo possiamo vederlo come l'equivalente della relazione totale, solo per il codominio (B). Viene infatti richiesto che ogni elemento di B sia raggiunto da almeno un elemento di A. Relazione Iniettiva Data \\(R: A \\leftrightarrow B\\) si dice univalente per tutti gli elementi \\(b \\in B\\) se esiste al pi\u00f9 un elemento \\(a \\in A\\) tale che \\((a,b) \\in R\\) E la relazione iniettiva richiede invece che ogni elemento di B venga raggiunto al pi\u00f9 da un elemento di A. Questa relazione tra totalit\u00e0 e surgettivit\u00e0 e tra univalenza ed iniettivit\u00e0 non passa inosservata: viene infatti detto che esiste una dualit\u00e0 tra le due coppie di relazioni. Possiamo riassumere quindi le quattro propriet\u00e0 in questo modo: elementi insieme di partenza insieme di arrivo almeno uno Totale Surgettiva al pi\u00f9 un elemento Univalente Iniettiva","title":"Le propriet\u00e0 TUSI"},{"location":"FdI/relazioni/#risultati-di-dualita","text":"Come detto, le relazioni che hanno una dualit\u00e0 tra di loro (quindi totale con surgettiva e univalente con iniettiva), ovvero impongono lo stesso vincolo, ma le prime lo esercitano sull'insieme di partenza, mentre le seconde su quello di arrivo. Inoltre, come abbiamo visto, l'operazione \\(\\cdot^{op}\\) inverte gli insiemi di partenza e di arrivo. Questo dualismo pu\u00f2 essere quindi arricchito con le relazioni opposte: \\(R: A \\leftrightarrow B \\text{ \u00e8 totale } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 surgettiva}\\) \\(R: A \\leftrightarrow B \\text{ \u00e8 univalente } \\Leftrightarrow \\text{ (se e solo se) } R^{op} : B \\leftrightarrow A \\text{ \u00e8 iniettiva}\\)","title":"Risultati di dualit\u00e0"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione","text":"Le propriet\u00e0 definite poco sopra possono essere caratterizzate attraverso delle operazioni sugli insiemi. Data la relazione \\(R: A \\leftrightarrow B\\) , vale che: \\(R\\) \u00e8 totale se e solo se \\(Id_A \\subseteq R;R^{op}\\) \\(R\\) \u00e8 univalente se e solo se \\(R^{op}; R \\subseteq Id_B\\) \\(R\\) \u00e8 surgettiva se e solo se \\(Id_B \\subseteq R^{op}; R\\) \\(R\\) \u00e8 iniettiva se e solo se \\(R;R^{op} \\subseteq Id_A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#chiusura-per-composizione","text":"\u00c8 importante sapere che le propriet\u00e0 vengono mantenute quando due relazioni vengono composte ed entrambe hanno le stesse funzioni: Date le relazioni \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow C\\) : Se R ed S sono totali, \\(R;S\\) \u00e8 totale Se R ed S sono univalenti, \\(R;S\\) \u00e8 univalente Se R ed S sono surgettive, \\(R;S\\) \u00e8 surgettiva Se R ed S sono iniettive, \\(R;S\\) \u00e8 iniettiva","title":"Chiusura per composizione"},{"location":"FdI/relazioni/#funzioni","text":"Definizione di Funzione Una relazione \\(R \\in Rel(A, B)\\) che sia totale ed univalente \u00e8 detta funzione . Per ogni \\(a \\in A\\) esiste esattamente un \\(b \\in B\\) tale che \\((a,b) \\in R\\) . Le funzioni vengono spesso denotate da lettere minuscole, tipicamente \\(f\\) , \\(g,\\) , \\(h\\) , ... In aggiunta una funzione non si dice essere TRA A e B, ma DA A a B L'insieme di tutte le funzioni da A a B \u00e8 denotato come \\(Fun(A, B)\\) , quindi \\(Fun(A,B) = \\{f: A \\leftarrow B\\}\\) Quando si lavora con le fuznioni \u00e8 particolarmente importante indicare gli insiemi di partenza e di arrivo. Per quanto riguarda le funzioni binarie, che prendono 2 argomenti, invece di usare la notazione prefissa ( \\(f(a,b)\\) ), si tende ad usare la notazione infissa ( \\(a f b\\) ).","title":"Funzioni"},{"location":"FdI/relazioni/#proprieta","text":"Una propriet\u00e0 \u00e8 un'entit\u00e0 che pero ogni elemento di un insieme \\(A\\) , si dice che l'elemento \\(a\\) soddisfa la propriet\u00e0 o no. Pi\u00f9 formalmente, \\(P\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) Definizione di propriet\u00e0 Una propriet\u00e0 su \\(A\\) \u00e8 una funzione \\(P: A \\rightarrow Bool\\) che ha come insieme di partenza l'insieme \\(A\\) e come insiemen di arrivo \\(Bool\\) . Per ogni elemento \\(a \\in A\\) , si dice che \\(a\\) soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = t\\) , mentre si dice che \\(a\\) non soddisfa la propriet\u00e0 \\(P\\) se \\(P(a) = f\\) .","title":"Propriet\u00e0"},{"location":"FdI/relazioni/#composizione-di-funzioni","text":"Tornando a trattare le relazioni e le funzioni come relazioni, l'unica operazione insiemistica che preserva le propriet\u00e0 \u00e8 la composizione. Per tutti gli insiemi A, B, C e per tutte le funzioni \\(f: A \\rightarrow B\\) e \\(g: B \\rightarrow C\\) , la relazione \\(f;g\\) \u00e8 una funzione. Ci possono essere poi svariati modi in cui la composizione pu\u00f2 essere scritta: \\(f;g\\) \\(f \\circ g\\) \\(f g\\) E la stessa cosa vale quando si ha un argomento \\(f;g(a)\\) \\(g(f(a))\\) \\(g f (a)\\)","title":"Composizione di funzioni"},{"location":"FdI/relazioni/#teorema-di-caratterizzazione_1","text":"Abbiamo gi\u00e0 visto il teorema di caratterizzazione poco sopra. Grazie al teorema possiamo caratterizzare le funzioni. Il teorema ci dice che, data la relazione \\(R: A \\leftrightarrow B\\) , questa \u00e8 una funzione se e solo se \\(id_A \\subseteq R;R^{op}\\) e \\(R^{op}; R \\subseteq id_B\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioni/#funzioni-parziali","text":"Definizione di Funzione Parziale Definiamo una relazione solo univalente (quindi non totale) come funzione parziale . Quando abbiamo a che fare con una funzione parziale con \\(a \\in A\\) , diciamo che \\(R\\) \u00e8 definita su \\(a\\) se esiste un b tale che \\(b \\in B\\) e \\((a,b) \\in R\\) , altrimenti diciamo che a non \u00e8 definita su R. Un esempio di funzione parziale pu\u00f2 essere \\(f(x) = \\frac {1}{x}\\) : dato che la divisione per 0 non \u00e8 definita, la funzione non \u00e8 totale, risultando quindi una funzione parziale.","title":"Funzioni parziali"},{"location":"FdI/relazioni/#funzioni-surgettive-ed-iniettive","text":"Le funzioni (quindi relazioni totali ed univalenti ) si diconono surgettive quando godono della propriet\u00e0 della surgettivit\u00e0, e iniettive quando godono della propriet\u00e0 dell'iniettivit\u00e0.","title":"Funzioni surgettive ed iniettive"},{"location":"FdI/relazioni/#biiezioni","text":"Le funzioni biiettive sono funzioni che sono contemporaneamente iniettive e surgettive. Queste funzioni vengono dette biiezioni o in biiezione.","title":"Biiezioni"},{"location":"FdI/relazioni/#caratterizzazione-attraverso-relazioni-invertibili","text":"Notare che se una relazione \\(R\\) \u00e8 una biiezione, anche il suo opposto \\(R^{op}\\) lo sar\u00e0. Possiamo quindi definire il concetto di relazione inversa: Relazione inversa Siano \\(R: A \\leftrightarrow B\\) e \\(S: B \\leftrightarrow\\) , si dice che \\(S\\) \u00e8 l'inversa di \\(R\\) se \\(R;S = Id_A\\) e \\(S;R = Id_B\\) . R si dice invertibile se esiste almeno una relazione inversa di R Possiamo quindi dire che \\(R\\) \u00e8 una biezione se e solo se \u00e8 invertibile","title":"Caratterizzazione attraverso relazioni invertibili"},{"location":"FdI/relazioni/#insiemi-in-biiezione","text":"Insiemi in biiezione Due insiemi si dicono in biiezione se esiste una biiezione \\(i: A \\rightarrow B\\) tra di loro (o in corrispondenza uno a uno). Questo pu\u00f2 essere scritto come \\(A \\cong B\\) Questo significa che ad esempio l'insieme \\(Bool = \\{t,f\\}\\) \u00e8 in biiezione con \\(2 = \\{0, 1\\}\\) Allo stesso modo, se \\(A \\cong \\varnothing\\) , allora \\(A = \\varnothing\\) . Questo perch\u00e9 essere in biiezione implica che le funzioni siano biiezioni. Se quindi A \u00e8 in biiezione \\(\\varnothing\\) , ogni elemento in \\(\\varnothing\\) avr\u00e0 un corrispettivo elemento in A, ma \\(\\varnothing\\) non ha elementi, e quindi neanche A ne avr\u00e0. Possiamo osservare delle propriet\u00e0 che possiamo osservare tra gli insiemi in biiezione: \\(A \\cong A\\) (Riflessivit\u00e0) Se \\(A \\cong B\\) e \\(B \\cong C\\) , allora \\(A \\cong C\\) (Transitivit\u00e0) Se \\(A \\cong B\\) allora \\(B \\cong A\\) (Simmetria) E altre: \\(\\mathcal P(A) \\cong Fun(A, Bool)\\) \\(A \\times (B \\times C) \\cong (A \\times B) \\times C\\) \\(A \\times 1 \\cong A\\) \u00c8 un buon esercizio dimostrare le propriet\u00e0 appena viste Potremmo dire che per essere in biiezione, due insiemi hanno bisogno di possedere la stessa cardinalit\u00e0.","title":"Insiemi in biiezione"},{"location":"FdI/relazioni/#n-uple-e-sequenze","text":"Il risultato del prodotto tra insiemi \\(A \\times B \\times C\\) ha come risultato una tripla \\((a,b,c)\\) Lo stesso procedimento si applica ad un prodotto tra n insiemi (quindi con 2 avremo le coppie, con 4 avremo le quadruple, con 5 le quintuple, e cos\u00ec via). Questo procedimento si applica per un qualsiasi numero \\(n \\in \\mathbb N\\) . Per \\(n=0\\) esiste solo una 0-upla, denotata con \\(()\\) . Definiamo quindi questi oggetti in maniera pi\u00f9 formale: Sequenze Una sequenza su un insieme \\(A\\) di lunghezza n \u00e8 una n-upla ( \\(a_0, a_1,...,a_{n-1}\\) ) dove per ogni indice \\(i \\in \\{0,...,n-1\\}, a_i \\in A\\) . L'insieme di tutte le sequenze \\(A^n\\) \u00e8 definito come \\(A^n = \\{ (a_0, a_1,...,a_{n-1}) | (\\forall i \\in A \\{ 0,...,n-1 \\}. a_i \\in A) \\}\\) Questa struttura dati \u00e8 molto usata in Matematica e Fisica: quando A \u00e8 l'insieme dei numeri reali \\(\\mathbb R\\) , una sequenza di lunghezza n \u00e8 chiamata vettore di \\(\\mathcal R^n\\) . Questo viene solitamente rappresentato in riga \\((r_0, r_1,...,r_{n-1})\\) o in colonna: \\(\\left ( {\\begin{array}r_0\\\\r_1\\\\...\\\\r_{n-1}\\end{array}} \\right )\\) L'insieme di tutte le sequenze \\(R^n\\) prende il nome di spazio vettoriale. In informatica queste sequenze sono chiamate array . Sequenze di lunghezza arbitraria Una sequenza di linghezza arbitraria \u00e8 una sequenza di lunghezza n (con \\(n \\in \\mathbb N\\) ). L'insieme di tutte le sequenze esistenti \\(A^*\\) \u00e8 quindi definito con l'unione di ogni possibile sequenza: \\[ A^* = \\bigcup _ {n \\in \\mathbb N} A^n \\]","title":"n-uple e sequenze"},{"location":"FdI/relazioniInsiemi/","text":"Relazioni su insiemi \u00b6 Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi . Propriet\u00e0 di relazioni su un insieme \u00b6 Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ). Teorema di caratterizzazione \u00b6 Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\) Le chiusure \u00b6 Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta Chiusura riflessiva \u00b6 Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme. Chiusura simmetrica \u00b6 Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta Chiusura transitiva \u00b6 La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\) La stella di Kleene \u00b6 Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\) Relazioni di equivalenza \u00b6 Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza. Kernel di una funzione \u00b6 Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa. Relazioni di equivalenza e partizioni \u00b6 Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\] Relazioni di ordinamento \u00b6 Relazione di ordinamento parziale \u00b6 Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) . Relazione di ordinamento \u00b6 Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\) Ordinamento lessicografico \u00b6 Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#relazioni-su-insiemi","text":"Riprendiamo il concetto di relazione, e per agevolare la lettura, anche la sua definizione: Definizione di Relazione Una relazione \\(R\\) tra l'insieme \\(A\\) e l'insieme \\(B\\) \u00e8 un sottoinsieme del prodotto cartesiano \\(A \\times B\\) , quindi \\(R \\subseteq A \\times B\\) . Indichiamo poi l'insieme di tutte le relazioni tra \\(A\\) e \\(B\\) con la notazione \\(Rel(A,B)\\) . Indichiamo quindi che \\(R\\) \u00e8 una relazione tra \\(A\\) e \\(B\\) scrivendo \\(R \\in Rel(A,B)\\) , o pi\u00f9 comunemente: \\(R: A \\leftrightarrow B\\) Dove \\(A\\) \u00e8 detto insieme di partenza e \\(B\\) insieme di arrivo. Ovviamente possiamo sostituire l'insieme \\(B\\) con \\(A\\) e mantenere la stessa definizione e tutte le propriet\u00e0 che abbiamo visto nei capitoli precedenti. Per quanto riguarda le relazioni su loro stessi, i classici diagrammi di Eulero-Venn possono essere rappresentati come grafi : Gli elementi dell'insieme vengono chiamati nodi , mntre gli elementi di \\(R\\) sono rappresentati come frecce e vengono chiamati archi .","title":"Relazioni su insiemi"},{"location":"FdI/relazioniInsiemi/#proprieta-di-relazioni-su-un-insieme","text":"Vediamo ora la relazione riflessiva Relazione riflessiva Una relazione \\(R: A \\leftrightarrow A\\) si dice riflessiva se per ogni elemento \\(a \\in A\\) : \\[ (a,a) \\in R \\] Un esempio di relazione rilessiva \u00e8 la relazione identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione completa \\(A \\times A: A \\leftrightarrow A\\) La relazione \\(\\varnothing: A \\leftrightarrow A\\) \u00e8 riflessiva solo quando \\(A = \\varnothing\\) Fondamentalmente, una relazione \\(R: A \\leftrightarrow A\\) per essere riflessiva deve contenere la relazione identit\u00e0 \\(Id_A \\subseteq A\\) Relazione transitiva Una relazione \\(R: A \\leftrightarrow A\\) si dice transitiva quando per tutti gli elementi \\(a,b,c \\in A\\) , se \\((a,b) \\in R\\) e \\((b,c) \\in R\\) , allora \\((a,c) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni transitive. Un altro esempio di relazioni transitive sono \\(< : A \\leftrightarrow A\\) e \\(\\leq : A \\leftrightarrow A\\) . Visalmente si pu\u00f2 fare riferimento alle relazioni che percorrono 2 nodi in successione. Per ogniuno di questi casi, ci dovr\u00e0 essere un arco ad unire gli \"estremi\": Relazione simmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice simmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) allora \\((b,a) \\in R\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) , il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni simmetriche. Praticamente ogni arco deve avere un corrispettivo arco con l'orientazione opposta. Relazione antisimmetrica Una relazione \\(R: A \\leftrightarrow A\\) si dice antisimmetrica quando per tutti gli elementi \\(a,b \\in A\\) , se \\((a,b) \\in R\\) e \\((b,a) \\in R\\) allora \\(a=b\\) Per ogni insieme, la relazioni di identit\u00e0 \\(Id_A: A \\leftrightarrow A\\) e la relazione vuota \\(\\varnothing: A \\leftrightarrow A\\) sono relazioni anti-simmetriche. Non sempre il prodotto cartesiano \\(A \\times A: A \\leftrightarrow A\\) \u00e8 antisimmetrico solo se vuoto o con cardinalit\u00e0 uno ( da verificare ) Si pu\u00f2 identificare facilmente una relazione antisimmetrica, verificando che non ci sono coppie di archi con orientamento opposto (quindi ad esempio \\((a,b)\\) e \\((b,a)\\) ).","title":"Propriet\u00e0 di relazioni su un insieme"},{"location":"FdI/relazioniInsiemi/#teorema-di-caratterizzazione","text":"Possiamo caratterizzare le propriet\u00e0 come abbiamo fatto per le propriet\u00e0 TUSI: Prendendo in considerazione una relazione \\(R: A \\leftrightarrow A\\) : \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) \\(R\\) \u00e8 antisimmetrica se e solo se \\(R \\cap R^{op} \\subseteq A\\)","title":"Teorema di caratterizzazione"},{"location":"FdI/relazioniInsiemi/#le-chiusure","text":"Possiamo vedere le chiusure come delle relazioni \"complementari\" che fanno s\u00ec che una certa propriet\u00e0 sia soddisfatta","title":"Le chiusure"},{"location":"FdI/relazioniInsiemi/#chiusura-riflessiva","text":"Data una relazione \\(R: A \\leftrightarrow A\\) , possiamo sempre renderla una chiusura riflessiva: Chiusura riflessiva La chiusura riflessiva di una relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup Id_A\\) Per avere una chiusura riflessiva, \u00e8 sufficiente inserire un arco in ogni elemento dell'insieme.","title":"Chiusura riflessiva"},{"location":"FdI/relazioniInsiemi/#chiusura-simmetrica","text":"Chiusura simmetrica La chiusura simmetrica della relazione \\(R: A \\leftrightarrow A\\) \u00e8 la relazione \\(R \\cup R^{op}\\) Questa definizione fa s\u00ec che per ogni relazione, esista anche la relazione opposta","title":"Chiusura simmetrica"},{"location":"FdI/relazioniInsiemi/#chiusura-transitiva","text":"La chiusura transitiva \u00e8 un attimo pi\u00f9 complicata: un approccio naive potrebbe essere pensare di unire la relazione con la combinazione di s\u00e9 stessa ( \\(R \\cup R;R\\) ), tuttavia la relazione risultante non sarebbe necessariamente transitiva. Prendiamo come esempio l'insieme \\(A=\\{1,2,3,4\\}\\) e la relazione \\(R=\\{(1,2), (2,3), (3,4)\\}\\) . L'unione di \\(R\\) con \\(R;R\\) porterebbe ad avere \\(R \\cup \\{(1,3), (2,4)\\}\\) , ma non \\((1,4)\\) ad esempio. Per averla relativa dobbiamo concatenare ancora una volta la relazione: \\(R \\cup R;R \\cup R;R;R = R \\cup R;R \\cup \\{(1,4)\\}\\) La chiusura transitiva \u00e8 una composizione n-aria di relazione che pu\u00f2 essere definita induttivamente: Per ogni \\(n \\in \\mathbb N\\) , definiamo \\(R^n\\) : \\(R^0 = id_A\\) (clausola base) \\(R^{n+1} = R;R^n\\) Per avere la chiusura transitiva, \u00e8 ora sufficiente fare l'unione infinita di \\(R^n\\) con \\(n = 1,2,...\\) : \\[ \\bigcup_{n \\in N+} R^n \\] Chiusura transitiva La chiusura transitiva di \\(R: A \\leftrightarrow A\\) , denotata \\(R^+\\) \u00e8 rappresentata dalla relazione \\[ R^+ = \\bigcup_{n \\in \\mathbb N+} R^n \\] Per ogni relazione \\(R: A \\leftrightarrow A\\) , vale che: \\(R^+\\) \u00e8 transitiva \\(R \\subseteq R^+\\) Per ogni relazione \\(S: A \\leftrightarrow A\\) , se \\(R \\subseteq S\\) ed \\(S\\) \u00e8 transitiva, allora \\(R^+ \\subseteq S\\)","title":"Chiusura transitiva"},{"location":"FdI/relazioniInsiemi/#la-stella-di-kleene","text":"Modificando la definizione appena data per la chiusura transitiva per avere \\(\\mathbb N\\) invece di \\(\\mathbb N+\\) , otteniamo la relazione \\(R^0 \\cup R^+ = id_A \\cup R^+\\) , definita chiusura riflessiva e transitiva Chiusura riflessiva e transitiva La chiusura e transitiva di \\(R\\) , denotata come \\(R^*\\) , \u00e8 definita come \\[ R = \\bigcup_{n \\in \\mathbb N} R^n \\] Valgono le stesse propriet\u00e0 definite poco sopra per la chiusura transitiva Questa \u00e8 la pi\u00f9 piccola relazione riflessiva e transitiva che contiere \\(R\\) . La stella di Krleene \\(R^*\\) \u00e8 pensata come una sorta di unione illimitata di R. Possiamo inoltre definire delle leggi: Legge Formula riflessivit\u00e0 \\(id_A \\subseteq R^*\\) transitivit\u00e0 \\(R^*;R^* \\subseteq R^*\\) chiusura \\(R \\subseteq R^*\\) idempotenza \\((R^*)^* = R^*\\) *-id \\(id^*_A = id_A\\) *-compl \\((A \\times A)^* = A \\times A\\) *-vuoto \\(\\varnothing^*_{A,A} = id_A\\) distributivit\u00e0 di * \\(R^* \\cup S^* \\subseteq (R \\cup S)^*\\) \\((R \\cap S)^* \\subseteq R^* \\cap S^*\\) \\((R^*)^{op} = (R^{op})^*\\)","title":"La stella di Kleene"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza","text":"Relazione di equivalenza Una relazione \\(R: A \\leftrightarrow A\\) si dice di equivalenza se riflessiva, transitiva e simmetrica. Per ogni insieme la relazione \\(id_A: A \\leftrightarrow A\\) e \\(A \\times A: A \\leftrightarrow A\\) sono relazioni di equivalenza Quindi, riprendendo parte del teorema di caratterizzazione: \\(R\\) \u00e8 rifelssiva se e solo se \\(Id_A \\subseteq R\\) \\(R\\) \u00e8 transitiva se e solo se \\(R; R \\subseteq R\\) \\(R\\) \u00e8 simmetrica se e solo se \\(R^{op} \\subseteq R\\) Tutte e tre queste propriet\u00e0 devono essere soddisfatte per definire la relazione come di equivalenza.","title":"Relazioni di equivalenza"},{"location":"FdI/relazioniInsiemi/#kernel-di-una-funzione","text":"Kernel di una funzione Il kernel della funzione \\(f: A \\rightarrow B\\) \u00e8 definita come: \\[ Ker(f) = \\{ (x,y) \\in A \\times A | f(x) = f(y) \\} \\] Esempio di kernel Dato un insieme \\(A = \\{a,b,c\\}\\) , un insieme \\(B = \\{ \\alpha, \\beta \\}\\) ed una funzione \\(f = \\{ (a,\\alpha), (b,\\alpha), (c, \\beta) \\}\\) , Il kernel della funzione sar\u00e0 \\(Ker(f) = \\{(a,a),(b,b),(c,c),(a,b),(b,a) \\}\\) Per ogni funzione \\(f: A \\rightarrow B\\) vale che \\(Ker(f) = f;f^{op}\\) \\(Ker(f)\\) \u00e8 una relazione di equivalenza Queste due proposizioni possono essere trasformate in un teorema di caratterizzazione: tutte le relazioni di equivalenza possono rappresentare il kernel di qualche funzione. Questo viene dimostrato anche facendo uso della nozione di classe di equivalenza: Classe di equivalenza Data la \\(R: A \\leftrightarrow A\\) e \\(a \\in A\\) , la classe i R-equivalenza \u00e8 \\[ [a]_R = \\{ b \\in A | (a,b) \\in R \\} \\] Questo pu\u00f2 essere visto come ogni elemento in \\(A\\) che sia presente nella prima posizione di una coppia della relazione \\(R\\) . Questa relazione ha come risultato tutti gli elementi al secondo posto nelle coppie. Esempio di classe di equivalenza Dato l'insieme \\(A = \\{a,b,c,d\\}\\) e la relazione \\(R = id_A \\cup {(a,b), (b, a)}\\) : \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d)\\} \\cup \\{(a,b), (b,a)\\}\\) \\(R = \\{(a,a), (b,b), (c,c), (d,d), (a,b), (b,a)\\}\\) : \\([a]_R = {a, b}\\) \\([b]_R = {b, a}\\) \\([c]_R = {c}\\) \\([d]_R = {d}\\) Per tutti gli insiemi A e per tutte le relazioni \\(R: A \\leftrightarrow A\\) , \\(R\\) \u00e8 una relazione di equivalenza se e solo se esiste un insieme B ed una funzione \\(f: A \\rightarrow B\\) tale che \\(R = Ker(f)\\) . Da rivedere - pagina 4-15 della dispensa.","title":"Kernel di una funzione"},{"location":"FdI/relazioniInsiemi/#relazioni-di-equivalenza-e-partizioni","text":"Una relazione di equivalenza \u00e8 ci\u00f2 che ci consente di raggruppare tutti quegli che condividono una certa propriet\u00e0 (ad esempio i numeri pari, o che iniziano con un numero). Data una relazione di equivalenza \\(R: A \\leftrightarrow A\\) , \u00e8 possibile considerare l'insieme delle classi di R-equivalenza come \\[ EC_R = \\{ [a]_R | a \\in A \\} \\] Possiamo notare come \\(EC_R\\) formi una partizione per ogni relazione di equivalenza \\(R: A \\leftrightarrow A\\) . Insieme delle classi di equivalenza Riprendendo l'esempio precedente, con \\(A = \\{a,b,c,d\\}\\) e \\(R = id_A \\cup \\{(a,b), (b,a)\\}\\) , \\(EC_R\\) sar\u00e0 uguale a \\(\\{ \\{a,b\\}, \\{c\\}, \\{d\\} \\}\\) . Essendo insiemi infatti gli elementi non ripetuti non aggiungono nessun tipo di informazione. Per tutti gli insiemi \\(A\\) e tutte le relazioni di equivalenza \\(R: A \\leftrightarrow A\\) , \\(EC_R\\) \u00e8 una partizione. Allo stesso modo, data una partizione di un insieme, \u00e8 possibile stabilire una relazione di equivalenza: Data una partizione \\(\\mathcal F = \\{ X_i\\}_{i \\in I}\\) dell'insieme \\(A\\) , definiamo la relazione \\(f_{\\mathcal F}: A \\leftrightarrow I\\) come \\[ f_{\\mathcal F} = \\{ (a,i) \\in A \\times I | a \\in X_i \\} \\] Quello che abbiamo appena descritto ci permette di assegnare ad ogni elemento \\(a\\) di una sottopartizione \\(X_i\\) un valore in \\(f_{\\mathcal F}\\) . Quindi tutto gli elementi \\(a\\) in ogni sottopartizione ( \\(a \\in X_i\\) ) avranno come immagine lo stesso valore in f, che \u00e8 uguale all'indice che usiamo per riferirci alla sottopartizione. Per tutti gli insiemi di A e tutte le partizioni \\(\\mathcal F = \\{ X_i \\}_{i \\in I}\\) di A, la relazione \\(f_{\\mathcal F}\\) \u00e8 una funzione. Per essere una funzione, \\(f_{\\mathcal F}\\) deve essere: Totale : dato che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, vale che \\(A \\subseteq \\bigcup _ {X \\in EC_R} X\\) , e quini per ogni \\(a \\in A\\) esiste un \\(X_i\\) tale che \\(a \\in X_i\\) . Quindi per definizione di \\(f_{\\mathcal F}\\) abbiamo che \\((a,i) \\in f_{\\mathcal F}\\) Univalente : visto che \\(f_{\\mathcal F} = \\{ X_i \\}_{i \\in I}\\) \u00e8 una partizione di A, se \\(i \\neq j\\) , allora \\(X_i \\cap X_j = \\varnothing\\) . Quindi per ogni \\(a \\in A\\) , esiste al pi\u00f9 un \\(i \\in I\\) , tale che \\(a \\in X_i\\) , cio\u00e8 esiste al pi\u00f9 in \\(i \\in I\\) tale che \\((x,i) \\in f_{\\mathcal F}\\) Quindi la relazione corrispontende ad \\(\\mathcal F\\) \u00e8 il kernel di \\(f_{\\mathcal F}\\) . Abbiammo quindi una biezione tra l'insieme delle relazioni di equivalenza su A (denotato da \\(ERel(A)\\) ) e l'insieme delle partizioni su A (denotato da \\(Part(A)\\) ) Questo principio \u00e8 esattamente quello rappresentato dal grafico sopra, che quindi va a valere per ogni partizione esistente in A. Per ogni insieme, vale quindi che \\[ ERel (A) \\cong Part(A) \\]","title":"Relazioni di equivalenza e partizioni"},{"location":"FdI/relazioniInsiemi/#relazioni-di-ordinamento","text":"","title":"Relazioni di ordinamento"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento-parziale","text":"Relazione di ordinamento parziale \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento parziale quando \u00e8 riflessiva, transitiva e antisimmetrica Un esempio di relazione parziale \u00e8 la relazione \\(\\{(X,Y) \\in \\mathcal P(A) \\times \\mathcal P(A) | X \\subseteq Y \\}\\) Per le relazioni di ordinamento parziale, usiamo la notazione infissa: \\(A \\ R \\ B \\cong (a,b) \\in R\\) Le reazioni di ordinamento sono in genere denotate dal simbolo \\(\\sqsubseteq\\) . Si usa il simbolo \\(\\sqsubset\\) per la relazione \\(\\sqsubset = \\{ (x,y) | x \\sqsubseteq y ~ e ~ x \\neq y \\}\\) . Questa notazione \u00e8 analoga alle notazioni \\(<\\) e \\(\\leq\\) sui naturali. C'\u00e8 una grande differenza tra i simboli \\(>\\) e \\(\\leq\\) : per ogni coppia di numeri \\((n,m) \\in \\mathbb N \\times \\mathbb N\\) , vale \\(n \\leq m\\) e \\(m \\leq n\\) .","title":"Relazione di ordinamento parziale"},{"location":"FdI/relazioniInsiemi/#relazione-di-ordinamento","text":"Relazione di ordinamento \\(R: A \\leftrightarrow A\\) \u00e8 una relazione di ordinamento quando: \\(\\text{per tutti gli } (a,b)\\in A \\times A \\text{ vale che } (a,b) \\in R \\text{ oppure } (b,a) \\in R\\) \\(R\\) \u00e8 un ordinamento se e solo se \\(id_A \\subseteq R\\)","title":"Relazione di ordinamento"},{"location":"FdI/relazioniInsiemi/#ordinamento-lessicografico","text":"Un ordinamento lessicografico \u00e8 un esempio particolare di ordinamento, utilizzato per ordinare le parole nei dizionari o negli elenchi. \\(s \\sqsubseteq _{A^n} t\\) se e solo se esiste un \\(i \\in \\{ 0, ..., n \\}\\) tale che per tutti gli indici \\(j < i\\) vale che \\(a_j = a^{'}_i\\) e \\(a_i \\sqsubset a^{'}_i\\) Ordinamento lessicografico Dato l'ordinamento \\(\\sqsubseteq _A : A \\leftrightarrow A\\) , l'ordinamento lessicografico \u00e8 definito come: Per tutte le stringhe \\(s=a_0 a_1 ... a_n\\) e \\(t=a_0 a_1 ... a_m\\) in \\(A^*\\) si ha che \\(s \\sqsubseteq _{A^*} t\\) se e solo se esiste un \\(i \\in \\mathbb N\\) tale che per tutti i \\(j <i\\) , vale che \\(a_j = a^{'}_j\\) ed almeno una delle due condizioni \u00e8 vera: \\(a_i \\sqsubset _A a^{'} _i\\) \\(i = n+1\\) e \\(n < m\\) \\[ s \\sqsubseteq _A t \\text{ se e solo se } \\exists i \\in \\mathbb N . \\forall j<i. a_j = a^{'}_j \\land (a_i \\sqsubset a^{'}_i \\lor (i = n+1 \\land n < m)) \\] Rivedere sezione sull'ordinamento","title":"Ordinamento lessicografico"},{"location":"LabI/","text":"","title":"Laboratorio I"},{"location":"ProAlgo/","text":"Definizione di Algoritmo \u00b6 Definizione di Programma \u00b6 Composizione di un programma \u00b6 Sintassi \u00b6 Categorie sintattiche \u00b6 Dichiarazioni \u00b6 Comandi \u00b6 Espressioni \u00b6 Lessico \u00b6 Grammatica \u00b6 Semantica \u00b6 Scoping \u00b6 Questa roba non so dove vada Funzioni \u00b6 Parametri formali Passaggio per riferimento e per valore Record di attivazione \u00b6 Contiene: - Identit\u00e0 - Chiamante - A chi restituire - Corpo della funzione corrente Tipologia di linguaggi \u00b6 Linguaggio interpretato \u00b6 Linugaggio compilato \u00b6 Architettura di von-Neumann \u00b6 Ciclo fetch-execute \u00b6 valutazione di un algoritmo \u00b6 Analizzare un algoritmo significa predirre le risorse che l'algoritmo richieder\u00e0. Si opssono predirre risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza. La recurisione e l'approccio divide-and-conquer \u00b6 Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera recursiva fino a generare una soluzione per il problema originale La recursione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo recursivo Si dice algoritmo recursivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso recursivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato. Analisi degli algoritmi divide-and-conquer \u00b6 Quando un algoritmo effettua una chiamata recursiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metod[o di sostituzione Il metodo di sostisuzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem Il master theorem \u00e8 un teorema che ci permtte di risolvere velocemente equazioni della forma \\(aT(\\frac{n}{b}) + f(n)\\) , con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema e \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi RISCRIVERE SEGUENDO GLI APPUNTI DEL PROF Classi di complessit\u00e0 \u00b6 se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo","title":"Definizione di Algoritmo"},{"location":"ProAlgo/#definizione-di-algoritmo","text":"","title":"Definizione di Algoritmo"},{"location":"ProAlgo/#definizione-di-programma","text":"","title":"Definizione di Programma"},{"location":"ProAlgo/#composizione-di-un-programma","text":"","title":"Composizione di un programma"},{"location":"ProAlgo/#sintassi","text":"","title":"Sintassi"},{"location":"ProAlgo/#categorie-sintattiche","text":"","title":"Categorie sintattiche"},{"location":"ProAlgo/#dichiarazioni","text":"","title":"Dichiarazioni"},{"location":"ProAlgo/#comandi","text":"","title":"Comandi"},{"location":"ProAlgo/#espressioni","text":"","title":"Espressioni"},{"location":"ProAlgo/#lessico","text":"","title":"Lessico"},{"location":"ProAlgo/#grammatica","text":"","title":"Grammatica"},{"location":"ProAlgo/#semantica","text":"","title":"Semantica"},{"location":"ProAlgo/#scoping","text":"Questa roba non so dove vada","title":"Scoping"},{"location":"ProAlgo/#funzioni","text":"Parametri formali Passaggio per riferimento e per valore","title":"Funzioni"},{"location":"ProAlgo/#record-di-attivazione","text":"Contiene: - Identit\u00e0 - Chiamante - A chi restituire - Corpo della funzione corrente","title":"Record di attivazione"},{"location":"ProAlgo/#tipologia-di-linguaggi","text":"","title":"Tipologia di linguaggi"},{"location":"ProAlgo/#linguaggio-interpretato","text":"","title":"Linguaggio interpretato"},{"location":"ProAlgo/#linugaggio-compilato","text":"","title":"Linugaggio compilato"},{"location":"ProAlgo/#architettura-di-von-neumann","text":"","title":"Architettura di von-Neumann"},{"location":"ProAlgo/#ciclo-fetch-execute","text":"","title":"Ciclo fetch-execute"},{"location":"ProAlgo/#valutazione-di-un-algoritmo","text":"Analizzare un algoritmo significa predirre le risorse che l'algoritmo richieder\u00e0. Si opssono predirre risorse come la memoria, la larghezza di banda per la comunicazione o qualche altra risorsa prima, ma tendenzialmente si tende a calcolare il tempo di computazione. Per farlo \u00e8 necessario fare uso di un modello che rappresenta l'implementazione che andremo ad usare (e quindi un modello per le risorse che andremo ad utilizzare). Il tempo di esecuzione di un algoritmo su un dato input \u00e8 il numero di operazioni primitive (o passi) eseguiti. \u00c8 conveniente definire la nozione di passo per essere il pi\u00f9 astratta e distaccata dalla macchina possibile. Il caso peggiore del tempo di esecuzione di un algoritmo ci fornisce il numero massimo di tempo che l'algoritmo impiegher\u00e0 per un dato input. Ci\u00f2 fornisce la garanzia che l'algoritmo non impiegher\u00e0 mai pi\u00f9 tempo del caso peggiore. Nei casi particolari nei quali si \u00e8 interessati ai casi medi, \u00e8 necessario ricorrere a tecniche di analisi probabilistica: potrebbe infatti non essere scontato cosa costituisce l'input di un problema medio. \u00c8 possibile poi applicare uno strato di astrazione: l'ordine di crescita (o rapporto di crescita): da un polinomio, prendiamo solo il monomio di grado superiore, ignorando i restati monomi di ordine inferiore. Oltre questo, ignoriamo anche il coefficiente del monomio che prendiamo in considerazione, che non risulta essere troppo influente sulla rapporto di crescita per grandi input. Possiamo quindi comparare 2 algoritmi sulla base della loro efficienza.","title":"valutazione di un algoritmo"},{"location":"ProAlgo/#la-recurisione-e-lapproccio-divide-and-conquer","text":"Si basa su 3 concetti: Divide: dividere il problema in sottoproblemi che sono istanze pi\u00f9 piccole del problema base Conquer: Risolvere il sottoproblema Combine: Combinare le soluzioni dei sottoproblemi in maniera recursiva fino a generare una soluzione per il problema originale La recursione termina quando arriva 'alla fine della corsa' (ovvero non \u00e8 pi\u00f9 possibile dividere il problema in ulteriori sottoproblemi dello stesso tipo dei precedenti). Questo tipo di approccio \u00e8 spesso utilizzato da algoritmi ricorsivi Definizione di algoritmo recursivo Si dice algoritmo recursivo quell'algoritmo che come parte della sua soluzione, chiama s\u00e9 stesso recursivamente una o pi\u00f9 volte per risolvere un sottoproblema strettamente correlato.","title":"La recurisione e l'approccio divide-and-conquer"},{"location":"ProAlgo/#analisi-degli-algoritmi-divide-and-conquer","text":"Quando un algoritmo effettua una chiamata recursiva a s\u00e9 stesso, spesso \u00e8 possibile descrivere il suo tempo di esecuzione facendo uso di una equazione (o relazione) di ricorrenza, che descrive il tempo di esecuzione dell'algoritmo dato un problema di grandezza n. Ricorrenza La ricorrenza \u00e8 un'equazione o diseguaglianza che descrive una funzione in termini di s\u00e9 stessa ma su valori pi\u00f9 piccoli Per risolvere un'equazione di ricorrenza (ovvero trovare il \\(\\Theta\\) asintotico (che tende ad infinito) ), ci sono vari metodi: Il metod[o di sostituzione Il metodo di sostisuzione si basa sull'indovinare un limite, per poi fare uso dell'induzione matematica per dimostrarlo Con un albero di ricorrenza Un albero di ricorrenza ci permette di convertire il problema in una struttura ad albero, in cui ogni nodo rappresenta il costo che si ha ai vari livelli della ricorsione. Esistono quindi tecniche per sommare i vari limiti e risolvere quindi la relazione Il master theorem Il master theorem \u00e8 un teorema che ci permtte di risolvere velocemente equazioni della forma \\(aT(\\frac{n}{b}) + f(n)\\) , con \\(a \\geq 1\\) che rappresenta il numero di sottoproblemi e \\(b > 1\\) , che descrive la grandeza di ogni sottoproblema e \\(f(n)\\) che descrive il tempo necessario ad effettuare la combinazione dei sottoproblemi RISCRIVERE SEGUENDO GLI APPUNTI DEL PROF","title":"Analisi degli algoritmi divide-and-conquer"},{"location":"ProAlgo/#classi-di-complessita","text":"se io ho la chiamata ricorsiva n/2 allora \u00e8 log in base 2 di n n/4 l'altezza \u00e8 log in base 4 di n il numero di chiamate ricorsive \u00e8 il numero di figli di ogni nodo","title":"Classi di complessit\u00e0"},{"location":"ProAlgo/programmazioneDinamica/","text":"Programmazione dinamica \u00b6 Un problema risolvibile in programmazione dinamica \u00e8 simile ad un algoritmo di recursione, in cui per\u00f2 si presentano pochi sottoproblemi diversi che si presentano pi\u00f9 volte. \u00c8 quindi un problema di ottimizzazione. I problemi risolvibili attraverso la programmazione dinamica: Devono avere sottostruttura ottima La soluzione ottima del problema deriva dalle soluzioni ottime dei sottoproblemi I problemi deovono essere sovrapponibili (si ripetono) Il problema deve presentare pochi stottoproblemi riptetuti pi\u00f9 volte. La soluzione deve essere polinomiale nella dimensione dell'input La struttura di una soluzione scritta in programmazione dinamica \u00e8 divisa in 4 fasi: Definizine dei sottoprobemi e dimensionamento della tabelle Soluzione dei sottoproblemi e memorizzazione della soluzione nella tabella Definizione delle regole di riempimento della tabella (?) Regole di ricorsione per ottenere la soluzione di un sottoproblema a partire dalle soluzioni dei sottoproblemi gi\u00e0 risolti Restituzione del risultato relativo al problema originale Longest Common Subsequence Date 2 stringhe di caratteri, trovare la sottosequenza comune pi\u00f9 lunga","title":"Programmazione dinamica"},{"location":"ProAlgo/programmazioneDinamica/#programmazione-dinamica","text":"Un problema risolvibile in programmazione dinamica \u00e8 simile ad un algoritmo di recursione, in cui per\u00f2 si presentano pochi sottoproblemi diversi che si presentano pi\u00f9 volte. \u00c8 quindi un problema di ottimizzazione. I problemi risolvibili attraverso la programmazione dinamica: Devono avere sottostruttura ottima La soluzione ottima del problema deriva dalle soluzioni ottime dei sottoproblemi I problemi deovono essere sovrapponibili (si ripetono) Il problema deve presentare pochi stottoproblemi riptetuti pi\u00f9 volte. La soluzione deve essere polinomiale nella dimensione dell'input La struttura di una soluzione scritta in programmazione dinamica \u00e8 divisa in 4 fasi: Definizine dei sottoprobemi e dimensionamento della tabelle Soluzione dei sottoproblemi e memorizzazione della soluzione nella tabella Definizione delle regole di riempimento della tabella (?) Regole di ricorsione per ottenere la soluzione di un sottoproblema a partire dalle soluzioni dei sottoproblemi gi\u00e0 risolti Restituzione del risultato relativo al problema originale Longest Common Subsequence Date 2 stringhe di caratteri, trovare la sottosequenza comune pi\u00f9 lunga","title":"Programmazione dinamica"},{"location":"ProAlgo/relazioniRicorrenza/","text":"Relazioni di ricorrenza \u00b6","title":"Relazioni di ricorrenza"},{"location":"ProAlgo/relazioniRicorrenza/#relazioni-di-ricorrenza","text":"","title":"Relazioni di ricorrenza"},{"location":"ProAlgo/IntroToAlgorithms/intro/","text":"Quando scriviamo gli algoritmi in pseudocodice, lo facciamo per garantire una maggiore espressivit\u00e0 e conicisione. Se necessario possiamo anche scrivere in linguaggio naturale. Di conseguenza, uno pseudocodice non si preoccupa di indirizzare problemi tipici dell'ingegnerizzazione del codice, ma solo di esprimere un algoritmo e quindi garantirne o renderne esplicita la correttezza. Dato che la performance della risoluzione di un certo problema dipende in equal modo sia dall'hardware di un calcolatore che dall'algoritmo, dovremmo considerare gli algoritmi come tecnologia. Cosa che gi\u00e0 facciamo per l'hardware. Loop invariants \u00b6 Quando abbiamo un ciclo in una algoritmo, possiamo parlare di alcune propriet\u00e0 che il ciclo deve soddisfare per aiutarci capire come mai un algoritmo \u00e8 corretto. Queste propriet\u00e0 sono dette invarianti di ciclo (loop invariants)e ci richiedono di dimostrare tre cose: Inizializzazione: Mostriamo che una certa propriet\u00e0 \u00e8 vera prima di effettuare la prima iterazione del ciclo Manutenzione: Una certa propriet\u00e0 \u00e8 vera prima di un'iterazione e rimane vera prima dell'iterazione successiva Terminazione: La propriet\u00e0 ottenuta alla fine del ciclo, che ci permette di dimostrare che un algoritmo \u00e8 corretto \u00c8 possibile tracciare un parallelismo con l' induzione matematica , dove per provare una certa propriet\u00e0, possiamo provare un caso base ed un passo induttivo. Analisi di un algoritmo \u00b6 Analizzare un algoritmo \u00e8 diventato sinonimo di predirre le risorse che l'algoritmo richieder\u00e0. Alcune tra queste risorse possono essere memoria, larghezza di banda o risorse fisiche, ma la pi\u00f9 calcolata e di maggiore interesse \u00e8 il tempo computazionale. Grazie ad un'analsi, siamo in grado di confrontare delle soluzioni tra di loro, scegliendo la pi\u00f9 efficiente tra le due. Modello di implementazione \u00b6 Prima di analizzare un algoritmo, dobbiamo avere un modello della tecnologia che andremo ad usare, includendo le tecnologie a disposizione ed il costo per l'accesso. Durante l'uso del libro, si far\u00e0 uso del modello RAM (Random-Access Machine), dove ogni istruzione \u00e8 eseguita ona dopo l'altra senza operazioni concorrenti. \u00c8 tuttavia necessario non abusare del sistema preso come riferimento: da un punto di vista formale sarebbe necessario definire ogni istruzione del modello ed il rispettivo costo, ma un tipo di analisi simile andrebbe ben oltre il dominio dell'analisi degli algoritmi. Un abuso potrebbe corrispondere a fare uso di un'istruzione in grado di ordinare un array in tempo costante. Un modello simile non risulterebbe realistico dato che i computer non hanno questo genere di istruzione. Possiamo limitarci quindi a dire che il modello RAM contiene istruzioni comunemente trovate nei computer reali (come aritmetica base (addizione, sottrazione, divisione, moltiplicazione, modulo, arrotondamento e troncamento), gestione dei dati (caricamento, salvataggio e copia), controllo (salti condizionati e non, chiamate a sottoprogrammi e return)). I computer reali tuttavia hanno anche loro zone \"grigie\", ad esempio un computer pu\u00f2 calcolare un numero \\(2^k\\) in tempo costante, effettuando un'operazione di shifting verso sinistra. I computer fanno inoltre uso di cache e memoria virtuale; Anche queste tecnologie non vengono incluse. La funzione di costo \u00b6 In genere, il tempo richiesto da un algoritmo per calcolare una risposta dipende dalla grandezza dei parametri in ingresso. \u00c8 quindi pratica comune descrivere il tempo di esecuzione di un programma in funzione della grandezza dei parametri dati in ingresso. La nozione di \"grandezza\" dell'input dipende dal tipo di problema preso in considerazione: per molti problemi, il modo pi\u00f9 naturale di misurare l'input \u00e8 il numero di oggetti dati in inputer, mentre per altri problemi pu\u00f2 essere il numero totale di bit richiesti per rappresentare l'input. Un'altra assunzione importante \u00e8 che ogni istruzione in ogni riga ( \\(n\\) ) di un programma impiega un tempo costante ( \\(c_n\\) ) per essere eseguita. Il tempo di esecuzione di un algoritmo \u00e8 quindi la somma dei tempi di esecuzioni di ogni istruzione eseguita. Analisi del caso medio e peggiore \u00b6 Durante l'analisi di un algoritmo, ci si tende a concentrare sull'analsi del caso peggiore, che fornisce il limite superiore (il massimo tempo che l'algoritmo pu\u00f2 impiegare) per ogni input. Ci viene quindi garantito che l'algoritmo non impiegher\u00e0 mai, pi\u00f9 tempo del limite superiore, senza doverci far compiere stime. Per alcuni algoritmi il caso peggiore si verifica quasi sempre (ad esempio nel caso di una ricerca). Il tempo medio invece \u00e8 spesso pessimo quanto il caso peggiore; Inoltre definire il caso medio \u00e8 cimplicato in quanto ricihede tecniche di analisi probabilistica. Potrebbe inoltre non sempre essere ovvio cosa costituisce un caso medio per un dato problema. Potrebbe essere possibile fare delle assunzioni, come che tutte le possibili grandezze siano equamente probabili, ma spesso questa assunzione \u00e8 violata. Ordine di grandezza \u00b6 Quando si analizza un algoritmo, si tende a considerare ogni istruzione dello stesso tipo come costante, ma spesso questo approccio ci fornisce pi\u00f9 dettagli di quanti veramente richiesti. Un'astrazione di livello ancora pi\u00f9 alto pu\u00f2 essere quella basata sul tasso di crescita o ordine di grandezza : Questo ci permette di considerare solo il termine di grado maggiore in un'equazione (ad esempio solo il termine \\(an^2\\) nell'equazione \\(an^2+bn+c\\) ). Questa considerazione viene dal fatto che per valori molto grandi, i valori di grado inferiore sono spesso insignificanti. Diciamo quindi che un algoritmo ha un caso peggiore di \\(\\theta (n^2)\\) ( theta di n al quadrato). Consideriamo quindi un algoritmo pi\u00f9 efficiente di un altro quando questo ha un ordine di grandezza del caso peggiore inferiore. Design di un algoritmo \u00b6 Dividi et impera \u00b6 Molti algoritmi utili sono recurisvi in natura: per risolvere un problema, chiamano s\u00e9 stessi pi\u00f9 volte in maniera recursiva, in modo da avere a che fare con problemi strettamente correlati. Tipicamente questi algoritmi seguono un approccio dividi et impera (o divide-and-conquer): Dividono un problema in sottoproblemi simili al problema originale ma pi\u00f9 piccoli in grandezza L'approccio dividi et impera \u00e8 composto da 3 fasi: Divide: Divide il problema in un numero di sottoproblemi pi\u00f9 piccoli Conquer: ' Conquista ' il sottoproblema, risolvendolo risorsivamente. Quando la grandezza del sottoproblema diventa abbastanza piccola, risolve banalmente il sottoproblema Combine: Combina le soluzioni di 2 sottoproblemi in una soluzione per il problema originale. Merging with the merge sort L'algoritmo merge sort \u00e8 un algoritmo recursivo che serve per ordinare dei numeri. L'operazione chiave dell'algoritmo \u00e8 l'unione (passo combine) di due sequenze ordinate in una unica. Nel caso del merge sort, effettuiamo l'unione (il merge) chiamando la procedura Merge(A,p,q,r) , dove A \u00e8 l'array di elementi che vogliamo ordinare, e p , q ed r sono indici che puntano all'array e tali che \\(p \\leq q < r\\) . Questi sono i tre step che l'algoritmo compie (per un array con numero pari di elementi, per semplicit\u00e0 di spiegazione): Dividi: L'array \u00e8 diviso a met\u00e0 e la funzione \u00e8 chiamata recursivamente. Al termine della chiamata si avranno 2 met\u00e0 dell'array che corrisponderanno a 2 elementi Conquista: Questo passo ordina i due elementi (quindi si tratta di comparare due numeri e determinare quale sia il pi\u00f9 grande) e ritorna la sequenza ordinata Combina: In quest'ultimo passo, che parte dalla penultima iterazione, l'algoritmo si trova due array da 2 elementi ogniuno ordinato e deve unirli in un solo array. Per farlo inizia comparando i due elementi dei due array, con un indice per array. L'elemento pi\u00f9 piccolo verr\u00e0 quindi messo in un nuovo array ed il puntatore corrispettivo avanzer\u00e0 fino a giungere alla fine dell'array. In questo modo si otterr\u00e0 quindi un array ordinato composto dagli array pi\u00f9 piccoli. Il risultato sar\u00e0 quindi calcolato iterativamente fino a giungere al primo chiamante della funzione di sort, che si trover\u00e0 quindi un array ordinato in tempo \\(\\Theta(n)\\) . (Rivedere; Sono andato praticamente solo a memoria) Analisi di un algoritmo divide-and-conquer \u00b6 Quando un algoritmo contiene una chiamata recursiva a s\u00e9 stesso, possiamo spesso descrivere il suo tempo di eseguzione con un'equazione di ricorrenza. Possiamo quindi usare strumenti matematici per risolvere la ricorrenzae fornire dei limiti alle performances dell'algoritmo. L'analisi di un algoritmo segue i tre step base del divide and conquer: Partiamo definendo come \\(T(n)\\) il costo del problema in funzione di un input di grandezza n. Se la grandezza del problema \u00e8 sufficientemente piccola (ovvero \\(n < c\\) per qualche costante \\(c\\) , si pensi all'ultima iterazione della fase di dividi ), la soluzione richede un tempo costante, che scriviamo come \\(\\Theta(1)\\) . Se invece la soluzione del problema richiede \\(a\\) sottoproblemi, ogniuno di grandezza \\(\\frac{1}{b}\\) rispetto al problema originale, allora il sottoproblema richieder\u00e0 un tempo di \\(T(\\frac{1}{b})\\) per essere risolto. Di conseguenza il tempo per risolvere \\(a\\) sottoproblemi sar\u00e0 \\(a\\cdot T(\\frac{1}{b})\\) . Big O \u00b6 Floor ceiling & modul \u00b6 \\(a mod n = a - n \\lower{a/n}\\) \\(a \\le a mod n < n\\) \\((a mod n) = (b mod n)\\) , then \\(a \\eqiv b (mod n)\\) (a is equibalente to be modulo n). \\(a \\nequiv b\\) if that's not the case \\(ln^* n\\)","title":"Intro"},{"location":"ProAlgo/IntroToAlgorithms/intro/#loop-invariants","text":"Quando abbiamo un ciclo in una algoritmo, possiamo parlare di alcune propriet\u00e0 che il ciclo deve soddisfare per aiutarci capire come mai un algoritmo \u00e8 corretto. Queste propriet\u00e0 sono dette invarianti di ciclo (loop invariants)e ci richiedono di dimostrare tre cose: Inizializzazione: Mostriamo che una certa propriet\u00e0 \u00e8 vera prima di effettuare la prima iterazione del ciclo Manutenzione: Una certa propriet\u00e0 \u00e8 vera prima di un'iterazione e rimane vera prima dell'iterazione successiva Terminazione: La propriet\u00e0 ottenuta alla fine del ciclo, che ci permette di dimostrare che un algoritmo \u00e8 corretto \u00c8 possibile tracciare un parallelismo con l' induzione matematica , dove per provare una certa propriet\u00e0, possiamo provare un caso base ed un passo induttivo.","title":"Loop invariants"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-di-un-algoritmo","text":"Analizzare un algoritmo \u00e8 diventato sinonimo di predirre le risorse che l'algoritmo richieder\u00e0. Alcune tra queste risorse possono essere memoria, larghezza di banda o risorse fisiche, ma la pi\u00f9 calcolata e di maggiore interesse \u00e8 il tempo computazionale. Grazie ad un'analsi, siamo in grado di confrontare delle soluzioni tra di loro, scegliendo la pi\u00f9 efficiente tra le due.","title":"Analisi di un algoritmo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#modello-di-implementazione","text":"Prima di analizzare un algoritmo, dobbiamo avere un modello della tecnologia che andremo ad usare, includendo le tecnologie a disposizione ed il costo per l'accesso. Durante l'uso del libro, si far\u00e0 uso del modello RAM (Random-Access Machine), dove ogni istruzione \u00e8 eseguita ona dopo l'altra senza operazioni concorrenti. \u00c8 tuttavia necessario non abusare del sistema preso come riferimento: da un punto di vista formale sarebbe necessario definire ogni istruzione del modello ed il rispettivo costo, ma un tipo di analisi simile andrebbe ben oltre il dominio dell'analisi degli algoritmi. Un abuso potrebbe corrispondere a fare uso di un'istruzione in grado di ordinare un array in tempo costante. Un modello simile non risulterebbe realistico dato che i computer non hanno questo genere di istruzione. Possiamo limitarci quindi a dire che il modello RAM contiene istruzioni comunemente trovate nei computer reali (come aritmetica base (addizione, sottrazione, divisione, moltiplicazione, modulo, arrotondamento e troncamento), gestione dei dati (caricamento, salvataggio e copia), controllo (salti condizionati e non, chiamate a sottoprogrammi e return)). I computer reali tuttavia hanno anche loro zone \"grigie\", ad esempio un computer pu\u00f2 calcolare un numero \\(2^k\\) in tempo costante, effettuando un'operazione di shifting verso sinistra. I computer fanno inoltre uso di cache e memoria virtuale; Anche queste tecnologie non vengono incluse.","title":"Modello di implementazione"},{"location":"ProAlgo/IntroToAlgorithms/intro/#la-funzione-di-costo","text":"In genere, il tempo richiesto da un algoritmo per calcolare una risposta dipende dalla grandezza dei parametri in ingresso. \u00c8 quindi pratica comune descrivere il tempo di esecuzione di un programma in funzione della grandezza dei parametri dati in ingresso. La nozione di \"grandezza\" dell'input dipende dal tipo di problema preso in considerazione: per molti problemi, il modo pi\u00f9 naturale di misurare l'input \u00e8 il numero di oggetti dati in inputer, mentre per altri problemi pu\u00f2 essere il numero totale di bit richiesti per rappresentare l'input. Un'altra assunzione importante \u00e8 che ogni istruzione in ogni riga ( \\(n\\) ) di un programma impiega un tempo costante ( \\(c_n\\) ) per essere eseguita. Il tempo di esecuzione di un algoritmo \u00e8 quindi la somma dei tempi di esecuzioni di ogni istruzione eseguita.","title":"La funzione di costo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-del-caso-medio-e-peggiore","text":"Durante l'analisi di un algoritmo, ci si tende a concentrare sull'analsi del caso peggiore, che fornisce il limite superiore (il massimo tempo che l'algoritmo pu\u00f2 impiegare) per ogni input. Ci viene quindi garantito che l'algoritmo non impiegher\u00e0 mai, pi\u00f9 tempo del limite superiore, senza doverci far compiere stime. Per alcuni algoritmi il caso peggiore si verifica quasi sempre (ad esempio nel caso di una ricerca). Il tempo medio invece \u00e8 spesso pessimo quanto il caso peggiore; Inoltre definire il caso medio \u00e8 cimplicato in quanto ricihede tecniche di analisi probabilistica. Potrebbe inoltre non sempre essere ovvio cosa costituisce un caso medio per un dato problema. Potrebbe essere possibile fare delle assunzioni, come che tutte le possibili grandezze siano equamente probabili, ma spesso questa assunzione \u00e8 violata.","title":"Analisi del caso medio e peggiore"},{"location":"ProAlgo/IntroToAlgorithms/intro/#ordine-di-grandezza","text":"Quando si analizza un algoritmo, si tende a considerare ogni istruzione dello stesso tipo come costante, ma spesso questo approccio ci fornisce pi\u00f9 dettagli di quanti veramente richiesti. Un'astrazione di livello ancora pi\u00f9 alto pu\u00f2 essere quella basata sul tasso di crescita o ordine di grandezza : Questo ci permette di considerare solo il termine di grado maggiore in un'equazione (ad esempio solo il termine \\(an^2\\) nell'equazione \\(an^2+bn+c\\) ). Questa considerazione viene dal fatto che per valori molto grandi, i valori di grado inferiore sono spesso insignificanti. Diciamo quindi che un algoritmo ha un caso peggiore di \\(\\theta (n^2)\\) ( theta di n al quadrato). Consideriamo quindi un algoritmo pi\u00f9 efficiente di un altro quando questo ha un ordine di grandezza del caso peggiore inferiore.","title":"Ordine di grandezza"},{"location":"ProAlgo/IntroToAlgorithms/intro/#design-di-un-algoritmo","text":"","title":"Design di un algoritmo"},{"location":"ProAlgo/IntroToAlgorithms/intro/#dividi-et-impera","text":"Molti algoritmi utili sono recurisvi in natura: per risolvere un problema, chiamano s\u00e9 stessi pi\u00f9 volte in maniera recursiva, in modo da avere a che fare con problemi strettamente correlati. Tipicamente questi algoritmi seguono un approccio dividi et impera (o divide-and-conquer): Dividono un problema in sottoproblemi simili al problema originale ma pi\u00f9 piccoli in grandezza L'approccio dividi et impera \u00e8 composto da 3 fasi: Divide: Divide il problema in un numero di sottoproblemi pi\u00f9 piccoli Conquer: ' Conquista ' il sottoproblema, risolvendolo risorsivamente. Quando la grandezza del sottoproblema diventa abbastanza piccola, risolve banalmente il sottoproblema Combine: Combina le soluzioni di 2 sottoproblemi in una soluzione per il problema originale. Merging with the merge sort L'algoritmo merge sort \u00e8 un algoritmo recursivo che serve per ordinare dei numeri. L'operazione chiave dell'algoritmo \u00e8 l'unione (passo combine) di due sequenze ordinate in una unica. Nel caso del merge sort, effettuiamo l'unione (il merge) chiamando la procedura Merge(A,p,q,r) , dove A \u00e8 l'array di elementi che vogliamo ordinare, e p , q ed r sono indici che puntano all'array e tali che \\(p \\leq q < r\\) . Questi sono i tre step che l'algoritmo compie (per un array con numero pari di elementi, per semplicit\u00e0 di spiegazione): Dividi: L'array \u00e8 diviso a met\u00e0 e la funzione \u00e8 chiamata recursivamente. Al termine della chiamata si avranno 2 met\u00e0 dell'array che corrisponderanno a 2 elementi Conquista: Questo passo ordina i due elementi (quindi si tratta di comparare due numeri e determinare quale sia il pi\u00f9 grande) e ritorna la sequenza ordinata Combina: In quest'ultimo passo, che parte dalla penultima iterazione, l'algoritmo si trova due array da 2 elementi ogniuno ordinato e deve unirli in un solo array. Per farlo inizia comparando i due elementi dei due array, con un indice per array. L'elemento pi\u00f9 piccolo verr\u00e0 quindi messo in un nuovo array ed il puntatore corrispettivo avanzer\u00e0 fino a giungere alla fine dell'array. In questo modo si otterr\u00e0 quindi un array ordinato composto dagli array pi\u00f9 piccoli. Il risultato sar\u00e0 quindi calcolato iterativamente fino a giungere al primo chiamante della funzione di sort, che si trover\u00e0 quindi un array ordinato in tempo \\(\\Theta(n)\\) . (Rivedere; Sono andato praticamente solo a memoria)","title":"Dividi et impera"},{"location":"ProAlgo/IntroToAlgorithms/intro/#analisi-di-un-algoritmo-divide-and-conquer","text":"Quando un algoritmo contiene una chiamata recursiva a s\u00e9 stesso, possiamo spesso descrivere il suo tempo di eseguzione con un'equazione di ricorrenza. Possiamo quindi usare strumenti matematici per risolvere la ricorrenzae fornire dei limiti alle performances dell'algoritmo. L'analisi di un algoritmo segue i tre step base del divide and conquer: Partiamo definendo come \\(T(n)\\) il costo del problema in funzione di un input di grandezza n. Se la grandezza del problema \u00e8 sufficientemente piccola (ovvero \\(n < c\\) per qualche costante \\(c\\) , si pensi all'ultima iterazione della fase di dividi ), la soluzione richede un tempo costante, che scriviamo come \\(\\Theta(1)\\) . Se invece la soluzione del problema richiede \\(a\\) sottoproblemi, ogniuno di grandezza \\(\\frac{1}{b}\\) rispetto al problema originale, allora il sottoproblema richieder\u00e0 un tempo di \\(T(\\frac{1}{b})\\) per essere risolto. Di conseguenza il tempo per risolvere \\(a\\) sottoproblemi sar\u00e0 \\(a\\cdot T(\\frac{1}{b})\\) .","title":"Analisi di un algoritmo divide-and-conquer"},{"location":"ProAlgo/IntroToAlgorithms/intro/#big-o","text":"","title":"Big O"},{"location":"ProAlgo/IntroToAlgorithms/intro/#floor-ceiling-modul","text":"\\(a mod n = a - n \\lower{a/n}\\) \\(a \\le a mod n < n\\) \\((a mod n) = (b mod n)\\) , then \\(a \\eqiv b (mod n)\\) (a is equibalente to be modulo n). \\(a \\nequiv b\\) if that's not the case \\(ln^* n\\)","title":"Floor ceiling &amp; modul"}]}